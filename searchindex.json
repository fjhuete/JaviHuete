[{
  "section": "Blog",
  "slug": "/blog/seguridad/2025-01-29-vpn-acceso-remoto-openvpn/",
  "title": "Configuración de una VPN de acceso remoto con OpenVPN y certificados x509",
  "description": "",
  "date": "January 29, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "seguridad",
  "tags": "cifrado, VPN, OpenVPN, OpenSSL, Debian, seguridad, redes, Administración de Sistemas, Seguridad y Alta Disponibilidad",
  "content":"En este post se configura una conexión VPN de acceso remoto entre dos equipos. El servidor está conectado a dos redes, una de ellas está formada por el cliente y la otra por otro equipo a al que el cliente debe acceder a través de la VPN. La VPN usa direcciones de la red 10.99.99.0/24. En esta red, el servidor tiene la IP 10.99.99.1. Así, el escenario está compuesto por cuatro máquinas: en una red sólo está el cliente VPN y, la otra red está formada por el servidor VPN y un equipo interno. Entre ambas redes hay un router de Internet. Por tanto, el escenario queda construido de la siguiente manera:\nInstalación de OpenVPN La instalación de OpenVPN se puede hacer a través de la paquetería disponible en los repositorios de varias distribuciones GNU/Linux, en este caso, el paquete openvpn de los repositorios de Debian instala en el equipo tanto el cliente como el servidor VPN. Por tanto, este paquete se isntala tanto en el equipo servidor como en el equipo cliente.\nsudo apt update sudo apt install openvpn Creación de la Autoridad Certificadora (CA) y certificados El primer paso para configurar una VPN usando OpenVPN es generar la estructura de certificados necesaria. Este modelo de certificación requiere del uso de un certificado o clave pública y una clave privada para el servidor y cada uno de los clientes, así como un certificado y clave privada de la Autoridad Certificadora (CA) que, además, debe firmar todos los certificados de los clientes.\nEsta estructura permite una autentificación bidireccional basada en certificados en la que el cliente autentifica el certificado del servidor y el servidor autentifica el certificado de cada cliente para poder establecer una confianza mutua. Para ello tanto el cliente como el servidor verifican que el certificado está firmado por la Autoridad Certificadora.\nPor tanto, para poder establecer esta estructura en este escenario es necesario generar un certificado y clave de la CA, un certificado y clave del servidor y un certificado y clave del cliente.\nOpenVPN cuenta con una herramienta llamada easy-rsa 2 que incluye un conjunto de scripts que facilitan esta tarea de manera que generan tanto la CA como los certificados y claves necesarios de forma automatizada a través de estos scripts. Sin embargo, en este caso, se usa la herramienta OpenSSL para la creación de estos ficheros.\nEl primer paso para generar todos los certificados necesarios para el funcionamiento de la VPN es crear la Autoridad Certificadora. Para ello, en primer lugar, se crea en el servidor VPN la siguiente estructura de directorios a partir de la raíz /etc/openvpn/server/:\nroot@debian:/etc/openvpn/server# mkdir -p CA/{certsdb,certreqs,crl,private} root@debian:/etc/openvpn/server# touch CA/index.txt A continuación se toma como referencia el fichero de ejemplo /etc/ssl/openssl.cnf para configurar la CA.\nroot@debian:/etc/openvpn/server# cp /etc/ssl/openssl.cnf ./CA En este fichero se modifican los siguientes parámetros:\n... [ CA_default ] dir = . # Where everything is kept certs = $dir/certsdb # Where the issued certs are kept ... new_certs_dir = $certs # default place for new certs. ... req_extensions = v3_req # The extensions to add to a certificate request [ req_distinguished_name ] countryName = Country Name (2 letter code) countryName_default = ES countryName_min = 2 countryName_max = 2 stateOrProvinceName = State or Province Name (full name) stateOrProvinceName_default = Andalucia localityName = Locality Name (eg, city) localityName_default = Dos Hermanas 0.organizationName = Organization Name (eg, company) 0.organizationName_default = IESGN ... [ req_attributes ] #challengePassword = A challenge password #challengePassword_min = 4 #challengePassword_max = 20 ... #unstructuredName = An optional company name ... Tras haber configurado la CA se puede generar su par de claves.\nroot@debian:/etc/openvpn/server/CA# openssl req -new -newkey rsa:2048 -keyout private/cakey.pem -out careq.pem -config openssl.cnf .......+.......+..+...+.+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*.+.+.....+.............+..+.......+..+...+...+...+.+...+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*.+...........+......+............+...............................+...........+...+...+............+......+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ ....+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*.+.......+...+.....+.+......+......+...+..+...+....+..+....+.....+...............+.+.....+......+...+......+......+.......+.....+...+.......+.....+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*....+..+..........+...+...+...+..+.........+......+.........+...+.+.........+.....+..........+...+..............+.+............+...+..+......+......+....+.....+....+..+.+...+...........+......+............+.+.....+..........+......+.....+...+.......+.....+.........+.+.........+.....+.......+..+.+......+........+...............+...+.........+.+..+.+.....+.+...........+...+.+...........+.........+.............+...+..+...+....+.........+............+........+.+...+.....+............+.........+.+...+........+..........+.....+...+....+......+.........+..+.........+....+..................+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ Enter PEM pass phrase: Verifying - Enter PEM pass phrase: ----- You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Country Name (2 letter code) [ES]: State or Province Name (full name) [Andalucia]: Locality Name (eg, city) [Dos Hermanas]: Organization Name (eg, company) [IESGN]: Organizational Unit Name (eg, section) []: Common Name (e.g. server FQDN or YOUR name) []:VPNCA Email Address []:admin@vpn.org A continuación, hay que autofirmar el certificado de la CA.\nroot@debian:/etc/openvpn/server/CA# openssl ca -create_serial -out cacert.pem -days 365 -keyfile private/cakey.pem -selfsign -extensions v3_ca -config openssl.cnf -infiles careq.pem Using configuration from openssl.cnf Enter pass phrase for private/cakey.pem: Check that the request matches the signature Signature ok Certificate Details: Serial Number: 72:4f:85:46:41:25:c7:3f:62:45:a1:80:95:ec:3d:70:42:de:56:ce Validity Not Before: Jan 11 15:37:59 2025 GMT Not After : Jan 11 15:37:59 2026 GMT Subject: countryName = ES stateOrProvinceName = Andalucia organizationName = IESGN commonName = VPNCA emailAddress = admin@vpn.org X509v3 extensions: X509v3 Subject Key Identifier: 48:E8:19:11:32:DF:50:CA:72:6E:20:AF:3E:17:51:C4:02:F5:2F:6D X509v3 Authority Key Identifier: 48:E8:19:11:32:DF:50:CA:72:6E:20:AF:3E:17:51:C4:02:F5:2F:6D X509v3 Basic Constraints: critical CA:TRUE Certificate is to be certified until Jan 11 15:37:59 2026 GMT (365 days) Sign the certificate? [y/n]:y 1 out of 1 certificate requests certified, commit? [y/n]y Write out database with 1 new entries Database updated Además, el servidor debe contar también con su propio certificado firmado por la CA, así que en el directorio /etc/openvp/server se genera una solicitud de certificado.\nroot@debian:/etc/openvpn/server# openssl req -newkey rsa:4096 -keyout servidor.key -out servidor.csr ...+....+.....+.+.....+.+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*..........+.........+...+...+...+....+.....+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*..........+......+...+....+............+...+......+..+...+...............+......+....+............+...+...........+.+.....+...+....+......+.....+......+.....................+....+...+.....+......+....+..+..........+.....+.+........+.+........+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ ..................................+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*......+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*.+..........+..............+....+..............+...............+.+.....+...............+.+........+......+....+...+............+...+.....+...+.........+.+...............+......+...+........+...+....+..+.+.................+......+......+.+..+..................+.........+....+.........+..+...+......+....+...+.........+...+......+......+........+.......+......+..............................+..+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ Enter PEM pass phrase: Verifying - Enter PEM pass phrase: ----- You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Country Name (2 letter code) [AU]:ES State or Province Name (full name) [Some-State]:Andalucia Locality Name (eg, city) []:Dos Hermanas Organization Name (eg, company) [Internet Widgits Pty Ltd]:IESGN Organizational Unit Name (eg, section) []: Common Name (e.g. server FQDN or YOUR name) []:VPNServer Email Address []:admin@vpnserver.org Please enter the following \u0026#39;extra\u0026#39; attributes to be sent with your certificate request A challenge password []: An optional company name []: Esta solicitud se le pasa a la CA.\nroot@debian:/etc/openvpn/server# cp servidor.csr CA/certreqs/ Y la CA firma el certificado.\nroot@debian:/etc/openvpn/server/CA# openssl ca -config openssl.cnf -out certsdb/servidor.crt -infiles certreqs/servidor.csr Using configuration from openssl.cnf Enter pass phrase for ./private/cakey.pem: Check that the request matches the signature Signature ok Certificate Details: Serial Number: 72:4f:85:46:41:25:c7:3f:62:45:a1:80:95:ec:3d:70:42:de:56:cf Validity Not Before: Jan 11 15:43:33 2025 GMT Not After : Jan 11 15:43:33 2026 GMT Subject: countryName = ES stateOrProvinceName = Andalucia organizationName = IESGN commonName = VPNServer emailAddress = admin@vpnserver.org X509v3 extensions: X509v3 Basic Constraints: CA:FALSE X509v3 Subject Key Identifier: 25:1B:D2:22:7F:DA:08:8E:06:6E:B1:0E:1C:AC:0A:01:A9:D3:09:3B X509v3 Authority Key Identifier: 48:E8:19:11:32:DF:50:CA:72:6E:20:AF:3E:17:51:C4:02:F5:2F:6D Certificate is to be certified until Jan 11 15:43:33 2026 GMT (365 days) Sign the certificate? [y/n]:y 1 out of 1 certificate requests certified, commit? [y/n]y Write out database with 1 new entries Database updated Para completar la estructura de certificados que permite la validación del servidor y el cliente que intervienen en esta VPN, falta por generar el certificado del cliente, esta vez, desde el directorio /etc/openvpn/client en el equipo cliente.\nroot@debian:/etc/openvpn/client# openssl req -newkey rsa:4096 -keyout cliente.key -out cliente.csr ..+.+..+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*..+..+.......+.....+.+.....+....+...+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*.+.........................+......+...+.....+.........+..................+.......+..+..................+.+.........+........+...+....+........+....+...+..+..........+.....+.+...+......+...+...+.....+.......+..+.........+....+......+......+........+...+..................+....+.......................+...+.+...+...............+...+.....+.............+..+.........+.............+......+.....+.......................................+...+.......+..+.+............+.....+..........+..+.............+...+..+...+...................+.....+.+..............+.........+....+..+....+..+...+...................+..+...+................+..+..........+...+...........+....+......+........+............+.+.....+.......+.....+.+......+..............+...............+.+.....+....+...........+.+........+.+....................+..................+..........+........+.......+.................................+..+...............+...+...+......+....+..+..........+........................+........+.+..+..........+...+...........+....+.....+.+..............+.+..............+......+.+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ .+......................+...+........+....+...........+.+...............+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*.....+.+.....+...+....+...+.....+....+.........+.........+...+...+.........+......+..+...+....+.....+......+.+.....+....+......+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*...+...................+..+...+.......+......+..................+..............+......+....+......+.........+...........+.+.........+.........+.....................+.....+....+...+..+.+..+.......+..+.........+.........+.......+........+.............+..............+...+......+.......+.....+.........+......+...................+...+......+.........+..+....+......+.....+......+...+....+..+..........+...+..+....+...........+.+..+...+.......+.....+.......+...............+.....+...............+.+..+......+............+....+.....+....+.........+......+......+.....+....+..+...+...................+..+....+.....+.+.......................+......+.+...+.................+.+..+.+..+..................+.........+...+.........+.+........+..........+.................+.......+...+............+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ Enter PEM pass phrase: Verifying - Enter PEM pass phrase: ----- You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Country Name (2 letter code) [AU]:ES State or Province Name (full name) [Some-State]:Andalucia Locality Name (eg, city) []:Dos Hermanas Organization Name (eg, company) [Internet Widgits Pty Ltd]:IESGN Organizational Unit Name (eg, section) []: Common Name (e.g. server FQDN or YOUR name) []:VPNClient Email Address []:cliente@vpnserver.org Please enter the following \u0026#39;extra\u0026#39; attributes to be sent with your certificate request A challenge password []: An optional company name []: Esta solicitud se envía a la CA.\nroot@debian:/etc/openvpn/client# scp cliente.csr debian@192.168.122.243:/home/debian cliente.csr 100% 1736 438.2KB/s 00:00 Y la firma.\nroot@debian:/etc/openvpn/server/CA# openssl ca -config openssl.cnf -out certsdb/cliente.crt -infiles certreqs/cliente.csr Using configuration from openssl.cnf Enter pass phrase for ./private/cakey.pem: Check that the request matches the signature Signature ok Certificate Details: Serial Number: 72:4f:85:46:41:25:c7:3f:62:45:a1:80:95:ec:3d:70:42:de:56:d0 Validity Not Before: Jan 11 15:53:13 2025 GMT Not After : Jan 11 15:53:13 2026 GMT Subject: countryName = ES stateOrProvinceName = Andalucia organizationName = IESGN commonName = VPNClient emailAddress = cliente@vpnserver.org X509v3 extensions: X509v3 Basic Constraints: CA:FALSE X509v3 Subject Key Identifier: 4F:02:55:C5:7C:D2:69:C0:F5:77:5C:72:CC:EE:55:87:E3:7E:69:9B X509v3 Authority Key Identifier: 48:E8:19:11:32:DF:50:CA:72:6E:20:AF:3E:17:51:C4:02:F5:2F:6D Certificate is to be certified until Jan 11 15:53:13 2026 GMT (365 days) Sign the certificate? [y/n]:y 1 out of 1 certificate requests certified, commit? [y/n]y Write out database with 1 new entries Database updated Por último, la CA devuelve el certificado del cliente firmado junto a su propio certificado autofirmado al cliente para que también pueda verificar la identidad del servidor VPN en las conexiones.\nroot@debian:/etc/openvpn/server/CA# scp certsdb/cliente.crt debian@192.168.122.147:/home/debian cliente.crt 100% 5922 536.4KB/s 00:00 root@debian:/etc/openvpn/server/CA# scp cacert.pem debian@192.168.122.147:/home/debian cacert.pem 100% 4439 601.8KB/s 00:00 En el cliente, estos certificados también se almacena en el directorio /etc/openvpn/client.\nEl último elemento pendiente de generar en esta estructra de certificados es el fichero de parámetros Diffie-Hellman. Las claves de intercambio Diffie-Hellman son un método matemático que permite generar una clave criptográfica simétrica de manera segura. Este método de intercambio de claves simétricas permite que dos partes que no han tenido comunicación previa establezcan una clave compartida de forma segura sobre un canal inseguro. Este fichero también se puede generar de forma sencilla usando las herramientas que incorpora OpenVPN o, con un breve comando usando la opción dhparam de la herramienta openssl. La ejecución de este comando puede alargarse de varios minutos a varias horas según el nivel de seguridad que se indique y la capacidad de cómputo del equipo. En este caso, se opta por generar un fichero de 4096 bits que, en la MV de GNS3 con la que se está trabajando necesita más de media hora para generar el fichero.\nroot@debian:/etc/openvpn/server# openssl dhparam -out dhparams.pem 4096 Generating DH parameters, 4096 bit long safe prime ........................................................+.................................................................................................................................................................................................................................................................................................+......................................................................................................................................................................................................................................................................................................................+.........................................+..............................................................................................................................................................................................................................................................................+..........+.......................................................... ... .......+.................................................................................................+.....................................................................................................................................................................................+...............................................................................................++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++*++* Así, un esquema de la estructura de certificados elaborada se puede representar en la siguiente tabla:\nFichero Ubicación cacert.pem servidor y cliente cakey.pem servidor (CA) dhparams.pem servidor servidor.crt servidor servidor.key servidor cliente.crt cliente cliente.key cliente Configuración del servidor VPN La instalación del paquete openvpn genera un directorio en el sistema en el que se almacenan varios ficheros de configuración de ejemplo tanto para configurar el servidor como el cliente VPN. A partir de estos ficheros de ejemplo se pueden configurar de forma más sencilla ambas partes de la VPN.\nAsí que, para empezar con la configuración del servidor VPN se puede copiar este fichero de ejemplo al directorio /etc/openvpn/server.\nroot@debian:/etc/openvpn/server# cp /usr/share/doc/openvpn/examples/sample-config-files/server.conf . Por defecto, este fichero configura el servidor para escuchar en el puerto 1194, usar el protocolo UDP, crear una interfaz tun que crea un túnel IP para enrutar el tráfico de la VPN. En el apartado de certificados SSL hay que indicar la ruta a los certificados necesarios par el funcionamiento del servidor: el certificado de la CA, el del servidor y la clave privada del servidor, así como el fichero de parámetros Diffie-Hellman.\nca cacert.pem cert servidor.crt key servidor.key # This file should be kept secret # Diffie hellman parameters. # Generate your own with: # openssl dhparam -out dh2048.pem 2048 dh dhparams.pem Después hay que configurar los parámetros relacionados con la red como el tipo de topología, en este caso subnet para que permita el direccionamiento IP y el direccionamiento de la red de la VPN, en este caso, se configura la 10.99.99.0/24.\n# Network topology # Should be subnet (addressing via IP) # unless Windows clients v2.0.9 and lower have to # be supported (then net30, i.e. a /30 per client) # Defaults to net30 (not recommended) topology subnet # Configure server mode and supply a VPN subnet # for OpenVPN to draw client addresses from. # The server will take 10.8.0.1 for itself, # the rest will be made available to clients. # Each client will be able to reach the server # on 10.8.0.1. Comment this line out if you are # ethernet bridging. See the man page for more info. server 10.99.99.0 255.255.255.0 En el resto de parámetros como el tipo de compresión, el tipo de cifrado, el tiempo de \u0026ldquo;keepalive\u0026rdquo;, etc. se mantienen los valores por defecto.\nTambién por defecto, la configuración de OpenVPN incluye un parámetro extra de seguridad cuyo uso es opcional. Para deshabilitarlo, es necesario comentar la siguiente línea del fichero de configuración:\n# For extra security beyond that provided # by SSL/TLS, create an \u0026#34;HMAC firewall\u0026#34; # to help block DoS attacks and UDP port flooding. # # Generate with: # openvpn --genkey tls-auth ta.key # # The server and each client must have # a copy of this key. # The second parameter should be \u0026#39;0\u0026#39; # on the server and \u0026#39;1\u0026#39; on the clients. ;tls-auth ta.key 0 # This file is secret Además, para que systemd pueda usar la frase de paso de la clave privada del servidor hay que indicarla en un fichero al que también se hace referencia en la configuración del servidor VPN.\necho \u0026#34;contraseña\u0026#34; \u0026gt; auth.txt Así, en el fichero de configuración del servidor VPN quedan recogido los siguientes parámetros y valores:\ndebian@debian:~$ cat /etc/openvpn/server/server.conf ################################################# # Sample OpenVPN 2.0 config file for # # multi-client server. # # # # This file is for the server side # # of a many-clients \u0026lt;-\u0026gt; one-server # # OpenVPN configuration. # # # # OpenVPN also supports # # single-machine \u0026lt;-\u0026gt; single-machine # # configurations (See the Examples page # # on the web site for more info). # # # # This config should work on Windows # # or Linux/BSD systems. Remember on # # Windows to quote pathnames and use # # double backslashes, e.g.: # # \u0026#34;C:\\\\Program Files\\\\OpenVPN\\\\config\\\\foo.key\u0026#34; # # # # Comments are preceded with \u0026#39;#\u0026#39; or \u0026#39;;\u0026#39; # ################################################# # Which local IP address should OpenVPN # listen on? (optional) ;local a.b.c.d # Which TCP/UDP port should OpenVPN listen on? # If you want to run multiple OpenVPN instances # on the same machine, use a different port # number for each one. You will need to # open up this port on your firewall. port 1194 # TCP or UDP server? ;proto tcp proto udp # \u0026#34;dev tun\u0026#34; will create a routed IP tunnel, # \u0026#34;dev tap\u0026#34; will create an ethernet tunnel. # Use \u0026#34;dev tap0\u0026#34; if you are ethernet bridging # and have precreated a tap0 virtual interface # and bridged it with your ethernet interface. # If you want to control access policies # over the VPN, you must create firewall # rules for the the TUN/TAP interface. # On non-Windows systems, you can give # an explicit unit number, such as tun0. # On Windows, use \u0026#34;dev-node\u0026#34; for this. # On most systems, the VPN will not function # unless you partially or fully disable # the firewall for the TUN/TAP interface. ;dev tap dev tun # Windows needs the TAP-Win32 adapter name # from the Network Connections panel if you # have more than one. On XP SP2 or higher, # you may need to selectively disable the # Windows firewall for the TAP adapter. # Non-Windows systems usually don\u0026#39;t need this. ;dev-node MyTap # SSL/TLS root certificate (ca), certificate # (cert), and private key (key). Each client # and the server must have their own cert and # key file. The server and all clients will # use the same ca file. # # See the \u0026#34;easy-rsa\u0026#34; directory for a series # of scripts for generating RSA certificates # and private keys. Remember to use # a unique Common Name for the server # and each of the client certificates. # # Any X509 key management system can be used. # OpenVPN can also use a PKCS #12 formatted key file # (see \u0026#34;pkcs12\u0026#34; directive in man page). ca cacert.pem cert servidor.crt key servidor.key # This file should be kept secret # Diffie hellman parameters. # Generate your own with: # openssl dhparam -out dh2048.pem 2048 dh dhparams.pem # Network topology # Should be subnet (addressing via IP) # unless Windows clients v2.0.9 and lower have to # be supported (then net30, i.e. a /30 per client) # Defaults to net30 (not recommended) topology subnet # Configure server mode and supply a VPN subnet # for OpenVPN to draw client addresses from. # The server will take 10.8.0.1 for itself, # the rest will be made available to clients. # Each client will be able to reach the server # on 10.8.0.1. Comment this line out if you are # ethernet bridging. See the man page for more info. server 10.99.99.0 255.255.255.0 # Maintain a record of client \u0026lt;-\u0026gt; virtual IP address # associations in this file. If OpenVPN goes down or # is restarted, reconnecting clients can be assigned # the same virtual IP address from the pool that was # previously assigned. ifconfig-pool-persist /var/log/openvpn/ipp.txt # Configure server mode for ethernet bridging. # You must first use your OS\u0026#39;s bridging capability # to bridge the TAP interface with the ethernet # NIC interface. Then you must manually set the # IP/netmask on the bridge interface, here we # assume 10.8.0.4/255.255.255.0. Finally we # must set aside an IP range in this subnet # (start=10.8.0.50 end=10.8.0.100) to allocate # to connecting clients. Leave this line commented # out unless you are ethernet bridging. ;server-bridge 10.8.0.4 255.255.255.0 10.8.0.50 10.8.0.100 # Configure server mode for ethernet bridging # using a DHCP-proxy, where clients talk # to the OpenVPN server-side DHCP server # to receive their IP address allocation # and DNS server addresses. You must first use # your OS\u0026#39;s bridging capability to bridge the TAP # interface with the ethernet NIC interface. # Note: this mode only works on clients (such as # Windows), where the client-side TAP adapter is # bound to a DHCP client. ;server-bridge # Push routes to the client to allow it # to reach other private subnets behind # the server. Remember that these # private subnets will also need # to know to route the OpenVPN client # address pool (10.8.0.0/255.255.255.0) # back to the OpenVPN server. push \u0026#34;route 10.0.0.0 255.255.255.0\u0026#34; ;push \u0026#34;route 192.168.20.0 255.255.255.0\u0026#34; # To assign specific IP addresses to specific # clients or if a connecting client has a private # subnet behind it that should also have VPN access, # use the subdirectory \u0026#34;ccd\u0026#34; for client-specific # configuration files (see man page for more info). # EXAMPLE: Suppose the client # having the certificate common name \u0026#34;Thelonious\u0026#34; # also has a small subnet behind his connecting # machine, such as 192.168.40.128/255.255.255.248. # First, uncomment out these lines: ;client-config-dir ccd ;route 192.168.40.128 255.255.255.248 # Then create a file ccd/Thelonious with this line: # iroute 192.168.40.128 255.255.255.248 # This will allow Thelonious\u0026#39; private subnet to # access the VPN. This example will only work # if you are routing, not bridging, i.e. you are # using \u0026#34;dev tun\u0026#34; and \u0026#34;server\u0026#34; directives. # EXAMPLE: Suppose you want to give # Thelonious a fixed VPN IP address of 10.9.0.1. # First uncomment out these lines: ;client-config-dir ccd ;route 10.9.0.0 255.255.255.252 # Then add this line to ccd/Thelonious: # ifconfig-push 10.9.0.1 10.9.0.2 # Suppose that you want to enable different # firewall access policies for different groups # of clients. There are two methods: # (1) Run multiple OpenVPN daemons, one for each # group, and firewall the TUN/TAP interface # for each group/daemon appropriately. # (2) (Advanced) Create a script to dynamically # modify the firewall in response to access # from different clients. See man # page for more info on learn-address script. ;learn-address ./script # If enabled, this directive will configure # all clients to redirect their default # network gateway through the VPN, causing # all IP traffic such as web browsing and # and DNS lookups to go through the VPN # (The OpenVPN server machine may need to NAT # or bridge the TUN/TAP interface to the internet # in order for this to work properly). ;push \u0026#34;redirect-gateway def1 bypass-dhcp\u0026#34; # Certain Windows-specific network settings # can be pushed to clients, such as DNS # or WINS server addresses. CAVEAT: # http://openvpn.net/faq.html#dhcpcaveats # The addresses below refer to the public # DNS servers provided by opendns.com. ;push \u0026#34;dhcp-option DNS 208.67.222.222\u0026#34; ;push \u0026#34;dhcp-option DNS 208.67.220.220\u0026#34; # Uncomment this directive to allow different # clients to be able to \u0026#34;see\u0026#34; each other. # By default, clients will only see the server. # To force clients to only see the server, you # will also need to appropriately firewall the # server\u0026#39;s TUN/TAP interface. ;client-to-client # Uncomment this directive if multiple clients # might connect with the same certificate/key # files or common names. This is recommended # only for testing purposes. For production use, # each client should have its own certificate/key # pair. # # IF YOU HAVE NOT GENERATED INDIVIDUAL # CERTIFICATE/KEY PAIRS FOR EACH CLIENT, # EACH HAVING ITS OWN UNIQUE \u0026#34;COMMON NAME\u0026#34;, # UNCOMMENT THIS LINE OUT. ;duplicate-cn # The keepalive directive causes ping-like # messages to be sent back and forth over # the link so that each side knows when # the other side has gone down. # Ping every 10 seconds, assume that remote # peer is down if no ping received during # a 120 second time period. keepalive 10 120 # For extra security beyond that provided # by SSL/TLS, create an \u0026#34;HMAC firewall\u0026#34; # to help block DoS attacks and UDP port flooding. # # Generate with: # openvpn --genkey tls-auth ta.key # # The server and each client must have # a copy of this key. # The second parameter should be \u0026#39;0\u0026#39; # on the server and \u0026#39;1\u0026#39; on the clients. ;tls-auth ta.key 0 # This file is secret # Select a cryptographic cipher. # This config item must be copied to # the client config file as well. # Note that v2.4 client/server will automatically # negotiate AES-256-GCM in TLS mode. # See also the ncp-cipher option in the manpage cipher AES-256-CBC # Enable compression on the VPN link and push the # option to the client (v2.4+ only, for earlier # versions see below) ;compress lz4-v2 ;push \u0026#34;compress lz4-v2\u0026#34; # For compression compatible with older clients use comp-lzo # If you enable it here, you must also # enable it in the client config file. ;comp-lzo # The maximum number of concurrently connected # clients we want to allow. ;max-clients 100 # It\u0026#39;s a good idea to reduce the OpenVPN # daemon\u0026#39;s privileges after initialization. # # You can uncomment this on non-Windows # systems after creating a dedicated user. ;user openvpn ;group openvpn # The persist options will try to avoid # accessing certain resources on restart # that may no longer be accessible because # of the privilege downgrade. persist-key persist-tun # Output a short status file showing # current connections, truncated # and rewritten every minute. status /var/log/openvpn/openvpn-status.log # By default, log messages will go to the syslog (or # on Windows, if running as a service, they will go to # the \u0026#34;\\Program Files\\OpenVPN\\log\u0026#34; directory). # Use log or log-append to override this default. # \u0026#34;log\u0026#34; will truncate the log file on OpenVPN startup, # while \u0026#34;log-append\u0026#34; will append to it. Use one # or the other (but not both). ;log /var/log/openvpn/openvpn.log ;log-append /var/log/openvpn/openvpn.log # Set the appropriate level of log # file verbosity. # # 0 is silent, except for fatal errors # 4 is reasonable for general usage # 5 and 6 can help to debug connection problems # 9 is extremely verbose verb 3 # Silence repeating messages. At most 20 # sequential messages of the same message # category will be output to the log. ;mute 20 # Notify the client that when the server restarts so it # can automatically reconnect. explicit-exit-notify 1 #Fichero de constraseña de la clave askpass auth.txt El servidor VPN se puede arrancar usando systemd pero el paquete openvpn incluye una herramienta de depuración que se recomienda usar en los primeros inicios del servidor. Cuando la salida del comando muestra la siguiente información la configuración del servidor es correcta:\nroot@debian:/etc/openvpn/server# openvpn server.conf 2025-01-11 18:02:30 DEPRECATED OPTION: --cipher set to \u0026#39;AES-256-CBC\u0026#39; but missing in --data-ciphers (AES-256-GCM:AES-128-GCM:CHACHA20-POLY1305). OpenVPN ignores --cipher for cipher negotiations. 2025-01-11 18:02:30 Note: Kernel support for ovpn-dco missing, disabling data channel offload. 2025-01-11 18:02:30 OpenVPN 2.6.3 x86_64-pc-linux-gnu [SSL (OpenSSL)] [LZO] [LZ4] [EPOLL] [PKCS11] [MH/PKTINFO] [AEAD] [DCO] 2025-01-11 18:02:30 library versions: OpenSSL 3.0.13 30 Jan 2024, LZO 2.10 2025-01-11 18:02:30 DCO version: N/A 2025-01-11 18:02:30 net_route_v4_best_gw query: dst 0.0.0.0 2025-01-11 18:02:30 net_route_v4_best_gw result: via 192.168.122.1 dev ens5 2025-01-11 18:02:30 Diffie-Hellman initialized with 4096 bit key Enter Private Key Password: ******* 2025-01-11 18:02:32 WARNING: this configuration may cache passwords in memory -- use the auth-nocache option to prevent this [ 180.660097] tun: Universal TUN/TAP device driver, 1.6 2025-01-11 18:02:32 TUN/TAP device tun0 opened 2025-01-11 18:02:32 net_iface_mtu_set: mtu 1500 for tun0 2025-01-11 18:02:32 net_iface_up: set tun0 up 2025-01-11 18:02:32 net_addr_v4_add: 10.99.99.1/24 dev tun0 2025-01-11 18:02:32 Could not determine IPv4/IPv6 protocol. Using AF_INET 2025-01-11 18:02:32 Socket Buffers: R=[212992-\u0026gt;212992] S=[212992-\u0026gt;212992] 2025-01-11 18:02:32 UDPv4 link local (bound): [AF_INET][undef]:1194 2025-01-11 18:02:32 UDPv4 link remote: [AF_UNSPEC] 2025-01-11 18:02:32 MULTI: multi_init called, r=256 v=256 2025-01-11 18:02:32 IFCONFIG POOL IPv4: base=10.99.99.2 size=253 2025-01-11 18:02:32 IFCONFIG POOL LIST 2025-01-11 18:02:32 Initialization Sequence Completed Una vez que se ha verificado el correcto funcionamiento del servidor VPN se puede usar systemd para arrancarlo.\nsystemctl start openvpn-server@server Al arrancar la VPN se crea una nueva interfaz de red virtual (tun0) con la IP 10.99.99.1.\nroot@debian:/etc/openvpn/server# ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host noprefixroute valid_lft forever preferred_lft forever 2: ens4: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 0c:bc:63:18:00:00 brd ff:ff:ff:ff:ff:ff altname enp0s4 inet 10.0.0.1/24 brd 10.0.0.255 scope global ens4 valid_lft forever preferred_lft forever inet6 fe80::ebc:63ff:fe18:0/64 scope link valid_lft forever preferred_lft forever 3: ens5: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 0c:bc:63:18:00:01 brd ff:ff:ff:ff:ff:ff altname enp0s5 inet 100.0.0.2/24 brd 100.0.0.255 scope global ens5 valid_lft forever preferred_lft forever inet6 fe80::ebc:63ff:fe18:1/64 scope link valid_lft forever preferred_lft forever 4: tun0: \u0026lt;POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP\u0026gt; mtu 1500 qdisc fq_codel state UNKNOWN group default qlen 500 link/none inet 10.99.99.1/24 scope global tun0 valid_lft forever preferred_lft forever inet6 fe80::1516:5e8c:5b38:b02/64 scope link stable-privacy valid_lft forever preferred_lft forever Además, también se crea una ruta en la tabla de enrutamiento.\nroot@debian:/etc/openvpn/server# ip r default via 100.0.0.1 dev ens5 onlink 10.0.0.0/24 dev ens4 proto kernel scope link src 10.0.0.1 10.99.99.0/24 dev tun0 proto kernel scope link src 10.99.99.1 100.0.0.0/24 dev ens5 proto kernel scope link src 100.0.0.2 Configuración del cliente VPN Para configurar el cliente también se puede partir del fichero de configuración de ejemplo proporcionado por OpenVPN.\nroot@debian:/etc/openvpn/client# cp /usr/share/doc/openvpn/examples/sample-config-files/client.conf . Este fichero también crea por defecto una interfaz de tipo tun y configura el uso del protocolo udp para la VPN. Entre los parámetros que se deben modificar están la dirección IP y puerto de escucha del servidor y la ruta relativa a los cetificados de la CA, del cliente y a la clave del cliente\n# The hostname/IP and port of the server. # You can have multiple remote entries # to load balance between the servers. remote 10.99.99.1 1194 ... # SSL/TLS parms. # See the server config file for more # description. It\u0026#39;s best to use # a separate .crt/.key file pair # for each client. A single ca # file can be used for all clients. ca cacert.pem cert cliente.crt key cliente.key Finalmente, el contenido íntegro del fichero de configuración del cliente VPN es el siguiente:\ndebian@debian:~$ cat /etc/openvpn/client/client.conf ############################################## # Sample client-side OpenVPN 2.0 config file # # for connecting to multi-client server. # # # # This configuration can be used by multiple # # clients, however each client should have # # its own cert and key files. # # # # On Windows, you might want to rename this # # file so it has a .ovpn extension # ############################################## # Specify that we are a client and that we # will be pulling certain config file directives # from the server. client # Use the same setting as you are using on # the server. # On most systems, the VPN will not function # unless you partially or fully disable # the firewall for the TUN/TAP interface. ;dev tap dev tun # Windows needs the TAP-Win32 adapter name # from the Network Connections panel # if you have more than one. On XP SP2, # you may need to disable the firewall # for the TAP adapter. ;dev-node MyTap # Are we connecting to a TCP or # UDP server? Use the same setting as # on the server. ;proto tcp proto udp # The hostname/IP and port of the server. # You can have multiple remote entries # to load balance between the servers. remote 100.0.0.2 1194 ;remote my-server-2 1194 # Choose a random host from the remote # list for load-balancing. Otherwise # try hosts in the order specified. ;remote-random # Keep trying indefinitely to resolve the # host name of the OpenVPN server. Very useful # on machines which are not permanently connected # to the internet such as laptops. resolv-retry infinite # Most clients don\u0026#39;t need to bind to # a specific local port number. nobind # Downgrade privileges after initialization (non-Windows only) ;user openvpn ;group openvpn # Try to preserve some state across restarts. persist-key persist-tun # If you are connecting through an # HTTP proxy to reach the actual OpenVPN # server, put the proxy server/IP and # port number here. See the man page # if your proxy server requires # authentication. ;http-proxy-retry # retry on connection failures ;http-proxy [proxy server] [proxy port #] # Wireless networks often produce a lot # of duplicate packets. Set this flag # to silence duplicate packet warnings. ;mute-replay-warnings # SSL/TLS parms. # See the server config file for more # description. It\u0026#39;s best to use # a separate .crt/.key file pair # for each client. A single ca # file can be used for all clients. ca cacert.pem cert cliente.crt key cliente.key # Verify server certificate by checking that the # certificate has the correct key usage set. # This is an important precaution to protect against # a potential attack discussed here: # http://openvpn.net/howto.html#mitm # # To use this feature, you will need to generate # your server certificates with the keyUsage set to # digitalSignature, keyEncipherment # and the extendedKeyUsage to # serverAuth # EasyRSA can do this for you. #remote-cert-tls server # If a tls-auth key is used on the server # then every client must also have the key. #tls-auth ta.key 1 # Select a cryptographic cipher. # If the cipher option is used on the server # then you must also specify it here. # Note that v2.4 client/server will automatically # negotiate AES-256-GCM in TLS mode. # See also the data-ciphers option in the manpage cipher AES-256-CBC # Enable compression on the VPN link. # Don\u0026#39;t enable this unless it is also # enabled in the server config file. #comp-lzo # Set log file verbosity. verb 3 # Silence repeating messages ;mute 20 #Fichero de contraseña de la clave privada askpass auth.txt Como ocurre en el caso del servidor, en el cliente también se puede usar la utilidad openvpn para verificar la sintaxis del fichero de configuración y probar la ejecución de la VPN. Después, se puede arrancar usando systemd.\nsudo systemctl start openvpn-client@client Al arrancar el cliente de VPN, se crea una nueva interfaz de red de tipo tun (tun0) con la IP 10.99.99.2.\nroot@debian:/etc/openvpn/client# ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host noprefixroute valid_lft forever preferred_lft forever 2: ens4: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 0c:1e:38:43:00:00 brd ff:ff:ff:ff:ff:ff altname enp0s4 inet 200.0.0.2/24 brd 200.0.0.255 scope global ens4 valid_lft forever preferred_lft forever inet6 fe80::e1e:38ff:fe43:0/64 scope link valid_lft forever preferred_lft forever 3: tun0: \u0026lt;POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP\u0026gt; mtu 1500 qdisc fq_codel state UNKNOWN group default qlen 500 link/none inet 10.99.99.2/24 scope global tun0 valid_lft forever preferred_lft forever inet6 fe80::dc6d:524c:186d:ced1/64 scope link stable-privacy valid_lft forever preferred_lft forever También aparecen dos nuevas rutas en la tabla de enrutamiento: la ruta hacia la red 10.99.99.0/24, como también se incluye en la tabla de enrutamiento del servidor pero, además, en el cliente se añade la ruta hacia la red 10.0.0.0/24, que se corresponde con la red local a la que da el servidor de VPN.\nroot@debian:/etc/openvpn/client# ip r default via 200.0.0.1 dev ens4 onlink 10.0.0.0/24 via 10.99.99.1 dev tun0 10.99.99.0/24 dev tun0 proto kernel scope link src 10.99.99.2 200.0.0.0/24 dev ens4 proto kernel scope link src 200.0.0.2 Una vez que la VPN está funcionando, el cliente puede comunicarse con el equipo de la red local que está conectado al servidor VPN.\nroot@debian:/etc/openvpn/client# ping -c4 10.0.0.2 PING 10.0.0.2 (10.0.0.2) 56(84) bytes of data. 64 bytes from 10.0.0.2: icmp_seq=1 ttl=63 time=2.27 ms 64 bytes from 10.0.0.2: icmp_seq=2 ttl=63 time=3.96 ms 64 bytes from 10.0.0.2: icmp_seq=3 ttl=63 time=2.08 ms 64 bytes from 10.0.0.2: icmp_seq=4 ttl=63 time=3.59 ms --- 10.0.0.2 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 3005ms rtt min/avg/max/mdev = 2.078/2.974/3.963/0.815 ms Además, se puede comprobar que esta conexión se realiza de forma segura a través de la red VPN que se ha configurado.\ndebian@debian:~$ traceroute 10.0.0.2 traceroute to 10.0.0.2 (10.0.0.2), 30 hops max, 60 byte packets 1 10.99.99.1 (10.99.99.1) 8.065 ms 7.889 ms 7.673 ms 2 10.0.0.2 (10.0.0.2) 7.634 ms 7.610 ms 7.570 ms En una captura de tráfico entre el cliente y el servidor también se puede apreciar cómo los paquetes de este ping entre el cliente y el equipo de la red interna del servidor VPN viajan cifrados. En la captura se muestran como paquetes del protocolo OpenVPN y no se puede ver su contenido. Además, en la captura de tráfico sí que se puede ver la dirección IP real de origen y destino de cada paquete en vez de la IP virtual que se usa internamente para enviar el tráfico a través de la VPN.\n"},{
  "section": "Blog",
  "slug": "/blog/seguridad/2025-01-29-vpn-acceso-remoto-ipsec/",
  "title": "Creación de una VPN de acceso remoto con IPSec",
  "description": "",
  "date": "January 29, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "seguridad",
  "tags": "cifrado, VPN, StrongSwan, IPSec, Debian, seguridad, redes, Administración de Sistemas, Seguridad y Alta Disponibilidad",
  "content":"Para la configuración de la VPN de acceso remoto con IPSec se usa una aplicación por software, en este caso, StrongSwan. El escenario cuenta con tres máquinas: un cliente, un servidor y un equipo en la red interna del servidor al que el cliente debe acceder.\nInstalación de StrongSwan Para instalar StrongSwan en Debian se puede usar el gestor de paquetes apt porque esta distribución cuenta con un paquete en sus repositorios oficiales que instala la aplicación.\nsudo apt update sudo apt install strongwan La instalación de este paquete crea en el sistema dos ficheros importantes a través de los cuales se puede configurar la VPN: el fichero /etc/ipsec.conf, para configurar la VPN; y el fichero /etc/ipsec.secret para configurar las credenciales de los diferentes equipos y usuarios que tienen permiso para usar la red.\nConfiguración del servidor StrongSwan Para configurar el servidor VPN con StrongSwan se usa el fichero /etc/ipsec.conf. Este fichero cuenta con una primera parte, en la que se indican los elementos de la configuración básica. A continuación, se incluye una conexión llamada %default, que recoge los parámetros que se aplican, por defecto, al resto de conexiones definidas en el fichero a continuación. Estos parámetros indican al servidor, entre otras cosas, el tipo y versión del mecanismo de autentificación que se usa para las conexiones VPN.\nDespués, en este fichero se define la conexión que crea la VPN. En este caso se han indicado, a través de los diferentes parámetros disponibles para usar en este fichero la dirección IP del servidor, la subred privada del servidor, la dirección IP del cliente y, por último, el parámetro auto, que hace que la conexión a través de la VPN se inicie automáticamente al arrancar StrongSwan.\n# Servidor # ipsec.conf - strongSwan IPsec configuration file # basic configuration config setup charondebug=\u0026#34;ike 2, knl 2, cfg 2, net 2, esp 2, dmn 2, mgr 2\u0026#34; conn %default ikelifetime=1h keylife=1h rekeymargin=5m keyingtries=3 keyexchange=ikev2 authby=secret ike=aes256-sha1-modp1024 esp=aes256-sha1 # Add connections here. # Sample VPN connections conn roadwarrior left=192.168.122.148 leftsubnet=10.0.0.0/24 right=192.168.122.133 rightsubnet=10.0.10.0/24 auto=start La herramienta StrongSwan permite usar varios mecanismos de autentificación diferentes para la creación de VPN como, por ejemplo, RSA (que usa un par de claves como OpenVPN y WireGuard), PSK (que usa una clave simétrica) o EAP (que usa un nombre de usuario y contraseña). En este caso, se usa el mecanismo PSK, que únicamente requiere generar una clave e intercambiarla entre ambos extremos del túnel para asegurar la conexión a través de la VPN.\nHay una gran cantidad de herramientas que permiten generar claves aleatorias para autentificar equipos o usuarios usando PSK. Para este ejemplo, se usa la herramienta /dev/urandom de Debian para generar una cadena de caracteres aleatorios de una longitud determinada, por ejemplo 30 caracteres.\nhead -c 30 /dev/urandom | base64 \u0026gt; psk Este comando genera un fichero llamado psk que contiene una clave de 30 caracteres aleatorios. Para indicar a StrongSwan la clave simétrica que usa el servidor, se rellena esta información en el fichero /etc/ipsec.secrets. El formato en el que se debe añadir la información a este fichero es primero la IP de la máquina en la que se configura la VPN, después el carácter dos puntos ( : ), a cotninuación el método de autentificación (PSK) y, por último, la clave simétrica como cadena de caracteres.\n192.168.122.148 : PSK \u0026#34;e522lXLfFbQz1ftQoG3HOiLhTnftfZUA7GI7ULnz\u0026#34; Si el método de autentificación es otro, el formato del fichero también varía. Por ejemplo, para la autentificación con un par de claves la línea comienza con el carácter dos puntos ( : ) y, a continuación, el método de autentificación (RSA) y el nombre del fichero con la clave pública. Si la autentificación usa un nombre de usuario y una contraseña, en cambio, la línea del fichero comienza con el nombre de usuario, el caráctar dos puntos ( : ) y después, el método de autentificación (EAP) y la contraseña en texto. En este fichero se pueden añadir varias líneas para la autentificación de varios clientes y cada uno de ellos puede usar un método diferente.\nTras haber configurado el servidor, se inicia el servicio.\nipsec start Configuración del cliente StrongSwan La configuración del cliente se realiza en el mismo fichero que se emplea para el servidor. Este fichero incluye los mismos parámetros, teniendo siempre en cuenta indicar correctamente los direccionamientos de los diferentes equipos y redes. El parámetro left hace siempre referencia al equipo en el que se edita el fichero de configuración mientras que el parámetro right se refiere al equipo que se encuentre en el otro extremo del túnel.\n# Cliente # ipsec.conf - strongSwan IPsec configuration file # basic configuration config setup charondebug=\u0026#34;ike 2, knl 2, cfg 2, net 2, esp 2, dmn 2, mgr 2\u0026#34; conn %default ikelifetime=1h keylife=1h rekeymargin=5m keyingtries=3 keyexchange=ikev2 authby=secret ike=aes256-sha1-modp1024 esp=aes256-sha1 # Add connections here. # Sample VPN connections conn roadwarrior left=192.168.122.133 leftsubnet=10.0.10.0/24 right=192.168.122.148 rightsubnet=10.0.0.0/24 auto=start Como se está usando el método de autentificación PSK, para garantizar la identidad del cliente, éste debe conocer la clave simétrica que se ha generado previamente en el servidor. Esta clave se indica en el fichero /etc/ipsec.secrets.\n192.168.122.148 : PSK \u0026#34;e522lXLfFbQz1ftQoG3HOiLhTnftfZUA7GI7ULnz\u0026#34; Tras haber configurado el cliente, se inicia el servicio.\nipsec start Demostración del funcionamiento de la VPN con StrongSwan Cuando tanto en el cliente como en el servidor se ha iniciado el servicio, se establece entre ellos la conexión segura a través de la VPN. El estado de la conexión se puede verificar usando el comando ipsec status tanto desde el servidor:\nSecurity Associations (1 up, 0 connecting): roadwarrior[2]: ESTABLISHED 13 minutes ago, 192.168.122.148[192.168.122.148]...192.168.12 2.133[192.168.122.133] roadwarrior{2}: INSTALLED, TUNNEL, reqid 1, ESP SPIs: c90c45eb_i ccc2b2e0_o roadwarrior{2}: 10.0.0.0/24 === 10.0.10.0/24 Como desde el cliente:\nSecurity Associations (1 up, 0 connecting): roadwarrior[1]: ESTABLISHED 12 minutes ago, 192.168.122.133[192.168.122.133]...192.1 68.122.148[192.168.122.148] roadwarrior{2}: INSTALLED, TUNNEL, reqid 1, ESP SPIs: ccc2b2e0_i c90c45eb_o roadwarrior{2}: 10.0.10.0/24 === 10.0.0.0/24 La salida de este comando lista las conexiones activas a través de VPN de cada equipo. Como se puede comprobar, en cada caso se ha establecido una conexión segura entre la IP propia y la IP del equipo en el otro extremo de la VPN. Además, en ambos equipos aparece que se ha instalado el túnel que permite al cliente VPN acceder a las máquinas de la red privada del servidor VPN.\nAsí, el cliente puede tener acceso a las máquinas de la red privada del servidor.\nroot@debian:/home/debian# ping 10.0.0.2 PING 10.0.0.2 (10.0.0.2) 56(84) bytes of data. 64 bytes from 10.0.0.2: icmp_seq=1 ttl=63 time=2.46 ms 64 bytes from 10.0.0.2: icmp_seq=2 ttl=63 time=2.61 ms 64 bytes from 10.0.0.2: icmp_seq=3 ttl=63 time=0.875 ms 64 bytes from 10.0.0.2: icmp_seq=4 ttl=63 time=1.77 ms ^C --- 10.0.0.2 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 3027ms rtt min/avg/max/mdev = 0.875/1.928/2.611/0.685 ms En este caso, no se puede demostrar el funcionamiento de la VPN usando el comando traceroute como en otras ocasiones porque StrongSwan no crea interfaces virtuales con una IP diferente. Sin embargo ,si se captura el tráfico de este ping entre el cliente y el servidor, el contenido de las tramas que circulan por la red no se puede identificar porque está cifrado, es decir, se demuestra que el tráfico está circulando a través de la VPN.\nUna diferencia fundamental, por tanto, entre la VPN creada con StrongSwan usando IPSec y las generadas con OpenVPN y WireGuard es que, en este caso, la aplicación no genera unas interfaces virtuales a través de las que se enruta el tráfico de la VPN, sino que usa las propias IP físicas públicas tanto del cliente como del servidor para enrutar a través de ellas el tráfico de la VPN. Sin embargo, cuando se hace una captura de tráfico, se puede comprobar cómo estos paquetes se envían encapsulados usando el protocolo IPSec, por lo que el tráfico a través de esta red virtual es seguro y cifrado sin necesidad de usar interfaces y rutas virtuales como en los otros casos.\n"},{
  "section": "Blog",
  "slug": "/blog/seguridad/2025-01-29-vpn-acceso-remoto-wireguard/",
  "title": "Creación de una VPN de acceso remoto con WireGuard",
  "description": "",
  "date": "January 29, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "seguridad",
  "tags": "cifrado, VPN, WireGuard, Debian, seguridad, redes, Administración de Sistemas, Seguridad y Alta Disponibilidad",
  "content":"En este escenario un servidor VPN permite el acceso a un equipo conectado a su red interna a los clientes conectados a él a través de la red VPN.\nEl escenario queda configurado de la siguiente forma:\nInstalación de WireGuard Para instalar WireGuard en Debian 12 se puede usar el paquete wireguard incluido en los repositorios de la distribución.\nsudo apt update sudo apt install wireguard Creación de las claves La VPN necesita un par de claves para identificar al servidor frente a los clientes. Para generarlo, se pueden usar las herramientas que se instalan con el paquete wireguard. Este par de claves se alamacena en el directorio /etc/wireguard del servidor.\nwg genkey \u0026gt; private cat private | wg pubkey \u0026gt; publickey Configuración del servidor VPN En el servidor se debe establecer la configuración necesaria para permitir el enrutamiento de paquetes. Para ello, en el fichero /etc/sysctl.conf se descomenta la siguiente línea:\nnet.ipv4.ip_forward = 1 Y después se aplican los cambios.\nsysctl -p A continuación, se debe crear la interfaz virtual que usará WireGuard para establecer la red VPN. Existen varias alternativas para establecer esta configuración. De forma temporal se puede hacer con los comandos ip l e ip a junto a la herramienta wg incluida en el paquete wireguard. Usando el método tradicional, se puede configurar en el fichero /etc/network/interfaces pero desde la versión 237, systemd incluye soporte para configurar las VPN de WireGuard. Esta configuración se establece en una unidad de systemd de tipo .netdev en el directorio /etc/systemd/network/ y, a partir de esta unidad, se debe crear también otra de tipo .network en el mismo directorio. Sin embargo, la opción persistente más sencilla es definir esta unidad en un fichero de configuración propio dentro del directorio /etc/wirguard.\n[Interface] Address = 10.99.99.1 PrivateKey = SG9uVVohWxX396k6pateLErGyuJqOLNDiG1V9ewuflY= ListenPort = 51820 [Peer] Publickey = Dfcin5MIdoNQgYP9KpsSm4vNe6kBalF4OjJkFcUFfG0= AllowedIPs = 10.99.99.2/24 PersistentKeepAlive = 25 En este fichero se incluye, en primer lugar, la definición de la interfaz ([Interface]), en la que se especifica su dirección IP, la clave privada del servidor y el puerto de escucha. En este caso, se mantiene el puerto de escucha por defecto de Wireguard, el 51820.\nA continuación, se incluye la información que define la conexión con el cliente ([Peer]), incluyendo la clave pública del cliente, la IP desde la que se puede establecer la VPN desde el cliente y el tiempo durante el cual el túnel VPN sigue funcionando mientras no haya tráfico entre ambos extremos.\nIgualmente, existen varias formas de levantar la interfaz. El paquete wireguard ofrece una herramienta que permite levantar la interfaz de manera rápida y sencilla: wg-quick:\nroot@debian:/etc/wireguard# wg-quick up wg0 [#] ip link add wg0 type wireguard [#] wg setconf wg0 /dev/fd/63 Warning: AllowedIP has nonzero host part: 10.99.99.2/24 [#] ip -4 address add 10.99.99.1 dev wg0 [#] ip link set mtu 1420 up dev wg0 [#] ip -4 route add 10.99.99.0/24 dev wg0 Al levantar y configurar esta nueva interfaz virtual se crea la interfaz wg0:\n4: wg0: \u0026lt;POINTOPOINT,NOARP,UP,LOWER_UP\u0026gt; mtu 1420 qdisc noqueue state UNKNOWN group default qlen 1000 link/none inet 10.99.99.2/24 scope global wg0 valid_lft forever preferred_lft forever Y, además, se crea la ruta necesaria para dirigir el tráfico al servidor a través de la VPN.\nroot@debian:/etc/wireguard# ip r default via 192.168.122.1 dev ens4 10.99.99.0/24 dev wg0 proto kernel scope link src 10.99.99.2 192.168.122.0/24 dev ens4 proto kernel scope link src 192.168.122.70 Configuración del cliente VPN En el cliente también se debe crear la interfaz virtual para establecer el túnel VPN con el servidor. Esta configuración se puede hacer usando las mismas opciones listadas en el apartado anterior.En este caso, el contenido del fichero de configuración de la interfaz es muy similar al de la interfaz del servidor.\n[Interface] Address = 10.99.99.2/24 PrivateKey = 8BjZyjtUg+5IWiDMcp4rpy5MRrFY5Sc9oAjIyAGNHUk= ListenPort = 51820 [Peer] PublicKey = pX17efJapqPoef5dGrQKZBduutknEuOUjBkPMyFyJWI= AllowedIPs = 0.0.0.0/0 Endpoint = 90.0.0.2:51820 PersistentKeepalive = 25 En este caso, el apartado [Interface] del fichero de configuración recoge la dirección IP de la interfaz, la clave privada del cliente y el puerto de escucha y el apartado [Peer] incluye la clave pública del servidor, las direcciones IP desde las que se pueden establecer las conexiones VPN con el cliente, la IP del otro extremo de la VPN en el servidor y el tiempo durante el que el túnel VPN sigue funcionando mientras no haya tráfico entre ambos extremos.\nTras configurar la interfaz, el comando wg-quick permite levantarla y configurar las rutas necesarias para el funcionamiento de la VPN.\nroot@debian:/etc/wireguard# wg-quick up wg0 [#] ip link add wg0 type wireguard [ 1160.345197] wireguard: WireGuard 1.0.0 loaded. See www.wireguard.com for information. [ 1160.346867] wireguard: Copyright (C) 2015-2019 Jason A. Donenfeld \u0026lt;Jason@zx2c4.com\u0026gt;. All Rights Reserved. [#] wg setconf wg0 /dev/fd/63 [#] ip -4 address add 10.99.99.2/24 dev wg0 [#] ip link set mtu 1420 up dev wg0 [#] wg set wg0 fwmark 51820 [#] ip -4 route add 0.0.0.0/0 dev wg0 table 51820 [#] ip -4 rule add not fwmark 51820 table 51820 [#] ip -4 rule add table main suppress_prefixlength 0 [#] sysctl -q net.ipv4.conf.all.src_valid_mark=1 [#] iptables-restore -n Tras haber completado correctamente la configuración de la VPN, desde el cliente se puede establecer conexión con las máquinas internas conectadas a la red privada del servidor.\nroot@debian:/etc/wireguard# ping -c4 10.0.0.2 PING 10.0.0.2 (10.0.0.2) 56(84) bytes of data. 64 bytes from 10.0.0.2: icmp_seq=1 ttl=63 time=4.39 ms 64 bytes from 10.0.0.2: icmp_seq=2 ttl=63 time=0.963 ms 64 bytes from 10.0.0.2: icmp_seq=3 ttl=63 time=2.73 ms 64 bytes from 10.0.0.2: icmp_seq=4 ttl=63 time=1.48 ms --- 10.0.0.2 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 3004ms rtt min/avg/max/mdev = 0.963/2.391/4.392/1.321 ms Con el comando traceroute se comprueba, además, que el tráfico se enruta a través de la VPN.\nroot@debian:/etc/wireguard# traceroute 10.0.0.2 traceroute to 10.0.0.2 (10.0.0.2), 30 hops max, 60 byte packets 1 10.99.99.1 (10.99.99.1) 1.146 ms 1.143 ms 2.143 ms 2 10.0.0.2 (10.0.0.2) 3.978 ms 4.137 ms 4.280 ms "},{
  "section": "Blog",
  "slug": "/blog/seguridad/2025-01-29-vpn-punto-a-punto-ipsec/",
  "title": "Creación de una VPN punto a punto con IPSec",
  "description": "",
  "date": "January 29, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "seguridad",
  "tags": "cifrado, VPN, Cisco, IPSec, Debian, seguridad, redes, Administración de Sistemas, Seguridad y Alta Disponibilidad",
  "content":"Este escenario está formado por dos routers Cisco c7200 que comparten una red. Por la otra interfaz, cada uno cuenta con una red privada. Usando el protocolo IPSec se crea un túnel entre ambos routers que permita comunicar las dos redes privadas a través de una VPN.\nEn primer lugar, se configura el direccionamiento de ambos routers en el escenario.\nR1#conf t R1(config)#interface fastEthernet 0/0 R1(config-if)#ip address 10.0.0.1 255.255.255.0 R1(config-if)#no shutdown R1(config-if)#exit R1(config)#interface fastEthernet 1/0 R1(config-if)#ip address 100.0.0.1 255.255.255.0 R1(config-if)#no shutdown R1(config-if)#end R1#wr R2#conf t R2(config)#interface fastEthernet 0/0 R2(config-if)#ip address 10.0.10.1 255.255.255.0 R2(config-if)#no shutdown R2(config-if)#exit R2(config)#interface fastEthernet 1/0 R2(config-if)#ip address 100.0.0.2 255.255.255.0 R2(config-if)#no shutdown R2(config-if)#end R2#wr Y se especifica la ruta por defecto de cada uno de ellos para que puedan enrutar el tráfico de una red a otra.\nR1#conf t Enter configuration commands, one per line. End with CNTL/Z. R1(config)#ip route 0.0.0.0 0.0.0.0 100.0.0.2 R1(config)#end R1#wr R2#conf t Enter configuration commands, one per line. End with CNTL/Z. R2(config)#ip route 0.0.0.0 0.0.0.0 100.0.0.1 R2(config)#end R2#wr Configuración de los routers Cisco con IPSec Una vez que el escenario está desplegado correctamente y todas las máquinas tienen conectividad, se puede comenzar a configurar la red virtual VPN. El sistema operativo IOS de los routers Cisco cuenta con las herramientas necesarias para implementar este tipo de redes usando varios métodos como, por ejemplo, el protocolo IPSec. A diferencia de la configuración de las VPN por software, en el caso de los routers Cisco la VPN no se crea editando ningún fichero de configuración, sino que se usan varias órdenes incorporadas al sistema operativo de los dispositivos.\nAsí, en primer lugar, se crea una política ISAKMP para la fase 1 de la negociación para el túnel IPSec de LAN a LAN entre los dos routers del escenario.\nR1(config)#crypto isakmp policy 10 R1(config-isakmp)#encryption aes R1(config-isakmp)#hash sha R1(config-isakmp)#authentication pre-share R1(config-isakmp)#group 1 R1(config-isakmp)#exit Después, se especifica una clave simétirca pre-compartida y la dirección IP del otro extremo de la VPN. En este caso la clave es \u0026lsquo;vpnuser\u0026rsquo; aunque se recomienda que esta clave sea una cadena más larga de caracteres aleatorios o, incluso, configurarla de forma cifrada con la opción 6 en vez de 0 del comando crypto isakmp key.\nR1(config)#crypto isakmp key 0 vpnuser address 100.0.0.2 El siguiente paso es crear una política de fase 2 para la negociación IPSec.\nR1(config)#crypto ipsec transform-set myset esp-aes esp-sha-hmac R1(cfg-crypto-trans)#exit A continuación, se crea una ACL para identificar el tráfico que se debe encriptar a través de la VPN. En este caso, el tráfico que circula de la red 10.0.0.0/24 a la 10.0.10.0/24 se encriptará y se enrutará por la VPN al llegar al router R1. En un escenario realista, en el que estos routers también diesen a Internet, el tráfico que no coincidiese con la lista de acceso, por ejemplo, el que circulase hacia cualquier otra dirección IP de Internet, no se encriptaría y saldría del router sin cifrar.\nR1(config)#access-list 100 permit ip 10.0.0.0 0.0.0.255 10.0.10.0 0.0.0.255 Con toda esta información, hay que crear un crypto map. En él se indica la dirección IP del otro extremo del túnel, el transform-set que se ha creado previamente y la ACL que define el tráfico que se encripta a través de la VPN.\nR1(config)#crypto map mymap 10 ipsec-isakmp % NOTE: This new crypto map will remain disabled until a peer and a valid access list have been configured. R1(config-crypto-map)#set peer 100.0.0.2 R1(config-crypto-map)#set transform-set myset R1(config-crypto-map)#match address 100 R1(config-crypto-map)#exit El último paso, es aplicar el crypto map a la interfaz de salida del tráfico del router.\nR1(config)#interface fastEthernet0/1 R1(config-if)#crypto map mymap *Mar 1 00:18:05.243: %CRYPTO-6-ISAKMP_ON_OFF: ISAKMP is ON R1(config-if)#end R1#wr Esta configuración, se repite en el router R2 modificando las direcciones IP para que correspondan al direccionamiento que se ha configurado en el escenario.\n!--- Creación de la política de negociaciones de fase 1 para el túnel R2(config)#crypto isakmp policy 10 R2(config-isakmp)#encryption aes R2(config-isakmp)#hash sha R2(config-isakmp)#authentication pre-share R2(config-isakmp)#group 1 R2(config-isakmp)#exit !--- Se indica la contraseña y la IP del otro extremo del túnel R2(config)#crypto isakmp key 0 vpnuser address 100.0.0.1 !--- Creación de política de fase 2 para la negociación IPSec R2(config)#crypto ipsec transform-set myset esp-aes esp-sha-hmac R2(cfg-crypto-trans)#exit !--- Creación de la ACL para identificar el tráfico que se debe encriptar. !--- En este caso, se encripta el tráfico que circula desde la red !--- 10.0.10.0/24 a la red 10.0.0.0/24. R2(config)#access-list 100 permit ip 10.0.10.0 0.0.0.255 10.0.0.0 0.0.0.255 !--- Creación del crypto map, especificando la IP del otro extremo del túnel, !--- el transform-set que se debe aplicar al tráfico y la ACL que distingue !--- el tráfico que se debe encriptar a través del túnel. R2(config)#crypto map mymap 10 ipsec-isakmp % NOTE: This new crypto map will remain disabled until a peer and a valid access list have been configured. R2(config-crypto-map)#set peer 100.0.0.1 R2(config-crypto-map)#set transform-set myset R2(config-crypto-map)#match address 100 R2(config-crypto-map)#exit !--- Aplicar el crypto map a la interfaz de salida del router R2(config)#interface fastEthernet0/1 R2(config-if)#crypto map mymap *Mar 1 00:14:04.259: %CRYPTO-6-ISAKMP_ON_OFF: ISAKMP is ON R2(config-if)#end R2#wr Demostración del funcionamiento Tras configurar la VPN en ambos routers, los equipos de las redes privadas detrás de cada router pueden comunicarse entre sí. Tanto desde el PC1 al PC2.\nPC1\u0026gt; ping 10.0.10.1 84 bytes from 10.0.10.1 icmp_seq=1 ttl=254 time=29.694 ms 84 bytes from 10.0.10.1 icmp_seq=2 ttl=254 time=18.364 ms 84 bytes from 10.0.10.1 icmp_seq=3 ttl=254 time=18.856 ms 84 bytes from 10.0.10.1 icmp_seq=4 ttl=254 time=18.179 ms 84 bytes from 10.0.10.1 icmp_seq=5 ttl=254 time=18.028 ms Como desde el PC2 al PC1.\nPC2\u0026gt; ping 10.0.0.2 84 bytes from 10.0.0.2 icmp_seq=1 ttl=62 time=27.434 ms 84 bytes from 10.0.0.2 icmp_seq=2 ttl=62 time=28.782 ms 84 bytes from 10.0.0.2 icmp_seq=3 ttl=62 time=27.554 ms 84 bytes from 10.0.0.2 icmp_seq=4 ttl=62 time=28.702 ms 84 bytes from 10.0.0.2 icmp_seq=5 ttl=62 time=27.058 ms Analizar la ruta que siguen estos paquetes no aporta mucha información porque, a diferencia de lo que ocurre con las VPN creadas con OpenVPN o WireGuard y a semejanza de lo que ocurre con la VPN configurada con StrongSwan, el tráfico se enruta a través de las interfaces físicas de los routers, con sus IP reales y no usa unas IP asignadas a unas interfaces virtuales creadas para su uso con la VPN.\nPC2\u0026gt; trace 10.0.0.2 trace to 10.0.0.2, 8 hops max, press Ctrl+C to stop 1 10.0.10.1 4.803 ms 9.537 ms 10.043 ms 2 100.0.0.1 19.241 ms 20.104 ms 19.980 ms 3 *10.0.0.2 30.040 ms Sin embargo, al capturar el tráfico de uno de estos ping entre los routers, se puede observar cómo los mensajes que circulan entre las direcciones IP públicas de los routers se muestran con el protocolo ESP (Encapsulating Securty Payload), lo que demuestra que el tráfico está viajando cifrado entre los extremos de la VPN.\n"},{
  "section": "Blog",
  "slug": "/blog/seguridad/2025-01-29-vpn-sitio-a-sitio-wireguard/",
  "title": "Creación de una VPN sitio a sitio con WireGuard",
  "description": "",
  "date": "January 29, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "seguridad",
  "tags": "cifrado, VPN, WireGuard, Debian, seguridad, redes, Administración de Sistemas, Seguridad y Alta Disponibilidad",
  "content":"En este post, el escenario está formado por dos servidores de VPN que actúan, a su vez, como clientes del otro servidor y un equipo en la red interna de cada servidor.\nInstalación de WireGuard Al usar WireGuard, la configuración para una red VPN punto a punto se puede hacer, a la vez, en los dos servidores. En primer lugar, se instala el paquete wireguard.\napt update apt install wireguard Creación de las claves Para configurar la VPN se trabaja en el directorio /etc/wireguard de ambos servidores. Esta configuración es idéntica en ambos casos y se puede establecer de forma simultánea en los dos puntos de la red VPN.\nEl paquete wireguard incluye una serie de herramientas útiles para la configuración de la VPN. Estas herramientas se gestionan con el comando wg. Así, este comando permite generar las claves públicas y privadas de ambos servidores.\nwg genkey \u0026gt; private wg pubkey \u0026lt; private \u0026gt; pubkey Configuración de los servidores En ambos servidores hay que permitir el enrutamiento de paquetes. Para ello, en el fichero /etc/sysctl.conf se descomenta la siguiente línea:\nnet.ipv4.ip_forward = 1 Y después se aplican los cambios.\nsysctl -p Para configurar la VPN punto a punto entre dos servidores con WireGuard ambos deben contar con una interfaz virtual de tipo wg0. Esta interfaz se puede configurar con un fichero similar al que se ha usado en el punto anterior. En este caso, el fichero del servidor 1 cuenta con el siguiente contenido:\n[Interface] Address = 10.99.99.1 PrivateKey = KJYhzp43mrlBGsFh4KoqJzsUpjdDXG+yjwLvilJAqk8= ListenPort = 51820 [Peer] Publickey = TN0YObylxd6vXYCZW+flN71jr93Q/srs6PSYvunUJik= AllowedIPs = 10.99.99.2/24,172.18.0.0/24 PersistentKeepAlive = 25 Endpoint = 192.168.122.106:51820 En la sección [Interface] del fichero se indica la IP de la interfaz, la clave privada del servidor y el puerto de escucha, en este caso, el 51820, el puerto de escucha por defecto de WireGuard. En la sección [Peer] se recoge la clave pública del servidor en el otro extremo de la VPN, las direcciones IP a las que se permite la conexión al servidor, la dirección IP por la que escucha el servidor VPN del otro extremo del túnel y el parámetro que determina el tiempo durante el cual el túnel se mantendrá activo sin tráfico. En este caso, en el parámetro AllowedIPs incluye la dirección IP de la red privada detrás del segundo servidor VPN con los que los clientes del primero se deben comunicar a través del túnel.\nEn el fichero del servidor 2 se establece una configuración simétrica a la del primero para permitir la conexión seguraa través del túnel VPN en sentido opuesto.\n[Interface] Address = 10.99.99.1 PrivateKey = iMjkgw+hKJcdbds9mDwCMesC0j18QfNiMvBzHucrfEs= ListenPort = 51820 [Peer] Publickey = Op5DIF4tSl+4vWcXcON21DDsHyr5J1P/zDSyyxPOpyU= AllowedIPs = 10.99.99.2/24,172.19.0.0/24 PersistentKeepAlive = 25 Endpoint = 192.168.122.69:51820 Para levantar estas interfaces en sendos servidores se puede usar la utilidad wg-quick instalada con el paquete wireguard que permite crear y configurar las interfaces.\nroot@debian:/etc/wireguard# wg-quick up wg0 [#] ip link add wg0 type wireguard [ 2495.380857] wireguard: WireGuard 1.0.0 loaded. See www.wireguard.com for information. [ 2495.383299] wireguard: Copyright (C) 2015-2019 Jason A. Donenfeld \u0026lt;Jason@zx2c4.com\u0026gt;. All Rights Reserved. [#] wg setconf wg0 /dev/fd/63 Warning: AllowedIP has nonzero host part: 10.99.99.2/24 [#] ip -4 address add 10.99.99.1 dev wg0 [#] ip link set mtu 1420 up dev wg0 [#] ip -4 route add 172.18.0.0/24 dev wg0 [#] ip -4 route add 10.99.99.0/24 dev wg0 La ejecución de este comando añade la interfaz, establece su configuración, configura la dirección IP de la interfaz, estable su mtu y añade las rutas necesarias para dirigir el tráfico al otro extremo del túnel VPN.\nEl mismo comando en el servidor 2 realiza las mismas acciones.\nroot@debian:/etc/wireguard# wg-quick up wg0 [#] ip link add wg0 type wireguard [ 2453.286738] wireguard: WireGuard 1.0.0 loaded. See www.wireguard.com for information. [ 2453.288837] wireguard: Copyright (C) 2015-2019 Jason A. Donenfeld \u0026lt;Jason@zx2c4.com\u0026gt;. All Rights Reserved. [#] wg setconf wg0 /dev/fd/63 Warning: AllowedIP has nonzero host part: 10.99.99.2/24 [#] ip -4 address add 10.99.99.1 dev wg0 [#] ip link set mtu 1420 up dev wg0 [#] ip -4 route add 172.19.0.0/24 dev wg0 [#] ip -4 route add 10.99.99.0/24 dev wg0 Tras aplicar esta configuración en ambos servidores se crea la interfaz virtual wg0.\nEn el servidor 1:\n4: wg0: \u0026lt;POINTOPOINT,NOARP,UP,LOWER_UP\u0026gt; mtu 1420 qdisc noqueue state UNKNOWN group default qlen 1000 link/none inet 10.99.99.1/32 scope global wg0 valid_lft forever preferred_lft forever Y en el servidor 2:\n4: wg0: \u0026lt;POINTOPOINT,NOARP,UP,LOWER_UP\u0026gt; mtu 1420 qdisc noqueue state UNKNOWN group default qlen 1000 link/none inet 10.99.99.1/32 scope global wg0 valid_lft forever preferred_lft forever Además, en ambos servidores se crean las rutas necesarias para llegar a las redes privadas detrás de cada servidor en el extremo opuesto del túnel VPN.\nEn el servidor 1:\nroot@debian:/etc/wireguard# ip r default via 192.168.122.1 dev ens4 10.99.99.0/24 dev wg0 scope link 172.18.0.0/24 dev wg0 scope link 172.19.0.0/24 dev ens5 proto kernel scope link src 172.19.0.1 192.168.122.0/24 dev ens4 proto kernel scope link src 192.168.122.69 Y en el servidor 2:\nroot@debian:/etc/wireguard# ip r default via 192.168.122.1 dev ens4 10.99.99.0/24 dev wg0 scope link 172.18.0.0/24 dev ens5 proto kernel scope link src 172.18.0.1 172.19.0.0/24 dev wg0 scope link 192.168.122.0/24 dev ens4 proto kernel scope link src 192.168.122.106 Esta configuración permite crear un túnel VPN seguro entre ambos servidores, de manera que los equipos en cada una de las redes pueden comunicarse con cualquier equipo de la otra red. De esta forma, un equipo conectado a la red privada del servidor 1 puede comunicarse con uno de la red privada del servidor 2:\nPC1\u0026gt; ping 172.18.0.2 84 bytes from 172.18.0.2 icmp_seq=1 ttl=62 time=2.400 ms 84 bytes from 172.18.0.2 icmp_seq=2 ttl=62 time=2.175 ms 84 bytes from 172.18.0.2 icmp_seq=3 ttl=62 time=1.252 ms 84 bytes from 172.18.0.2 icmp_seq=4 ttl=62 time=1.994 ms 84 bytes from 172.18.0.2 icmp_seq=5 ttl=62 time=1.597 ms De la misma manera, un equipo de la red privada del servidor 2 se puede comunicar con uno de la red privada opuesta:\nPC2\u0026gt; ping 172.19.0.2 84 bytes from 172.19.0.2 icmp_seq=1 ttl=62 time=1.166 ms 84 bytes from 172.19.0.2 icmp_seq=2 ttl=62 time=2.214 ms 84 bytes from 172.19.0.2 icmp_seq=3 ttl=62 time=1.361 ms 84 bytes from 172.19.0.2 icmp_seq=4 ttl=62 time=1.894 ms 84 bytes from 172.19.0.2 icmp_seq=5 ttl=62 time=1.329 ms La captura de tráfico entre ambos servidores durante el ping del PC2 al PC1 muestra cómo el tráfico circula encriptado por la red. En este caso, se identifican los paquetes como protocolo WireGuard y, en el análisis del contenido de cada paquete se muestra el mensaje \u0026ldquo;paquete encriptado\u0026rdquo;. Aunque en la captura se muestra la IP real de origen y destino en el tramo capturado y no las IP virtuales de la VPN, el protocolo y encriptación del mensaje demuestra que está circulando a través de la VPN.\n"},{
  "section": "Blog",
  "slug": "/blog/servicios/2025-01-27-configuracion-de-vistas-en-bind9/",
  "title": "Configuración de vistas en el servidor DNS con  Bind9",
  "description": "",
  "date": "January 27, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "servicios",
  "tags": "dns, servidor dns, Bind9, Debian, Administración de Sistemas, servicios, Servicios de Red e Internet",
  "content":"En un escenario formado por dos máquinas, en el que una de ellas contiene dos contenedores LXC, se configura un servidor DNS con diferentes vistas.\nEl servidor DNS se configura en uno de los contenedores alojados en la máquina que funciona como router del escenario. Para ello, en primer lugar se accede al conetenedor y se instala el servidor DNS Bind9.\napt install bind9 En el fichero /etc/bind/named.conf.options se configuran las opciones del servidor. En principio, se puede usar el parámetro allow-query para permitir consultas desde todas las redes del escenario y desactivar el sistema dnssec-validation.\ndnssec-validation no; allow-query {172.22.0.0/16; 192.168.0.0/24; 172.16.0.0/16; }; A continuación, se definen las zonas sobre las que el servidor DNS tiene dominio en el fichero /etc/bind/named.conf.local. Para ello se van a usar dos vistas diferentes según si la consulta al DNS llega desde la red intra (192.168.0.0/24) o desde la red DMZ (172.16.0.0/16).\nview red_intra { match-clients { 192.168.0.0/24; }; allow-recursion { any; }; zone \u0026#34;javi.gonzalonazareno.org\u0026#34; { type master; file \u0026#34;db.javiintra.gonzalonazareno.org\u0026#34;; }; zone \u0026#34;0.168.192.in-addr.arpa\u0026#34; { type master; file \u0026#34;db.192.168.0\u0026#34;; }; zone \u0026#34;16.172.in-addr.arpa\u0026#34; { type master; file \u0026#34;db.172.16\u0026#34;; }; include \u0026#34;/etc/bind/zones.rfc1918\u0026#34;; include \u0026#34;/etc/bind/named.conf.default-zones\u0026#34;; }; view red_DMZ { match-clients { 172.16.0.0/16; 127.0.0.1; }; allow-recursion { any; }; zone \u0026#34;javi.gonzalonazareno.org\u0026#34; { type master; file \u0026#34;db.javidmz.gonzalonazareno.org\u0026#34;; }; zone \u0026#34;0.168.192.in-addr.arpa\u0026#34; { type master; file \u0026#34;db.192.168.0\u0026#34;; }; zone \u0026#34;16.172.in-addr.arpa\u0026#34; { type master; file \u0026#34;db.172.16\u0026#34;; }; include \u0026#34;/etc/bind/zones.rfc1918\u0026#34;; include \u0026#34;/etc/bind/named.conf.default-zones\u0026#34;; }; Además, hay que comentar las zonas que se han declarado en este fichero en los otros ficheros incluidos en él. Así, en el fichero /etc/bind/zones.frc1918 se comentan las siguientes líneas:\n//zone \u0026#34;16.172.in-addr.arpa\u0026#34; { type master; file \u0026#34;/etc/bind/db.empty\u0026#34;; }; //zone \u0026#34;168.192.in-addr.arpa\u0026#34; { type master; file \u0026#34;/etc/bind/db.empty\u0026#34;; }; Y en el fichero /etc/bind/named.conf se comenta la línea que incluye el fichero de zonas por defecto.\n//include \u0026#34;/etc/bind/named.conf.default-zones\u0026#34;; Después, hay que rellenar los ficheros de de zona para las zonas declaradas previamente. Primero, se configura la zona javi.gonzalonazareno.org\ncp /etc/bind/db.empty /var/cache/bind/db.javiintra.gonzalonazareno.org En este fichero se configura la resolución directa de los nombres de las máquinas y servicios del escenario.\n$TTL\t86400 @\tIN\tSOA\tnami.javi.gonzalonazareno.org. root.javi.gonzalonazareno.org. ( 1\t; Serial 604800\t; Refresh 86400\t; Retry 2419200\t; Expire 86400 )\t; Negative Cache TTL ; @\tIN\tNS\tnami.javi.gonzalonazareno.org. $ORIGIN javi.gonzalonazareno.org. nami\tIN\tA\t192.168.0.2 sanji\tIN\tA\t192.168.0.3 luffy\tIN\tA\t192.168.0.1 zoro\tIN\tA\t172.16.0.200 www\tIN\tCNAME\tzoro bd\tIN\tCNAME\tsanji A partir de este fichero de zona, se puede generar el fichero para la otra zona definida anteriormente.\ncp /var/cache/bind/db.javiintra.gonzalonazareno.org /var/cache/bind/db.javidmz.gonzalonazareno.org En este caso, sólo cambia la línea para la resolución de luffy, que es la única máquina del escenario que cuenta con dos direcciones IP diferentes.\nluffy\tIN\tA\t172.16.0.1 También hay que rellenar la información para los ficheros de resolución inversa. En este escenario hay dos redes y, por tanto, se usan dos ficheros de resolución inversa diferentes. Primero, se rellena el fichero para la resolución inversa de la red 192.168.0.0/24.\ncp /etc/bind/db.empty /var/cache/bind/db.192.168.0 Con el siguiente contenido:\n$TTL 86400 @ IN SOA nami.javi.gonzalonazareno.org. root.javi.gonzalonazaren\u0026gt; 1 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 86400 ) ; Negative Cache TTL ; @ IN NS nami.javi.gonzalonazareno.org. $ORIGIN 0.168.192.in-addr.arpa. 1 IN PTR luffy.javi.gonzalonazareno.org. 2 IN PTR nami.javi.gonzalonazareno.org. 3 IN PTR sanji.javi.gonzalonazareno.org. Después se repite la operación con el fichero para la zona 172.16.0.0/16.\ncp /etc/bind/db.empty /var/cache/bind/db.172.16 Este fichero tiene el siguiente contenido:\n$TTL 86400 @ IN SOA nami.javi.gonzalonazareno.org. root.javi.gonzalonazaren\u0026gt; 1 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 86400 ) ; Negative Cache TTL ; @ IN NS nami.javi.gonzalonazareno.org. $ORIGIN 16.172.in-addr.arpa. 1.0 IN PTR luffy.javi.gonzalonazareno.org. 200.0 IN PTR zoro.javi.gonzalonazareno.org. Configuración del DNS en los clientes Para que el resto de máquinas de la red se refieran a nami como servidor DNS, hay que configurar su dirección como DNS por defecto en los clientes. En este escenario nami y sanji son contenedores Ubuntu, con un direccionamiento estático y que usan netplan para su configuración de red. Así, un ejemplo de configuración de una de estas máquinas contendo con nami como servidor DNS es el siguiente:\nnetwork: version: 2 ethernets: eth0: dhcp4: false addresses: - 192.168.0.3/24 routes: - to: default via: 192.168.0.1 mtu: 1442 nameservers: addresses: - 192.168.0.2 En ambos contenedores se aplican los cambios.\nnetplan apply La otra máquina del escenario, zoro usa el sistema operativo Rocky Linux 9. En esta distribución se establece la configuración de red a través de NetworkManager usando algunos de sus clientes para terminal, ya sea nmcli (línea de comandos) o nmtui (interfaz de texto). En este caso, usando nmtui se accede al menú edit connection y se edita la única conexión configurada en la máquina para añadir la IP de nami como DNS por defecto.\n┌───────────────────────────┤ Edit Connection ├───────────────────────────┐ │ ↑│ │ Profile name Wired connection 1______________________ ▮│ │ Device eth0 (FA:16:3E:67:F3:1E)________________ ▒│ │ ▒│ │ ═ ETHERNET \u0026lt;Show\u0026gt; ▒│ │ ═ 802.1X SECURITY \u0026lt;Show\u0026gt; ▒│ │ ▒│ │ ╤ IPv4 CONFIGURATION \u0026lt;Manual\u0026gt; \u0026lt;Hide\u0026gt; ▒│ │ │ Addresses 172.16.0.200/32__________ \u0026lt;Remove\u0026gt; ▒│ │ │ \u0026lt;Add...\u0026gt; ▒│ │ │ Gateway 172.16.0.1_______________ ▒│ │ │ DNS servers 192.168.0.4______________ \u0026lt;Remove\u0026gt; ▒│ │ │ \u0026lt;Add...\u0026gt; ▒│ │ │ Search domains \u0026lt;Add...\u0026gt; ▒│ │ │ ▒│ │ │ Routing (No custom routes) \u0026lt;Edit...\u0026gt; ▒│ │ │ [ ] Never use this network for default route ▒│ │ │ [ ] Ignore automatically obtained routes ▒│ │ ↓│ └─────────────────────────────────────────────────────────────────────────┘ Por último, luffy toma el servidor DNS por defecto de la configuración DHCP y, además, usa systemd para gestionar la configuración de red. Así, se puede configurar su servidor DNS modificando el contenido del fichero de configuración /etc/systemd/resolved.conf.\n[Resolve] DNS=192.168.0.2 Para aplicar el cambio, se reinicia el servicio.\nsudo systemctl restart systemd-resolved.service Configuración del parámetro search para poder usar los nombres cortos del escenario Para poder usar los nombres cortos de las máquinas del escenario, se debe configurar en todos los clientes el nombre de dominio de las máquinas en el parámetro search en la configuración del DNS.\nEn los contenedores, tanto nami como sanji, este parámetro se puede configurar en el fichero de configuración de red /etc/netplan/10-lxc.yaml.\nnetwork: version: 2 ethernets: eth0: dhcp4: false addresses: - 192.168.0.2/24 routes: - to: default via: 192.168.0.1 mtu: 1442 nameservers: addresses: - 192.168.0.2 search: - javi.gonzalonazareno.org En el caso de zoro, con Rocky Linux 9, esta configuración se puede añadir a través de la interfaz de texto nmtui, desde la interfaz de la línea de comando nmcli o editando el menú de configuración de la conexión. En este caso, este fichero es /etc/NetworkManager/system-connections/Wired connection 1.nmconnection. En este fichero, la configuración de la conexión para IPv4 es la siguiente:\n[ipv4] address1=172.16.0.200/32,172.16.0.1 dns=192.168.0.2; method=manual dns-search=javi.gonzalonazareno.org Por úlitmo, en la máquina luffy, que usa systemd, una opción para configurar la búsqueda de dominios es uasr usa el parámetro Domains en el fichero /etc/systemd/resolved.conf.\n[Resolve] DNS=192.168.0.2 Domains=javi.gonzalonazareno.org Para aplicar el cambio, se reinicia el servicio.\nsudo systemctl restart systemd-resolved.service Configuración para acceder al servidor DNS desde el exterior La máquina router de este escenario, luffy es la única que tiene una dirección IP accesible desde fuera de esta red. Para que se pueda usar el servidor DNS desde fuera de la red hay que configurar una regla DNAT en el router que redirija el tráfico del puerto 53 al DNS. También es necesario contar con una nueva vista que muestre sólo la información que debe ser accesible desde fuera de la red y oculte aquella que no debe ser pública.\nRegla DNAT En el router luffy una regla DNAT debe redirigir el tráfico que llegue al puerto 53 del router a la IP de nami.\niptables -t nat -A PREROUTING -p udp --dport 53 -i ens3 -j DNAT --to 192.168.0.2 iptables-save \u0026gt; /etc/iptables/rules.v4 Creación de una nueva vista Para que el servidor DNS sólo muestre al exterior la información relevante para el acceso a la red a través de la IP pública, es decir, la IP de luffy y el alias del servicio www, hay que configurar una nueva vista en el servidor DNS. Esta vista se añade al fichero /etc/bind/named.conf.local.\nview red_externa { match-clients { 172.22.0.0/16; }; allow-recursion { any; }; zone \u0026#34;javi.gonzalonazareno.org\u0026#34; { type master; file \u0026#34;db.javiexterna.gonzalonazareno.org\u0026#34;; }; include \u0026#34;/etc/bind/named.conf.default-zones\u0026#34;; }; En /var/cache/bind/ se rellena el fichero de zona.\n$TTL 86400 @ IN SOA luffy.javi.gonzalonazareno.org. root.javi.gonzalonazare\u0026gt; 1 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 86400 ) ; Negative Cache TTL ; @ IN NS luffy.javi.gonzalonazareno.org. $ORIGIN javi.gonzalonazareno.org. luffy IN A 172.22.201.28 www IN CNAME luffy Configurar el DNS como forwarder Para que desde dentro del escenario se puedan resolver direcciones de fuera, hay que configurar el servidor DNS como forwarder hacia el servidor DNS principal en la red, que tiene configurada la delegación de dominio a los subdominos del resto de compañeros. Esta configuración se aplica en el fichero /etc/bind/named.conf.options.\nforwarders { 172.22.0.1; }; "},{
  "section": "Blog",
  "slug": "/blog/servicios/2025-01-27-instalacion-wordpress-rocky-linux/",
  "title": "Instalación de WordPress en Rocky Linux 9",
  "description": "",
  "date": "January 27, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "servicios",
  "tags": "web, servidor web, Apache, Rocky Linux, Administración de Sistemas, servicios, Servicios de Red e Internet",
  "content":"En este post se instala WordPress en un equipo con Rocky Linux 9 en el que se ha instalado el servidor web de Apache httpd y que se conecta a una base de datos instalada en otro servidor basado en Ubuntu 22.04.\nWordPress es una aplicación escrita en PHP y, por tanto, el servidor web necesita contar con los módulos necesarios para ejecutar el código.\nyum install php php-mysqlnd php-gd php-xml php-mbstring Para poder descargar al servidor web el instalador del a aplicación web, es necesario contar con el comando wget en el sistema.\nyum install wget Con wget se puede descargar la última versión de la aplicación al servidor web.\nwget https://wordpress.org/latest.tar.gz En el directorio de trabajo se descomprime el código de la aplicación.\ntar -xzvf latest.tar.gz Y se copia el contenido de este directorio al directorio raíz del VirtualHost del servidor web.\ncp -r wordpress/* /var/www/html/ Para que el servidor web pueda acceder al contenido del directorio, se debe cambiar la propiedad del mismo al usuario apache.\nchown -R apache: /var/www/html/ En el directorio raíz del VirtualHost, a partir del fichero de ejemplo, se crea el fichero de configuración de la aplicación.\ncp wp-config-sample.php wp-config.php Y en él se configura el acceso a la base de datos.\n// ** Database settings - You can get this info from your web host ** // /** The name of the database for WordPress */ define( \u0026#39;DB_NAME\u0026#39;, \u0026#39;wp\u0026#39; ); /** Database username */ define( \u0026#39;DB_USER\u0026#39;, \u0026#39;wp-user\u0026#39; ); /** Database password */ define( \u0026#39;DB_PASSWORD\u0026#39;, \u0026#39;usuario\u0026#39; ); /** Database hostname */ define( \u0026#39;DB_HOST\u0026#39;, \u0026#39;sanji\u0026#39; ); /** Database charset to use in creating database tables. */ define( \u0026#39;DB_CHARSET\u0026#39;, \u0026#39;utf8\u0026#39; ); /** The database collate type. Don\u0026#39;t change this if in doubt. */ define( \u0026#39;DB_COLLATE\u0026#39;, \u0026#39;\u0026#39; ); En este caso, la base de datos se aloja en un servidor diferente al que aloja el servicio web y, por tanto, se debe permitir la conexión entre servidores para que el servidor web pueda acceder a la base de datos tal y como se ha configurado. El sistema operativo Rocky Linux 9, como muchos otros derivados de Red Hat, tiene habilitado por defecto el sistema de seguridad extendida SELinux. La configuración de este sistema de seguridad impide que se pueda establecer la conexión necesaria con el servidor de base de datos. Para permitirlo es necesario cambiar el modo de SELinux.\nsetenforce Passive Tras permitir la conexión al servidor de base de datos, se puede instalar WordPress desde el navegador al acceder a la dirección del servidor web o, en este caso, a la IP pública del router que tiene configurada la regla DNAT pertinente para redirigir el tráfico web al servidor web.\n"},{
  "section": "Blog",
  "slug": "/blog/servicios/2025-01-27-instalacion-servidor-web-rocky-linux/",
  "title": "Instalación del servidor web Apache en Rocky Linux 9",
  "description": "",
  "date": "January 27, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "servicios",
  "tags": "web, servidor web, WordPress, Apache, Rocky Linux, Administración de Sistemas, servicios, implantación, Servicios de Red e Internet",
  "content":"El de Apache es uno de los servidores web más usados del mundo. Aunque en otras distribuciones, como las basadas en Debian, este servidor se instala con el paquete apache2 en las distribuciones basadas en Red Hat como CentOS o Rocky Linux, este servidor se instala con el paquete httpd.\nyum update yum install httpd Para gestionar el servicio se usa systemd, por tanto, este servicio se puede habilitar y encender con los siguientes conmandos:\nsystemctl enable httpd systemctl start httpd Para acceder al servidor web desde el exterior de la red, se configura en el router una regla DNAT.\niptables -t nat -A PREROUTING -p tcp --dport 80 -i ens3 -j DNAT --to 172.16.0.200 "},{
  "section": "Blog",
  "slug": "/blog/administracion-de-sistemas/2025-01-27-systemd-journal-remote/",
  "title": "Recolección centralizada de logs de sistema mediante jouranld",
  "description": "",
  "date": "January 27, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "administracion-sistemas",
  "tags": "sistemas, systemd, linux, debian, journald, log, Administración de Sistemas Operativos",
  "content":"Para configurar un servidor de journald en la red local es necesario que todos los equipos de la red cuenten con el componente systemd-journal-remote instalado. Este componente de systemd permite a los diferentes nodos de la red interactuar entre sí y trasladar la información relativa a los logs del sistema desde los clientes al servidor de logs.\nCon esta herramienta cliente y servidor establecen una comunicación usando HTTP o HTTPS para transferir los ficheros de log desde los clientes al servidor. El servidor se puede configurar en modo activo para que solicite periódicamente los logs a los clientes de la red o en modo pasivo para que reciba los logs cada vez que los clientes los envíen.\nEn este caso, se configura un cliente y un servidor en modo activo que usan HTTP para centralizar el registro de logs de la red.\nConfiguración de journald usando HTTP Configuración del cliente Para que un equipo de una red local pueda funcionar como cliente de un servidor de logs necesita tener instalada la utilidad systemd-journal-upload, que se incluye en el paquete systemd-journal-remote.\nsudo apt update sudo apt install systemd-journal-remote En el fichero /etc/systemd/journal-upload.conf se configura la dirección IP del servidor de logs, así como el puerto de escucha del servidor para recibir los ficheros de journald de los clientes que, por defecto, es el 19532.\n[Upload] URL=http://10.0.0.157:19532 Para poner en funcionamiento el cliente hay que arrancar el servicio.\nsudo systemctl start systemd-journal-upload.service Este servicio se puede hacer persistente a los reinicios del sistema habilitando su ejecución durante el arranque.\nsudo systemctl enable systemd-journal-upload.service Configuración del servidor En el servidor también hay que instalar el componente de systemd que permite centralizar el registro de logs de los equipos de la red a través de journald.\nsudo apt update sudo apt install systemd-journal-remote Como se puede ver en el fichero /lib/systemd/system/systemd-journal-remote.socket, el puerto de escucha configurado por defecto es el 19532.\n# SPDX-License-Identifier: LGPL-2.1-or-later # # This file is part of systemd. # # systemd is free software; you can redistribute it and/or modify it # under the terms of the GNU Lesser General Public License as published by # the Free Software Foundation; either version 2.1 of the License, or # (at your option) any later version. [Unit] Description=Journal Remote Sink Socket [Socket] ListenStream=19532 [Install] WantedBy=sockets.target La configuración por defecto del servicio systemd-journal-remote se recoge en el fichero cat /lib/systemd/system/systemd-journal-remote.service.\n# SPDX-License-Identifier: LGPL-2.1-or-later # # This file is part of systemd. # # systemd is free software; you can redistribute it and/or modify it # under the terms of the GNU Lesser General Public License as published by # the Free Software Foundation; either version 2.1 of the License, or # (at your option) any later version. [Unit] Description=Journal Remote Sink Service Documentation=man:systemd-journal-remote(8) man:journal-remote.conf(5) Requires=systemd-journal-remote.socket [Service] ExecStart=/lib/systemd/systemd-journal-remote --listen-https=-3 --output=/var/log/journal/remote/ LockPersonality=yes LogsDirectory=journal/remote MemoryDenyWriteExecute=yes NoNewPrivileges=yes PrivateDevices=yes PrivateNetwork=yes PrivateTmp=yes ProtectProc=invisible ProtectClock=yes ProtectControlGroups=yes ProtectHome=yes ProtectHostname=yes ProtectKernelLogs=yes ProtectKernelModules=yes ProtectKernelTunables=yes ProtectSystem=strict RestrictAddressFamilies=AF_UNIX AF_INET AF_INET6 RestrictNamespaces=yes RestrictRealtime=yes RestrictSUIDSGID=yes SystemCallArchitectures=native User=systemd-journal-remote WatchdogSec=3min # If there are many split up journal files we need a lot of fds to access them # all in parallel. LimitNOFILE=524288 [Install] Also=systemd-journal-remote.socket Para configurar el servicio para que use HTTP en vez de HTTPS se debe cambiar la opción --listen-https=-3 del comando indicado en el parámetro ExecStart del servicio por la opción --listen-http=-3. Sin embargo es conveniente no editar directamente este fichero, sino hacer una copia en otra ubicación para mantener la integridad del fichero original con la configuración del servicio por defecto.\nsudo cp /lib/systemd/system/systemd-journal-remote.service /etc/systemd/system/systemd-journal-remote.service La copia del fichero se puede modificar para adaptar las opciones por defecto.\n# SPDX-License-Identifier: LGPL-2.1-or-later # # This file is part of systemd. # # systemd is free software; you can redistribute it and/or modify it # under the terms of the GNU Lesser General Public License as published by # the Free Software Foundation; either version 2.1 of the License, or # (at your option) any later version. [Unit] Description=Journal Remote Sink Service Documentation=man:systemd-journal-remote(8) man:journal-remote.conf(5) Requires=systemd-journal-remote.socket [Service] ExecStart=/lib/systemd/systemd-journal-remote --listen-http=-3 --output=/var/log/journal/remote/ LockPersonality=yes LogsDirectory=journal/remote MemoryDenyWriteExecute=yes NoNewPrivileges=yes PrivateDevices=yes PrivateNetwork=yes PrivateTmp=yes ProtectProc=invisible ProtectClock=yes ProtectControlGroups=yes ProtectHome=yes ProtectHostname=yes ProtectKernelLogs=yes ProtectKernelModules=yes ProtectKernelTunables=yes ProtectSystem=strict RestrictAddressFamilies=AF_UNIX AF_INET AF_INET6 RestrictNamespaces=yes RestrictRealtime=yes RestrictSUIDSGID=yes SystemCallArchitectures=native User=systemd-journal-remote WatchdogSec=3min # If there are many split up journal files we need a lot of fds to access them # all in parallel. LimitNOFILE=524288 [Install] Also=systemd-journal-remote.socket Por último, se puede habilitar y activar el servicio para que el servidor empiece a recibir los logs de los equipos de la red.\nsudo systemctl enable systemd-journal-remote.service sudo systemctl start systemd-journal-remote.service El componente systemd-journal-remote genera en el directorio configurado en el fichero de configuración de la unidad de systemd un fichero de log para cada cliente de la red.\ndebian@debian12:~$ ls -l /var/log/journal/remote/ total 24580 -rw-r----- 1 systemd-journal-remote systemd-journal-remote 25165824 Jan 17 09:09 remote-10.0.0.57.journal Para ver el contenido de los logs se puede usar el comando journalctl que permite leer los logs de un fichero o directorio.\nConfiguración de journald usando HTTPS Para configurar un servidor de recolección centralizada de logs usando journald a través de HTTPS es necesario contar con una autoridad certificadora que firme los certificados tanto del servidor como de los clientes cuyos ficheros de log recolecta.\nCreación y firma de certificados Para la creación y firma de los certificados se usa la herramienta Easy-RSA. Esta herramienta se instala desde los repositorios de Debian con el paquete easy-rsa.\napt update apt install easy-rsa Para poder configurar la Autoridad Certificadora se parte del fichero /usr/share/easy-rsa/vars.example.\ncp /usr/share/easy-rsa/vars.example /usr/share/easy-rsa/vars En este fichero se editan los campos necesarios para cumplimentar la información tanto de la Autoridad Certificadora como de los diferentes certificados de cada una de las máquinas del escenario.\nset_var EASYRSA_REQ_COUNTRY \u0026#34;ES\u0026#34; set_var EASYRSA_REQ_PROVINCE \u0026#34;Andalucia\u0026#34; set_var EASYRSA_REQ_CITY \u0026#34;Dos Hermanas\u0026#34; set_var EASYRSA_REQ_ORG \u0026#34;JaviHueteCA\u0026#34; A continuación, la herramienta Easy-RSA permite inicializar un nuevo directorio de la Autoridad Certificadora en el que se trabajará para generar y firmar de forma sencilla los diferentes certificados necesarios, así como crear la Autoridad Certificadora a partir de la configuración especificada.\n./easyrsa init-pki ./easyrsa build-ca Tanto el servidor, luffy como cada cliente necesitan una clave privada y un certificado. La solicitud de certificados también se puede generar con Easy-RSA. Para evitar problemas de desencriptación de la clave privada en la configuración tanto de los clientes como del servidor de recolección de ficheros de log, las solicitudes de certificado se generan con la opción nopass, que crea una clave privada sin frase de paso a la que systemd podrá acceder sin problema para identificar a los clientes frente al servidor y viceversa de forma segura.\n./easyrsa gen-req luffy nopass ./easyrsa gen-req nami nopass ./easyrsa gen-req sanji nopass ./easyrsa gen-req zoro nopass Esta misma herramienta también facilita la firma de estos certificados por parte de la CA.\n./easyrsa sign-req server luffy ./easyrsa sign-req server nami ./easyrsa sign-req server sanji ./easyrsa sign-req server zoro Tras firmar los certificados, cada máquina del escenario debe contar con los siguientes ficheros:\nEl certificado autofirmado de la Autoridad Certificadora (cacert.pem) Una clave privada (máquina.key) Un certificado firmado por la CA (máquita.crt) Estos ficheros se pasan desde el equipo en el que se han creado y firmado, en este caso el servidor luffy, al resto de equipos de la red.\nscp pki/ca.crt usuario@nami:/home/usuario scp pki/ca.crt usuario@sanji:/home/usuario scp pki/ca.crt usuario@zoro:/home/usuario scp pki/private/nami.key usuario@nami:/home/usuario scp pki/private/sanji.key usuario@sanji:/home/usuario scp pki/private/zoro.key usuario@zoro:/home/usuario scp pki/issued/nami.crt usuario@nami:/home/usuario scp pki/issued/sanji.crt usuario@nami:/home/usuario scp pki/issued/zoro.crt usuario@zoro:/home/usuario En el servidor, se recomienda ubicar estos ficheros en el directorio /etc/ssl/. En él, la clave se guarda en el directorio private/ y los certificados, tanto del servidor como de la CA en el directorio certs/.\ncp pki/ca.crt /etc/ssl/certs/ cp pki/private/luffy.key /etc/ssl/certs/ cp pki/issued/luffy.crt /etc/ssl/private/ Configuración del servidor En este escenario, luffy funciona como servidor de logs para el resto de máquinas de la red. Así, la configuración del servidor se realiza en esta máquina. En el servidor hay que instalar el componente de systemd que permite centralizar el registro de logs de los equipos de la red a través de journald.\nsudo apt update sudo apt install systemd-journal-remote En el fichero /lib/systemd/system/systemd-journal-remote.socket se define el puerto de escucha del servidor. En este caso, el 19532, el puerto de escucha por defecto.\n[Socket] ListenStream=19532 Igualmente, en el fichero /lib/systemd/system/systemd-journal-remote.service se recoge la configuración del servicio. Como en este escenario los clientes deben usar HTTPS para enviar sus logs al servidor, en este fichero de configuración el parámetro ExecStart debe incluir la opción --listen-https=-3.\n[Service] ExecStart=/lib/systemd/systemd-journal-remote --listen-https=-3 --output=/var/log/journal/remote/ Finalmente, para configurar la conexión HTTPS entre el servidor y los clientes se edita el fichero /etc/systemd/journal-remote.conf en el que hay que indicar la ruta a los ficheros del certificado tanto de la CA como del servidor, junto a la ruta a la clave privada del servidor.\n[Remote] # Seal=false # SplitMode=host ServerKeyFile=/etc/ssl/private/luffy.key ServerCertificateFile=/etc/ssl/certs/luffy.crt TrustedCertificateFile=/etc/ssl/certs/ca.crt Para garantizar el correcto funcionamiento del servidor es necesario verificar que el usuario systemd-journal-remote puede acceder a los certificados y la clave privada. En este caso, ha sido necesario cambiar el grupo de los certificados y el propietario del directorio /etc/ssl/private en el que está la clave privada.\nchown root:systemd-journal-remote /etc/ssl/certs/luffy.crt chown root:systemd-journal-remote /etc/ssl/certs/ca.crt chown -R systemd-journal-remote: /etc/ssl/private Para aplicar la configuración se reinicia el servicio y para hacer que se ejecuta tras cada reinicio de la máquina, se habilita.\nsystemctl start systemd-journal-remote.service systemctl enable systemd-journal-remote.service Configuración de los clientes Para que el resto de equipos de la red pueda funcionar como clientes del servidor de logs necesita tener instalada la utilidad systemd-journal-upload, que se incluye en el paquete systemd-journal-remote.\nsudo apt update sudo apt install systemd-journal-remote La configuración de los clientes del escenario es mucho más sencilla. El fichero de configuración más relevante es /etc/systemd/journal-upload.conf, que recoge la dirección del servidor al que los clientes deben enviar los logs junto al puerto de escucha configurado en el servidor. Además, en esta configuración también se apunta a los certificados, tanto del cliente como de la Autoridad Certificadora, así como a la clave privada del cliente.\n[Upload] URL=https://luffy.javi.gonzalonazareno.org:19532 ServerKeyFile=/etc/ssl/private/nami.key ServerCertificateFile=/etc/ssl/certs/nami.crt TrustedCertificateFile=/etc/ssl/certs/ca.crt Para que el servicio se puede ejecutar correctamente, es necesario establecer una pequeña modificación en el fichero de la unidad de systemd que define el servicio. En /lib/systemd/system/systemd-journal-upload.service se cambia el parámetro DynamicUser a no y en el parámetro User hay que corregir el usuario de systemd-journal-upload, que no se instala al instalar el paquete a systemd-journal-remote.\n[Service] DynamicUser=no ... User=systemd-journal-remote Otra alternativa para solucionar este error es crear el usuario systemd-journal-upload sin permisos para iniciar sesión.\nAdemás, es fundamental que el usuario que ejecuta el servicio, en este caso systemd-journal-remote, tenga los permisos necesarios para acceder a todos los ficheros a los que se apunta desde la configuración.\nchown systemd-journal-remote: /etc/ssl/certs/zoro.crt chown systemd-journal-remote: /etc/ssl/certs/ca.crt chown -R systemd-journal-remote: /etc/ssl/private La misma configuración se replica en el resto de clientes de la red, de manera que, una vez que se ha configurado el servicio tanto en el servidor como en todos los clientes el directorio configurado en el servidor para almacenar los logs de la red contiene un fichero de log para cada uno de los clientes.\nusuario@luffy:~$ ls -l /var/log/journal/remote/ total 40972 -rw-r----- 1 systemd-journal-remote systemd-journal-remote 16777216 Jan 24 18:01 remote-172.16.0.200.journal -rw-r----- 1 systemd-journal-remote systemd-journal-remote 16777216 Jan 24 18:17 remote-192.168.0.2.journal -rw-r----- 1 systemd-journal-remote systemd-journal-remote 8388608 Jan 24 19:00 remote-192.168.0.3.journal Comprobación del funcionamiento Para verificar que los clientes envían correctamente sus registros de log al servidor se genera un mensaje manualmente usando la herramienta logger desde uno de ellos.\nlogger Mensaje escrito manualmente En el servidor se leen los ficheros de log registrados.\njournalctl -D /var/log/journal/remote/ Y, entre los logs recibidos, aparece el mensaje escrito en los logs del cliente.\n1 2 3 4 5 6 7 Jan 24 08:37:28 nami systemd[2194]: Reached target Main User Target. Jan 24 08:37:28 nami systemd[2194]: Startup finished in 44ms. Jan 24 08:37:28 nami systemd[1]: Started Session 244 of User usuario. Jan 24 08:37:43 nami usuario[2218]: Mensaje escrito manualmente Jan 24 08:37:50 nami sshd[2209]: Received disconnect from 192.168.0.1 port 4575\u0026gt; Jan 24 08:37:50 nami sshd[2209]: Disconnected from user usuario 192.168.0.1 por\u0026gt; Jan 24 08:37:50 nami sshd[2191]: pam_unix(sshd:session): session closed for use\u0026gt; Fuentes How To Centralize Logs With Journald on Debian 10\nHow to configure systemd journal-remote?\nsystemd-journal-remote using HTTPS \u0026amp; TrustedCertificateFile neither requires nor verifies client certificates\nIntroduction to the Systemd journal\nsystemd (Español)/Journal (Español)\nSYSTEMD-JOURNAL-REMOTE(8)\nHow to configure systemd journal remote logging "},{
  "section": "Blog",
  "slug": "/blog/servicios/2025-01-16-instalaci-configuracion-dns-bind9/",
  "title": "Instalación y configuración de un servidor DNS con Bind9",
  "description": "",
  "date": "January 16, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "servicios",
  "tags": "dns, bind9, Debian, Administración de Sistemas, servicios, Servicios de Red e Internet",
  "content":"El servidor Bind9 es uno de los servidores DNS más usados. Aunque todos los proveedores de Internet cuentan con servidores DNS para permitir la navegación usando direcciones URL por Internet, en muchas ocasiones puede ser interesante contar con un servidor DNS configurado para la resolución de nombres en la red local.\nInstalación y configuración básica de Bind9 En este post se usa una máquina que se llama dns1.javi.org para instalar y configurar el servidor DNS. Para darle el FQDN a la máquina se añade una línea en el fichero /etc/hosts.\n127.0.1.1\tdns1.javi.org dns1 Para instalar el servidor DNS se usa el gestor de paquetes apt.\nsudo apt install bind9 Configuración básica de bind9 Aunque la configuración por defecto de bind9 permite usar el servidor DNS desde el momento en el que se instala, se pueden modificar algunos parámetros como, por ejemplo, el parámetro options del fichero /etc/default/named para evitar la resolución de direcciones IPv6.\nOPTIONS=\u0026#34;-4 -f -u bind\u0026#34; Como bind9 sólo acepta consultas desde la red local por defecto, para poder usarlo en entornos como OpenStack, donde se usan IP flotantes o para poder consultar usando una conexión a través de una VPN, se debe modificar el parámetro allow-query del fichero /etc/bind/named.conf.options.\nallow-query {172.201.0.0/16; 172.22.0.0/16;}; Para que el servidor funcione correctamente en este entorno, también es necesario desactivar el sistema de seguridad dnssec-validation en este fichero.\ndnssec-validation no; Prueba de funcionamiento Para comprobar el funcionamiento del servidor DNS se consulta la resolución del nombre de dominio de una web, por ejemplo, \u0026ldquo;www.marca.es\u0026rdquo;.\n❯ dig @172.22.201.193 www.marca.es ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.18.28-1~deb12u2-Debian \u0026lt;\u0026lt;\u0026gt;\u0026gt; @172.22.201.193 www.marca.es ; (1 server found) ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 40638 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 1232 ; COOKIE: edae20696a6fbaf9010000006784c4660eddb44059fca349 (good) ;; QUESTION SECTION: ;www.marca.es.\tIN\tA ;; ANSWER SECTION: www.marca.es.\t256\tIN\tA\t193.110.128.199 ;; Query time: 132 msec ;; SERVER: 172.22.201.193#53(172.22.201.193) (UDP) ;; WHEN: Mon Jan 13 08:43:27 CET 2025 ;; MSG SIZE rcvd: 85 La consulta ha tardado 132 milisegundos. Para averiguar la IP de www.marca.es el servidor ha consultado, primero, a un servidor DNS raíz (.); después al servidor con autoridad sobre la zona .es.; y, por último, al servidor con autoridad sobre la zona marca.es..\n❯ dig @172.22.201.193 www.marca.es ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.18.28-1~deb12u2-Debian \u0026lt;\u0026lt;\u0026gt;\u0026gt; @172.22.201.193 www.marca.es ; (1 server found) ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 39396 ;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 1232 ; COOKIE: b6936c508548bcc9010000006784c4f0c6a5c63c576d6598 (good) ;; QUESTION SECTION: ;www.marca.es.\tIN\tA ;; ANSWER SECTION: www.marca.es.\t118\tIN\tA\t193.110.128.199 ;; Query time: 4 msec ;; SERVER: 172.22.201.193#53(172.22.201.193) (UDP) ;; WHEN: Mon Jan 13 08:45:45 CET 2025 ;; MSG SIZE rcvd: 85 Al volver a realizar la consulta sólo tarda 4 milisegundos. Esto se debe a que el servidor DNS ha guardado la información en la caché y, por tanto, para resolver la dirección IP en este caso sólo ha tenido que consultar sus propios registros.\nConfiguración de una zona directa de dominio en el servidor DNS Para crear una zona directa para un dominio en bind9 se define la zona en el fichero /etc/bind/named.conf.local.\nzone \u0026#34;javi.org\u0026#34; { type master; file \u0026#34;db.javi.org\u0026#34;; } A continaución se crea el fichero de zona en el directorio /var/cache/bind a partir de la plantilla /etc/bind/db.empty.\ndebian@dns1:~$ sudo cp /etc/bind/db.empty /var/cache/bind/db.javi.org debian@dns1:~$ sudo nano /var/cache/bind/db.javi.org Con el siguiente contenido:\n$TTL\t86400 @\tIN\tSOA\tdns1.javi.org. root.javi.org. ( 1\t; Serial 604800\t; Refresh 86400\t; Retry 2419200\t; Expire 86400 )\t; Negative Cache TTL ; @\tIN\tNS\tdns1.javi.org. @\tIN\tMX\t10\tcorreo.javi.org. $ORIGIN javi.org. dns1\tIN\tA\t172.22.201.193 correo\tIN\tA\t172.22.200.101 asterix\tIN\tA\t172.22.200.102 obelix\tIN\tA\t172.22.200.103 www\tIN\tCNAME\tasterix informatica\tIN\tCNAME\tasterix ftp\tIN\tCNAME\tobelix Configuración de una zona inversa en el DNS Esta zona también se declara en el fichero /etc/bind/named.conf.local.\nzone \u0026#34;22.172.in-addr.arpa\u0026#34; { type master; file \u0026#34;db.172.22.0.0\u0026#34;; } En este fichero también se descomenta la línea\ninclude \u0026#34;/etc/bind/zones.rfc1918\u0026#34;; Esto evita que el DNS intente hacer la resolución inversa de las IP privadas preguntando a un servidor raíz.\nAdemás, en el fichero /etc/bind/zones.rfc1918 hay que comentar la línea referente a la IP privada de la red cuyas direcciones sí debe resolver el servidor DNS.\n//zone \u0026#34;22.172.in-addr.arpa\u0026#34; { type master; file \u0026#34;/etc/bind/db.empty\u0026#34;; }; Por útlimo, se crea el fichero de zona en /var/cache/bind/db.172.22.0.0 a partir de la plantilla en /etc/bind/db.empty.\n$TTL\t86400 @\tIN\tSOA\tdns1.javi.org. root.javi.org. ( 1\t; Serial 604800\t; Refresh 86400\t; Retry 2419200\t; Expire 86400 )\t; Negative Cache TTL ; @\tIN\tNS\tdns1.javi.org. $ORIGIN 22.172.in-addr.arpa. 193.201\tIN\tPTR\tdns1.javi.org. 101.200\tIN\tPTR\tcorreo.javi.org. 102.200\tIN\tPTR\tasterix.javi.org. 103.200\tIN\tPTR\tobelix.javi.org. Demostración del funcionamiento del DNS Consulta de la IP de un servicio ❯ dig www.javi.org ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.18.28-1~deb12u2-Debian \u0026lt;\u0026lt;\u0026gt;\u0026gt; www.javi.org ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 41239 ;; flags: qr aa rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 1232 ; COOKIE: 6e103d4f5bfd34d9010000006784ccff50d9a71428c955be (good) ;; QUESTION SECTION: ;www.javi.org.\tIN\tA ;; ANSWER SECTION: www.javi.org.\t86400\tIN\tCNAME\tasterix.javi.org. asterix.javi.org.\t86400\tIN\tA\t172.22.200.102 ;; Query time: 8 msec ;; SERVER: 172.22.201.193#53(172.22.201.193) (UDP) ;; WHEN: Mon Jan 13 09:20:08 CET 2025 ;; MSG SIZE rcvd: 107 Consulta del servidor DNS con autoridad del dominio ❯ dig NS javi.org. ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.18.28-1~deb12u2-Debian \u0026lt;\u0026lt;\u0026gt;\u0026gt; NS javi.org. ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 22504 ;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 2 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 1232 ; COOKIE: 18e226f3f575cfa3010000006784cd6c22f38adb1d38e17d (good) ;; QUESTION SECTION: ;javi.org.\tIN\tNS ;; ANSWER SECTION: javi.org.\t86400\tIN\tNS\tdns1.javi.org. ;; ADDITIONAL SECTION: dns1.javi.org.\t86400\tIN\tA\t172.22.201.193 ;; Query time: 4 msec ;; SERVER: 172.22.201.193#53(172.22.201.193) (UDP) ;; WHEN: Mon Jan 13 09:21:58 CET 2025 ;; MSG SIZE rcvd: 100 Consulta del servidor de correo del dominio ❯ dig MX javi.org ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.18.28-1~deb12u2-Debian \u0026lt;\u0026lt;\u0026gt;\u0026gt; MX javi.org ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 5583 ;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 2 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 1232 ; COOKIE: 0b5cb5134bc0944b010000006784cdb40b2da6360f48f0b5 (good) ;; QUESTION SECTION: ;javi.org.\tIN\tMX ;; ANSWER SECTION: javi.org.\t86400\tIN\tMX\t10 correo.javi.org. ;; ADDITIONAL SECTION: correo.javi.org.\t86400\tIN\tA\t172.22.200.101 ;; Query time: 4 msec ;; SERVER: 172.22.201.193#53(172.22.201.193) (UDP) ;; WHEN: Mon Jan 13 09:23:09 CET 2025 ;; MSG SIZE rcvd: 104 Consulta de una resolución inversa ❯ dig -x 172.22.200.102 ; \u0026lt;\u0026lt;\u0026gt;\u0026gt; DiG 9.18.28-1~deb12u2-Debian \u0026lt;\u0026lt;\u0026gt;\u0026gt; -x 172.22.200.102 ;; global options: +cmd ;; Got answer: ;; -\u0026gt;\u0026gt;HEADER\u0026lt;\u0026lt;- opcode: QUERY, status: NOERROR, id: 64988 ;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; udp: 1232 ; COOKIE: d7dd86865fb75af6010000006784ce93495573bf53185e65 (good) ;; QUESTION SECTION: ;102.200.22.172.in-addr.arpa.\tIN\tPTR ;; ANSWER SECTION: 102.200.22.172.in-addr.arpa. 86400 IN\tPTR\tasterix.javi.org. ;; Query time: 4 msec ;; SERVER: 172.22.201.193#53(172.22.201.193) (UDP) ;; WHEN: Mon Jan 13 09:26:52 CET 2025 ;; MSG SIZE rcvd: 114 Instalación y configuración de un servidor DNS esclavo Para ofrecer el servicio de DNS en alta disponibilidad dentro de la red local se debe configurar un segundo servidor como servidor DNS esclavo. Para ello, se usa una segunda máquina que, en este caso, se llama dns2.javi.org.\nEn esta máquina también se instala el servidor DNS bind9 y se configura como servidor esclavo.\nPara ello, en primer lugar, se deshabilitan las transferencias de zona en el fichero /etc/bind/named.conf.options\noptions { ... allow-transfer { none; }; ... }; Warning\nEsta configuración se debe hacer, en general, en todos los servidores que no tengan otros servidores esclavos a los que deban transferirles información de sus zonas de dominio.\nEn cambio, en el servidor DNS maestro se debe indicar a qué dirección IP se permite realizar una transferencia de zonas. En este caso, se indica la dirección del servidor esclavo. También se activa la opción que hace que el maestro envíe una notificación a los servidores esclavos cada vez que se actualiza su configuración.\ninclude \u0026#34;/etc/bind/zones.rfc1918\u0026#34;; zone \u0026#34;javi.org\u0026#34; { type master; file \u0026#34;db.javi.org\u0026#34;; allow-transfer { 172.22.200.110; }; notify yes; }; zone \u0026#34;22.172.in-addr.arpa\u0026#34; { type master; file \u0026#34;db.172.22.0.0\u0026#34;; allow-transfer { 172.22.200.110; }; notify yes; }; En el servidor esclavo también se deben definir las zonas que se transfieren desde el servidor maestro y sobra las que el DNS tiene dominio. Con la opción master se indica la dirección IP del servidor maestro desde el que se transfiere la información de las zonas al esclavo.\ninclude \u0026#34;/etc/bind/zones.rfc1918\u0026#34;; zone \u0026#34;javi.org\u0026#34; { type slave; file \u0026#34;db.javi.org\u0026#34;; masters { 172.22.200.100; }; }; zone \u0026#34;22.172.in-addr.arpa\u0026#34; { type slave; file \u0026#34;db.172.22.0.0\u0026#34;; masters { 172.22.200.100; }; };\tEn el servidor DNS maestro también hay que añadir la información del nuevo servidor DNS de la red en el fichero de zona /var/cache/bind/db.javi.org\n$TTL 86400 @ IN SOA dns1.javi.org. root.javi.org. ( 1 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 86400 ) ; Negative Cache TTL ; @\tIN\tNS\tdns1.javi.org. @\tIN\tNS\tdns2.javi.org. @\tIN\tMX\t10\tcorreo.javi.org. $ORIGIN javi.org. dns1\tIN\tA\t172.22.200.100 dns2\tIN\tA\t172.22.200.110 Y también en el fichero de zona de resolución inversa.\n$TTL 86400 @ IN SOA dns1.javi.org. root.javi.org. ( 1 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 86400 ) ; Negative Cache TTL ; @\tIN\tNS\tdns1.javi.org. @\tIN\tNS\tdns2.javi.org. $ORIGIN 22.172.in-addr.arpa. 100.200\tIN\tPTR\tdns1.javi.org. 110.200\tIN\tPTR\tdns2.javi.org. Cada vez que se modifique la información de la zona sobre la que tiene autoridad el servidor DNS maestro se debe aumentar el número de serie del fichero de configuración de zona. De esta forma, el servidor DNS esclavo actualizará sus registros para que sean idénticos a los del maestro.\nConfiguración de una subdelegación de dominio El primer paso para configurar la delegación de un subdominio a un servidor DNS diferente al servidor DNS del dominio principal es añadir al fichero de zona del dominio principal las líneas necearias para realizar la delegación del subdominio.\n$ORIGIN informatica.javi.org. @ IN NS dns3 dns3 IN A 172.22.200.203 Después, en el servidor DNS delegado se debe crear, primero, la configuración básica del servidor DNS en el fichero /etc/bind/named.conf.local.\nzone \u0026#34;informatica.javi.org\u0026#34; { type master; file \u0026#34;db.informatica.javi.org\u0026#34;; }; Y, a continuación, hay que crear también el fichero de zona /var/cache/bind/db.informatica.javi.org\n$TTL 86400 @ IN SOA dns.informatica.javi.org. root.informatica.javi.org. ( 1 ; Serial 604800 ; Refresh 86400 ; Retry 2419200 ; Expire 86400 ) ; Negative Cache TTL ; @ IN NS dns.informatica.javi.org. @ IN MX 10 mail.informatica.javi.org. $ORIGIN informatica.javi.org. dns3 IN A 172.22.200.203 mail IN A 172.22.200.201 web IN A 172.22.200.202 www IN CNAME web "},{
  "section": "Blog",
  "slug": "/blog/seguridad/2025-01-14-autentificacion-con-gpg/",
  "title": "Autentificación SSH con cifrado asimétrico usando GPG",
  "description": "",
  "date": "January 14, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "seguridad",
  "tags": "cifrado, criptografía, GPG, autentificación, ssh, seguridad, Administración de Sistemas, Seguridad y Alta Disponibilidad",
  "content":"Para que la conexión entre cliente y servidor por SSH sea más ágil y rápida, se usa un cifrado simétrico. Sin embargo, para que una conexión con cifrado simétrico sea segura es necesario que ambos interlocutores negocien una clave simétrica usando una conexión segura.\nEl primer paso para establecer una conexión SSH es que el cliente inicie la conexión con el servidor. Cuando esto ocurre el servidor envía un mensaje aleatorio al cliente cifrado con su clave pública. El cliente debe desencriptar este mensaje con la clave privada del usuario y devolverlo al servidor. El servidor compara el mensaje con el enviado y, si es igual, se verifica la identidad del cliente y se establece la conexión. A partir de este momento, el cifrado de la conexión ya es simétrico.\nEn una conexión SSH la criptografía asimétrica se usa únicamente para verificar la identidad del cliente y negociar una clave simétrica.\nLa criptografía simétrica se usa para encriptar el resto de comunicaciones que se producen en ambas direcciones entre cliente y servidor durante la conexión.\nCuando se usa la autentificación por contraseña en una conexión SSH, tras establecer una conexión segura con el servidor remoto, el cliente envía su nombre de usuario y contraseña al servidor remoto para establecer la autentificación. Estas credenciales se comparten a través de un túnel seguro que usa criptografía simétrica entre ambos interlocutores de la comunicación. El servidor verifica las credenciales en su base de datos y, si las encuentra, autentifica al cliente y le permite establecer la comunicación con el servidor.\nCuando se usa la autentificación asimétrica con un par de claves pública y privada, tras establecer la conexión segura con el servidor el cliente comunica el par de claves con el que se quiere identificar frente al servidor. El servidor verifica entonces si existe ese par de claves en su base de datos, generalmente, en el fichero authorized_keys y envía un mensaje encriptado al cliente. El cliente debe desencriptar este mensaje con su clave privada y genera un hash que se devuelve al servidor. Entonces el servidor genera su propio hash y lo compara con el recibido desde el cliente. Si ambas cadenas coinciden, se verifica la autenticidad del cliente y se le permite establecer la comunicación con el servidor.\nEn el fichero ~/.ssh/known_hosts del cliente se almacenan las huellas de los servidores con los que se ha establecido alguna conexión usando el protocolo SSH. Estas claves son identificadores únicos para cada servidor SSH y permiten que el cliente verifique que el servidor al que se está conectando es el servidor al que verdaderamente tiene intención de conectarse.\nEl mensaje que aparece la primera vez que un cliente se conecta a un servidor SSH avisa de que la autenticidad del host no puede se demostrada, es decir, indica que no hay constancia de que el servidor al que el cliente se está conectando sea el servidor que realmente dice ser.\nJunto a esta advertencia, el mensaje muestra también la huella del servidor SSH, que permite identificarlo de forma única e inequívoca. Tras aportar esta información, se pregunta al usuario si está seguro de continuar con la conexión.\nPara contestar a esta pregunta es necesario tener en cuenta varios factores. El primero de ellos es si es la primera vez que se establece una conexión con ese servidor. Si es la primera conexión SSH al equipo, es normal que aparezca este mensaje puesto que la huella del servidor no se ha podido almacenar aún en el fichero known_hosts del cliente. Para verificar la identidad del servidor hay que comprobar que el fingerprint que se muestra en el mensaje realmente coincide con el del servidor.\nEn cambio, si no es la primera vez que se conecta por SSH a esta máquina, la situación puede ser más delicada. Por una parte este mensaje puede ser totalmente inofensivo si se produce porque algún administrador ha cambiado el par de claves del servidor. Sin embargo, puede ser una situación peligrosa para la integridad de la información que se comparte durante la conexión si el mensaje es resultado de una suplantación del servidor SSH. De esta forma, si un servidor SSH suplanta la dirección IP del servidor al que el cliente se intenta conectar, el protocolo de conexión identificará que la huella del servidor no está almacenada en el fichero known_hosts y, por tanto, mostrará esta advertencia. En este caso, se debe contestar negativamente a la pregunta e interrumpir el intento de conexión.\nUn mensaje de advertencia aparece cuando la huella del servidor SSH al que el cliente se está intentando conectar es diferente a la huella del servidor al que se conectó en la misma dirección IP la última vez.\nEsta advertencia se muestra cuando la identificación del equipo remoto cambia respecto a la última conexión a la misma dirección IP. El mensaje explica que esta situación se puede deber a una suplantación de la dirección IP del servidor con el que se pretende establecer la conexión SSH o que puede ser consecuencia de un cambio en la clave del servidor.\nPara que se produzca este mensaje, es necesario que la revisión estricta esté configurada en el servicio SSH.\nPara solventar el problema y poder conectar por SSH al servidor se proponen dos opciones. Por una parte, revisar que, efectivamente, la clave del servidor que está almacenada en el fichero ~/.ssh/known_hosts es la correcta. En el caso de que se haya reutilizado una IP flotante, la solución pasa por borrar la línea del fichero de known_hosts que hace referencia a la huella asociada a la IP flotante reutilizada. Esto se puede hacer con el comando que propone el propio mensaje de advertencia: ssh-keyge -f ~/.ssh/known_hosts -R \u0026lt;Dirección IP\u0026gt;.\nEn el fichero ~/.ssh/authorized_keys de una máquina se almacenan las claves públicas de los clientes que pueden conectarse a ella por SSH. Durante el establecimiento de la conexión SSH, el servidor usa estas claves públicas para cifrar los mensajes que permiten verificar la autenticidad de los clientes que se intentan conectar a él por el procedimiento que se ha descrito en los apartados 1 y 2 de esta tarea.\n"},{
  "section": "Blog",
  "slug": "/blog/seguridad/2025-01-14-certificado-http-ssl/",
  "title": "Certificado HTTP y SSL",
  "description": "",
  "date": "January 14, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "seguridad",
  "tags": "cifrado, criptografía, CA, Autirodad Certificadora, HTTPS, SSL, seguridad, Administración de Sistemas, Seguridad y Alta Disponibilidad",
  "content":"Autoridad Certificadora (CA) y certificado autofirmado Para la creación de una autoridad certificadora, en primer lugar se debe crear un directorio con el esquema de directorios y documentos necesarios para poder configurar la autoridad certificadora.\n❯ mkdir CA mkdir: se ha creado el directorio \u0026#39;CA\u0026#39; ❯ mkdir CA/{certsdb,certreqs,crl,private} mkdir: se ha creado el directorio \u0026#39;CA/certsdb\u0026#39; mkdir: se ha creado el directorio \u0026#39;CA/certreqs\u0026#39; mkdir: se ha creado el directorio \u0026#39;CA/crl\u0026#39; mkdir: se ha creado el directorio \u0026#39;CA/private\u0026#39; ❯ chmod 700 CA/private/ ❯ touch CA/index.txt Así, la estructura de directorios necesaria para la creación de la autoridad certificadora es la siguiente:\n❯ tree CA CA ├── certreqs ├── certsdb ├── crl ├── index.txt └── private 5 directories, 1 file Para configurar la autoridad certificadora se puede partir del fichero de configuración de openssl que ya está en el sistema. Este fichero puede estar en varios directorios. En este caso, se encuentra en /etc/ssl/openssl.cnf\n❯ sudo cp /etc/ssl/openssl.cnf . La autoridad certificadora se configura modificando este fichero.\n❯ cat openssl.cnf # # OpenSSL example configuration file. # See doc/man5/config.pod for more info. # # This is mostly being used for generation of certificate requests, # but may be used for auto loading of providers # Note that you can include other files from the main configuration # file using the .include directive. #.include filename # This definition stops the following lines choking if HOME isn\u0026#39;t # defined. HOME\t= ./ # Use this in order to automatically load providers. openssl_conf = openssl_init # Comment out the next line to ignore configuration errors config_diagnostics = 1 # Extra OBJECT IDENTIFIER info: # oid_file = $ENV::HOME/.oid oid_section = new_oids # To use this configuration file with the \u0026#34;-extfile\u0026#34; option of the # \u0026#34;openssl x509\u0026#34; utility, name here the section containing the # X.509v3 extensions to use: # extensions\t= # (Alternatively, use a configuration file that has only # X.509v3 extensions in its main [= default] section.) [ new_oids ] # We can add new OIDs in here for use by \u0026#39;ca\u0026#39;, \u0026#39;req\u0026#39; and \u0026#39;ts\u0026#39;. # Add a simple OID like this: # testoid1=1.2.3.4 # Or use config file substitution like this: # testoid2=${testoid1}.5.6 # Policies used by the TSA examples. tsa_policy1 = 1.2.3.4.1 tsa_policy2 = 1.2.3.4.5.6 tsa_policy3 = 1.2.3.4.5.7 # For FIPS # Optionally include a file that is generated by the OpenSSL fipsinstall # application. This file contains configuration data required by the OpenSSL # fips provider. It contains a named section e.g. [fips_sect] which is # referenced from the [provider_sect] below. # Refer to the OpenSSL security policy for more information. # .include fipsmodule.cnf [openssl_init] # providers = provider_sect # List of providers to load # [provider_sect] # default = default_sect # The fips section name should match the section name inside the # included fipsmodule.cnf. # fips = fips_sect # If no providers are activated explicitly, the default one is activated implicitly. # See man 7 OSSL_PROVIDER-default for more details. # # If you add a section explicitly activating any other provider(s), you most # probably need to explicitly activate the default provider, otherwise it # becomes unavailable in openssl. As a consequence applications depending on # OpenSSL may not work correctly which could lead to significant system # problems including inability to remotely access the system. # [default_sect] # activate = 1 #################################################################### [ ca ] default_ca\t= CA_default\t# The default ca section #################################################################### [ CA_default ] dir\t= ./\t# Where everything is kept certs\t= $dir/certsdb\t# Where the issued certs are kept crl_dir\t= $dir/crl\t# Where the issued crl are kept database\t= $dir/index.txt\t# database index file. #unique_subject\t= no\t# Set to \u0026#39;no\u0026#39; to allow creation of # several certs with same subject. new_certs_dir\t= $certs\t# default place for new certs. certificate\t= $dir/cacert.pem\t# The CA certificate serial\t= $dir/serial\t# The current serial number crldir\t= $dir/crl crlnumber\t= $dir/crlnumber\t# the current crl number # must be commented out to leave a V1 CRL crl\t= $dir/crl.pem\t# The current CRL RANDFILE\t= $dir/private/.rand private_key\t= $dir/private/cakey.pem# The private key x509_extensions\t= usr_cert\t# The extensions to add to the cert copy_extnesions = copy # Comment out the following two lines for the \u0026#34;traditional\u0026#34; # (and highly broken) format. name_opt\t= ca_default\t# Subject Name options cert_opt\t= ca_default\t# Certificate field options # Extension copying option: use with caution. # copy_extensions = copy # Extensions to add to a CRL. Note: Netscape communicator chokes on V2 CRLs # so this is commented out by default to leave a V1 CRL. # crlnumber must also be commented out to leave a V1 CRL. # crl_extensions\t= crl_ext default_days\t= 365\t# how long to certify for default_crl_days= 30\t# how long before next CRL default_md\t= sha1\t# use public key default MD preserve\t= no\t# keep passed DN ordering # A few difference way of specifying how similar the request should look # For type CA, the listed attributes must be the same, and the optional # and supplied fields are just that :-) policy\t= policy_match # For the CA policy [ policy_match ] countryName\t= match stateOrProvinceName\t= match localityName\t= supplied organizationName\t= match organizationalUnitName\t= optional commonName\t= supplied emailAddress\t= optional # For the \u0026#39;anything\u0026#39; policy # At this point in time, you must list all acceptable \u0026#39;object\u0026#39; # types. [ policy_anything ] countryName\t= optional stateOrProvinceName\t= optional localityName\t= optional organizationName\t= optional organizationalUnitName\t= optional commonName\t= supplied emailAddress\t= optional #################################################################### [ req ] default_bits\t= 2048 default_keyfile\t= privkey.pem distinguished_name\t= req_distinguished_name attributes\t= req_attributes x509_extensions\t= v3_ca\t# The extensions to add to the self signed cert req_extensions\t= v3_req # Passwords for private keys if not present they will be prompted for # input_password = secret # output_password = secret # This sets a mask for permitted string types. There are several options. # default: PrintableString, T61String, BMPString. # pkix\t: PrintableString, BMPString (PKIX recommendation before 2004) # utf8only: only UTF8Strings (PKIX recommendation after 2004). # nombstr : PrintableString, T61String (no BMPStrings or UTF8Strings). # MASK:XXXX a literal mask value. # WARNING: ancient versions of Netscape crash on BMPStrings or UTF8Strings. string_mask = nombstr # req_extensions = v3_req # The extensions to add to a certificate request [ req_distinguished_name ] countryName\t= Country Name (2 letter code) countryName_default\t= ES countryName_min\t= 2 countryName_max\t= 2 stateOrProvinceName\t= State or Province Name (full name) stateOrProvinceName_default\t= Andalucia localityName\t= Locality Name (eg, city) localityName_dafault\t= Dos Hermanas 0.organizationName\t= Organization Name (eg, company) 0.organizationName_default\t= JaviHueteCA # we can do this but it is not needed normally :-) #1.organizationName\t= Second Organization Name (eg, company) #1.organizationName_default\t= World Wide Web Pty Ltd organizationalUnitName\t= Organizational Unit Name (eg, section) #organizationalUnitName_default\t= commonName\t= Common Name (e.g. server FQDN or YOUR name) commonName_max\t= 64 emailAddress\t= Email Address emailAddress_max\t= 64 # SET-ex3\t= SET extension number 3 [ req_attributes ] #challengePassword\t= A challenge password #challengePassword_min\t= 4 #challengePassword_max\t= 20 #unstructuredName\t= An optional company name [ usr_cert ] # These extensions are added when \u0026#39;ca\u0026#39; signs a request. # This goes against PKIX guidelines but some CAs do it and some software # requires this to avoid interpreting an end user certificate as a CA. basicConstraints=CA:FALSE # This is typical in keyUsage for a client certificate. # keyUsage = nonRepudiation, digitalSignature, keyEncipherment # PKIX recommendations harmless if included in all certificates. subjectKeyIdentifier=hash authorityKeyIdentifier=keyid,issuer # This stuff is for subjectAltName and issuerAltname. # Import the email address. # subjectAltName=email:copy # An alternative to produce certificates that aren\u0026#39;t # deprecated according to PKIX. # subjectAltName=email:move # Copy subject details # issuerAltName=issuer:copy # This is required for TSA certificates. # extendedKeyUsage = critical,timeStamping crlDistributionPoints = URI:http://www.example.com/example_ca.crl # Same as above, but cert req already has SubjectAltName [ usr_cert_has_san ] basicConstraints = CA:false subjectKeyIdentifier = hash authorityKeyIdentifier = keyid,issuer crlDistributionPoints = URI:http://www.example.com/example_ca.crl [ v3_req ] # Extensions to add to a certificate request #basicConstraints = CA:FALSE #keyUsage = nonRepudiation, digitalSignature, keyEncipherment #subjetctAltName = email:move [ v3_ca ] # Extensions for a typical CA # PKIX recommendation. subjectKeyIdentifier=hash authorityKeyIdentifier=keyid:always,issuer basicConstraints = CA:true # Key usage: this is typical for a CA certificate. However since it will # prevent it being used as an test self-signed certificate it is best # left out by default. # keyUsage = cRLSign, keyCertSign # Include email address in subject alt name: another PKIX recommendation # subjectAltName=email:copy # Copy issuer details # issuerAltName=issuer:copy # DER hex encoding of an extension: beware experts only! # obj=DER:02:03 # Where \u0026#39;obj\u0026#39; is a standard or added object # You can even override a supported extension: # basicConstraints= critical, DER:30:03:01:01:FF crlDistributionPoints = URI:http://www.example.com/example_ca.crl # Same as above, but CA req already has SubjectAltName [ v3_ca_has_san ] subjectKeyIdentifier = hash authorityKeyIdentifier = keyid:always,issuer:always basicConstraints = CA:true crlDistributionPoints = URI:http://www.example.com/example_ca.crl [ crl_ext ] # CRL extensions. # Only issuerAltName and authorityKeyIdentifier make any sense in a CRL. # issuerAltName=issuer:copy authorityKeyIdentifier=keyid:always [ proxy_cert_ext ] # These extensions should be added when creating a proxy certificate # This goes against PKIX guidelines but some CAs do it and some software # requires this to avoid interpreting an end user certificate as a CA. basicConstraints=CA:FALSE # This is typical in keyUsage for a client certificate. # keyUsage = nonRepudiation, digitalSignature, keyEncipherment # PKIX recommendations harmless if included in all certificates. subjectKeyIdentifier=hash authorityKeyIdentifier=keyid,issuer # This stuff is for subjectAltName and issuerAltname. # Import the email address. # subjectAltName=email:copy # An alternative to produce certificates that aren\u0026#39;t # deprecated according to PKIX. # subjectAltName=email:move # Copy subject details # issuerAltName=issuer:copy # This really needs to be in place for it to be a proxy certificate. proxyCertInfo=critical,language:id-ppl-anyLanguage,pathlen:3,policy:foo #################################################################### [ tsa ] default_tsa = tsa_config1\t# the default TSA section [ tsa_config1 ] # These are used by the TSA reply generation only. dir\t= ./demoCA\t# TSA root directory serial\t= $dir/tsaserial\t# The current serial number (mandatory) crypto_device\t= builtin\t# OpenSSL engine to use for signing signer_cert\t= $dir/tsacert.pem # The TSA signing certificate # (optional) certs\t= $dir/cacert.pem\t# Certificate chain to include in reply # (optional) signer_key\t= $dir/private/tsakey.pem # The TSA private key (optional) signer_digest = sha256\t# Signing digest to use. (Optional) default_policy\t= tsa_policy1\t# Policy if request did not specify it # (optional) other_policies\t= tsa_policy2, tsa_policy3\t# acceptable policies (optional) digests = sha1, sha256, sha384, sha512 # Acceptable message digests (mandatory) accuracy\t= secs:1, millisecs:500, microsecs:100\t# (optional) clock_precision_digits = 0\t# number of digits after dot. (optional) ordering\t= yes\t# Is ordering defined for timestamps? # (optional, default: no) tsa_name\t= yes\t# Must the TSA name be included in the reply? # (optional, default: no) ess_cert_id_chain\t= no\t# Must the ESS cert id chain be included? # (optional, default: no) ess_cert_id_alg\t= sha1\t# algorithm to compute certificate # identifier (optional, default: sha1) [insta] # CMP using Insta Demo CA # Message transfer server = pki.certificate.fi:8700 # proxy = # set this as far as needed, e.g., http://192.168.1.1:8080 # tls_use = 0 path = pkix/ # Server authentication recipient = \u0026#34;/C=FI/O=Insta Demo/CN=Insta Demo CA\u0026#34; # or set srvcert or issuer ignore_keyusage = 1 # potentially needed quirk unprotected_errors = 1 # potentially needed quirk extracertsout = insta.extracerts.pem # Client authentication ref = 3078 # user identification secret = pass:insta # can be used for both client and server side # Generic message options cmd = ir # default operation, can be overridden on cmd line with, e.g., kur # Certificate enrollment subject = \u0026#34;/CN=openssl-cmp-test\u0026#34; newkey = insta.priv.pem out_trusted = apps/insta.ca.crt # does not include keyUsage digitalSignature certout = insta.cert.pem [pbm] # Password-based protection for Insta CA # Server and client authentication ref = $insta::ref # 3078 secret = $insta::secret # pass:insta [signature] # Signature-based protection for Insta CA # Server authentication trusted = $insta::out_trusted # apps/insta.ca.crt # Client authentication secret = # disable PBM key = $insta::newkey # insta.priv.pem cert = $insta::certout # insta.cert.pem [ir] cmd = ir [cr] cmd = cr [kur] # Certificate update cmd = kur oldcert = $insta::certout # insta.cert.pem [rr] # Certificate revocation cmd = rr oldcert = $insta::certout # insta.cert.pem Por último hay que crear la autoridad certificadora. Para ello se necesita un par de claves.\n❯ openssl req -new -newkey rsa:2048 -keyout private/cakey.pem -out careq.pem -config ./openssl.cnf .........+.....+......+......+.+.........+.....+...+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*....+..+...+.+........+.+..+...+.......+........+.+.....+...+.+.....+......+...+.......+...+..+....+............+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*..........+...+.............................+..........+...+.....+....+.........+..+.........+......+.......+..+....+.....+.+...+...+........+.+...+...........+..........+..+....+...+..+.+........+.+..............+......+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ .......+..+...............+......+...+............+..................+.......+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*........+....+..+.+........+...............+.......+..+..........+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*............+.........+.+.....+.........+......+....+..+.+.....+...+.+...+..+.+........+......+..........+...+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ Enter PEM pass phrase: Verifying - Enter PEM pass phrase: ----- You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Country Name (2 letter code) [ES]: State or Province Name (full name) [Sevilla]: Locality Name [Dos Hermanas]: Organization Name (eg, company) [JaviHueteCA]: Organizational Unit Name (eg, section) []: Common Name (e.g. server FQDN or YOUR name) []:JaviHuete Email Address []:javi@javihueteca.org El siguiente paso en la creación de la autoridad certificadora es autofirmar la solicitud CSR para crear el certificado CRT de la autoridad.\n❯ openssl ca -create_serial -out cacert.pem -days 365 -keyfile private/cakey.pem -selfsign -extensions v3_ca -config ./openssl.cnf -infiles careq.pem Using configuration from ./openssl.cnf Enter pass phrase for private/cakey.pem: Check that the request matches the signature Signature ok Certificate Details: Serial Number: 03:63:db:72:4f:8c:36:21:62:9a:21:2c:e8:2d:9a:40:b9:2a:35:71 Validity Not Before: Jan 9 11:23:27 2025 GMT Not After : Jan 9 11:23:27 2026 GMT Subject: countryName = ES stateOrProvinceName = Sevilla organizationName = JaviHueteCA commonName = JaviHuete emailAddress = javi@javihueteca.org X509v3 extensions: X509v3 Subject Key Identifier: 1E:36:CD:F9:E7:98:C3:AB:66:61:45:C0:41:78:CF:2A:6C:27:8B:05 X509v3 Authority Key Identifier: 1E:36:CD:F9:E7:98:C3:AB:66:61:45:C0:41:78:CF:2A:6C:27:8B:05 X509v3 Basic Constraints: critical CA:TRUE Certificate is to be certified until Jan 9 11:23:27 2026 GMT (365 days) Sign the certificate? [y/n]:y 1 out of 1 certificate requests certified, commit? [y/n]y Write out database with 1 new entries Database updated Firmar solicitudes de certificados como Autoridad Certificadora (CA) Para firmar una solicitud CSR recibida se descarga en el directorio CA/certreqs.\n❯ openssl ca -config openssl.cnf -out certsdb/pineda.crt -infiles certreqs/server.csr Using configuration from openssl.cnf Enter pass phrase for /home/javi/Dropbox/ASIR/Seguridad/Criptografía/CA/private/cakey.pem: Check that the request matches the signature Signature ok Certificate Details: Serial Number: 03:63:db:72:4f:8c:36:21:62:9a:21:2c:e8:2d:9a:40:b9:2a:35:72 Validity Not Before: Jan 9 11:38:36 2025 GMT Not After : Jan 9 11:38:36 2026 GMT Subject: countryName = ES stateOrProvinceName = Sevilla organizationName = JaviHueteCA commonName = JaviHuete X509v3 extensions: X509v3 Basic Constraints: CA:FALSE X509v3 Subject Key Identifier: 1B:D9:6B:78:1A:76:B7:E4:49:92:A5:AD:6C:38:B2:D0:2F:EA:3C:D0 X509v3 Authority Key Identifier: 1E:36:CD:F9:E7:98:C3:AB:66:61:45:C0:41:78:CF:2A:6C:27:8B:05 Certificate is to be certified until Jan 9 11:38:36 2026 GMT (365 days) Sign the certificate? [y/n]:y 1 out of 1 certificate requests certified, commit? [y/n]y Write out database with 1 new entries Database updated Este comando genera un certificado firmado con la extensión .crt en el directorio CA/certsdb. Este certificado se envía al solicitante junto con el certificado autofirmado de la autoridad certificadora.\nConfiguración de un servidor web con un certificado HTTPS Solicitud del certificado Para poder configurar de forma adecuada su servidor web se necesita el certificado firmado por la Autoridad Certificadora (CA) y el certificado autofirmado de la propia CA.\nPara solicitar un certificado a la CA se debe generar una solicitud de certificado CSR junto a la clave privada asociada a ese certificado o se puede usar una clave privada previamente existente.\n❯ openssl req -newkey rsa:4096 -keyout servidor.key -out servidor.csr ..+......+...+.+...+..+...+......+....+..+.+.....+..........+..+................+..+...+.+......+..+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*.+....+.....+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*....+.................+...+........................+......+......+.+.....+....+...............+...+......+.....................+...+......+..+............+.+.....+.+...+.....+.+......+...........+..................+.+.........+............+....................+.............+......+...+..+.+.........+......+........+.+.....+.........+....+...............+..+...+...............+.............+...+......+........+......+.+......+...+.........+...+...............+..............+...+.....................+.......+................................+...+............+.......+.....+.........+.....................+...+.+............+.................+.......+...........+..................+....+......+..+............+...............+.+.....+...................+..+....+......+...............+...+..+.+........+....+...+.....+.......+...+....................+.......+...+...+..+.......+......+.....+......+...+......+....+.................+.+.....+.........+......+.........+....+.....+.+........+.+..+....+...+..+.+..+......+.......+.....+.........+.+..+...+...+.+...+..+.............+........+.......+......+.....+.+...+......+.....+.+.........+......+...........+....+...+..+...+..........+......+.....+.......+.....+.......+........+...+....+......+.....+........................+............+.+..+.............+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ ..+.+..............+.+..+......+.+...+...+........+.......+.....+....+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*...+..+....+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++*...+.....+...+.............+.....+...+....+...+...+.....+.......+...+.....+.+.....+...+...+....+.....+....+...............+......+.........+............+.....+.......+..+.+..................+...........+.+.....+...+.+...+.................+............................+...+..+.+...........+.+..+.............+..+......+....+.....+.......+......+...+..+..........+..+..........+...............+........+.........+....+...........+....+.....+....+...............+...+.....+.........+..................................+......+..............+.........+.......+......+..+...+..........+............+..+.+...+......+.........+.....+....+.....+.............+........+......+...+.+.........+............+...........+...+....+............+........+......+.+...+...+........+....+.....+..................+............+...+...+......+.....................+.............+.................+...+....+......+...............+..+...............+..........+...+..+.......+...+...+.........+..+.........+.+.........+.........+......+...........+...+.+..............................+.........+..+......+....+...........+...+.+...........+....+........+......+.+.....+...+.+.........+..+.+............+......+.....+................+...+.....+...+..........+..+...+.........+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ Enter PEM pass phrase: Verifying - Enter PEM pass phrase: ----- You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter \u0026#39;.\u0026#39;, the field will be left blank. ----- Country Name (2 letter code) [AU]:ES State or Province Name (full name) [Some-State]:Sevilla Locality Name (eg, city) []:Dos Hermanas Organization Name (eg, company) [Internet Widgits Pty Ltd]:Certificaciones Pineda Organizational Unit Name (eg, section) []: Common Name (e.g. server FQDN or YOUR name) []:pineda Email Address []: Please enter the following \u0026#39;extra\u0026#39; attributes to be sent with your certificate request A challenge password []: An optional company name []: Este comando utiliza el módulo req de openssl con la opción -newkey, que permite crear tanto la clave pirvada (-keyout) como el CSR (-out) en un único comando.\nLa CA debe devolver tanto el certificado firmado como su propio certificado autofirmado.\nConfiguración HTTPS en Apache2 Para configurar un virtual host en apache2 usando un certificado HTTPS se usa una configuración similar a la siguiente:\n\u0026lt;VirtualHost *:443\u0026gt; ServerAdmin webmaster@localhost DocumentRoot /var/www/html ErrorLog ${APACHE_LOG_DIR}/error.log CustomLog ${APACHE_LOG_DIR}/access.log combined SSLEngine on SSLCertificateFile /ruta/a/javihuete.crt SSLCertificateKeyFile /ruta/a/servidor.key SSLCACertificateFile\t/ruta/a/cacert.pem \u0026lt;FilesMatch \u0026#34;\\.(?:cgi|shtml|phtml|php)$\u0026#34;\u0026gt; SSLOptions +StdEnvVars \u0026lt;/FilesMatch\u0026gt; \u0026lt;Directory /usr/lib/cgi-bin\u0026gt; SSLOptions +StdEnvVars \u0026lt;/Directory\u0026gt; \u0026lt;/VirtualHost\u0026gt; Para que se fuerce la redirección a la versión https del servidor web se establece también la siguiente configuración en el virtual host por defecto.\n\u0026lt;VirtualHost *:80\u0026gt; ServerAdmin webmaster@localhost DocumentRoot /var/www/html RedirectMatch 301 ^/$ https://localhost ErrorLog ${APACHE_LOG_DIR}/error.log CustomLog ${APACHE_LOG_DIR}/access.log combined \u0026lt;/VirtualHost\u0026gt; En el navegador, hay que instalar el certificado de la autoridad certificadora para poder acceder al sitio HTTPS. En el caso de Firefox esto se hace pulsando el botón \u0026ldquo;importar\u0026rdquo; desde el menú de certificados en los ajustes del navegador.\nAl acceder al servidor web por HTTPS desde el navegador se muestra un mensaje de error\nEsto se debe a que el servidor web usa un certificado autofirmado cuyo emisor es desconocido para el navegador y, por tanto, no confía en él. Sin embargo, como tenemos confianza en el emisor del certificado, podemos pulsar \u0026ldquo;Aceptar el riesgo y continuar\u0026rdquo;.\nEntonces podemos acceder a la web alojado en el servidor. En la información del a página se muestra que, aunque el sitio web no proporciona información de su dueño, sí está verificado, en este caso, por \u0026ldquo;Certificaciones Pineda\u0026rdquo;.\nConfiguración HTTPS en Nginx Para configurar el servidor web Nginx para servir la página estática usando HTTPS se modifica el fichero por defecto con los siguientes parámetros:\n## # You should look at the following URL\u0026#39;s in order to grasp a solid understanding # of Nginx configuration files in order to fully unleash the power of Nginx. # https://www.nginx.com/resources/wiki/start/ # https://www.nginx.com/resources/wiki/start/topics/tutorials/config_pitfalls/ # https://wiki.debian.org/Nginx/DirectoryStructure # # In most cases, administrators will remove this file from sites-enabled/ and # leave it as reference inside of sites-available where it will continue to be # updated by the nginx packaging team. # # This file will automatically load configuration files provided by other # applications, such as Drupal or Wordpress. These applications will be made # available underneath a path with that package name, such as /drupal8. # # Please see /usr/share/doc/nginx-doc/examples/ for more detailed examples. ## # Default server configuration server { listen 80 default_server; listen [::]:80 default_server; return 301 https://localhost; } server { listen 443 ssl; listen [::]:443 ssl; ssl_certificate /ruta/a/javihuete.crt; ssl_certificate_key /ruta/a/servidor.key; ssl_password_file /ruta/a/password_file; ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers HIGH:!aNULL:!MD5; server_name _; root /var/www/html; index index.html; location / { try_files $uri $uri/ =404; } } Para que funcione la directiva ssl_password_file, que pasa la frase de paso de la clave privada con la que se solicitó el certificado a la autoridad certificadora, hay que crear este fichero y rellenarlo con esta frase de paso.\necho \u0026#34;passphrase\u0026#34; \u0026gt; password_file Con esta configuración, se puede acceder a la web HTTPS alojada en el servidor Nginx.\n"},{
  "section": "Blog",
  "slug": "/blog/seguridad/2025-01-14-criptografia-gpg-openssl/",
  "title": "Cifrado asimétrico con GPG y OpenSSL",
  "description": "",
  "date": "January 14, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "seguridad",
  "tags": "cifrado, criptografía, GPG, OpenSSL, seguridad, Administración de Sistemas, Seguridad y Alta Disponibilidad",
  "content":"Generación de claves Creación de claves con GPG Para generar un par de claves se usa el comando gpg --gen-key:\n❯ gpg --gen-key gpg (GnuPG) 2.2.27; Copyright (C) 2021 Free Software Foundation, Inc. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Nota: Usa \u0026#34;gpg --full-generate-key\u0026#34; para el diálogo completo de generación de clave. GnuPG debe construir un ID de usuario para identificar su clave. Nombre y apellidos: Javi Huete Dirección de correo electrónico: correo@correo.org Está usando el juego de caracteres \u0026#39;utf-8\u0026#39;. Ha seleccionado este ID de usuario: \u0026#34;Javi Huete \u0026lt;correo@correo.org\u0026gt;\u0026#34; ¿Cambia (N)ombre, (D)irección o (V)ale/(S)alir? v Es necesario generar muchos bytes aleatorios. Es una buena idea realizar alguna otra tarea (trabajar en otra ventana/consola, mover el ratón, usar la red y los discos) durante la generación de números primos. Esto da al generador de números aleatorios mayor oportunidad de recoger suficiente entropía. Es necesario generar muchos bytes aleatorios. Es una buena idea realizar alguna otra tarea (trabajar en otra ventana/consola, mover el ratón, usar la red y los discos) durante la generación de números primos. Esto da al generador de números aleatorios mayor oportunidad de recoger suficiente entropía. gpg: clave 6E42360E895488ED marcada como de confianza absoluta gpg: creado el directorio \u0026#39;/home/javi/.gnupg/openpgp-revocs.d\u0026#39; gpg: certificado de revocación guardado como \u0026#39;/home/javi/.gnupg/openpgp-revocs.d/4A914508FF0E1A5087F727166E42360E895488ED.rev\u0026#39; claves pública y secreta creadas y firmadas. pub rsa3072 2024-12-12 [SC] [caduca: 2026-12-12] 4A914508FF0E1A5087F727166E42360E895488ED uid Javi Huete \u0026lt;correo@correo.org\u0026gt; sub rsa3072 2024-12-12 [E] [caduca: 2026-12-12] Las claves se guardan en el fichero pubring.kbx dentro del directorio oculto .gnupg en el home del usuario.\nListar las claves públicas Para listar las claves públicas se usa el comando gpg --list-keys:\n❯ gpg --list-keys /home/javi/.gnupg/pubring.kbx --------------------------------- pub rsa3072 2024-12-12 [SC] [caduca: 2026-12-12] 4A914508FF0E1A5087F727166E42360E895488ED uid [ absoluta ] Javi Huete \u0026lt;correo@correo.org\u0026gt; sub rsa3072 2024-12-12 [E] [caduca: 2026-12-12] La salida de este comando aporta información relevante sobre la clave almacenada. En primer lugar, se muestra el fichero en el que se almacenan las claves.\n/home/javi/.gnupg/pubring.kbx A continuación se recogen los detalles de las claves públicas del usuario. La primera parte de la información hace referencia a la clave pública: pub.\nSe muestra el algoritmo de encriptación y el tamaño de la clave: rsa3072, es decir, una clave que usa el algoritmo de encriptación RSA y que tiene un tamaño de 3072 bits.\nDespués aparece la fecha de creación: 2024-12-12.\nEl siguiente campo indica el uso de la clave: [SC], en este caso se puede usar para firmar (Sign) y certificar (key Certification).\nDespués, se muestra la fecha de caducidad de la clave: [caduca: 2026-12-12].\nY el último campo de esta primera fila es la huella o fingerprint: 4A914508FF0E1A5087F727166E42360E895488ED. Esta huella se puede usar para referirse de forma más corta a la clave que si se muestra completa en formato ASCII contiene cientos de caracteres.\nEn la segunda fila se muestra la información sobre la identificación del usuario asociada a la clave pública: uid.\nDespués se indica el nivel de confianza en la clave: [ absoluta ].\nY también el nombre y correo electrónico del usuario que se han indicado durante la creación de la clave: Javi Huete \u0026lt;correo@correo.org\u0026gt;\nLa tercera parte de la firma recoge la información sobre la subclave de encriptación relacionada con la clave pública: sub.\nEn esta línea se muestra el algoritmo y tamaño de la clave: rsa3072.\nEl uso de la clave: [E], en este caso se puede usar para encriptar comunicaciones y ficheros almacenados.\nY, por último, se indica también la fecha de caducidad: [caduca: 2026-12-12].\nPara establecer un periodo de validez durante la creación de un par de claves se usa el argumento expire del comando gpg --key-gen. Este argumento soporta varios formatos como por ejemplo el formato ISO (YYYY-MM-DD). Así, para hacer que el par de claves caduque en un mes se debería usar el argumento months=1 al ejecutar el comando gpg --key-gen para generar el par de claves.\nListar las claves privadas Para listar las claves privadas se usa el comando gpg --list-secret-keys.\n❯ gpg --list-secret-keys /home/javi/.gnupg/pubring.kbx --------------------------------- sec rsa3072 2024-12-12 [SC] [caduca: 2026-12-12] uid [ absoluta ] Javi Huete \u0026lt;correo@correo.org\u0026gt; ssb rsa3072 2024-12-12 [E] [caduca: 2026-12-12] Importar y exportar claves con GPG Para exportar la clave pública se usa el comando gpg --export.\ngpg --export \u0026gt; javi_huete.asc De la misma forma, para importar una clave pública se usa el comando gpg --import.\n❯ gpg --import juan_pineda.asc gpg: clave 35045657E85B4EAA: clave pública \u0026#34;Juan Pineda\u0026#34; \u0026lt;a@a.com\u0026gt;\u0026#34; importada gpg: Cantidad total procesada: 1 gpg: importadas: 1 Con el comando gpg --list-key se comprueba que la clave pública se ha importado correctamente.\n❯ gpg --list-key /home/javi/.gnupg/pubring.kbx --------------------------------- pub rsa3072 2024-12-12 [SC] [caduca: 2026-12-12] 4A914508FF0E1A5087F727166E42360E895488ED uid [ absoluta ] Javi Huete \u0026lt;correo@correo.org\u0026gt; sub rsa3072 2024-12-12 [E] [caduca: 2026-12-12] pub rsa3072 2024-12-12 [SC] [caduca: 2026-12-12] 1B0B8EA692D1C32493D20E5535045657E85B4EAA uid [desconocida] Juan Pineda \u0026lt;a@a.com\u0026gt; sub rsa3072 2024-12-12 [E] [caduca: 2026-12-12] Cifrado asimétrico con claves públicas Para cifrar un fichero usando la clave pública del destinatario se puede usar el siguiente comando:\n❯ gpg -se -r raulhr fichero.txt gpg: 33DC17FB92D2D65A: No hay seguridad de que esta clave pertenezca realmente al usuario que se nombra sub rsa3072/33DC17FB92D2D65A 2024-12-13 raulhr \u0026lt;raulhr@correo.org\u0026gt; Huella clave primaria: D2B4 66A2 EA5E AFA3 D01E D7C5 F9E5 1736 F896 495A Huella de subclave: F6CD 0599 A6EE C8A1 B6AA D9AF 33DC 17FB 92D2 D65A No es seguro que la clave pertenezca a la persona que se nombra en el identificador de usuario. Si *realmente* sabe lo que está haciendo, puede contestar sí a la siguiente pregunta. ¿Usar esta clave de todas formas? (s/N) s Para descifrar un mensaje recibido que ha sido cifrado usando nuestra clave pública, se usa la opción -d del comando gpg. Para que el contenido del fichero se almacene en un fichero y no sólo se muestre por pantalla es necesario usar también la opción -o.\n❯ gpg -o pokemon.txt -d pokemon.txt.gpg gpg: cifrado con clave de 3072 bits RSA, ID 1129E3EA155B0A3B, creada el 2024-12-13 \u0026#34;Javi Huete \u0026lt;correo@correo.org\u0026gt;\u0026#34; gpg: Firmado el vie 13 dic 2024 13:36:20 CET gpg: usando RSA clave XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX gpg: emisor \u0026#34;raulhr@correo.org\u0026#34; gpg: Firma correcta de \u0026#34;raulhr \u0026lt;raulhr@correo.org\u0026gt;\u0026#34; [desconocido] gpg: ATENCIÓN: ¡Esta clave no está certificada por una firma de confianza! gpg: No hay indicios de que la firma pertenezca al propietario. Huellas dactilares de la clave primaria: XXXX XXXX XXXX XXXX XXXX XXXX Si otra persona recibe el mensaje no lo puede descifrar\n⟩ gpg --decrypt fichero.txt.gpg gpg: cifrado con clave RSA, ID 33DC17FB92D2D65A gpg: descifrado fallido: No secret key Tanto las claves públicas como privadas almacenadas en el keyring se pueden borrar usando el comando gpg. Este comando cuenta con una opción para el borrado de todas las claves públicas y otra para el borrado de todas las claves privadas.\n--delete-keys elimina claves del almacén público --delete-secret-keys elimina claves del almacén privado Exportar clave a un servidor público de claves PGP Para generar una clave de revocación de la clave pública se usa la opción --gen-revoke del comando gpg. Este comando es interactivo y permite añadir al certificado de revocación de la clave pública una razón para la revocación entre una lista y, además, permite añadir también un comentario.\n❯ gpg --gen-revoke \u0026#34;Javi Huete \u0026#34; sec rsa3072/6E42360E895488ED 2024-12-12 Javi Huete \u0026lt;correo@correo.org\u0026gt; ¿Crear un certificado de revocación para esta clave? (s/N) s Por favor elija una razón para la revocación: 0 = No se dio ninguna razón 1 = La clave ha sido comprometida 2 = La clave ha sido reemplazada 3 = La clave ya no está en uso Q = Cancelar (Probablemente quería seleccionar 1 aquí) ¿Su decisión? 0 Introduzca una descripción opcional; acábela con una línea vacía: \u0026gt; Certificado de revocación generado por si aparece algún problema al compartir la clave pública en un servidor de claves \u0026gt; Razón para la revocación: No se dio ninguna razón Certificado de revocación generado por si aparece algún problema al compartir la clave pública en un servidor de claves ¿Es correcto? (s/N) s se fuerza salida con armadura ASCII. -----BEGIN PGP PUBLIC KEY BLOCK----- Comment: This is a revocation certificate iQIwBCABCgCaFiEESpFFCP8OGlCH9ycWbkI2DolUiO0FAmdcEpV8HQBDZXJ0aWZp Y2FkbyBkZSByZXZvY2FjacOzbiBnZW5lcmFkbyBwb3Igc2kgYXBhcmVjZSBhbGfD um4gcHJvYmxlbWEgYWwgY29tcGFydGlyIGxhIGNsYXZlIHDDumJsaWNhIGVuIHVu IHNlcnZpZG9yIGRlIGNsYXZlcwAKCRBuQjYOiVSI7dIOC/9C1hOkkUxkrJN92fUL 6BrqctyIUkkoWeMM9Kx6ihpsFmAYRkBTzHFZ4xZuVGtR5VrzIhQ+amPvZElLnlAO 6TibJ3w/ndrBBR391z0KCSzf0mhGBIo8RdJ/R3i3SScYHCDusRERRcqi5UGIdnp6 QG6lt4Zy0x/9hux/gBhN9t6Rx8J/orW4AQXUwWaA9rvlp5hw+5nqHk62BlTcl3G7 9CWQSPz0wcrNJ/hnNiMNa0XBMh9MI0mKbNT+BTM62l7UITC0C208fIzCULJgUzvw j+GQ594RTCBCV2xrR5vJHAbvHjrIpn7KlLko/z8vwXFBzVuklbKibmwRivfmTOy8 aCdEceyBeryJ/cwaCUshr7OBEDP8MBASBNmrSoW5DT+cTOSqgWF5ZsrG6zA+KmKz 9EG2o2RKjlKOB1WLtfddZcUDH+m2ozBdT9kiemtj1VecSf8bSQe9zSCNtKpndlin 3bzJEHl+ACDyomvFhfr6y6yCkqiTIzIeDT3FQ7z5oggdGQY= =cY5D -----END PGP PUBLIC KEY BLOCK----- Certificado de revocación creado. Por favor consérvelo en un medio que pueda esconder; si alguien consigue acceso a este certificado puede usarlo para inutilizar su clave. Es inteligente imprimir este certificado y guardarlo en otro lugar, por si acaso su medio resulta imposible de leer. Pero precaución: ¡el sistema de impresión de su máquina podría almacenar los datos y hacerlos accesibles a otras personas! Para exportar una clave pública al servidor de claves por defecto de openpgp (hkps://keys.openpgp.org) se usa la opción --send-keys del comando gpg. Con la opción --keyserver se puede especificar también el servidor al que se envía la clave.\n❯ gpg --keyserver pgp.rediris.es --send-keys 4A914508FF0E1A5087F727166E42360E895488ED gpg: enviando clave 6E42360E895488ED a hkp://pgp.rediris.es Para importar una clave pública desde un servidor primero hay que buscar el identificador de la clave con la opción --search-keys del comando gpg.\n❯ gpg --keyserver pgp.rediris.es --search-keys \u0026#34;nombre\u0026#34; gpg: data source: http://130.206.1.8:11371 (1)\tNombre \u0026lt;correo@correo.org\u0026gt; 3072 bit RSA key E68CA61054C58A9E, creado: 2024-12-13, caduca: 2026-12-13 (2)\tPedro (Contraseña CriptoAsimetrica) \u0026lt;nombre@gmail.c 3072 bit RSA key 5252337E783EC15B, creado: 2023-10-17 (3)\tAngelika \u0026lt;nombre@gmail.com\u0026gt; 4096 bit RSA key 2FC32C6A3FE01D57, creado: 2017-04-01, caduca: 2021-04-01 (caducada) (4)\tMarc \u0026lt;marc@gmail.com\u0026gt; 3072 bit RSA key 428D682E205EF071, creado: 2016-07-26 ... (20)\tGINES SANS \u0026lt;GIALBA@santandersupernet.com\u0026gt; 1024 bit DSA key 6E94CCF6237D0F00, creado: 1998-06-28 Keys 12-20 of 20 for \u0026#34;nombre\u0026#34;. Introduzca número(s), O)tro, o F)in \u0026gt; q Con el identificador de la clave se puede importar desde el servidor usando la opción --receive-keys\n❯ gpg --keyserver pgp.rediris.es --receive-keys E68CA61054C58A9E gpg: clave E68CA61054C58A9E: clave pública \u0026#34;Alejandro \u0026lt;alejandro@correo.org\u0026gt;\u0026#34; importada gpg: Cantidad total procesada: 1 gpg: importadas: 1 Cifrado asimétrico con OpenSSL Para generar un par de claves con openssl se usa el comando openssl genrsa.\nPrimero se genera la clave privada.\n❯ openssl genrsa -out javi_huete.pem 2048 Y, a partir de ella, se genera la pública.\n❯ openssl rsa -in javi_huete.pem -pubout -out javi_huete.pub writing RSA key Para cifrar un fichero de texto usando openssl se usa el comando openssl pkeyutl con la opción -encrypt.\n❯ openssl pkeyutl -encrypt -in fichero.txt -out fichero.txt.enc -inkey clav_public_raulhr.pem -pubin Para descifrar el fichero de texto del compañero se usa el comando openssl pkeyutl con la opción -decrypt\n❯ openssl pkeyutl -decrypt -inkey javi_huete.pem -in pikachu.bin -out pikachu.txt Al leer el fichero se puede acceder a su contenido.\n❯ cat pikachu.txt pokemon "},{
  "section": "Blog",
  "slug": "/blog/seguridad/2025-01-14-correo-electronico-cifrado-thunderbird/",
  "title": "Correo electrónico cifrado con Thunderbird",
  "description": "",
  "date": "January 14, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "seguridad",
  "tags": "cifrado, criptografía, GPG, correo electrónico, Thunderbird, seguridad, Administración de Sistemas, Seguridad y Alta Disponibilidad",
  "content":"En este tutorial se muestra cómo configurar el cliente de correo electrónico Mozilla Thunderbird para enviar y recibir correos electrónicos cifrados con un par de claves pública y privada generadas con GPG.\nLos detalles sobre la configuración básica del cliente de correos Thunderbird se omiten en esta entrada. La configuración necesaria para la firma y cifrado de mensajes se detalla a continuación.\nPara configurar el uso del par de claves en un cliente de correos como Thunderbird hay que acceder a la configuración de la cuenta en la aplicación y, a continuación, a la sección de cifrado de extremo a extremo.\nEn esta zona de configuración de la cuenta del cliente de correo electrónico se pueden configurar las herramientas de cifrado OpenPGP o S/MIME. Para usar OpenPGP es necesario importar a la aplicación la clave privada del usuario (o crear un par de claves desde la propia aplicación, si el usuario no cuenta con uno ya).\nPara poder importar la clave privada a la aplicación es necesario exportarla antes. Esto se hace usando la opción --export-secret-key del comando gpg.\n❯ gpg --export-secret-key \u0026gt; private.asc Después, se usa este fichero para importar la clave a Thunderbird.\nTras importar la clave correctamente, ya se puede usar para cifrar y firmar mensajes de correo electrónico enviados desde el cliente Mozilla Thunderbird.\nPara que el cliente de correo electrónico pueda firmar los mensajes según el destinatario, debe contar también con la clave pública del destinatario en su administrador de claves.\nA este almacén de claves se pueden importar las claves públicas de los destinatarios de los mensajes cifrados de varias formas. Una de ellas es exportar las claves del keyring a un fichero e importarlas a partir del fichero al depósito de claves de Thunderbird.\nAl importar cada clave, el cliente de correo Mozilla Thunderbird muestra la información y detalles más relevantes de la clave como su tamaño, fecha de creación y huella digital.\nLas claves públicas importadas se almacenan en el administrador de claves de Thunderbird. A todas las personas cuyas claves estén almacenadas en la aplicación se podrá enviar mensajes cifrados. El destinatario debe tener correctamente configurado el cifrado extremo a extremo en su cliente de correo electrónico para poder leer el mensaje.\nPor ejemplo, si el destinatario intentase acceder al mensaje desde la aplicación web de gmail no podría ver su contenido, sin embargo, sí podría verlo al acceder desde su cliente de correos. En este caso, Thunderbird descifra automáticamente el mensaje al recibirlo.\nAdemás, al enviar mensajes cifrados o, simplemente, firmados, Thunderbird adjunta, de forma automática y por defecto, la clave pública del remitente al mensaje para que el destinatario pueda almacenarla directamente en su almacén de claves de forma cómoda desde la ventana de lectura de ese mismo mensaje.\nEnviar y recibir mensajes cifrados Para enviar un mensaje cifrado sólo hay que marcar el botón \u0026ldquo;cifrar\u0026rdquo; de la ventana de redacción del mensaje de Thunderbird.\nEste mensaje sólo se puede descifrar usando alguna aplicación que tenga acceso a la clave privada del remitente o a la pública del destinatario y que tenga configurada la herramienta de encriptación de OpenPGP, de manera que no se puede acceder a él en ninguna otra aplicación como, por ejemplo gmail.\nPara descifrar un mensaje cifrado recibido no es necesario realizar ninguna acción. El mensaje se mostrará en texto en claro cuando el destinatario lo abra desde un cliente de correo configurado con su clave privada para descifrar mensajes encriptados.\n"},{
  "section": "Blog",
  "slug": "/blog/seguridad/2025-01-14-criptografia-integridad/",
  "title": "Firmas y autenticación con GPG",
  "description": "",
  "date": "January 14, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "seguridad",
  "tags": "cifrado, criptografía, GPG, firma digital, seguridad, Administración de Sistemas, Seguridad y Alta Disponibilidad",
  "content":"Firmas electrónicas con GPG Para firmar un documento:\n❯ gpg --detach-sign ficherofirmado.txt Para verificar que la firma que se ha recibido es correcta:\n❯ gpg --verify doc_p2.txt.sig doc_p2.txt gpg: Firmado el vie 13 dic 2024 14:30:16 CET gpg: usando RSA clave XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX gpg: Firma correcta de \u0026#34;raulhr \u0026lt;raul@correo.org\u0026gt;\u0026#34; [desconocido] gpg: ATENCIÓN: ¡Esta clave no está certificada por una firma de confianza! gpg: No hay indicios de que la firma pertenezca al propietario. Huellas dactilares de la clave primaria: XXXX XXXX XXXX XXXX XXXX XXXX XXXX XXXX Al verificar la firma aparece un mensaje que indica que la firma es correcta pero que procede de un par de calves con un nivel de confianza desconocido y, por tanto, no hay certezas de que la firma pertenezca realmente al propietario que ha firmado el documento.\nPara evitar que aparezca este aviso, se debe indicar un nivel de confianza para la clave pública del remitente del mensaje, de manera que, al verificar la firma, no haya ninguna duda de que el firmante del documento es quien dice ser.\nFirma de claves públcias con GPG Para descargar las claves públicas de otras personas hay que buscar las claves en el servidor y, a continuación, descargarlas.\n❯ gpg --keyserver pgp.rediris.es --search-key kiko@correo.org ❯ gpg --keyserver pgp.rediris.es --recv-key XXXXXXXXXXXXXXX Después, se edita para modificar el nivel de confianza.\n❯ gpg --edit-key XXXXXXXXXXXXXXX gpg (GnuPG) 2.2.27; Copyright (C) 2021 Free Software Foundation, Inc. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. pub rsa3072/XXXXXXXXXXXXXXX creado: 2024-12-13 caduca: 2026-12-13 uso: SC confianza: desconocida validez: desconocida sub rsa3072/XXXXXXXXXXXXXXX creado: 2024-12-13 caduca: 2026-12-13 uso: E [ desconocida ] (1). Kiko \u0026lt;kiko@correo.org\u0026gt; gpg\u0026gt; trust pub rsa3072/XXXXXXXXXXXXXXX creado: 2024-12-13 caduca: 2026-12-13 uso: SC confianza: desconocida validez: desconocida sub rsa3072/XXXXXXXXXXXXXXX creado: 2024-12-13 caduca: 2026-12-13 uso: E [ desconocida ] (1). Kiko \u0026lt;kiko@correo.org\u0026gt; Por favor, decida su nivel de confianza en que este usuario verifique correctamente las claves de otros usuarios (mirando pasaportes, comprobando huellas dactilares en diferentes fuentes...) 1 = No lo sé o prefiero no decirlo 2 = NO tengo confianza 3 = Confío un poco 4 = Confío totalmente 5 = confío absolutamente m = volver al menú principal ¿Su decisión? 5 ¿De verdad quiere asignar absoluta confianza a esta clave? (s/N) s pub rsa3072/XXXXXXXXXXXXXXX creado: 2024-12-13 caduca: 2026-12-13 uso: SC confianza: absoluta validez: absoluta sub rsa3072/XXXXXXXXXXXXXXX creado: 2024-12-13 caduca: 2026-12-13 uso: E [ absoluta ] (1). Kiko \u0026lt;kiko@correo.org\u0026gt; Finalmente, tras firmar la clave, se devuelve a su propietario firmada.\nPor otra parte, cuando la clave propia ha recibido varias firmas de otras personas se vuelve a subir al servidor de claves. Así, cuando alguien la descargue verá que es una clave de confianza sin confía también en alguno de los firmantes.\n❯ gpg --keyserver pgp.rediris.es --send-keys 6E42360E895488ED Para ver las firmas que tiene una clave se usa la opción --list-sigs del comando gpg.\n❯ gpg --list-sig 4A914508FF0E1A5087F727166E42360E895488ED pub rsa3072 2024-12-12 [SC] [caduca: 2026-12-12] 4A914508FF0E1A5087F727166E42360E895488ED uid [ absoluta ] Javi Huete \u0026lt;Javi@correo.org\u0026gt; sig 3 6E42360E895488ED 2024-12-12 Javi Huete \u0026lt;Javi@correo.org\u0026gt; sig XXXXXXXXXXXXXXX 2024-12-13 Kiko \u0026lt;kiko@correo.org\u0026gt; sig XXXXXXXXXXXXXXX 2024-12-15 Juan Pineda \u0026lt;juan@correo.org sig XXXXXXXXXXXXXXX 2024-12-16 Alejandro \u0026lt;alejandro@correo.com\u0026gt; sub rsa3072 2024-12-12 [E] [caduca: 2026-12-12] sig XXXXXXXXXXXXXXX 2024-12-12 Javi Huete \u0026lt;Javi@correo.org\u0026gt; Después de haber firmado la clave pública de otra persona y haber indicado el nivel de confianza como \u0026ldquo;absoluta\u0026rdquo;, la verificación de su firma no devuelve ningún mensaje de advertencia.\n❯ gpg --verify doc_p2.txt.sig doc_p2.txt gpg: Firmado el vie 13 dic 2024 14:30:16 CET gpg: usando RSA clave XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX gpg: Firma correcta de \u0026#34;raulhr \u0026lt;raul@correo.org\u0026gt;\u0026#34; [absoluta] Aunque una clave pública no esté verificada en mi anillo de claves, las claves públicas de quienes han firmado su clave sí tienen mi confianza en el keyring. Así, al verificar la firma de un documento de esta persona, la confianza es \u0026ldquo;total\u0026rdquo; aunque yo no haya firmado su clave.\n❯ gpg --verify validado.txt.sig validado.txt gpg: Firmado el mié 18 dic 2024 08:53:38 CET gpg: usando RSA clave XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX gpg: Firma correcta de \u0026#34;Iván \u0026lt;ivan@correo.org\u0026gt;\u0026#34; [total] "},{
  "section": "Blog",
  "slug": "/blog/seguridad/2025-01-15-integridad-de-ficheros-con-gpg/",
  "title": "Verificar la integridad de ficheros con GPG y apt-secure",
  "description": "",
  "date": "January 14, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "seguridad",
  "tags": "cifrado, criptografía, GPG, integridad de ficheros, Debian, seguridad, Administración de Sistemas, Seguridad y Alta Disponibilidad",
  "content":"Integridad de ficheros con GPG Para verificar las firmas de un archivo como, por ejemplo, la ISO de Debian hay que descargar todos los ficheros que publica la distribución en un mismo directorio. Esto incluye la imagen .iso del sistema operativo, los ficheros SHA256SUMS y SHA512SUMS y los ficheros SHA256SUMS.sign y SHA512SUMSsign.\n❯ ll total 632M -rw-rw-r-- 1 fj_huete fj_huete 631M dic 16 19:34 debian-12.8.0-amd64-netinst.iso -rw-rw-r-- 1 fj_huete fj_huete 302 dic 16 19:34 SHA256SUMS -rw-rw-r-- 1 fj_huete fj_huete 833 dic 16 19:34 SHA256SUMS.sign -rw-rw-r-- 1 fj_huete fj_huete 494 dic 16 19:34 SHA512SUMS -rw-rw-r-- 1 fj_huete fj_huete 833 dic 16 19:35 SHA512SUMS.sign Para garantizar la veracidad del contenido de la imagen iso se usan los comandos sha512sum y sha256sum con la opción -c para leer la suma del contenido de la imagen y verificarla con la que se indica en los ficheros SHA512SUM y SHA256SUM respectivamente.\n❯ sha512sum -c SHA512SUMS --ignore-missing debian-12.8.0-amd64-netinst.iso: La suma coincide ❯ sha256sum -c SHA256SUMS --ignore-missing debian-12.8.0-amd64-netinst.iso: La suma coincide Con esta verificación se comprueba que el contenido del archivo .iso es idéntico al que se ha usado para generar los ficheros de sumas que se encuentran en el directorio público de descargas de la distribución.\nAhora queda por verificar el origen de esos ficheros comprobando que la firma corresponde realmente con la del equipo de desarrollo de Debian. Para ello se usa el comando gpg. Para poder verificar la firma, tal y como se ha demostrado en la Tarea 1, es necesario que la clave pública de la entidad firmante se encuentre en el anillo de claves del equipo en el que se comprueba la veracidad de la firma.\nPara obtener la clave pública, se puede buscar su ID en la firma del equipo de desarrolladores de Debian.\n❯ gpg --verify SHA512SUMS.sign gpg: asumiendo que los datos firmados están en \u0026#39;SHA512SUMS\u0026#39; gpg: Firmado el sáb 09 nov 2024 17:35:02 CET gpg: usando RSA clave DF9B9C49EAA9298432589D76DA87E80D6294BE9B gpg: Imposible comprobar la firma: No hay clave pública Para obtener la clave a partir de este identificador se puede buscar en repositorios de claves públicas. Parece más que probable que la clave pública de la distribución Debian estará almacenada en el servidor de claves de Debian y, desde él, se puede descargar al anillo de claves usando la opción --recv-keys del comando gpg.\n❯ gpg --keyserver keyring.debian.org --recv-keys DF9B9C49EAA9298432589D76DA87E80D6294BE9B gpg: clave DA87E80D6294BE9B: clave pública \u0026#34;Debian CD signing key \u0026lt;debian-cd@lists.debian.org\u0026gt;\u0026#34; importada gpg: Cantidad total procesada: 1 gpg: importadas: 1 Como curiosidad, llama la atención que el servidor keyring.debian.org no permite la búsqueda de claves.\n❯ gpg --keyserver keyring.debian.org --search-keys DF9B9C49EAA9298432589D76DA87E80D6294BE9B gpg: error searching keyserver: No está implementado gpg: búsqueda del servidor de claves fallida: No está implementado Tras importar la clave pública desde el servidor, se puede verificar la firma.\n❯ gpg --verify SHA512SUMS.sign gpg: asumiendo que los datos firmados están en \u0026#39;SHA512SUMS\u0026#39; gpg: Firmado el sáb 09 nov 2024 17:35:02 CET gpg: usando RSA clave DF9B9C49EAA9298432589D76DA87E80D6294BE9B gpg: Firma correcta de \u0026#34;Debian CD signing key \u0026lt;debian-cd@lists.debian.org\u0026gt;\u0026#34; [desconocido] gpg: ATENCIÓN: ¡Esta clave no está certificada por una firma de confianza! gpg: No hay indicios de que la firma pertenezca al propietario. Huellas dactilares de la clave primaria: DF9B 9C49 EAA9 2984 3258 9D76 DA87 E80D 6294 BE9B ❯ gpg --verify SHA256SUMS.sign gpg: asumiendo que los datos firmados están en \u0026#39;SHA256SUMS\u0026#39; gpg: Firmado el sáb 09 nov 2024 17:35:02 CET gpg: usando RSA clave DF9B9C49EAA9298432589D76DA87E80D6294BE9B gpg: Firma correcta de \u0026#34;Debian CD signing key \u0026lt;debian-cd@lists.debian.org\u0026gt;\u0026#34; [desconocido] gpg: ATENCIÓN: ¡Esta clave no está certificada por una firma de confianza! gpg: No hay indicios de que la firma pertenezca al propietario. Huellas dactilares de la clave primaria: DF9B 9C49 EAA9 2984 3258 9D76 DA87 E80D 6294 BE9B Integridad de ficheros con apt-secure Como se explica en su manual el software que utiliza apt-secure es apt-key. Apt-key es el programa que maneja las claves usadas por APT para confiar en sus repositorios. Este software se usa para añadir o eliminar claves, así como para listar claves en las que se confía.\nAsimismo, para firmar sus paquetes, apt-secure recomienda a los mantenedores usar la herramienta gpg.\nLa herramienta apt-key sirve para gestionar la lista de claves en las que confía APT para autentificar paquetes. Los paquetes que se verifican con estas claves se consideran confiables.\nSin embargo, el uso de apt-key está en desuso actualmente, excepto para el uso de apt-key del en los scritps de los mantenedores para eliminar claves existentes en sus anillos de clave.\nEl comando apt-key list muestra una lista de claves en las que se confía junto a sus huellas.\nLos ficheros con los que trabaja apt-key son:\n/etc/apt/trusted.gpg Es el fichero en el que se almacenan las claves locales en las que se confía. Las nuevas claves se añaden también a este fichero. /etc/apt/trusted.gpg.d/ Es el directorio en el que se almacenan fragmentos de ficheros para las claves en las que se confía, así como keyrings adicionales generados por otros paquetes o el administrador del sistema. /etc/apt/keyrings/ En este directorio se almacenan los keyrings adicionales que se usan con la opción signed-by de la herramienta. El fichero Release de un repositorio de Debian contiene una lista de las sumas de verificación de cada uno de los paquetes del repositorio. El archivo Release.gpg contiene la clave pública de Debian para verificar la veracidad de las firmas de verificación incluidas en el fichero Release.\nCuando se ejecuta un apt update, el sistema busca el contenido de los repositorios de la distribución y lo descarga. Antes de ejecutar ninguna otra acción, el gestor de paquetes, en este caso apt, revisa la suma de verificación de cada uno de los ficheros que conforman los paquetes de la actualización.\nPara ello, verifica que el fichero Release es el fichero realmente publicado por Debian comprobando que la firma del fichero coincide con la clave pública del fichero Release.gpg. A continuación equipara la suma de verificación de cada uno de los paquetes que se van a actualizar con la suma de verificación que se indica en el fichero Release.\nAsí, el gestor de paquetes se asegura de que el contenido de los paquetes que se actualizan es legítimo.\nSólo tras realizar esta verificación y asegurarse de que los paquetes de la actualización son legítimos el gestor de paquetes los instala en el sistema.\nIntegridad de ficheros desde un repositorio de terceros Para añadir el repositorio de VirtualBox al sistema se añade una nueva línea al fichero /etc/apt/sources.list en la que se indica el keyring en el que está almacenada la clave pública que permite verificar la legitimidad de los ficheros descargados desde este repositorio junto con el enlace al propio repositorio y la versión de la distribución del sistema.\ndeb [arch=amd64 signed-by=/usr/share/keyrings/oracle-virtualbox-2016.gpg] https://download.virtualbox.org/virtualbox/debian bookworm contrib Para que el gestor de paquetes pueda descargar e instalar paquetes desde el repositorio es necesario importar al sistema la clave pública de Orcle con la que apt pueda verificar la integridad de los paquetes. Para conseguirlo, se puede usar el comando wget para descargar la clave pública y el comando gpg para almacenarla en el directorio que se ha indicado al añadir el repositorio de VirtualBox al fichero sources.list.\nwget -O- https://www.virtualbox.org/download/oracle_vbox_2016.asc | sudo gpg --yes --output /usr/share/keyrings/oracle-virtualbox-2016.gpg --dearmor "},{
  "section": "Blog",
  "slug": "/blog/servicios/2025-01-13-gestion-del-almacenamiento/",
  "title": "Gestión de almacenamiento en Openstack",
  "description": "",
  "date": "January 13, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "servicios",
  "tags": "OpenStack, Gestión de almacenamiento, almacenamiento, cloud, IaaS, Administración de Sistemas, servicios, Servicios de Red e Internet",
  "content":"Creación de volúmenes Para crear un volumen usando OpenStack Client se ejecuta el siguiente comando:\nopenstack volume create --size 1 vol1 Después se puede asociar el volumen a un instancia previamente creada.\nopenstack server add volume --device /dev/sdb Debian12 vol1 Desde la instancia, se puede dar un sistema de ficheros al volumen y montarlo en una partición de la máquina virtual.\nsudo mkfs.ext4 /dev/vdb sudo mount /dev/vdb /mnt Redimensionar volúmenes Para redimensionar un volumen primero hay que desasociarlo de la instancia a la que esté asociado.\nopenstack server remove volume Debian12 vol1 Después se puede asignar un nuevo tamaño al volumen.\nopenstack volume set --size 2 vol1 Tras redimensionar el volumen se redimensiona el sistema de ficheros.\nsudo e2fsck -f /dev/vdc sudo resize2fs /dev/vdc 2G Creación de volúmenes arrancalbes Para crear un volumen arrancable desde OpenStack Client se usa la opción --bootable del comando openstack volume create.\nopenstack volume create --bootable --size 8 --image \u0026#34;Debian 12 Bookworm\u0026#34; Taller2 Con este volumen se puede crear una instancia.\nopenstack server create --flavor vol.mini --volume Taller2 --security-group default --key-name ClaveSSH --network \u0026#34;Red de fhuemej702\u0026#34; Taller2 Para poder acceder a ella se le asocia una IP flotante.\nopenstack server add floating ip Taller2 172.22.201.193 "},{
  "section": "Blog",
  "slug": "/blog/servicios/2025-01-13-gestion-de-redes-openstack/",
  "title": "Gestión de redes en Openstack",
  "description": "",
  "date": "January 13, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "servicios",
  "tags": "OpenStack, Gestión de Redes, Redes, cloud, IaaS, Administración de Sistemas, servicios, Servicios de Red e Internet",
  "content":"En este post se muestra un caso práctica de gestión de redes en un escenario de OpenStack formado por una instancia que funciona como router y otra máquina, conectada a una red interna, que cuenta con un servidor web.\nPara generar el escenario se crea, en primer lugar, una red.\nopenstack network create red-externa Para configurar la red se crea una subred.\nopenstack subnet create --network red-externa --subnet-range 192.168.0.0/24 --dns-nameserver 172.22.0.1 subred-externa Se crea también un router para poder acceder desde la nueva red a Internet.\nopenstack router create taller3 Por último se conecta el router a la nueva red, por una interfaz y a la red que le da conexión a Internet por la otra.\nopenstack router set taller3 --external-gateway ext-net openstack router add subnet taller3 subred-externa Además de los routers propios de OpenStack, en este tipo de escenarios también se pueden crear instancias que funcionen como router. Para ello, se genera una instancia conectada al router que se acaba de crear.\nopenstack server create --flavor m1.normal --image \u0026#34;Debian 12 Bookworm\u0026#34; --security-group default --key-name claveSSH --network red-externa maquina-router La nueva máquina obtiene una IP de la red que se ha creado previamente.\n+-------------+-------------+---------+-------------+--------------+-----------+ | ID | Name | Status | Networks | Image | Flavor | +-------------+-------------+---------+-------------+--------------+-----------+ | 74a0a734- | maquina- | ACTIVE | red-externa | Debian 12 | m1.normal | | 9d10-4e2e- | router | | =192.168.0. | Bookworm | | | 9041- | | | 214 | | | | e76638f019d | | | | | | | 5 | | | | | | +-------------+-------------+---------+-------------+--------------+-----------+ Para poder acceder a ella se le asocia una IP flotante.\nopenstack server add floating ip maquina-router 172.22.201.193 Para que esta máquina funciona como router se crea una nueva red interna, se configura creando una subred y se conecta a ella.\nopenstack network create red-interna openstack subnet create --network red-interna --subnet-range 10.0.100.0/24 --dns-nameserver 172.22.0.1 subred-interna Para conectar la maquina-router a la red interna y que funcione como router de esta red conviene que obtenga la primera dirección del pool DHCP que se ha configurado. Para conseguir esto, es necesario usar los puertos de OpenStack.\nEn primer lugar hay que crear un puerto.\nopenstack port create --network red-interna --fixed-ip ip-address=10.0.100.1 maquina-router Después, se conecta la mquina-router a este puerto a través de una nueva interfaz.\nopenstack server add port maquina-router maquina-router Como la máquina se conecta al nuevo puerto después de haberse creado, no puede configurar la red de la instancia de forma automática usando cloud init. Para establecer la configuración de la nueva interfaz se usa el fichero /etc/netplan/50-cloud-init.yaml. En él se asigna el direccionamiento a cada interfaz. En este caso, se asigna la IP 10.0.100.1 a la nueva interfaz.\nnetwork: version: 2 ethernets: ens3: dhcp4: true match: macaddress: fa:16:3e:47:71:d9 mtu: 1442 set-name: ens3 ens4: dhcp4: false dhcp6: false addresses: - 10.0.100.1/24 A continuación, a la nueva red se conecta la maquina-cliente, que tiene una dirección estática. Para asignarle la dirección esática hay que crear de nuevo un puerto antes de crear la máquina y después se crea la instancia conectada a este puerto.\nopenstack port create --network red-interna --fixed-ip ip-address=10.0.100.200 maquina-cliente openstack server create --flavor m1.normal --image \u0026#34;Debian 12 Bookworm\u0026#34; --security-group default --key-name ClaveSSH --port maquina-cliente maquina-cliente Para que la maquina-router puede actuar como router en este escenario, se deben realizar varias configuraciones. En la máquina se activa el bit de forwarding y se añade una regla de SNAT para permitir que el tráfico de la red-interna llegue al exterior.\napt install iptables iptables-persistent iptables -t nat -A POSTROUTING -o ens3 -s 10.0.100.0/24 -j MASQUERADE iptables-save \u0026gt; /etc/iptables/rules.v4 echo \u0026#34;net.ipv4.ip_forward=1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf En el escenario hay que eliminar los grupos de seguridad de ambas máquinas para que no interfieran en las comunicaciones entre las diferentes redes creadas en el proyecto.\nopenstack server remove security group maquina-router default openstack server remove security group maquina-cliente default openstack port set --disable-port-security maquina-router openstack port set --disable-port-security 6ff1dbe2-f08d-48d3-aa1a-ac65f9244cbe openstack port set --disable-port-security maquina-cliente Note\nSe deben eliminar los grupos de seguridad para todos los puertos del escenario. En este caso, no es suficiente con eliminar la seguridad de los puertos asociados a las interfaces que conectan a la máquina-router con la máquina- clinete, sino que también hay que eliminar los grupos de seguridad de la interfaz que conecta la máquina-router al router de OpenStack.\nAsí, se consigue que la máquina-cliente tenga conexión a Internet.\ndebian@maquina-cliente:~$ ping -c 4 8.8.8.8 PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data. 64 bytes from 8.8.8.8: icmp_seq=1 ttl=103 time=17.8 ms 64 bytes from 8.8.8.8: icmp_seq=2 ttl=103 time=18.7 ms 64 bytes from 8.8.8.8: icmp_seq=3 ttl=103 time=19.2 ms 64 bytes from 8.8.8.8: icmp_seq=4 ttl=103 time=17.3 ms --- 8.8.8.8 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 3005ms rtt min/avg/max/mdev = 17.347/18.270/19.243/0.743 ms En esta instancia, se instala un servidor web.\nsudo apt update sudo apt install git apache2 git clone https://github.com/fjhuete/javi_webte_public sudo cp -ra javi_webte_public/* /var/www/html/ Para que el servidor web sea accesible desde el exterior, el router tiene que contar con una regla de DNAT que redirija el tráfico HTTP al servidor.\niptables -t nat -A PREROUTING -p tcp --dport 80 -i ens3 -j DNAT --to 10.0.100.200 iptables-save \u0026gt; /etc/iptables/rules.v4 Tras realizar esta configuración, al acceder a la IP flotante de la máquina-router desde un navegador se accede al contenido alojado en el servidor web.\n"},{
  "section": "Blog",
  "slug": "/blog/servicios/2025-01-13-introduccion-a-openstack/",
  "title": "Introducción a Openstack Client",
  "description": "",
  "date": "January 13, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "servicios",
  "tags": "OpenStack, OpenStack Client, cloud, IaaS, Administración de Sistemas, servicios, Servicios de Red e Internet",
  "content":"Instalación y configuración de OpenStack Client en un entorno virtual Primero se crea el entorno virtual y se instala OpenStack client usando pip.\n❯ python3 -m venv os ❯ source os/bin/activate ❯ pip install python-openstackclient Para conectar a la cuenta de OpenStack hay que usar el fichero OpenStack RC. El fichero se descarga desde la interfaz web después de iniciar sesión y se ejecuta para autenticarse en OpenStack desde la línea de comandos.\n❯ source \u0026#34;Proyecto de fhuemej702-openrc(1).sh\u0026#34; Please enter your OpenStack Password for project Proyecto de fhuemej702 as user fhuemej702: Uso de OpenStack client Gestión de claves ssh Para crear una clave ssh:\n❯ openstack keypair create --public-key ~/.ssh/id_rsa.pub ClaveSSH Para ver las claves creadas en el proyecto:\n❯ openstack keypair list +----------+-------------------------------------------------+------+ | Name | Fingerprint | Type | +----------+-------------------------------------------------+------+ | ClaveSSH | 6d:3c:7a:4d:a0:87:d5:b3:bf:94:2e:46:01:37:37:9f | ssh | +----------+-------------------------------------------------+------+ Gestión de grupos de seguridad Para abrir el puerto 443 en el grupo de seguridad Default:\n❯ openstack security group rule create --protocol tcp --remote-ip 0.0.0.0/0 --dst-port 443 default Gestión de imágenes El cliente de OpenStack permite subir imágenes al proyecto.\n❯ openstack image create --container-format=bare --disk-format=qcow2 \\ --file cirros-0.6.2-x86_64-disk.img \u0026#34;Cirros 0.6.2\u0026#34; También permite ver las imágenes disponibles en el proyecto.\n❯ openstack image list ❯ openstack image list +----------------------------------+---------------------------------+--------+ | ID | Name | Status | +----------------------------------+---------------------------------+--------+ | ce5ca1e6-30d6-4e6b-b2da- | Cirros 0.6.2 | active | | f9ca654a1d9a | | | | e7caa035-5bb0-47fb-b9e8- | Debian 12 Bookworm | active | | ef73dce54499 | | | | 1a39c3de- | Fedora-Cloud-Base-37-1.7.x86_64 | active | | cf79-4d17-a470-a490ba89b366 | | | | 52f6e1bd- | Rocky Linux 9 | active | | edc0-49e8-87e2-c99a3f173d41 | | | | d57c4744-177a-4f53-8db9- | Ubuntu 22.04 LTS | active | | 6368dc17f979 | | | | e2cfdd56-7474-4772-a43c- | Ubuntu 24.04 LTS | active | | ad0429f4b78e | | | | ffebc834-5c2f-4319-b5b8- | cirros-0.6.2-x86_64-disk | active | | a0c360050d4f | | | +----------------------------------+---------------------------------+--------+ También se pueden ver los sabores disponibles para crear instancias.\n❯ openstack flavor list +----+------------+------+------+-----------+-------+-----------+ | ID | Name | RAM | Disk | Ephemeral | VCPUs | Is Public | +----+------------+------+------+-----------+-------+-----------+ | 10 | vol.medium | 2048 | 0 | 0 | 2 | True | | 11 | vol.large | 4096 | 0 | 0 | 2 | True | | 12 | vol.xlarge | 8192 | 0 | 0 | 4 | True | | 2 | m1.micro | 256 | 10 | 0 | 1 | True | | 3 | m1.mini | 512 | 10 | 0 | 1 | True | | 4 | m1.normal | 1024 | 10 | 0 | 1 | True | | 5 | m1.medium | 2048 | 20 | 0 | 2 | True | | 6 | m1.large | 4096 | 20 | 0 | 2 | True | | 7 | m1.xlarge | 8192 | 20 | 0 | 4 | True | | 8 | vol.mini | 512 | 0 | 0 | 1 | True | | 9 | vol.normal | 1024 | 0 | 0 | 1 | True | +----+------------+------+------+-----------+-------+-----------+ Creación de configuración de instancias con Cloud-init Para crear una instancia se usa el comando server create. Los parámetros necesarios para la creación de la instancia se pueden consultar con los comandos openstack flavor list, openstack image list, openstack netwrok list, etc.\n❯ openstack server create --flavor m1.mini --image \u0026#34;Debian 12 Bookworm\u0026#34; --security-group default --key-name ClaveSSH --network \u0026#34;Red de fhuemej702\u0026#34; Taller1 En el fichero cloud-init se configura que esta instancia actualice los paquetes al iniciarse, que instale Apache2, que cree un usuario con contraseña y se le cambia el nombre y dominio.\n#cloud-config # Actualiza los paquetes package_update: true package_upgrade: true # Instala el paquete apache2 packages: - apache2 # Configura el hostname y el fqdn fqdn: maquina1.example.org hostname: maquina1 manage_etc_hosts: true # Crear dos usuarios, configura el acceso por sudo y añade clave pública ssh users: - name: usuario1 shell: /bin/bash # Cambia las contraseña a los usuarios creados chpasswd: expire: False users: - name: usuario1 password: usuario type: text El fichero se debe indicar durante la creación de la instancia.\n❯ openstack server create --flavor m1.mini --image \u0026#34;Debian 12 Bookworm\u0026#34; --security-group default --key-name ClaveSSH --network \u0026#34;Red de fhuemej702\u0026#34; --user-data cloud-init.yaml Taller1 Conexión a instancias Para conectarse a la instancia tiene que contar con una IP flotante. Se pueden ver las IP flotantes asignadas al proyecto.\nopenstack floating ip list Si todas están en uso, se debe crear una nueva.\n❯ openstack floating ip create ext-net +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | created_at | 2024-12-02T08:52:19Z | | description | | | dns_domain | | | dns_name | | | fixed_ip_address | None | | floating_ip_address | 172.22.201.193 | | floating_network_id | | | id | 02d9a479-fffc-4522-b80a-22cf10506b61 | | name | 172.22.201.193 | | port_details | None | | port_id | None | | project_id | | | qos_policy_id | None | | revision_number | 0 | | router_id | None | | status | DOWN | | subnet_id | None | | tags | [] | | updated_at | 2024-12-02T08:52:19Z | +---------------------+--------------------------------------+ Para asignarla a la nueva instancia:\n❯ openstack server add floating ip Taller1 172.22.201.193 Con esta IP ya se puede establecer la conexión a la instancia.\n❯ ssh javi@172.22.201.193 Linux maquina1 6.1.0-28-amd64 #1 SMP PREEMPT_DYNAMIC Debian 6.1.119-1 (2024-11-22) x86_64 The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. javi@maquina1:~$ Listar y eliminar instancias Por último, el cliente por línea de comandos de OpenStack también permite listar las instancias creadas en el proyecto.\n❯ openstack server list +--------------+----------+--------+--------------+----------------+-----------+ | ID | Name | Status | Networks | Image | Flavor | +--------------+----------+--------+--------------+----------------+-----------+ | 10b4710e- | Taller1 | ACTIVE | Red de fhuem | Debian 12 | m1.mini | | 8769-406c- | | | =10.0.0 | Bookworm | | | 895e- | | | .202, 172.22 | | | | 9224bf20a880 | | | .201.193 | | | | add49a45- | Debian12 | ACTIVE | Red de fhuem | Debian 12 | m1.normal | | 82ac-4f6f- | | | =10.0.0 | Bookworm | | | a03c- | | | .87, 172.22. | | | | 419786d8e9db | | | 200.247 | | | +--------------+----------+--------+--------------+----------------+-----------+ Y eliminarlas.\n❯ openstack server delete Taller1 "},{
  "section": "Blog",
  "slug": "/blog/servicios/2025-01-13-uso-de-cloud-init-con-libvirt/",
  "title": "Uso de cloud-init con libvirt",
  "description": "",
  "date": "January 13, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "servicios",
  "tags": "cloud-init, libvirt, cloud, IaaS, debian, Administración de Sistemas, servicios, Servicios de Red e Internet",
  "content":"Para configurar una máquina virtual con cloud-init usando libvirt se necesitan tres ficheros: network-config, meta-data y user-data. En este caso, los dos primeros están vacíos. El fichero user-data incluye la configuración necesaria para actualizar los paquetes, instalar Apache2, crear un usuario y configurar el nombre de la máquina.\n#cloud-config # Actualiza los paquetes package_update: true package_upgrade: true # Instala el paquete apache2 packages: - apache2 # Configura el hostname y el fqdn fqdn: maquina-cloud.example.org hostname: maquina-cloud manage_etc_hosts: true # Crear dos usuarios, configura el acceso por sudo y añade clave pública ssh users: - name: javi sudo: ALL=(ALL) NOPASSWD:ALL shell: /bin/bash ssh_authorized_keys: - ssh-rsa xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx # Cambia las contraseña a los usuarios creados chpasswd: expire: False users: - name: root password: root type: text - name: javi password: usuario type: text Para poder ejecutar la configuración con cloud init es necesario instalar imágenes que tengan cloud init ya instalado. En el caso de Debian, estas imágenes están publicadas en su repositorio.\nLos ficheros de cloud init se indican en el comando de creación de la instancia con virt-install.\nvirt-install --name DebianCloud --memory 1024 --os-variant debian11 --disk=size=10,backing_store=\u0026#34;$(pwd)/debian-12-generic-amd64-20241201-1948.qcow2\u0026#34; --cloud-init user-data=$(pwd)/user-data,meta-data=$(pwd)/meta-data,network-config=$(pwd)/network-config\u0026#34; "},{
  "section": "Blog",
  "slug": "/blog/servicios/2025-01-13-creacion-escenario-openstack/",
  "title": "Uso de Openstack para crear un escenario de despliegue",
  "description": "",
  "date": "January 13, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "servicios",
  "tags": "OpenStack, Gestión de almacenamiento, almacenamiento, redes, cloud, IaaS, Administración de Sistemas, servicios, Servicios de Red e Internet",
  "content":"En este post se crea un escenario en OpenStack que consta de 4 máquinas: 2 instancias y dos contenedores LXC que se ejecutan en una de estas dos instancias. Este escenario está orientado a alojar diferentes servicios en cada una de las máquinas en el futuro.\nCreación de la infraestructura de red El primer paso en la creación de la infraestructura de red de este escenario es crear un nuevo router en el proyecto de OpenStack.\nopenstack router create RouterPractica Este router está conectado a una red llamada Red Intra.\nopenstack network create \u0026#39;Red Intra\u0026#39; openstack subnet create --network \u0026#39;Red Intra\u0026#39; --subnet-range 10.0.200.0/24 --dns-nameserver 172.22.0.1 --gateway 10.0.200.1 --dhcp subred-intra openstack router set RouterPractica --external-gateway ext-net openstack router add subnet RouterPractica subred-intra En el escenario hay una segunda red.\nopenstack network create \u0026#39;Red DMZ de fhuemej702\u0026#39; openstack subnet create --network \u0026#39;Red DMZ\u0026#39; --subnet-range 172.16.0.0/16 --no-dhcp --gateway none subred-dmz Para conectar esta nueva red al router se necesita un puerto que le configure la IP estática para que esta interfaz del router funcione como puerta de enlace de la red DMZ.\nopenstack port create --network \u0026#39;Red DMZ\u0026#39; --fixed-ip ip-address=172.16.0.1 luffy Creación de instancias Las instancias del escenario se configuran usando un fichero cloud-init.\nLuffy El contenido del fichero cloud-init de Luffy es el siguiente:\n#cloud-config # Actualiza los paquetes package_update: true package_upgrade: true # Configura el hostname y el fqdn fqdn: luffy.javi.gonzalonazareno.org hostname: luffy manage_etc_hosts: true # Crear dos usuarios, configura el acceso por sudo y añade clave pública ssh users: - name: usuario sudo: ALL=(ALL) NOPASSWD:ALL shell: /bin/bash ssh_authorized_keys: - ssh-rsa xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx - name: profesor sudo: ALL=(ALL) NOPASSWD:ALL shell: /bin/bash ssh_authorized_keys: - ssh-rsa xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx # Cambia las contraseña a los usuarios creados chpasswd: expire: False users: - name: root password: root type: text - name: usuario password: usuario type: text Tras escribir el fichero, se puede usar para crear una instancia. En su creación, esta instancia se asocia a un volumen y a dos interfaces de red.\nopenstack server create --flavor vol.medium --image \u0026#34;Debian 12 Bookworm\u0026#34; --security-group default --key-name ClaveSSH --boot-from-volume 15 --user-data cloud-config-luffy.yaml --network \u0026#39;Red Intra\u0026#39; --port luffy luffy Zoro El fichero cloud-init de zoro es el siguiente:\n#cloud-config # Actualiza los paquetes package_update: true package_upgrade: true # Configura el hostname y el fqdn fqdn: zoro.javi.gonzalonazareno.org hostname: zoro manage_etc_hosts: true # Crear dos usuarios, configura el acceso por sudo y añade clave pública ssh users: - name: usuario sudo: ALL=(ALL) NOPASSWD:ALL shell: /bin/bash ssh_authorized_keys: - ssh-rsa xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx - name: profesor sudo: ALL=(ALL) NOPASSWD:ALL shell: /bin/bash ssh_authorized_keys: - ssh-rsa xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx # Cambia las contraseña a los usuarios creados chpasswd: expire: False users: - name: root password: root type: text - name: usuario password: usuario type: text Para crear esta instancia se crea un volumen basado en la imagen de Rocky Linux 9.\nopenstack volume create --image \u0026#39;Rocky Linux 9\u0026#39; --size 15 zoro Y, a partir de este volumen, se crea la instancia.\nopenstack server create --flavor vol.medium --volume zoro --security-group default --key-name ClaveSSH --user-data cloud-config-zoro.yaml --network \u0026#39;Red Intra\u0026#39; zoro Note\nAunque esta instancia se debe conectar a la red DMZ, debe estar conectada a una red con un servidor DHCP para poder establecer una configuración en ella usando la herramienta cloud-init. Por eso, en su creación se conecta a la red Intra y, posteriormente, se desconecta de esa red y se conecta a la red DMZ.\nPara conectar esta instancia a la Red DMZ hay que usar un puerto que le permita mantener un direccionamiento IP estático.\nopenstack port create --network \u0026#39;Red DMZ\u0026#39; --fixed-ip ip-address=172.16.0.200 zoro A continuación, se debe desconectar la instancia de la Red Intra y conectar al puerto recién creado en la Red DMZ.\nopenstack server remove port zoro 8d6dd153-862c-4773-aaa8-74f04cade4b6 openstack server add port zoro zoro Al llevar a cabo este cambio, es necesario configurar la interfaz de red de zoro de forma manual. Esta instancia usa un sistema operativo Rocky Linux 9 y, por tanto, configura sus interfaces de red con Network Manager.\nnmcli con edit id \u0026#39;Wired connection 1\u0026#39; nmcli\u0026gt; set ipv4.addresses 172.16.0.200 nmcli\u0026gt; set ipv4.gateway 172.16.0.1 nmcli\u0026gt; set ipv4.dns 172.22.0.1 nmcli\u0026gt; save nmcli con up id \u0026#39;Wired connection 1\u0026#39; Por último, para que zoro pueda tener acceso a Internet hay que configurar el funcionamiento de luffy como router.\napt install iptables iptables-persistent iptables -t nat -A POSTROUTING -o ens3 -s 172.16.0.0/16 -j MASQUERADE iptables-save \u0026gt; /etc/iptables/rules.v4 echo \u0026#34;net.ipv4.ip_forward=1\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf Además, hay que eliminar los grupos de seguridad de los puertos implicados para que la instancia pueda enrutar el tráfico.\nopenstack port set --no-security-group --disable-port-security luffy openstack port set --no-security-group --disable-port-security 09edfc05-0ddf-47ba-8f24-d5a4752b424b openstack port set --no-security-group --disable-port-security zoro Tras configurar adecuadamente las instancias, se puede generar una instantánea de los volúmenes asociados para facilitar su recuperación en caso de que sea necesario.\nopenstack volume snapshot create --force --volume zoro zoro-backup openstack volume snapshot create --force --volume 3fb035f6-74f4-4ecf-928a-98ce00b04978 luffy-backup Creación de contenedores Las dos máquinas restantes en el escenario son contenedores LXC en la instancia luffy.\nEl primer paso para poder tener contenedores alojados en la instancia es crear un bridge al que se puedan conectar para tener acceso a Internet. La creación del bridge se puede hacer con varias herramientas. En este caso, se usa bridge-utils.\nsudo apt install bridge-utils Para configurar el bridge se debe modificar el fichero de configuración de la instancia. Aunque luffy usa un sistema operativo Debian 12, las instancias de cloud de Debian configuran sus interfaces de red usando netplan por compatibilidad con cloud-init. Así, para crear el bridge al que se van a conectar los contenedores desde un fichero de configuración se debe editar el fichero /etc/netplan/50-cloud-init.yaml\nbridges: br-intra: addresses: - 192.168.0.1 mtu: 1442 nameservers: addresses: - 172.22.0.1 Finalmente, se aplica la configuración añadida en el fichero:\nsudo netplan apply Una vez que la instancia ya cuenta con el bridge al que se tienen que conectar los contenedores, se pueden crear las dos nuevas máquinas. Para ello se instala LXC.\nsudo apt install lxc Y se crean los contenedores para las nuevas máquinas: nami y sanji.\nsudo lxc-create -n nami -t ubuntu -- -r jammy sudo lxc-create -n sanji -t ubuntu -- -r jammy Para conectar los contenedores al bridge hay que editar los ficheros de configuración de cada uno de ellos para añadir la siguiente línea. El de nami es /var/lib/lxc/nami/config. En este fichero se puede configurar también el mtu para que se adapte al que usa la instalación de OpenStack en la que se está trabajando.\nlxc.net.0.link = br-intra lxc.net.0.mtu = 1442 Y el de sanji es /var/lib/lxc/sanji/config.\nlxc.net.0.link = br-intra lxc.net.0.mtu = 1442 Para configurar el direccionamiento estático en cada uno de los contenedores, hay que acceder a ellos.\nsudo lxc-start nami sudo lxc-attach nami Primero, nami tendrá la dirección IP 192.168.0.2. Como el contenedor usa un sistema operativo Ubuntu, este direccionamiento se configura en el fichero /etc/netplan/10-lxc.yaml.\nnetwork: version: 2 ethernets: eth0: dhcp4: false addresses: - 192.168.0.2/24 routes: - to: default via: 192.168.0.1 mtu: 1442 nameservers: addresses: - 172.22.0.1 Después, se aplica la nueva configuración\nnetplan apply Para configurar sanji se le asigna la IP 192.168.0.3 en el fichero /etc/netplan/10-lxc.yaml. Para acceder al contenedor:\nsudo lxc-start sanji sudo lxc-attach sanji Se modifica el fichero de configuración de red:\nnetwork: version: 2 ethernets: eth0: dhcp4: false addresses: - 192.168.0.3/24 routes: - to: default via: 192.168.0.1 mtu: 1442 nameservers: addresses: - 172.22.0.1 Y, por último, se aplica la nueva configuración:\nnetplan apply Adicionalmente, se puede hacer que los contenedores se enciendan al iniciar luffy añadiendo en su fichero de configuración la línea:\nlxc.start.auto = 1 Los contenedores creados en luffy están conectados al bridge br-intra pero no tienen conexión a Internet. Para que puedan salir al exterior hay que añadir una regla de iptables en luffy para que haga SNAT.\nsudo iptables -t nat -A POSTROUTING -o ens3 -s 192.168.0.0/24 -j MASQUERADE iptables-save \u0026gt; /etc/iptables/rules.v4 En este caso práctico se pide que cada contenedor tenga los paquetes de la distribución actualizados, el FQDN y el hostname correctamente configurado y dos usuarios.\nPara actualizar los paquetes:\nsudo apt update \u0026amp;\u0026amp; sudo apt upgrade Para configurar el FQDN se modifica el fichero /etc/hosts, que debe contar con una línea como esta:\n127.0.1.1 nami.javi.gonzalonazareno.org nami Finalmente se crean los dos usuarios. Primero uno que se llama así, usuario:\nadduser usuario Y se configura el acceso por SSH.\nsu - usuario mkdir .ssh cd .ssh nano authorized_keys En el fichero authorized_keys se añade la clave pública del usuario.\nPara que el usuario pueda usar sudo sin contraseña se edita el fichero /etc/sudoers para añadir la siguiente línea:\nusuario ALL=(ALL) NOPASSWD:ALL El mismo proceso se repite en ambos contenedores y para la creación de los dos usuarios.\n"},{
  "section": "Blog",
  "slug": "/blog/administracion-de-sistemas/2025-01-09-systemd-sshfs/",
  "title": "Compartición de sistemas de ficheros con sshfs y systemd",
  "description": "",
  "date": "January 9, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "administracion-sistemas",
  "tags": "sistemas, systemd, linux, debian, sshfs, sistema de archivos, ficheros compartidos, Administración de Sistemas Operativos",
  "content":"Configuración del sistema de archivos sshfs en el servidor En el servidor se anexa un volumen de 2GB y se le da un sistema de ficheros.\ndebian@servidor:~$ sudo mkfs.ext4 /dev/vdb mke2fs 1.47.0 (5-Feb-2023) Discarding device blocks: done Creating filesystem with 524288 4k blocks and 131072 inodes Filesystem UUID: 140701b6-050d-4585-8640-3cfbf7355113 Superblock backups stored on blocks: 32768, 98304, 163840, 229376, 294912 Allocating group tables: done Writing inode tables: done Creating journal (16384 blocks): done Writing superblocks and filesystem accounting information: done Este volumen se monta en un directorio del servidor, en este caso, en el directorio /srv/sshfs. Para hacerlo de forma persistente se usa el fichero /etc/fstab, en el que se añade la siguiente línea:\nUUID=140701b6-050d-4585-8640-3cfbf7355113 /srv/sshfs ext4 defaults 0 0 Y se aplican los cambios.\nsudo mount -a Montaje manual del sistema de archivos remoto En el cliente se crea el directorio en el que se monta el directorio remoto usando sshfs. En este caso, el directorio estará en el home del usuario debian y se llamará sshfs.\nmkdir sshfs Para hacer el montaje se usa el comando sshfs.\nsshfs 10.0.0.253:/srv/sshfs sshfs Así se crea en el directorio /home/debian/sshfs el punto de montaje del directorio remoto /srv/sshfs del servidor.\ndebian@debian12:~$ df -Th Filesystem Type Size Used Avail Use% Mounted on udev devtmpfs 462M 0 462M 0% /dev tmpfs tmpfs 97M 500K 96M 1% /run /dev/vda1 ext4 9.7G 6.0G 3.4G 65% / tmpfs tmpfs 481M 84K 481M 1% /dev/shm tmpfs tmpfs 5.0M 0 5.0M 0% /run/lock /dev/vda15 vfat 124M 12M 113M 10% /boot/efi tmpfs tmpfs 97M 0 97M 0% /run/user/1000 10.0.0.253:/srv/sshfs fuse.sshfs 2.0G 24K 1.8G 1% /home/debian/sshfs Montaje automático usando el fichero fstab Cuando el sistema lee el fichero fstab y monta los sistemas de archivo que se indican en el fichero en los puntos de montaje recogidos, lo hace como root. Por tanto, para que el cliente pueda acceder al servidor sshfs la clave privada del cliente debe estar almacenada no en el directorio .ssh de ningún usuario sino en el del root: /root/.ssh.\nsudo cp .ssh/id_rsa /root/.ssh La sintaxis para añadir este puntode montaje al fichero fstab es muy similar a la que se usa con otros dispositivos de bloques exceptuando el hecho de que para indicar el dispositivo no se usa su UUID, sino una cadena con el formato sshfs#usuario@host:ruta.\nsshfs#debian@10.0.0.253:/srv/sshfs /home/debian/sshfs fuse defaults,allow_other 0 0 Al aplicar los cambios indicados en el fichero fstab, se monta este sistema de archivos en el punto de montaje indicado.\ndebian@debian12:~$ df -Th Filesystem Type Size Used Avail Use% Mounted on ... debian@10.0.0.253:/srv/sshfs fuse.sshfs 2.0G 24K 1.8G 1% /home/debian/sshfs Montaje automático usando una unidad .mount de systemd Para configurar el montaje automático del sistema de ficheros usando una unidad .mount de systemd hay que crear este fichero. Las unidades de systemd se almacenan en el directorio /lib/systemd/system. En él se guarda un fichero de configuración para cada unidad. El fichero de configuración de la unidad .mount usando sshfs es el siguiente:\n[Unit] Description=Mount datos with sshfs After=network-online.target Wants=network-online.target [Install] WantedBy=default.target [Mount] What=debian@10.0.0.253:/srv/sshfs Where=/home/debian/datos Type=fuse.sshfs Options=_netdev,reconnect,ServerAliveInterval=30,ServerAliveCountMax=5,x-system\u0026gt; TimeoutSec=60 Para aplicar los cambios generados por la nueva unidad creada se recarga el daemon de systemd y se habilita la unidad de montaje.\ndebian@debian12:/lib/systemd/system$ sudo systemctl daemon-reload debian@debian12:/lib/systemd/system$ sudo systemctl enable home-debian-datos.mount Created symlink /etc/systemd/system/default.target.wants/home-debian-datos.mount → /lib/systemd/system/home-debian-datos.mount. Para comprobar que la unidad monta correctamente el sistema de ficheros, se puede ejecutar la unidad manualmente usando el comando systemctl.\nsudo systemctl start home-debian-datos.mount Con este comando el sistema de ficheros se monta en el directorio indicado.\ndebian@debian12:~$ df -Th Filesystem Type Size Used Avail Use% Mounted on ... debian@10.0.0.253:/srv/sshfs fuse.sshfs 2.0G 24K 1.8G 1% /home/debian/datos Como la unidad de montaje se ha habilitado con el comando systemctl enable, su estado es loaded y, por tanto, el sistema de ficheros se monta automáticamente cada vez que se reinicia el sistema.\ndebian@debian12:~$ sudo systemctl status home-debian-datos.mount ● home-debian-datos.mount - Mount datos with sshfs Loaded: loaded (/lib/systemd/system/home-debian-datos.mount; enabled; pres\u0026gt; Active: active (mounted) since Sat 2024-12-21 11:25:07 UTC; 1min 31s ago Where: /home/debian/datos What: debian@10.0.0.253:/srv/sshfs Tasks: 5 (limit: 1107) Memory: 8.6M CPU: 212ms CGroup: /system.slice/home-debian-datos.mount ├─323 ssh -x -a -oClearAllForwardings=yes -oServerAliveInterval=30\u0026gt; └─372 /sbin/mount.fuse.sshfs debian@10.0.0.253:/srv/sshfs /home/de\u0026gt; Dec 21 11:25:05 debian12 systemd[1]: Mounting home-debian-datos.mount - Mount d\u0026gt; Dec 21 11:25:07 debian12 systemd[1]: Mounted home-debian-datos.mount - Mount da\u0026gt; Para desmontar el sistema de archivos de forma manual también se puede usar el comando systemctl stop.\nsudo systemctl stop home-debian-datos.mount Montaje automático usando una unidad .automount de systemd Las unidades .automount de systemd permiten montar un sistema de archivos automáticamente cuando se accede a la ruta especificada en la unidad. Para que estas unidades funciones es necesario tener correctamente configurada la unidad .mount tal y como se ha documentado en el punto anterior. A continuación, se puede crear el fichero de configuración para la unidad .automount.\n[Unit] Description=Automount datos whit sshfs [Automount] Where=/home/debian/datos [Install] WantedBy=multi-user.target Las unidades .automount neceistan que exista previamente una unidad .mount con el mismo nombre para funcionar.\ndebian@debian12:/lib/systemd/system$ ls -l | grep \u0026#34;datos\u0026#34; -rw-r--r-- 1 root root 122 Dec 21 11:38 home-debian-datos.automount -rw-r--r-- 1 root root 334 Dec 21 11:20 home-debian-datos.mount De nuevo, para activar la nueva unidad de systemd se usa el comando daemon-reload, se habilita la unidad y se arranca la unidad.\ndebian@debian12:~$ sudo systemctl enable home-debian-datos.automount Created symlink /etc/systemd/system/multi-user.target.wants/home-debian-datos.automount → /lib/systemd/system/home-debian-datos.automount. Tras encender la unidad .automount se puede comprobar cómo el sistema de archivos pasa de no estar montado a estar montado simplemente accediendo al directorio.\ndebian@debian12:~$ df -Th Filesystem Type Size Used Avail Use% Mounted on udev devtmpfs 462M 0 462M 0% /dev tmpfs tmpfs 97M 500K 96M 1% /run /dev/vda1 ext4 9.7G 6.0G 3.4G 65% / tmpfs tmpfs 481M 84K 481M 1% /dev/shm tmpfs tmpfs 5.0M 0 5.0M 0% /run/lock /dev/vda15 vfat 124M 12M 113M 10% /boot/efi tmpfs tmpfs 97M 0 97M 0% /run/user/1000 debian@debian12:~$ cd datos/ debian@debian12:~/datos$ df -Th Filesystem Type Size Used Avail Use% Mounted on udev devtmpfs 462M 0 462M 0% /dev tmpfs tmpfs 97M 500K 96M 1% /run /dev/vda1 ext4 9.7G 6.0G 3.4G 65% / tmpfs tmpfs 481M 84K 481M 1% /dev/shm tmpfs tmpfs 5.0M 0 5.0M 0% /run/lock /dev/vda15 vfat 124M 12M 113M 10% /boot/efi tmpfs tmpfs 97M 0 97M 0% /run/user/1000 debian@10.0.0.253:/srv/sshfs fuse.sshfs 2.0G 24K 1.8G 1% /home/debian/datos Para que systemd use sólo la unidad .automount y no monte automáticamente el sistema de ficheros del servidor sshfs al iniciar el equipo, hay que deshabilitar la unidad de montaje.\nsudo systemctl disable home-debian-datos.mount Además, para que el sistema de ficheros se desmonte de forma automática cuando ya no se esté usando, es necesario marcar a verdadero el parámetro StopWhenUnneeded en el fichero de configuración de la unidad de montaje de systemd.\n[Unit] Description=Mount datos with sshfs After=network-online.target Wants=network-online.target StopWhenUnneeded=true [Install] WantedBy=default.target [Mount] What=debian@10.0.0.253:/srv/sshfs Where=/home/debian/datos Type=fuse.sshfs Options=allow_other,_netdev,reconnect,ServerAliveInterval=30,ServerAliveCountMax=5,x-systemd.automount TimeoutSec=60 Con esta configuración, el sistema de ficheros compartido con el cliente por parte del servidor sshfs no se montará en el cliente hasta que no se use. Además, después de un tiempo sin uso, el sistema de ficheros se desmontará del punto de montaje asigando en el cliente de forma automática.\ndebian@debian12:~$ df -Th Filesystem Type Size Used Avail Use% Mounted on udev devtmpfs 462M 0 462M 0% /dev tmpfs tmpfs 97M 500K 96M 1% /run /dev/vda1 ext4 9.7G 6.0G 3.4G 65% / tmpfs tmpfs 481M 84K 481M 1% /dev/shm tmpfs tmpfs 5.0M 0 5.0M 0% /run/lock /dev/vda15 vfat 124M 12M 113M 10% /boot/efi tmpfs tmpfs 97M 0 97M 0% /run/user/1000 debian@debian12:~$ cd datos/ debian@debian12:~/datos$ df -Th Filesystem Type Size Used Avail Use% Mounted on udev devtmpfs 462M 0 462M 0% /dev tmpfs tmpfs 97M 500K 96M 1% /run /dev/vda1 ext4 9.7G 6.0G 3.4G 65% / tmpfs tmpfs 481M 84K 481M 1% /dev/shm tmpfs tmpfs 5.0M 0 5.0M 0% /run/lock /dev/vda15 vfat 124M 12M 113M 10% /boot/efi tmpfs tmpfs 97M 0 97M 0% /run/user/1000 debian@10.0.0.253:/srv/sshfs fuse.sshfs 2.0G 24K 1.8G 1% /home/debian/datos debian@debian12:~/datos$ cd debian@debian12:~$ df -Th Filesystem Type Size Used Avail Use% Mounted on udev devtmpfs 462M 0 462M 0% /dev tmpfs tmpfs 97M 500K 96M 1% /run /dev/vda1 ext4 9.7G 6.0G 3.4G 65% / tmpfs tmpfs 481M 84K 481M 1% /dev/shm tmpfs tmpfs 5.0M 0 5.0M 0% /run/lock /dev/vda15 vfat 124M 12M 113M 10% /boot/efi tmpfs tmpfs 97M 0 97M 0% /run/user/1000 Note\nEs importante indicar que, durante la demostración de los comandos reflejados en las líneas anteriores se han dejado pasar varios minutos entre la ejecución del penúltimo y último comando registrados.\n"},{
  "section": "Blog",
  "slug": "/blog/administracion-de-sistemas/2025-01-09-sistemas-operativos-inmutables/",
  "title": "Sistemas operativos inmutables",
  "description": "",
  "date": "January 9, 2025",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "administracion-sistemas",
  "tags": "sistemas, MicroOS, linux, Fedora, Red Hat, distrobox, OpenSUSE, Administración de Sistemas Operativos",
  "content":"La inmutabilidad en sistemas operativos ¿Qué es la inmutabilidad? La inmutabilidad de los sistemas operativos se refiere a la característica de estos que impide al usuario modificar libremente el sistema de archivos raíz con el objetivo de evitar los problemas que esto puede provocar.\nEstos sistemas operativos suelen incluir unos elementos básicos que se aíslan del resto de aplicaciones como el sistema de ficheros raíz, el entorno de escritorio, herramientas básicas del sistema y bibliotecas esenciales para el sistema operativo. Este conjunto de elementos constituye el núcleo del sistema que el usuario no puede modificar.\nPara la instalación de otro tipo de aplicaciones, se usan sistemas de paquetería universal como Flatpak o Snap que permiten la instalación en entornos más aislados sin interactuar con el sistema raíz como hacen los gestores de paquetes tradicionales, así como contenedores que aíslan las aplicaciones del resto del sistema.\nFundamentos de los sistemas operativos inmutables Este tipo de sistemas operativos se basa en tres conceptos clave para mantener la filosofía de la inmutabilidad y conseguir hacer sistemas funcionales pero en los que el usuario no necesite interactuar con el sistema raíz.\nContenedores de aplicaciones. Los sistemas operativos inmutables usan gestores de contenedores como distrobox, docker o podman para instalar aplicaciones aisladas del sistema operativo en contenedores. Esta forma de instalar aplicaciones permite que no interactúen con los ficheros del sistema de archivos raíz del sistema operativo.\nSistemas de paquetería universales. Los gestores de paquetes universales como flatpak o snap facilitan la instalación de aplicaciones de forma independiente a la distribución sobre la que se instalen. Consiguen esto haciendo paquetes más pesados pero que incluyen la mayor parte de las dependencias necesarias para el funcionamiento de la aplicación. Esto permite que la aplicación se instale y se ejecute sin interactuar con el sistema de ficheros raíz y de forma mucho más aislada que las aplicaciones instaladas usando gestores de paquetes tradicionales como apt o dnf.\nSanpshots. Para garantizar la consistencia del sistema en todo momento, los sistemas operativos inmutables dependen enormemente del uso de snapshots o instantáneas que almacenan el estado del sistema operativo antes de hacer cualquier modificación en el sistema de ficheros raíz. Así, este tipo de sistemas operativos genera una instantánea del sistema cada vez que se modifica un fichero de configuración o se instala una herramienta usando el gestor de paquetes tradicional propio de la distribución.\n¿A qué sector van destinados? Por sus características, no parece que los sistemas operativos inmutables se vayan a convertir en una opción extendida en entornos profesionales de servidores. Se trata de sistemas que requieren un cambio de perspectiva a la hora de trabajar con ellos en cuanto a la interacción con el propio sistema operativo. Esto hace que cualquier operación sobre el sistema de ficheros raíz se ralentice mucho respecto a la dinámica de trabajo previa. Además, este tipo de sistemas operativos exigen muchos más recursos en cuanto a capacidad de almacenamiento, por ejemplo.\nAún así, cabe tener en cuenta que la creciente popularidad de los contenedores en el despliegue de aplicaciones puede suponer un cambio de paradigma en la gestión de servidores para el despliegue de aplicaciones si se combina con el uso de sistemas operativos inmutables en los servidores.\nEn cambio, parece que el planteamiento de este tipo de sistemas operativos se orienta más hacia las versiones de escritorio. Mientras que las distribuciones con las que se trabajan en entornos de servidores permiten el uso de una enorme variedad de herramientas que se ejecutan desde la línea de comandos, los sistemas de paquetería universal están más dirigidos a la distribución de aplicaciones con interfaz gráfica, diseñadas para su ejecución en un entorno de escritorio.\nAdemás, los ordenadores que se usan como equipos personales o de trabajo en entornos de escritorio son menos sensibles a los requisitos de almacenamiento que conlleva el uso de los sistemas operativos inmutables, de manera que mientras que almacenar una instantánea de todo el sistema para cada modificación del sistema raíz en un servidor puede suponer un coste demasiado grande, en el caso de los ordenadores de escritorio, el uso de almacenamiento no suele ser tan intensivo y es más habitual que los dispositivos cuenten con espacio suficiente para almacenar estas instantáneas sin suponer un problema de rendimiento para los usuarios.\nAunque el uso de sistemas operativos inmutables puede llevar más comodidad a los usuarios de ordenadores personales en el entorno doméstico, su principal potencial puede estar en los entornos profesionales en los que personas que no tienen conocimientos relacionados con la informática deben trabajar con estos equipos en su día a día. Este tipo de sistemas operativos permite que estos ordenadores de escritorio cuenten con las herramientas necesarias para que el trabajador desarrolle sus tareas pero impide que pueda ejecutar cualquier modificación sobre el sistema operativo que afecte al correcto funcionamiento del mismo, haciéndolo mucho más robusto y minimizando la probabilidad de que un error humano genere una incidencia en el parque informático de la empresa.\nDistribuciones inmutables actuales Casi todas las principales distribuciones de GNU/Linux cuentan con una versión de su sistema operativo inmutable a día de hoy. Algunos ejemplos son:\nFedora Silverblue. Silverblue es la versión inmutable de la distribución Fedora derivada de Fedora Workstation. Esta distribución usa Flatpak como gestor de paquetes universales y Podman como gestor de contenedores. Silverblue usa GNOME como entorno de escritorio pero Fedora cuenta con otras opciones de sistemas operativos inmutables que usan otros entornos de escritorio diferentes.\nopenSUSE MicroOS. MicroOS es la versión inmutable de openSUSE. De entre todas las distribuciones de sistemas operativos inmutables es una de las más orientadas al entorno de servidores. Usa el gestor de paquetes Flatpak y pretende aportar la robustez y seguridad que permiten los sistemas operativos inmutables al entorno de servidores. Está especialmente destinado al trabajo en servidores pequeños que ofrecen aplicaciones en contenedores o microservicios. También está destinado a su uso en dispositivos inteligentes.\nVanilla OS. Vanilla OS es la distribución inmutable de Ubuntu. Desarrollada por Canonical, mantiene la filosofía de sencillez y facilidad de uso que caracteriza a Ubuntu aportando, además, las ventajas de los sistemas operativos inmutables en cuanto a seguridad de la integridad del sistema operativo. Vanilla OS usa el gestor de paquetes Snap, desarrollado también por Canonical.\nNixOS. NixOS es una distribución concebida para funcionar como un sistema operativo inmutable. Usa su propio sistema gestor de paquetería universal.\nUbuntu Core. Otro sistema operativo inmutable derivado de Ubuntu es Ubuntu Core. Este sistema operativo está especialmente diseñado para su uso en dispositivos inteligentes.\nBottlerocket. Bottlerocket es un sistema operativo inmutable desarrollado por Amazon que se puede usar al crear una instancia en Amazon Web Services. Este sistema operativo está diseñado para ejecutar aplicaciones sobre contenedores y suponer un mantenimiento mínimo a los usuarios de la plataforma.\nSteamOS. Algunas distribuciones de sistemas operativos no inmutables tienen están diseñadas con una utilidad más concreta y no son de propósito generalista. Es el caso de SteamOS, una distribución basada en Debian y desarrollada por Valve que está optimizada para videojuegos. Entre sus características cuenta con una gran compatibilidad con hardware de lo más variado.\nEndless OS. Otro sistema operativo inmutable de nicho es Endless OS, orientado a entornos educativos. El propio sistema operativo cuenta con una importante variedad de aplicaciones y contenido educativo preinstalado, con el planteamiento de que el usuario final no necesite instalar ninguna aplicación más para poder usar el equipo.\nAdemás de los sistemas operativos listados, no paran de surgir nuevas distribuciones que se basan en la inmutabilidad del sistema operativo. Algunas de ellas están destinadas al uso en equipos de escritorio mientras que otras muchas se orientan al despliegue de aplicaciones en contenedores, como Talos Linux, que está diseñado para el uso de Kubernetes.\nEn conclusión Aunque no es la primera vez que la idea de los sistemas operativos inmutables aparece en el mundo de la informática (ya hace décadas que existen los sistemas operativos live en CD sobre los que no se pueden hacer modificaciones), todo apunta a que esta vez han llegado para quedarse.\nY es que se dan varias circunstancias que, en conjunto, pueden suponer un cambio de paradigma en la forma en que se conciben los sistemas operativos.\nEs evidente que los sistemas operativos inmutables tienen importantes ventajas como la seguridad y estabilidad que ofrecen o la facilidad para instalar aplicaciones a través de los sistemas de paquetería universal. Además, estas aplicaciones, al estar más aisladas, son mucho más fáciles de actualizar hasta el punto de que en un mismo sistema pueden convivir varias versiones de la misma aplicación.\nAunque también conllevan algunas desventajas como el consumo de espacio en disco, la limitación en el número de aplicaciones que actualmente están disponibles en los sistemas de paquetería universal y la reconversión que supone también para el usuario adaptarse a este nuevo paradigma.\nSin embargo, el auge del uso de contenedores para el despliegue de aplicaciones tanto en entornos de escritorio como en entorno de servidores puede suponer el caldo de cultivo perfecto para la proliferación de este tipo de sistemas operativos.\nLos SO inmutables de OpenSUSE y Red Hat OpenSUSE MicroOS MicroOS es el sistema operativo inmutable de OpenSUSE. Se trata de un sistema operativo Linux de creación relativamente reciente que usa imágenes pequeñas y ligeras, fácilmente escalable, con actualizaciones automáticas y continuas que no afectan al sistema y resistente a fallos, con una gran facilidad para la recuperación al permitir volver al estado de la última instantánea en cualquier momento.\nSegún sus desarrolladores, se trata de un sistema operativo del que el usuario no tiene que preocuparse y que está específicamente diseñado para el alojamiento de contenedores pero enfocado a un entorno de grandes implantaciones.\nopenSUSE MicroOS hereda los conocimientos de openSUSE Tumbleweed y SUSE Linux Enterprise, al tiempo que redefine el sistema operativo en una distribución pequeña, eficiente y fiable. openSUSE\nEl sistema operativo MicroOS cuenta con un sistema de ficheros raíz de sólo lectura que evita las modificaciones accidentales del sistema. Además, cuenta con la tecnología Transactional Updates, que aprovecha las instantáneas de btrfs (el sistema de ficheros que usa este sistema operativo) para aplicar actualizaciones de paquetes sin interferir con el sistema en funcionamiento.\nOtras herramientas presentes en este sistema operativo son health-checker, que verifica el correcto funcionamiento del sistema y revierte los cambios que produzcan problemas; cloud-init, que configura el sistema durante su primer arranque en la nube; o Combustion e Ignition, que cumplen la misma función en el resto de imágenes.\nCabe destacar, además, que MicroOS es un sistema operativo de tipo rolling release, es decir, que cada nueva versión o instantánea liberada de openSUSE Tumbleweed produce automáticamente una nueva versión de este sistema operativo.\nLa innovación más reciente en el marco de este sistema operativo es que está en un proceso de modificación de nombre. Se están desarrollando dos nuevas versiones paralelas de MicroOS: Aeon y Kalpa. Cuando termine el desarrollo de estas nuevas versiones, openSUSE MicroOS pasará a llamarse Aeon cuando use un entorno de escritorio Gnome o Kalpa cuando use un entorno de escritorio Plasma. Ambos sistemas operativos están aún en desarrollo y todavía no se recomienda implementarlos en entornos de producción.\nFedora Silverblue Fedora Silverblue es un sistema operativo inmutable basado en Fedora, la distribución rolling release del ecosistema Red Hat. Una de las características principales de este sistema operativo del proyecto fedora es la fiabilidad. Cada versión de Silverblue se actualiza durante unos 13 meses y cada actualización se aplica automáticamente en el reinicio del equipo, de manera que el sistema se mantiene consistente. Incluso se puede seguir trabajando en el equipo mientras se aplican las actualizaciones.\nAdemás, se trata de un sistema operativo atómico, que se sólo se actualiza si la actualización se puede efectuar sin problemas. Si durante el proceso de actualización surge algún inconveniente, el sistema se revierte al último estado consistente y la actualización no se aplica.\nComo el resto de sistemas operativos inmutables, Silverblue almacena instantáneas de la última versión funcional del sistema, a la que se puede recurrir en caso de que fuese necesario. Igualmente, las aplicaciones gráficas se instalan de forma aislada usando el gestor de paquetería universal Flatpak, que las mantiene separadas del sistema raíz.\nEste sistema operativo también cuenta con una herramienta orientada al trabajo de los desarrolladores, toolbox, que facilita mantener la gestión de diferentes versiones de las mismas herramientas organizadas por proyectos sin que se afecten unas a otras o al propio sistema operativo.\nEl entorno de escritorio elegido por Fedora para desarrollar Silverblue es Gnome. Para la gestión de la paquetería propia del sistema operativo, esta distribución usa rpm-ostree, una sistema híbrido de paquetería e instantáneas basado en el gestor de paquetes RPM que permite actualizaciones atómicas y seguras del sistema raíz.\nOtros proyectos de sistemas operativos inmutables relacionados con Silverblue son Fedora Kinoite, que usa el entorno de escritorio Plasma o Fedora CoreOS, que es un sistema operativo inmutable minimalista, monolítico y que se actualiza automáticamente orientado al trabajo con contenedores y especialmente optimizado para el uso de Kubernetes.\nInstalación de MicroOS y Silverblue Instalación de MicroOS La imagen iso de openSUSE MicroOS se puede descargar desde la página de descargas de la distribución. A diferencia de lo que ocurre con la mayoría de distribuciones de GNU/Linux tradicionales, que a penas exigen unos requisitos mínimos muy báicos, MicroOS necesita, como mínimo 1GB de memoria RAM, 5GB de disco para la partición raíz y otros 5GB de disco para la partición /var. Sin embargo, openSUSE recomienda contar con 2GB de RAM y 60GB de disco duro (20 para la raíz y 40 para la partición /var) en las máquinas en las que se vaya a instalar este sistema operativo.\nOtra diferencia relevante entre MicroOS y los sistemas operativos tradicionales de GNU/Linux es que, generalmente, las imágenes de estos sistemas operativos suelen ser bastante ligeras. Al menos, suelen contar con una versión para instalación a través de internet que cuenta con la estructura mínima del sistema operativo e instala el resto de la paquetería desde los repositorios de la distribución. En el caso de MicroOS, las imágenes son, en geneeral, algo más pesadas, de unos 2,5GB.\nAl iniciar la imagen iso de MicroOS se muestra un menú de arranque que incluye las opciones de arrancar desde el disco duro o instalar el sistema operativo junto con un menú de opciones avanzadas.\nAl seleccionar la opción de instalación, lo primero que hace el sistema es inicializar la configuración de red. Para ello detecta los dispositivos de red y sus drivers, analiza el estado de la red, y lee la configuración tanto de los dispositivos como de la red.\nLa primera parte (y, prácticamente, la única) interactiva del proceso de instalación consiste en elegir la función del sistema. A diferencia del proceso de instalación de la mayoría de distribuciones de GNU/Linux en la que el usuario debe configurar los diferentes elementos del sistema, el instalador de MicroOS muestra una lista de posibles funciones que puede tomar el sistema que se instala para que el usuario elija la instalación predeterminada que mejor se adapte a la función que le va a dar a la máquina.\nSegún la opción que se elija, el instalador solicita una información u otra como, por ejemplo, el nombre de usuario y la contraseña o el servidor NTP para sincronizar el reloj del equipo.\nPara hacer una configuración más específica de la instalación: por ejemplo, para elegir determinado software durante la instalación o hacer un determinado particionado manual hay que acceder a cada uno de los apartados del resumen de instalación que muestra el asistente al finalizar el proceso.\nPor defecto, MicroOS crea en el disco duro una pequeña partición de arranque y dos particiones más de un tamaño similar entre ellas en las que monta los directorios raíz y /var. En un sistema operativo inmutable en el que las snapshots tienen una importancia crucial tiene especial sentido que el directorio /var, donde se suelen almacenar las instantáneas, esté separado de la raíz del sistema. Ambas particiones se crean usando un sistema de archivos btrfs.\nDesde esa misma pantalla se puede pulsar el botón \u0026ldquo;instalar\u0026rdquo; para lanzar el instalador, que instala en el sistema toda la paquetería básica necesaria para su funcionamiento, así como los paquetes específicos que se hayan indicado en el menú de instalación.\nInstalación de Silverblue La imagen para la instalación de Fedora Silverblue se puede descargar desde la página de descargas del sistema operativo. A diferencia de MicroOS, Silverblue no especifica en su página de descargas los requisitos mínimos con los que debe contar la máquina sobre la que se instala el sistema. Sin embargo, las imágnes sí son de un tamaño similar a las que distribuye openSUSE. En este caso, la iso de Fedora Silverblue es de 2,8GB, mucho mayor que las imágenes netinstall de otras distribuciones como Debian, que a penas llegan a los 500MB.\nEl menú de arranque del instalador de Fedora Silverblue muestra diferentes opciones para instalar directamente el sistema operativo, instalarlo tras probarlo o resolver posible problemas.\nLa interfaz del instalador de Fedora Silverblue es muy similar a las del resto de distribuciones del ecosistema de Red Hat (como RHEL, CentOS, Fedora y otras distribuciones derivdas como AlmaLinux o Rocky Linux). La principal diferencia es que Silverblue casi no permite configurar ningún elemento del sistema durante la instalación, de hecho, el único aspecto del sistema al que se puede acceder desde el instalador es el de particionado.\nEl menú de particionado es análogo al que usan el resto de distribuciones basadas en Red Hat. Sin embargo, tal y como avisan en su documentación, \u0026ldquo;Fedora Silverblue no ofrece una experiencia totalmente funcional para el arranque dual o el particionado manual\u0026rdquo; y, por tanto, es recomendable hacer la instalación usando el particionado automático.\nTras acceder al menú de particionado y validar el tipo de particionado deseado en la instalación, se puede lanzar el instalador.\nEste instalador prerpara el disco, lo particiona e instala el sistema operativo con todos los paquetes necesarios para su funcionamiento. Si el proceso de instalación de openSUSE MicroOS es poco interactivo, la capacidad del usuario para intervenir en la instalación de Silverblue es mínima hasta el punto de que no se puede crear un usuario o elegir la paquetería que se instala junto al sistema operativo base.\nTras finalizar el proceso de instalación, se reinicia el sistema.\nEn el primer inicio de Silverblue, se muestra un asistente de configuración del sistema. Durante esta configuración, se puede configurar la privacidad, se puede activar el software de terceros y, además, se crea el usuario sin privilegios del sistema.\nGestión de paquetes y aplicaciones en MicroOS y Silverblue Gestión de paquetes y aplicaciones en MicroOS Aunque el gestor de paquetes de los diferentes sistemas operativos de openSUSE es zypper, en el caso de MicroOS este gestor de paquetes no puede efectuar ningún cambio en el sistema raíz. Para getionar la paquetería del sistema operativo se usa en esta distribución la herramienta transactional-update. Esta herramienta hace una instantánea del sistema en el momento previo a la instalación o actualización del paquete y, posteriormente, lo instala. De esta manera, el sistema garantiza que ante un posible fallo durante la instalación o actualización del paquete se puede volver al estado anterior.\nPor ejemplo, para actualizar la paquetería del sistema se usa el comando transactional-update, que genera una instantánea del sistema operativo antes de usar zypper para instalar todas las actualizaciones necesarias en el sistema.\nlocalhost:~ # transactional-update Checking for newer version. transactional-update 4.8.3 started Options: Separate /var detected. 2024-12-18 16:57:40 tukit 4.8.3 started 2024-12-18 16:57:40 Options: -c1 open 2024-12-18 16:57:42 Using snapshot 1 as base for new snapshot 2. 2024-12-18 16:57:42 /var/lib/overlay/1/etc 2024-12-18 16:57:42 No previous snapshot to sync with - skipping Relabeled /var from system_u:object_r:unlabeled_t:s0 to system_u:object_r:var_t:s0 Relabeled /var/lib from unconfined_u:object_r:unlabeled_t:s0 to unconfined_u:object_r:var_lib_t:s0 ID: 2 2024-12-18 16:57:45 Transaction completed. Calling zypper --no-cd dup ... 2024-12-18 16:59:26 Application returned with exit status 0. 2024-12-18 16:59:28 Transaction completed. Trying to rebuild kdump initrd 2024-12-18 16:59:30 tukit 4.8.3 started 2024-12-18 16:59:30 Options: call 2 /sbin/mkdumprd 2024-12-18 16:59:32 Executing `/sbin/mkdumprd`: /var/lib/kdump not writable, not regenerating initrd. 2024-12-18 16:59:32 Application returned with exit status 0. 2024-12-18 16:59:33 Transaction completed. 2024-12-18 16:59:33 tukit 4.8.3 started 2024-12-18 16:59:33 Options: close 2 2024-12-18 16:59:35 New default snapshot is #2 (/.snapshots/2/snapshot). 2024-12-18 16:59:35 Transaction completed. Please reboot your machine to activate the changes and avoid data loss. New default snapshot is #2 (/.snapshots/2/snapshot). transactional-update finished Como se muestra en la salida del comando, el último paso que realiza la herramienta transactional-update tras instalar todas las actualizaciones pendientes y mostrar el mensaje Transaction completed es generar una nueva instantánea en el directorio oculto .snapshots dentro del directorio raíz. Tras realizar un reinicio del sistema, se cargará esta nueva instantánea que ya contará con todas las actualizaciones instaladas. Mientras no se haga este reinicio, las actualizaciones aún no se aplicarán al sistema.\nEste mecanismo de respaldo del sistema basado en las instantáneas permite, por ejemplo, arrancar el sistema desde una imagen previamente guardada en modo de sólo lectura desde el gestor de arranque grub. Esta opción puede ser muy útil en caso de necesitar acceder a un estado consistente previo del sistema para poder solventar algún error en el mismo.\nDe igual modo se instalan nuevos paquetes en el sistema. En este caso, al comando transactional-update hay que añadirle la orden pkg install seguida del nombre del paquete que se quiere instalar.\nlocalhost:~ # transactional-update pkg in tree Checking for newer version. transactional-update 4.8.3 started Options: pkg in tree Separate /var detected. 2024-12-18 17:06:47 tukit 4.8.3 started 2024-12-18 17:06:47 Options: -c2 open 2024-12-18 17:06:47 Using snapshot 2 as base for new snapshot 4. 2024-12-18 17:06:47 /var/lib/overlay/2/etc 2024-12-18 17:06:47 Syncing /etc of previous snapshot 1 as base into new snapshot \u0026#34;/.snapshots/4/snapshot\u0026#34; 2024-12-18 17:06:47 SELinux is enabled. ID: 4 2024-12-18 17:06:50 Transaction completed. Calling zypper install 2024-12-18 17:06:53 tukit 4.8.3 started 2024-12-18 17:06:53 Options: callext 4 zypper -R {} install tree 2024-12-18 17:06:55 Executing `zypper -R /tmp/transactional-update-8QTVUT install tree`: Loading repository data... Reading installed packages... Resolving package dependencies... The following NEW package is going to be installed: tree 1 new package to install. ... Retrieving: tree-2.2.1-1.1.x86_64 (openSUSE-Tumbleweed-Oss) (1/1), 78.1 KiB Retrieving: tree-2.2.1-1.1.x86_64.rpm [...done (15.2 KiB/s)] (1/1) Installing: tree-2.2.1-1.1.x86_64 [..done] 2024-12-18 17:07:30 Application returned with exit status 0. 2024-12-18 17:07:30 Transaction completed. Trying to rebuild kdump initrd 2024-12-18 17:07:32 tukit 4.8.3 started 2024-12-18 17:07:32 Options: call 4 /sbin/mkdumprd 2024-12-18 17:07:33 Executing `/sbin/mkdumprd`: /var/lib/kdump not writable, not regenerating initrd. 2024-12-18 17:07:33 Application returned with exit status 0. 2024-12-18 17:07:34 Transaction completed. 2024-12-18 17:07:34 tukit 4.8.3 started 2024-12-18 17:07:34 Options: close 4 2024-12-18 17:07:36 New default snapshot is #4 (/.snapshots/4/snapshot). 2024-12-18 17:07:36 Transaction completed. Please reboot your machine to activate the changes and avoid data loss. New default snapshot is #4 (/.snapshots/4/snapshot). transactional-update finished Nuevamente, la herramienta transactional-update genera una instantánea del sistema con el nuevo paquete instalado e indica que se debe reiniciar el sistema para aplicar los cambios. Sin embargo, este sistema operativo también permite cargar una instantánea del sistema en caliente para aplicar estos cambios sin necesidad de reiniciar la máquina.\nSiguiendo con este ejemplo, tras haber generado la snapshot número 4 durante la ejecución del comando anterior, esta orden hace que el sistema cargue la nueva instantánea y la use para remplazar la instantánea sobre la que se basa el sistema en ejecución.\nlocalhost:~ # transactional-update apply Checking for newer version. transactional-update 4.8.3 started Options: apply Separate /var detected. Using default snapshot 4 to replace running system... Applying /usr... Applying /etc... Applying /boot... Executing systemctl daemon-reexec... Executing create_dirs_from_rpmdb... Executing systemd-tmpfiles --create... =\u0026gt; Applied default snapshot as new base for running system! Running processes will not be restarted automatically. transactional-update finished Tras aplicar los cambios, el nuevo paquete está disponible en el sistema.\nlocalhost:~ # tree . ├── Desktop │ ├── Home.desktop │ └── trash.desktop ├── Documents ├── Downloads ├── Music ├── Pictures ├── Public ├── Templates ├── Videos ├── bin └── inst-sys └── yast2-screen-shots 12 directories, 2 files Otra práctica habitual en este tipo de sistemas operativos inmutables es el uso de sistemas de paquetería universal para la instalación de aplicaciones de escritorio. En este caso, MicroOS usa Flatpak como gestor de paquetería universal.\nAunque se puede usar desde la línea de comandos, el método más habitual de usar Flatpak es desde la herramienta gráfica de gestión de aplicaciones del sistema operativo. En el caso de MicroOS esta aplicación se llama Discover. Al acceder a ella por primera vez es necesario configurar las fuentes de Flatpak desde las que se van a descargar las aplicaciones. Para hacerlo, sólo hay que pulsar el botón en el que pone \u0026ldquo;Add Flathub\u0026rdquo;. Flathub es uno de los repositorios más populares de aplicaciones en Flatpak.\nIgualmente, la pestaña \u0026ldquo;Settings\u0026rdquo; de la aplicación \u0026ldquo;Discover\u0026rdquo; permite añadir una lista de repositorios de Flatpak a partir de su URL.\nTras añadir el repositorio a Flatpak, en la pestaña principal de \u0026ldquo;Discover\u0026rdquo; se muestra una lista de aplicaciones disponibles en Flatpak y que se pueden instalar en el sistema. Estas aplicaciones se instalan aisladas del sistema raíz, sin afectar al mismo y sin interactuar con él, lo que mantiene la inmutabilidad del sistema operativo.\nUna tercera opción alternativa para la instalación de aplicaciones en este sistema operativo es el uso de contenedores. Es el caso de distrobox, una herramienta que permite gestionar contenedores para ejecutar aplicaciones con independencia del sistema operativo sobre el que lo hagan.\nEsta herramienta se debe instalar como un paquete usando el sistema de instalación propio de MicroOS transactional-update.\nlocalhost:~ # transactional-update pkg install distrobox localhost:~ # transactional-update apply Esta herramienta permite crear contenedores a partir de imágenes de otros sistemas operativos.\nlocalhost:~ # distrobox create --name debian01 --image debian:latest localhost:~ # distrobox enter debian01 En ellos se pueden instalar y ejecutar aplicaciones disponibles en esos sistemas opeativos y, además, exportar un acceso directo a esas aplicaciones al panel de aplicaciones del sistema.\nGestión de paquetes y aplicaciones en Silverblue Como es habitual en los sistemas operativos inmutables, la versión Silverblue de Fedora tampoco permite el uso del gestor de paquetes propio del ecosistema Red Hat, dnf. La herramienta usada en Fedora Silverblue para interactuar con el sistema raíz y poder instalar y actualizar la paquetería del sistema es rpm-ostree. De forma análoga a transactional-update, esta herramienta hace una instantánea que guarda el estado presente del sistema operativo antes de efectuar ninguna modificación. Posteriormente, se instalan o actualizan los paquetes necesarios y, finalmente, se crea una nueva instantánea si los cambios han sido existosos. De nuevo, para aplicar los cambios es necesario reinicar el sistema.\nroot@fedora:~# rpm-ostree update ⠤ Receiving objects; 99% (15311/15315) 2,8 MB/s 974,2 MB 2641 metadata, 12674 content objects fetched; 951438 KiB transferred in 428 seconds; 2,2 GB content written Receiving objects; 99% (15311/15315) 2,8 MB/s 974,2 MB... done Staging deployment... done Upgraded: ImageMagick 1:7.1.1.38-1.fc41 -\u0026gt; 1:7.1.1.41-1.fc41 ImageMagick-libs 1:7.1.1.38-1.fc41 -\u0026gt; 1:7.1.1.41-1.fc41 PackageKit-glib 1.2.8-7.fc41 -\u0026gt; 1.2.8-8.fc41 ... xorg-x11-xinit-1.4.2-3.fc41.x86_64 xrdb-1.2.2-4.fc41.x86_64 Added: OpenCL-ICD-Loader-3.0.6-1.20241023git5907ac1.fc41.x86_64 bootc-1.1.2-2.fc41.x86_64 hiredis-1.2.0-3.fc41.x86_64 opensc-libs-0.26.0-1.fc41.x86_64 Run \u0026#34;systemctl reboot\u0026#34; to start a reboot Silverblue se refiere a cada una de las instantáneas que crea para guardar el estado del sistema operativo como \u0026ldquo;despliegues\u0026rdquo;. Tras aplicar alguna instalación o actualización, es necesario reiniciar el sistema para aplicar el nuevo \u0026ldquo;despliegue\u0026rdquo;.\nDe la misma forma se pueden instalar nuevos paquetes en el sistema.\noot@fedora:~# rpm-ostree install cmatrix Checking out tree e3782ee... done Enabled rpm-md repositories: fedora-cisco-openh264 updates fedora updates-archive Importing rpm-md... done rpm-md repo \u0026#39;fedora-cisco-openh264\u0026#39; (cached); generated: 2024-03-11T19:22:31Z solvables: 3 rpm-md repo \u0026#39;updates\u0026#39; (cached); generated: 2024-12-17T03:55:59Z solvables: 13865 rpm-md repo \u0026#39;fedora\u0026#39; (cached); generated: 2024-10-24T13:55:59Z solvables: 76624 rpm-md repo \u0026#39;updates-archive\u0026#39; (cached); generated: 2024-12-17T04:21:09Z solvables: 16853 Resolving dependencies... done Will download: 1 package (40,1 kB) Downloading from \u0026#39;fedora\u0026#39;... done Importing packages... done Checking out packages... done Running pre scripts... done Running post scripts... done Running posttrans scripts... done Writing rpmdb... done Writing OSTree commit... done Staging deployment... done Added: cmatrix-2.0-10.fc41.x86_64 Changes queued for next boot. Run \u0026#34;systemctl reboot\u0026#34; to start a reboot Al igual que MicroOS, Silverblue también permite cambiar en caliente entre estos diferentes \u0026ldquo;despliegues\u0026rdquo;.\nroot@fedora:~# rpm-ostree apply-live Computing /etc diff to preserve... done Updating /usr... done Updating /etc... done Running systemd-tmpfiles for /run and /var... done Added: cmatrix-2.0-10.fc41.x86_64 Successfully updated running filesystem tree. Por otra parte, en Silverblue también se pueden instalar las aplicaciones del gestor de paquetería universal Flatpak. Por defecto, la herramienta gráfica de instalación de software de Fedora Silverblue tiene configurado los repositorios de Flatpak de la propia distribución. En estos repositorios hay disponible una gran variedad de aplicaciones que se instalan de forma aisladas en el sistema sin interactuar con el sistema de ficheros raíz.\nAdemás, desde el menú de repositorios de software se pueden añadir nuevos repositorios a Flatpak como, por ejemplo, el repositorio Flathub, uno de los más usados por la comunidad de GNU/Linux.\nPor último, cabe destacar que, tal y como se ha documentado en el apartado anterior, en Fedora Silverblue también se pueden ejecutar aplicaciones en contenedores usando gestores de contenedores como, por ejemplo, Distrobox.\nEn el repostorio Flathub de Flatpak se incluye una herramienta de interfaz gráfica que permite gestionar los contenedores creados con la herramienta Distrobox en los entornos de escritorio basados en Gnome. Desde su interfaz se pueden crear nuevos contenedores, acceder a la terminal de cada uno de ellos, cambiar el nombre, elegir el sistema operativo que usan, ver las aplicaciones instaladas en ellos, etc.\nPara que BoxBuddy pueda funcionar, primero es necesario instalar Distrobox en el equipo. Esta instalación se debe hacer usando la opción de instalación de la distribución que permite la instalación de paquetes en el sistema raíz, en el caso de Fedora Silverblue, con rpm-ostree.\nrpm-ostree install distrobox sudo rpm-ostree apply-live Pulsando el botón + de la ventana de BoxBuddy se abre el menú de creación de un nuevo contenedor. En este menú se puede indicar el nombre y distribución del contenedor y, con el botón crear, se inica su proceso de creación.\nCuando crea el contenedor, BoxBuddy abre una terminal desde la que se puede interactuar con este sistema. Además, desde la interfaz de esta herramienta se pueden ejecutar algunas acciones relevantes sobre el contenedor como abrir una terminal, actualizarlo, ver las aplicaciones instaladas en él, instalar aplicaciones desde un fichero .deb almacenado localmente, clonar el contenedor o eliminarlo.\nEn la terminal del contenedor se puede trabajar como en cualquier otro contenedor de distrobox. Por ejemplo, se puede instalar una aplicación determinada.\nsudo apt update sudo apt install deepin-calculator Cuando finaliza la instalación de la paquetería necesaria, la aplicación aparece en la lista de aplicaciones que se muestra en la interfaz gráfica de BoxBuddy. Esta ventana permite no sólo ver las aplicaciones que están instaladas en el contenedor sino también ejecutarlas y exportarlas con el botón Añadir al Menú.\nCuando se exporta una aplicación con este botón, aparece en el panel de aplicaciones de Gnome (esquina inferior izquierda en la siguiente captura de pantalla) al igual que si se hubiese exportado desde la terminal del contenedor.\nOtra herramienta interesante para usar en este tipo de sistemas operativos inmutables es Flatseal. Flatseal es una aplicación gráfica que permite gestionar los accesos de las diferentes aplicaciones instaladas con el gestor de paquetería universal Flatpak.\nFuentes Los sistemas operativos inmutables en Linux\nQué es una distro inmutable de Linux y por qué tienen tantas ventajas\nQué es un Linux \u0026lsquo;inmutable\u0026rsquo;: estas son las ventajas que ofrece esta nueva categoría de sistema operativo\n12 Immutable Linux Distributions for Those Looking to Embrace the Future\nopenSUSE MicroOS\nMicroOS\nQué es Fedora Silverblue. Todavía hay espacio para distribuciones originales\nFedora Silverblue\n"},{
  "section": "Blog",
  "slug": "/blog/implantacion-aplicaciones-web/2024-12-03-instalacion-cms-python/",
  "title": "Instalación de un CMS Python usando Django",
  "description": "",
  "date": "December 3, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "implantacion",
  "tags": "Python, django, Framework, Nginx, servidor web, LEMP, CMS, implantacion, Implantación de Aplicaciones Web",
  "content":"En este post se instala el CMS CMS-Django usando un entorno virtual.\nPara ello, en primer lugar, se crea un entorno virtual en el que se instala la aplicación.\ncd venv/ python3 -m venv cms source cms/bin/activate pip install django-cms Para crear un proyecto se usa el comando djangocms.\n❯ djangocms javiblog Clone template using django-admin django-admin startproject \u0026#34;javiblog\u0026#34; --template https://github.com/django-cms/cms-template/archive/4.1.tar.gz cd \u0026#34;/home/debian/javiblog\u0026#34; Install requirements in /home/debian/javiblog/requirements.in python -m pip install -r \u0026#34;/home/debian/javiblog/requirements.in\u0026#34; Run migrations python -m manage migrate Create superuser python -m manage createsuperuser Username (leave blank to use \u0026#39;debian\u0026#39;): admin Email address: admin@javiblog.org Password: Password (again): The password is too similar to the username. This password is too short. It must contain at least 8 characters. This password is too common. Bypass password validation and create user anyway? [y/N]: y Superuser created successfully. Check installation python -m manage cms check *************************************** django CMS 4.1.4 installed successfully *************************************** Congrat Para probar la instalación se puede ejecutar un servidor de pruebas con python3 manage.py runserver 0.0.0.0:8080.\nConfiguración del servidor Apache2 Para poder servir el CMS en Apache2 hay que configurar el VirtualHost indicando el ServerName, DocumentRoot y también aportando la información necesaria para que funcione el módulo wsgi de Apache2.\n\u0026lt;VirtualHost *:80\u0026gt; ServerName portal.javi.org ServerAdmin webmaster@localhost DocumentRoot /home/debian/javiblog WSGIDaemonProcess javiblog python-path=/home/debian/javiblog:/home/debian/venv/cms/lib/python3.11/site-packages WSGIProcessGroup javiblog WSGIScriptAlias / /home/debian/javiblog/javiblog/wsgi.py process-group=javiblog \u0026lt;Directory /home/debian/javiblog\u0026gt; Require all granted \u0026lt;/Directory\u0026gt; Alias /static/ /home/debian/javiblog/static/ \u0026lt;Directory /home/debian/javiblog/static/\u0026gt; Require all granted \u0026lt;/Directory\u0026gt; ErrorLog ${APACHE_LOG_DIR}/error.log CustomLog ${APACHE_LOG_DIR}/access.log combined \u0026lt;/VirtualHost\u0026gt; Después se activa el VirtualHost.\n❯ sudo a2ensite djangocms.conf Enabling site djangocms. To activate the new configuration, you need to run: systemctl reload apache2 ❯ sudo systemctl reload apache2.service A continuación se usa el comando collectstatic para generar un directorio de ficheros estáticos en el directorio del proyecto con todos los ficheros estáticos. Para que este comando funcione, se debe indicar la URL base de los ficheros estáticos en el fichero settings.py\nSTATIC_ROOT = os.path.join(BASE_DIR, \u0026#39;static\u0026#39;) Y después se puede ejecutar el comando collectstatic.\n❯ python3 manage.py collectstatic Found another file with the destination path \u0026#39;admin/img/search.svg\u0026#39;. It will be ignored since only the first encountered file is collected. If this is not what you want, make sure every static file has a unique path. 1159 static files copied to \u0026#39;/home/debian/javiblog/static\u0026#39;. Accediendo al servidor se puede usar el CMS instalado.\nMigración del CMS Volcado del proyecto En este caso, la aplicación django no está en un repositorio de GitHub, sino que se ha instalado localmente en el entorno de desarrollo. Para llevar el CMS al entorno de producción se puede crear un repositorio en GitHub y clonarlo o, directamente, sucar scp para copiar el directorio en el servidor en producción.\nAntes de llevar el directorio al entorno de producción conviene crear todos los ficheros necesarios como el fichero de respaldo del contenido de la base de datos.\n❯ python3 manage.py dumpdata \u0026gt; cms.json Para copiar el directorio al entorno de producción se puede usar el comando scp.\n❯ scp -r javiblog/ debian@pignite.javihuete.site:/home/debian En el entorno de desarrollo también se crea un entorno virtual y se instala el CMS y sus dependencias.\ncd venv/ python3 -m venv cms source venv/cms/bin/activate cd pip install django-cms cd javiblog pip install -r requirements.in pip install mysqlclient Para poder hacer la migración se crea la base de datos para la aplicación.\nMariaDB [(none)]\u0026gt; create database cms; Query OK, 1 row affected (0,002 sec) MariaDB [(none)]\u0026gt; create user \u0026#39;cms\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;*****\u0026#39;; Query OK, 0 rows affected (0,002 sec) MariaDB [(none)]\u0026gt; grant all privileges on cms.* to \u0026#39;cms\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;*****\u0026#39;; Query OK, 0 rows affected (0,001 sec) MariaDB [(none)]\u0026gt; flush privileges; Query OK, 0 rows affected (0,001 sec) Y en el fichero settings.py del proyecto se deben indicar los datos de la nueva base de datos.\n# Database # https://docs.djangoproject.com/en/5.1/ref/settings/#databases DATABASES = { \u0026#39;default\u0026#39;: { \u0026#39;ENGINE\u0026#39;: \u0026#39;django.db.backends.mysql\u0026#39;, \u0026#39;NAME\u0026#39;: \u0026#39;cms\u0026#39;, \u0026#39;USER\u0026#39;: \u0026#39;cms\u0026#39;, \u0026#39;PASSWORD\u0026#39;: \u0026#39;djangocms\u0026#39;, \u0026#39;HOST\u0026#39;: \u0026#39;localhost\u0026#39;, \u0026#39;PORT\u0026#39;: \u0026#39;\u0026#39;, } } Finalmente, se puede migrar la estructura de la base de datos.\npython3 manage.py migrate Y, por último, el contenido.\npython3 manage.py loaddata cms.json Antes de terminar con la configuración de la aplicación en el entorno de producción hay que permitir el acceso a través de la URL en el fichero settings.py.\nALLOWED_HOSTS = [\u0026#34;portal.javihuete.site\u0026#34;] Configuración del servidor de aplicaciones Para poder usar el servidor de aplicaciones uwsgi desde el entorno virtual del CMS hay que instalarlo dentro de este entorno virtual.\npip install uwsgi Para configurar el servidor de aplciaciones, en primer lugar, se genera el fichero .ini en el directorio del entorno virtual.\n[uwsgi] http = :8083 chdir = /home/debian/javiblog/javiblog wsgi-file = wsgi.py processes = 4 threads = 2 A partir de este fichero se puede configurar la unidad de systemd que controla este servicio en el directorio /etc/systemd/system/uwsgi-cms.\n[Unit] Description=uwsgi-cms After=network.target [Install] WantedBy=multi-user.target [Service] User=debian Group=debian Restart=always ExecStart=/home/debian/venv/cms/bin/uwsgi /home/debian/venv/cms/cms.ini ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s TERM $MAINPID WorkingDirectory=/home/debian/javiblog Environment=PYTHONPATH=\u0026#39;/home/debian/javiblog:/home/debian/venv/cms/lib/python3.11/s\u0026gt; PrivateTmp=true Para habilitar y arrancar el servicio se usa systemctl.\nsudo systemctl enable uswgi-cms.service sudo systemctl start uswgi-cms.service Configuración de Nginx como proxy inverso Para que Nginx dirija el tráfico al servidor de aplicaciones uwsgi se crea un VirtualHost con la siguiente configuración:\nserver { #listen 80; #server_name python.javihuete.site; #server_tokens off; #return 301 https://$server_name$request_uri; listen 443 ssl; server_name portal.javihuete.site; ssl_certificate /etc/letsencrypt/live/javihuete.site/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/javihuete.site/privkey.pem; ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers HIGH:!aNULL:!MD5; root /home/debian/javiblog; location / { proxy_pass http://localhost:8083; #include proxy_params; }\tlocation /static/ { alias /home/debian/javiblog/static/; } error_log /var/log/nginx/cms_error.log; access_log /var/log/nginx/cms_access.log; } Por último, para habilitar el sitio se crea el enlace simbólico y se reinicia el servidor web.\nsudo ln -s ../sites-available/cms sudo systemctl restart nginx.service Al poner en producción el CMS, se usa el protocolo HTTPS para el acceso a la página web. Esto hace que sea necesario añadir la siguiente línea al fichero settings.py de la aplicación:\nCSRF_TRUSTED_ORIGINS = [\u0026#34;https://portal.javihuete.site\u0026#34;,] "},{
  "section": "Blog",
  "slug": "/blog/administracion-de-sistemas/2024-12-02-convulsion-en-el-mundo-del-software-libre/",
  "title": "Convulsión en el mundo del software libre",
  "description": "",
  "date": "December 2, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "administracion-sistemas",
  "tags": "sistemas, redhat, linux, centOS, AlmaLinux, IBM, software libre, GPL, administracion-sistemas, Administración de Sistemas Operativos",
  "content":"Red Hat convulsiona el mundo del software libre Red Hat es una empresa creada en 1993 que cuenta con una historia que ha sido convulsa desde sus inicios. En 1994 publica Red Hat Linux (RHL) y en menos de 10 años abandona el proyecto para lanzar Red Hat Enterprise Linux, más orientado a empresas.\nLa relación entre Red Hat y CentOS En este momento, empiezan a aparecer proyectos independientes como Fedora o CentOS. Red Hat apoya desde un primer momento a la comunidad de Fedora que se convierte en una suerte de versión de pruebas o rolling release de Red Hat donde se pueden usar y testear las versiones más recientes de los paquetes de la distribución.\nSin embargo, CentOS se mantiene completamente independiente hasta 2014 cuando Red Hat entra en el proyecto con el acuerdo de apoyarlo en un primer momento. Unos años después IBM anuncia la compra de Red Hat y esto supone un cambio en las condiciones de CentOS.\nHasta este momento, CentOS se había mantenido como una distribución libre, sin embargo, con la llegada de IBM al accionariado de Red Hat la empresa decide reconvertir el proyecto en CentOS Stream, una distribución menos estable y con una licencia más privativa que limita el acceso a la paquetería, al código fuente del software y, sobre todo, que impide que este código se distribuya de forma libre por otros proyectos derivados de CentOS, como AlmaLinux, RockyLinux o SUSE. Además, anuncia un recorte en el período durante el que se mantendrá la última versión de CentOS cuyo fin de vida útil (EoL) llegó a mediados de 2024.\nEl 30 de junio de 2024 será una fecha crucial para el mundo del software empresarial de Linux. Durante casi 20 años, CentOS Linux ha sido el sistema operativo preferido por muchos para las cargas de trabajo de los servidores. Sin embargo, esto cambiará cuando CentOS Linux 7, la última versión que seguía en pie del Community ENTerprise Operating System (sistema operativo para empresas basado en los aportes de la comunidad), llegue al final de su vida útil (EOL).\nEric Hendricks - Red Hat\nAdemás, Red Hat cambia la propia naturaleza del proyecto CentOS con este movimiento. Así, CentOS pasa de ser la alternativa libre y abierta a Red Hat pero 100% compatible con su paquetería y con una mirada similar a la estabilidad y robustez de la distribución a convertirse en un punto intermedio en el desarrollo de las versiones de Red Hat entre Fedora y RHEL.\nLas reacciones de la comunidad Entre los meses de junio y julio de 2023, antes incluso de que pasasen 24 horas desde el anuncio de Red Hat, las distribuciones derivadas de CentOS empezaron a pronunciarse sobre la decisión de la empresa.\nLa primera en publicar su posicionamiento fue AlmaLinux, que emitió un comunicado en el que informaban del impacto que la decisión de Red Hat suponía para los proyectos forks y derivados de CentOS. Además, AlmaLinux denuncia en este comunicado que conocen la decisión de Red Hat porque un miembro del equipo de desarrollo no encuentra las actualizaciones de la versión 8 del sistema operativo en el repositorio git.centos.org, como era habitual hasta entonces, días antes del anuncio de la empresa.\nEn este mismo comunicado, el proyecto resalta la gravedad de la decisión de Red Hat, que afecta a todo el ecosistema de Red Hat y sus derivados y plantea un diálogo con el resto de proyectos derivados de CentOS para abordar la situación.\nPor su parte, SUSE destacaba en su publicación la preocupación que esta decisión estaba provocando en la comunidad open source y apuntaba a lo mucho que RHEL le debe a los esfuerzos colaborativos para mantener proyectos entre muchos colaboradores, incluyendo el kernel de Linux.\nEl centro de nuestro mundo es innovar juntos. Trabajamos juntos para construir algo mayor que la suma de todas las partes. Somos interdependientes.\nSUSE\nOtra empresa con intereses comerciales en CentOS es Oracle, que distribuye su propio sistema operativo basado en esta distribución. El 10 de julio emitían un duro comunicado contra la decisión de Red Hat en el que señalaban directamente a IBM, empresa competencia de Oracle, como responsables de esta decisión y de la gravedad de las consecuencias que tenía.\nEn su publicación, Oracle pone de manifiesto la importancia de las contribuciones que su equipo hace al kernel de Linux, así como a los sistemas de ficheros y herramientas que usa Red Hat y se muestran orgullosos de los beneficios que esas contribuciones suponen no sólo para los usuarios de Oracle, sino para todos los usuarios de Linux.\nAnte la decisión de Red Hat, Oracle, como el resto de proyectos derivados de CentOS se posiciona firmemente con el planteamiento del ecosistema de software libre de Linux y se muestran abiertos a trabajar con distribuciones derivadas.\nTras la adquisición de Red Hat por parte de IBM la Rocky Enterprise Software Foundation, formada por uno de los creadores de CentOS, crea el proyecto Rocky Linux con el propósito de seguir los objetivos que originalmente se planteaba CentOS. Ante la decisión de Red Hat, este proyecto patrocinado por la empresa MontaVista amplió los períodos de soporte (EoL) de sus distribuciones hasta 2029 (Rocky Linux 8) y 2032 (Rocky Linux).\nAdemás, MontaVista incorporó en su cartera de servicios un programa de apoyo para aquellas empresas que quisiesen hacer la migración de sus servidores desde CentOS a Rocky Linux.\nSituación actual Ante el fin del desarrollo de CentOS como un sistema operativo estable equivalente a Red Hat Enterprise Linux, aquellas empresas que usaban esta distribución en sus servidores han tenido que tomar la decisión de hacer una migración a un nuevo sistema operativo optando por una de los dos alternativas que se presentan a partir de esta situación.\nActualmente, lo que empezó siendo un entorno simbiótico en el que unos proyectos alimentaban a otros se encuentra dividido en dos visiones: por una parte la de los proyectos propietarios de Red Hat (RHEL, CentOS Stream) y proyectos apoyados por Red Hat como Fedora y, por otra, la de los proyectos derivados que se han mantenido fieles a los planteamientos del software libre (Rocky Linux, AlmaLinux, Oracle Linux, openSUSE\u0026hellip;).\nAsí, algunas empresas, habrán optado por la solución que propone Red Hat: migrar los servidores que usan una distribución de CentOS a REHL. Esta migración es sencilla y muy similar a una actualización de la versión del sistema operativo. Para estas empresas, esta solución supone pasar de usar un sistema operativo libre y gratuito a tener que firmar una licencia y pagar por el uso de RHEL.\nOtras, habrán optado en cambio por una opción alternativa y migrar sus servidores a otro sistema operativo. Uno de los derivados más común es Rocky Linux, que se ha posicionado como un sistema operativo capaz de suplir a CentOS en este tiempo. Por otra parte, AlmaLinux también ha conseguido tener una amplia difusión ante el fin de CentOS y cuenta con el apoyo de varias empresas importantes para su desarrollo. Oracle Linux, en cambio, ha seguido una estrategia comercial muy similar a la que tenía antes del fin de CentOS ofreciendo un sistema operativo robusto y compatible con otros productos de la compañía y trabajando en la implementación por adelantado de mejoras en el kernel de Linux.\nCabe destacar que, a pesar de la decisión tomada por IBM tras adquirir Red Hat, su modelo de licencia sigue estando basado en las licencias open source. De hecho, Red Hat Enterprise Linux es una distribución que se encuentra bajo la licencia GNU General Public License (GPL) que debe permitir usar, estudiar, modificar y copiar el código libremente.\nDe hecho, la propia licencia GPL bajo la que se distribuye el kernel de Linux obliga a usar licencias libres también para los sistemas operativos que lo usen.\nSin embargo, tras el cierre de CentOS por parte de Red Hat se pone en cuestión si la licencia de sus distribuciones como Red Hat Enterprise Linux o CentOS Stream cumple realmente con los requisitos necesarios que establece la Free Software Foundation para las licencias GLP.\nUso de Red Hat Registro en Red Hat Para poder descargar, instalar y probar en una máquina el sistema operativo de Red Hat, Red Hat Enterprise Linux (REHL) es necesario crear una cuenta en la página web de la empresa y solicitar una versión de prueba de su distribución de Linux. Este versión de prueba permite usar el sistema operativo durante 60 días, acceso al portal de clientes de la compañía, acceso a todas las versiones disponibles de la distribución y acceso a otros productos de la empresa como Red Hat Satellite y Red Hat Insights.\nHay dos formas de acceder a una versión de prueba. Una de ellas es creando una cuenta en la web de Red Hat y solicitando la imagen iso para la instalación del sistema operativo y otra es contactando con el servicio de ventas de la empresa, que puede poner a disposición de los clientes versiones de prueba más completas que incluyan, por ejemplo, soporte por parte de la compañía. En cualquier caso, las condiciones de la licencia de pruebas de Red Hat impide implantar su sistema operativo en un servidor en producción si no se adquiere una licencia de pago incluso durante el período en el que la licencia de pruebas está vigente.\nAl crear la cuenta de usuario en la web, Red Hat recopila una gran cantidad de información personal como el número de teléfono, dirección o sector profesional y puesto de la persona que solicita la versión de prueba de su sistema operativo.\nTras aportar la información solicitada, Red Hat envía un correo de validación con un enlace que lleva a una página de confirmación de la creación de la cuenta y que, directamente comienza la descarga de la versión de pruebas de RHEL desde el navegador web. En ese momento, comienzan a contar los 60 días del período de prueba.\nInstalación y funcionamiento del sistema operativo Instalación de Red Hat Enterprise Linux Tras comenzar la descarga de la imagen iso de instalación de la versión de prueba de RHEL, la web de bienvenida enlaza a la guía de instalación interactiva del sistema operativo. En esta guía se incluye información sobre los requisitos básicos del equipo para poder instalar el sistema operativo, la forma de crear un medio de instalación arrancable, instrucciones para crear una máquina virtual en la que probar el sistema operativo, cómo arrancar el medio de instalación o personalizar las opciones de arranque o la instalación del sistema.\nAl arrancar el instalador de Red Hat el sistema operativo muestra un menú de instalación escueto y poco amigable. De entrada, sólo muestra las opciones de instalar o probar e instalar el sistema operativo. En las opciones avanzadas se incluye una opción para comprobar si el equipo cumple con los requisitos del sistema operativo para su instalación o también cuenta con opciones para arrancar el equipo en modo de recuperación.\nEl primer paso tras elegir la opción de instalación en el menú principal de la iso de RHEL es elegir el idioma y la distribución del teclado.\nEn este caso, al acceder a la opción de instalación, el sistema también avisa de que existen ficheros de log disponibles en el directorio /tmp durante todo el proceso de instalación. Además, durante la instalación hay disponible una shell en la terminal TTY2.\nA continuación, el instalador abre un resumen de la instalación en el que se listan todos los diferentes apartados sobre los que el usuario puede tomar decisiones de cara a la instalación del sistema operativo. Habitualmente, los instaladores de otros sistema operativos suelen hacer un recorrido por cada uno de estos apartados. En cambio, RHEL muestra directamente un resumen interactivo de la instalación en el que se puede acceder y configurar cada uno de los apartados del proceso de instalación.\nUsando esta lista se puede acceder, por ejemplo, al menú de particionado. El apartado de particionado del instalador de RHEL contempla varias opciones como la selección del disco duro en el que se instala el sistema operativo, la opción de dejar espacio del disco sin usar durante la instalación o la selección de un particionado manual o automático. También se pueden añadir nuevos discos especializados o almacenamiento compartido en red. Si se elige la opción del particionado manual, se muestran diferentes menús de particionado posteriormente.\nOtro de los apartados de la instalación de RHEL, como en todos los sistemas operativos, es el de la creación de usuarios. En este caso, se muestran dos opciones diferentes: para acceder a la configuración del usuario privilegiado y para configurar el usuario normal. Además del nombre de usuario y contraseña, en esta página del instalador se puede especificar el directorio home de usuario, el uid y gid del usuario o añadirlo a varios grupos directamente desde este instalador. Además, se puede activar la opción de que el usuario tenga permisos de administración.\nPor otra parte, desde el resumen de la instalación también se puede acceder al menú de selección del software que se añade durante el proceso de instalación del sistema operativo. RHEL ofrece varias configuraciones por defecto según el uso que se vaya a dar al equipo en el que se instala el sistema operativo: servidor con interfaz gráfica, servidor, equipo de escritorio, una instalación mínima o una instalación optimizada para virtualización, entre otros.\nJunto al tipo de instalación predeterminada para cada finalidad se pueden seleccionar también una lista de paquetes que añaden nuevas funcionalidades al sistema. Esta lista también es diferente según la finalidad de la instalación. Por ejemplo, en la instalación determinada para servidor se pueden añadir paquetes que instalan servidores de almacenamiento compartido, FTP, DNS o también el entorno gráfico de GNOME, así como herramientas de Debugging o de red.\nLa particularidad que tiene este menú de instalación que no tienen otras distribuciones de GNU/Linux es que durante el proceso de instalación se puede conectar a la cuenta de Red Hat del usuario o vincular al equipo una clave de activación del sistema operativo.\nUso de Red Hat Enterprise Linux Uno de los primeros aspectos que llama la atención del uso de Red Hat es la cantidad de servicios que se ofrecen constantemente cada vez que se inicia una terminal:\nActivate the web console with: systemctl enable --now cockpit.socket O, al acceder por SSH:\nWeb console: https://localhost:9090/ or https://172.22.1.45:9090/ Register this system with Red Hat Insights: rhc connect Example: # rhc connect --activation-key \u0026lt;key\u0026gt; --organization \u0026lt;org\u0026gt; The rhc client and Red Hat Insights will enable analytics and additional management capabilities on your system. View your connected systems at https://console.Red Hat.com/insights You can learn more about how to register your system using rhc at https://red.ht/registration Muchos de estos servicios adicionales que ofrece la distribución requieren una suscripción de pago para su uso.\nUno de estos servicios es la consola web de RHEL, que aunque tiene algunas partes a las que sólo se puede acceder por suscripción también se puede usar desde la versión de prueba. Esta herramienta ofrece una interfaz web a la que se accede conectándose al puerto 9090 de la máquina RHEL y desde la que se puede gestionar una parte importante del sistema.\nEsta herramienta permite ver la información básica del sistema y recopilar datos sobre su uso y funcionamiento. Además, también cuenta con diferentes apartados desde los que se puede acceder a los logs del sistema, configurar el almacenamiento o las redes, gestionar contenedores Podman o gestionar las cuentas y servicios contratados a Red Hat.\nEl sistema operativo RHEL usa dos herramientas diferentes para la gestión de la paquetería del sistema: dnf y yum. Estos gestores de paquetes son muy similares a otros gestores de paquetes por línea de comando que se usan en otras distribuciones basadas GNU/Linux como, por ejemplo, el gestor de paquetes apt en Debian. Como todas las distribuciones basadas en Red Hat, estos gestores usan paquetes .rpm. La particularidad que tiene este sistema operativo respecto a otras distribuciones basadas en el propio Red Hat es que cualquier interacción con el sistema de paquetería exige el uso de la licencia ya sea de pago o de prueba. Así, al intentar realizar una actualización de la paquetería del sistema, por ejemplo, con dnf o yum el sistema devuelve el siguiente error:\n[usuario@localhost ~]$ sudo dnf update Actualización de repositorios de Subscription Management. No se pudo leer identidad del consumidor This system is not registered with an entitlement server. You can use \u0026#34;rhc\u0026#34; or \u0026#34;subscription-manager\u0026#34; to register. Error: No hay repositorios habilitados en \u0026#34;/etc/yum.repos.d\u0026#34;, \u0026#34;/etc/yum/repos.d\u0026#34;, \u0026#34;/etc/distro.repos.d\u0026#34;. La licencia de Red Hat se puede activar desde el proceso de instalación pero también una vez instalado el sistema desde la interfaz web de administración del sistema o desde la terminal usando las herramientas subscription-manager o rhc.\n[usuario@localhost ~]$ sudo rhc connect Connecting localhost.localdomain to Red Hat. This might take a few seconds. Username: fjhuete Password: ● Connected to Red Hat Subscription Management ● Connected to Red Hat Insights ● Activated the Remote Host Configuration daemon ● Enabled console.redhat.com services: insights, remediations, compliance, remote configuration Successfully connected to Red Hat! Manage your connected systems: https://red.ht/connector Al conectar el equipo a la cuenta de Red Hat se desbloquean algunas funcionalidades del panel de gestión de la herramienta web como la actualización de paquetes. En esta pestaña de actualización de software se muestra el estado de la paquetería del sistema. Desde esta interfaz se puede activar la actualización automática tanto de paquetes como de parches en vivo del kernel.\nAdemás, en esta pestaña se muestra en una lista todas las actualizaciones disponibles para el sistema. Esta lista incluye el nombre de cada paquete y su versión pero también una categoría (corrección de fallo, seguridad\u0026hellip;) y, en el caso de las actualizaciones de seguridad un nivel de severidad. Junto a toda esta información se añade una descripción del contenido del paquete pendiente de actualizar.\nAdemás, se pueden usar los gestores de paquetes dnf y yum para actualizar e instalar nueva paquetería en el sistema operativo.\n[usuario@localhost ~]$ sudo dnf update Actualización de repositorios de Subscription Management. Red Hat Enterprise Linux 9 for x86_64 - BaseOS 11 MB/s | 38 MB 00:03 Red Hat Enterprise Linux 9 for x86_64 - AppStre 13 MB/s | 46 MB 00:03 Última comprobación de caducidad de metadatos hecha hace 0:00:07, el vie 29 nov 2024 11:57:54. Dependencias resueltas. ================================================================================ Paquete Arq. Versión Repositorio Tam. ================================================================================ Instalando: kernel x86_64 5.14.0-503.15.1.el9_5 rhel-9-for-x86_64-baseos-rpms 2.0 M Actualizando: bpftool x86_64 7.4.0-503.15.1.el9_5 rhel-9-for-x86_64-baseos-rpms 2.8 M buildah x86_64 2:1.37.5-1.el9_5 rhel-9-for-x86_64-appstream-rpms 11 M containers-common x86_64 2:1-93.el9_5 rhel-9-for-x86_64-appstream-rpms 144 k emacs-filesystem noarch 1:27.2-10.el9_4 rhel-9-for-x86_64-appstream-rpms 9.3 k expat x86_64 2.5.0-3.el9_5.1 rhel-9-for-x86_64-baseos-rpms 119 k kernel-tools x86_64 5.14.0-503.15.1.el9_5 rhel-9-for-x86_64-baseos-rpms 2.3 M kernel-tools-libs x86_64 5.14.0-503.15.1.el9_5 rhel-9-for-x86_64-baseos-rpms 2.0 M krb5-libs x86_64 1.21.1-4.el9_5 rhel-9-for-x86_64-baseos-rpms 771 k libappstream-glib x86_64 0.7.18-5.el9_4 rhel-9-for-x86_64-appstream-rpms 399 k libipa_hbac x86_64 2.9.5-4.el9_5.1 rhel-9-for-x86_64-baseos-rpms 39 k libsmbclient x86_64 4.20.2-2.el9_5 rhel-9-for-x86_64-baseos-rpms 75 k libsoup x86_64 2.72.0-8.el9_5.2 rhel-9-for-x86_64-appstream-rpms 407 k libsss_certmap x86_64 2.9.5-4.el9_5.1 rhel-9-for-x86_64-baseos-rpms 95 k libsss_idmap x86_64 2.9.5-4.el9_5.1 rhel-9-for-x86_64-baseos-rpms 45 k libsss_nss_idmap x86_64 2.9.5-4.el9_5.1 rhel-9-for-x86_64-baseos-rpms 49 k libsss_sudo x86_64 2.9.5-4.el9_5.1 rhel-9-for-x86_64-baseos-rpms 38 k libwbclient x86_64 4.20.2-2.el9_5 rhel-9-for-x86_64-baseos-rpms 44 k pam x86_64 1.5.1-22.el9_5 rhel-9-for-x86_64-baseos-rpms 632 k pixman x86_64 0.40.0-6.el9_3 rhel-9-for-x86_64-appstream-rpms 271 k podman x86_64 4:5.2.2-9.el9_5 rhel-9-for-x86_64-appstream-rpms 16 M python-unversioned-command noarch 3.9.19-8.el9_5.1 rhel-9-for-x86_64-appstream-rpms 11 k python3 x86_64 3.9.19-8.el9_5.1 rhel-9-for-x86_64-baseos-rpms 30 k python3-libs x86_64 3.9.19-8.el9_5.1 rhel-9-for-x86_64-baseos-rpms 8.1 M python3-perf x86_64 5.14.0-503.15.1.el9_5 rhel-9-for-x86_64-baseos-rpms 2.1 M samba-client-libs x86_64 4.20.2-2.el9_5 rhel-9-for-x86_64-baseos-rpms 5.3 M samba-common noarch 4.20.2-2.el9_5 rhel-9-for-x86_64-baseos-rpms 175 k samba-common-libs x86_64 4.20.2-2.el9_5 rhel-9-for-x86_64-baseos-rpms 104 k sssd x86_64 2.9.5-4.el9_5.1 rhel-9-for-x86_64-baseos-rpms 29 k sssd-ad x86_64 2.9.5-4.el9_5.1 rhel-9-for-x86_64-baseos-rpms 220 k sssd-client x86_64 2.9.5-4.el9_5.1 rhel-9-for-x86_64-baseos-rpms 173 k sssd-common x86_64 2.9.5-4.el9_5.1 rhel-9-for-x86_64-baseos-rpms 1.6 M sssd-common-pac x86_64 2.9.5-4.el9_5.1 rhel-9-for-x86_64-baseos-rpms 99 k sssd-ipa x86_64 2.9.5-4.el9_5.1 rhel-9-for-x86_64-baseos-rpms 287 k sssd-kcm x86_64 2.9.5-4.el9_5.1 rhel-9-for-x86_64-baseos-rpms 114 k sssd-krb5 x86_64 2.9.5-4.el9_5.1 rhel-9-for-x86_64-baseos-rpms 77 k sssd-krb5-common x86_64 2.9.5-4.el9_5.1 rhel-9-for-x86_64-baseos-rpms 98 k sssd-ldap x86_64 2.9.5-4.el9_5.1 rhel-9-for-x86_64-baseos-rpms 164 k sssd-proxy x86_64 2.9.5-4.el9_5.1 rhel-9-for-x86_64-baseos-rpms 76 k tuned noarch 2.24.0-2.el9_5 rhel-9-for-x86_64-baseos-rpms 442 k tzdata noarch 2024b-2.el9 rhel-9-for-x86_64-baseos-rpms 841 k webkit2gtk3-jsc x86_64 2.46.3-2.el9_5 rhel-9-for-x86_64-appstream-rpms 4.4 M xfsdump x86_64 3.1.12-4.el9_3 rhel-9-for-x86_64-baseos-rpms 327 k Instalando dependencias: kernel-core x86_64 5.14.0-503.15.1.el9_5 rhel-9-for-x86_64-baseos-rpms 18 M kernel-modules x86_64 5.14.0-503.15.1.el9_5 rhel-9-for-x86_64-baseos-rpms 37 M kernel-modules-core x86_64 5.14.0-503.15.1.el9_5 rhel-9-for-x86_64-baseos-rpms 31 M Resumen de la transacción ================================================================================ Instalar 4 Paquetes Actualizar 42 Paquetes Tamaño total de la descarga: 149 M ... Actualizado: bpftool-7.4.0-503.15.1.el9_5.x86_64 buildah-2:1.37.5-1.el9_5.x86_64 containers-common-2:1-93.el9_5.x86_64 emacs-filesystem-1:27.2-10.el9_4.noarch expat-2.5.0-3.el9_5.1.x86_64 kernel-tools-5.14.0-503.15.1.el9_5.x86_64 kernel-tools-libs-5.14.0-503.15.1.el9_5.x86_64 krb5-libs-1.21.1-4.el9_5.x86_64 libappstream-glib-0.7.18-5.el9_4.x86_64 libipa_hbac-2.9.5-4.el9_5.1.x86_64 libsmbclient-4.20.2-2.el9_5.x86_64 libsoup-2.72.0-8.el9_5.2.x86_64 libsss_certmap-2.9.5-4.el9_5.1.x86_64 libsss_idmap-2.9.5-4.el9_5.1.x86_64 libsss_nss_idmap-2.9.5-4.el9_5.1.x86_64 libsss_sudo-2.9.5-4.el9_5.1.x86_64 libwbclient-4.20.2-2.el9_5.x86_64 pam-1.5.1-22.el9_5.x86_64 pixman-0.40.0-6.el9_3.x86_64 podman-4:5.2.2-9.el9_5.x86_64 python-unversioned-command-3.9.19-8.el9_5.1.noarch python3-3.9.19-8.el9_5.1.x86_64 python3-libs-3.9.19-8.el9_5.1.x86_64 python3-perf-5.14.0-503.15.1.el9_5.x86_64 samba-client-libs-4.20.2-2.el9_5.x86_64 samba-common-4.20.2-2.el9_5.noarch samba-common-libs-4.20.2-2.el9_5.x86_64 sssd-2.9.5-4.el9_5.1.x86_64 sssd-ad-2.9.5-4.el9_5.1.x86_64 sssd-client-2.9.5-4.el9_5.1.x86_64 sssd-common-2.9.5-4.el9_5.1.x86_64 sssd-common-pac-2.9.5-4.el9_5.1.x86_64 sssd-ipa-2.9.5-4.el9_5.1.x86_64 sssd-kcm-2.9.5-4.el9_5.1.x86_64 sssd-krb5-2.9.5-4.el9_5.1.x86_64 sssd-krb5-common-2.9.5-4.el9_5.1.x86_64 sssd-ldap-2.9.5-4.el9_5.1.x86_64 sssd-proxy-2.9.5-4.el9_5.1.x86_64 tuned-2.24.0-2.el9_5.noarch tzdata-20 Aunque RHEL y sus distribuciones derivadas mantienen el gestor de paquetes yum por compatibilidad con sistemas antiguos, el uso de este sistema está en desuso en la actualidad en favor de su sucesor, dnf.\nEl sistema de ficheros que usa, por defecto, RHEL es xfs. Llama la atención que, aunque se ha seleccionado el particionado automático en la instalación, el sistema se ha instalado en un volumen lógico y no en una partición. Además, se ha creado una partición separada, /dev/vda1 para el directorio boot.\nS.ficheros Tipo Tamaño Usados Disp Uso% Montado en devtmpfs devtmpfs 4,0M 0 4,0M 0% /dev tmpfs tmpfs 636M 0 636M 0% /dev/shm tmpfs tmpfs 255M 5,0M 250M 2% /run /dev/mapper/rhel-root xfs 17G 1,9G 16G 11% / /dev/vda1 xfs 960M 307M 654M 32% /boot tmpfs tmpfs 128M 0 128M 0% /run/user/1000 Como en otras muchas distribuciones de GNU/Linux, RHEL configura los dispositivos de red del equipo usando NetworkManager. Este gestor de redes está muy extendido en distribuciones que usan, por defecto, el entorno de escritorio de GNOME. NetworkManager crea un fichero por cada interfaz de red del equipo. Este fichero se almacena en el directorio /etc/NetworkManager/system-connections/ (anteriormente lo hacía en /etc/sysconfig/network-scripts/ pero esta configuración está desfasada actualmente). En este directorio se almacena la configuración de cada una de las interfaces de red en un fichero diferente con el siguiente formato:\n[connection] id=enp1s0 uuid=4cc774cc-d170-30b4-98e9-a92067acec23 type=ethernet autoconnect-priority=-999 interface-name=enp1s0 timestamp=1732866148 [ethernet] [ipv4] method=auto [ipv6] addr-gen-mode=eui64 method=auto [proxy] Para gestionar procesos, como en la mayor parte de las distribuciones GNU/Linux actualmente, este sistema operativo usa systemd.\n[usuario@localhost ~]$ sudo systemctl status NetworkManager ● NetworkManager.service - Network Manager Loaded: loaded (/usr/lib/systemd/system/NetworkManager.service; enabled; p\u0026gt; Active: active (running) since Fri 2024-11-29 09:24:13 CET; 30min ago Docs: man:NetworkManager(8) Main PID: 740 (NetworkManager) Tasks: 3 (limit: 7851) Memory: 8.0M CPU: 382ms CGroup: /system.slice/NetworkManager.service └─740 /usr/sbin/NetworkManager --no-daemon nov 29 09:24:23 localhost.localdomain NetworkManager[740]: \u0026lt;info\u0026gt; [1732868663.\u0026gt; nov 29 09:24:23 localhost.localdomain NetworkManager[740]: \u0026lt;info\u0026gt; [1732868663.\u0026gt; nov 29 09:24:23 localhost.localdomain NetworkManager[740]: \u0026lt;info\u0026gt; [1732868663.\u0026gt; nov 29 09:24:23 localhost.localdomain NetworkManager[740]: \u0026lt;info\u0026gt; [1732868663.\u0026gt; nov 29 09:24:23 localhost.localdomain NetworkManager[740]: \u0026lt;info\u0026gt; [1732868663.\u0026gt; nov 29 09:24:23 localhost.localdomain NetworkManager[740]: \u0026lt;info\u0026gt; [1732868663.\u0026gt; nov 29 09:24:23 localhost.localdomain NetworkManager[740]: \u0026lt;info\u0026gt; [1732868663.\u0026gt; nov 29 09:25:15 localhost.localdomain NetworkManager[740]: \u0026lt;info\u0026gt; [1732868715.\u0026gt; nov 29 09:25:45 localhost.localdomain NetworkManager[740]: \u0026lt;info\u0026gt; [1732868745.\u0026gt; nov 29 09:29:45 localhost.localdomain NetworkManager[740]: \u0026lt;info\u0026gt; [1732868985. Sistemas operativos derivados CentOS Stream La imagen iso para la instalación de la versión más reciente de CentOS Stream (9) está disponible en la sección de descargas de la web de CentOS. CentOS Stream es una distribución derivada de RHEL, de manera que tanto la manera de instalar el sistema operativo como el funcionamiento del mismo es muy similar al descrito previamente.\nInstalación de CentOS Stream El proceso de instalación de CentOS es muy parecido al de RHEL. De hecho, la única diferencia que se aprecia en el menú de instalación de este sistema operativo respecto al anterior es que aquí no hay ninguna opción para registrar la licenica. El resto de opciones del menú principal de instalación son equivalentes.\nEl menú de arranque del instalador de CentOS es idéntico al que usa la distribución RHEL. El procedimiento de arranque hasta llegar al menú de instalación también es el mismo en ambos casos. Y este menú de instalación también es muy parecido con pequeñas modificaciones estéticas, principalmente.\nAsí, antes de comenzar la instalación CentOS Stream ofrece la posibilidad de configurar todos los parámetros del proceso. Por ejemplo, se pueden selecionar diferentes instalaciones básicas según el uso que vaya a tener el equipo, tal y como ocurre en el caso de RHEL. Aglunas de estas instalaciones predefinidas son la instalación para servidor, la instalación para servidor con entorno gráfico, una instalación minimalista, la instalación para equipos de escritorio o la instalación especializada para virtualización.\nEn otros de los menús se puede configurar el particionado del disco duro. Este menú es idéntico al de RHEL y también permite particionar el disco de forma automática o manual o configurar otros discos especiales o almacenamiento en red durante la instalación del sistema operativo.\nEl menú de creación de usuarios de CentOS es análogo al de RHEL y también permite definir el nombre de usuario y contraseña, asignar al usuario un directorio home, uid y gid específicos, incluirlo en varios grupos o darle privilegio de administrador.\nUso de CentOS Stream El funcionamiento interno de CentOS Stream es muy similar al de RHEL y el resto de características analizadas en ambos sistemas operativos es análogo. CentOS había sido un proyecto proyecto independiente pero desde hace muchos años es propiedad de la compañía Red Hat y esto ha hecho que ambos sistemas operativos se hayan desarrollado de forma paralela hasta que, tras la compra de Red Hat por parte de IBM la nueva empresa decide convertir el proyecto CentOS es una especie de versión de pruebas de Red Hat, en un punto intermedio entre su rolling release, Fedora, y su distribución más estable, Red Hat Enterprise Linux.\nEsto hace que tanto el gestor de paquetes, como el sistema de ficheros que usa por defecto, así como la gestión de las interfaces de red o de los procesos del sistema sea, prácticamente idéntica en ambas distribuciones.\nAsí, cabe destacar que CentOS Stream usa, al igual que RHEL, los gestores de paquetes dnf y yum (actualmente en desuso). A diferencia de lo que ocurre al instalar RHEL, en el caso de CentOS se puede actualizar la paquetería del sistema sin necesidad de validar ninguna licencia ni iniciar sesión con la cuenta de Red Hat.\n[usuario@localhost ~]$ sudo dnf update CentOS Stream 9 - BaseOS 2.2 MB/s | 8.3 MB 00:03 CentOS Stream 9 - AppStream 3.3 MB/s | 21 MB 00:06 CentOS Stream 9 - Extras packages 18 kB/s | 19 kB 00:01 Dependencias resueltas. Nada por hacer. ¡Listo! Otra similitud que tiene CentOS con RHEL, así como con otras distribuciones libres derivadas de Red Hat que se analizan más adelante en esta práctica es la interfaz web de administración del servidor. Accediendo al puerto 9090 de la máquina en la que se ejecuta el sistema operativo, se puede hacer uso de una interfaz gráfica idéntica a la que ofrece RHEL para administrar la máquina.\nA través de esta herramienta, al igual que en los equipos que usan RHEL como sistema operativo, se puede consultar la información básica sobre el sistema y su configuración, se puede gestionar el almacenamiento del servidor o sus interfaces de red, también se puede acceder a los logs y registros del sistema, así como gestionar las cuentas y servicios de Red Hat contratados. Además, se pueden ejecutar actualizaciones del sistema operativo o comprobar si hay paquetes pendientes de actualizar, así como realizar volcados del kernel, informes de diagnóstico o acceder a una terminal.\nEl sistema de ficheros que usa, por defecto, CentOS es el mismo que emplea RHEL: xfs. Como ocurre con la distribución principal de Red Hat, en el caso de CentOS, aunque se ha seleccionado el particionado automático en la instalación, el sistema se ha instalado en un volumen lógico y no en una partición. Además, se ha creado una partición separada, /dev/vda1 para el directorio boot.\nS.ficheros Tipo Tamaño Usados Disp Uso% Montado en devtmpfs devtmpfs 4,0M 0 4,0M 0% /dev tmpfs tmpfs 635M 0 635M 0% /dev/shm tmpfs tmpfs 254M 3,9M 251M 2% /run /dev/mapper/cs-root xfs 17G 2,0G 15G 12% / /dev/vda1 xfs 960M 308M 653M 33% /boot tmpfs tmpfs 127M 0 127M 0% /run/user/1000 CentOS también replica a RHEL en la gestión de los dispositivos e interfaces de red del equipo. Con esta finalidad, usa el gestor de redes NetworkManager, propio de muchas otras distribuciones en las que es habitual encontrar el entorno de escritorio de GNOME. Como ocurre con la distribución principal de Red Hat, en CentOS NetworkManager también crea un fichero para cada interfaz de red del equipo que se almacena en el directorio /etc/NetworkManager/system-connections y que contiene la configuración de la interfaz.\n[connection] id=enp1s0 uuid=9c791151-2181-3146-83ae-228271556413 type=ethernet autoconnect-priority=-999 interface-name=enp1s0 timestamp=1732896220 [ethernet] [ipv4] method=auto [ipv6] addr-gen-mode=eui64 method=auto [proxy] Por último, como todas las distribuciones analizadas en esta práctica, cabe destacar que CentOS también usa la herramienta systemd para gestionar los procesos del sistema.\n[usuario@localhost ~]$ sudo systemctl status cockpit.service ● cockpit.service - Cockpit Web Service Loaded: loaded (/usr/lib/systemd/system/cockpit.service; static) Active: active (running) since Sat 2024-11-30 20:01:56 CET; 12min ago TriggeredBy: ● cockpit.socket Docs: man:cockpit-ws(8) Process: 1743 ExecStartPre=/usr/libexec/cockpit-certificate-ensure --for-co\u0026gt; Main PID: 1757 (cockpit-tls) Tasks: 2 (limit: 7848) Memory: 4.7M CPU: 1.294s CGroup: /system.slice/cockpit.service └─1757 /usr/libexec/cockpit-tls nov 30 20:01:55 localhost.localdomain systemd[1]: Starting Cockpit Web Service.\u0026gt; nov 30 20:01:56 localhost.localdomain systemd[1]: Started Cockpit Web Service. nov 30 20:01:56 localhost.localdomain cockpit-tls[1757]: cockpit-tls: gnutls_ha openSUSE Leap OpenSUSE distribuye a través de su página de descargas varias versiones de su sistema operativo. Por una parte, algunas de las versiones de la distribución están optimizadas para su uso en ordenadores de escritorio mientras otras están optimizadas para servidores. Dentro del caso de los servidores, existen también varias versiones de openSUSE.\nLa distribución Tumbleweed es una distribución de tipo rolling release en la que el proyecto openSUSE libera las versiones más recientes de la paquetería del sistema operativo. Por otra parte, openSUSE Leap es una distribución más estable orientada a su uso en servidores y que cuenta con actualizaciones periódicas pero no tan constantes como en el caso de Tumbleweed. OpenSUSE cuenta, además, con otras distribuciones como MicroOS o Leap Micro orientadas a sistemas ligeros, virtualización y contenedores.\nInstalación de OpenSUSE El proceso de instalación de OpenSUSE se divide en dos partes. A diferencia del instalador de Debian, que instala el sistema operativo en el equipo de forma interactiva mientras va solicitando la información necesaria para ejecutar las acciones al usuario, OpenSUSE lanza primero todas las preguntas y, cuando toda la instalación se ha configurado entonces ejecuta el proceso de instalación del sistema operativo en el equipo. De hecho, antes de comenzar con el proceso de instalación se muestra una página de resumen en la que el usuario puede comprobar que toda la configuración es correcta y modificar aquellos parámetros que no sean adecuados.\nEl primer menú del instalador de OpenSUSE permite modificar algunos parámetros como el idioma o indicar algunas opciones de instalación desde la línea de arranque del propio instalador.\nA continuación, se muestra una ventana desde la que se configuran todos los parámetros del instalador. Durante la primera parte del proceso, el instalador solicita la información al usuario para finalmente mostrar un resumen de la configuración y ejecutar la instalación.\nDurante la fase de preparación de la instalación se configura la red y, de forma automática, se ejecutan algunas actualizaciones en el instalador, se inicializan los repositorios, se activa la red y se analiza el sistema. De forma interactiva, el instalador pide al usuario que confirme los repositorios que se van a consultar durante la instalación.\nTras configurar los repositorios también se debe eligir el tipo de entorno de escritorio que se instala con el sistema operativo. Aunque OpenSUSE es un sistema operativo muy orientado al trabajo en servidores, permite instalar entornos de escritorio como KDE Plasma, GNOME, XFCE o un entorno genérico más ligero propio de la distribución.\nEl siguiente paso en la configuración del instalador es el particionado del disco. Por defecto, OpenSUSE crea una tabla de particiones GPT y una partición de arranque de 8MB. Además crea dos particiones más, una para el sistema, que usa un sistema de ficheros btrfs y una para la swap. En este paso también se puede acceder al particionado manual o al modo experto.\nPor último, se configura el huso horario, se sincroniza el reloj y se crea el usuario y contraseña para acceder a la máquina tras la instalación del sistema operativo.\nTras establecer toda la configuración, el instalador muestra resumen de los parámetros indicados anteriormente. Algunos de ellos cuentan con botones que permiten modificarlos de nuevo en este punto de la instalación. Cuando toda la configuración sea correcta, se puede ejecutar el instalador que instala el sistema operativo en el equipo.\nUso de OpenSUSE OpenSUSE usa el sistema de gestión de paquetería YaST. Este gestor de paquetes usa interfaces gráficas para la interacción con el usuario. En el caso de que el sistema operativo esté instalado sin un entorno de escritorio, YaST usa ncourses a modo de interfaz gráfica desde la terminal.\nTal y como se ha configurado durante el proceso de instalación del sistema operativo, OpenSUSE usa btrfs como sistema de ficheros para su estructura de directorios.\nS.ficheros Tipo Tamaño Usados Disp Uso% Montado en /dev/vda2 btrfs 19G 2,3G 16G 13% / devtmpfs devtmpfs 4,0M 0 4,0M 0% /dev tmpfs tmpfs 987M 0 987M 0% /dev/shm tmpfs tmpfs 395M 6,0M 389M 2% /run /dev/vda2 btrfs 19G 2,3G 16G 13% /.snapshots /dev/vda2 btrfs 19G 2,3G 16G 13% /boot/grub2/i386-pc /dev/vda2 btrfs 19G 2,3G 16G 13% /boot/grub2/x86_64-efi /dev/vda2 btrfs 19G 2,3G 16G 13% /home /dev/vda2 btrfs 19G 2,3G 16G 13% /srv /dev/vda2 btrfs 19G 2,3G 16G 13% /opt /dev/vda2 btrfs 19G 2,3G 16G 13% /tmp /dev/vda2 btrfs 19G 2,3G 16G 13% /usr/local /dev/vda2 btrfs 19G 2,3G 16G 13% /var /dev/vda2 btrfs 19G 2,3G 16G 13% /root tmpfs tmpfs 198M 4,0K 198M 1% /run/user/1000 Para la configuración de la red OpenSUSE se puede habilitar el uso de NetworkManager (también disponible en Ubuntu) o Wicked. Esta instalación usa la herramienta wicked. Esta herramienta es compatible con los ficheros /etc/sysconfig/network/ifcfg-* muy comunes en alguna distribuciones de Linux. Esta herramienta se basa en un conjunto de scripts que gestionan la configuración de red del equipo.\n/etc/wicked ├── client.xml ├── common.xml ├── extensions │ ├── dispatch │ ├── firewall │ ├── hostname │ ├── ibft │ ├── netconfig │ └── redfish-config ├── ifconfig ├── nanny.xml ├── scripts │ └── redfish-update └── server.xml Cada interfaz de red cuenta con su propio fichero. Por ejemplo, la interfaz eth0 está configurada en el fichero /var/run/netconfig/eth0/netconfig0:\nCREATETIME=\u0026#39;28\u0026#39; SERVICE=\u0026#39;wicked-dhcp-ipv4\u0026#39; INTERFACE=\u0026#39;eth0\u0026#39; TYPE=\u0026#39;dhcp\u0026#39; FAMILY=\u0026#39;ipv4\u0026#39; UUID=\u0026#39;a4bc4567-f92a-0000-4603-000004000000\u0026#39; IPADDR=\u0026#39;172.22.1.229/16\u0026#39; NETMASK=\u0026#39;255.255.0.0\u0026#39; NETWORK=\u0026#39;172.22.0.0\u0026#39; BROADCAST=\u0026#39;172.22.255.255\u0026#39; PREFIXLEN=\u0026#39;16\u0026#39; GATEWAYS=\u0026#39;172.22.0.1\u0026#39; DNSDOMAIN=\u0026#39;gonzalonazareno.org\u0026#39; DNSSERVERS=\u0026#39;172.22.0.1 192.168.0.1\u0026#39; DNSSEARCH=\u0026#39;gonzalonazareno.org 41011038.41.andared.ced.junta-andalucia.es\u0026#39; CLIENTID=\u0026#39;ff:00:67:57:c2:00:01:00:01:2e:d8:73:c7:52:54:00:67:57:c2\u0026#39; SERVERID=\u0026#39;172.22.0.1\u0026#39; SENDERHWADDR=\u0026#39;bc:24:11:87:0b:93\u0026#39; ACQUIRED=\u0026#39;1732623523\u0026#39; LEASETIME=\u0026#39;85014\u0026#39; RENEWALTIME=\u0026#39;42506\u0026#39; REBINDTIME=\u0026#39;74387\u0026#39; BOOTSERVERADDR=\u0026#39;172.22.0.1\u0026#39; BOOTFILE=\u0026#39;iventoy_loader_16000\u0026#39; Otros ficheros de configuración de red están ubicados en el directorio /etc/dbus-1/system.d/.\n/etc/dbus-1/system.d/ ├── com.Red Hat.tuned.conf ├── cups.conf ├── org.opensuse.Network.AUTO4.conf ├── org.opensuse.Network.conf ├── org.opensuse.Network.DHCP4.conf ├── org.opensuse.Network.DHCP6.conf ├── org.opensuse.Network.Nanny.conf └── org.opensuse.Snapper.conf Sin embargo, el directorio principal para la configuración de red en OpenSUSE es /etc/sysconfig/network, en el que hay diferentes ficheros para la configuración de cada una de las interfaces de red del equipo.\n/etc/sysconfig/network/ ├── config ├── dhcp ├── ifcfg-eth0 ├── ifcfg-eth0.bak ├── ifcfg-lo ├── ifcfg.template ├── if-down.d ├── if-up.d ├── providers [error opening dir] └── scripts └── functions.netconfig El contenido del fichero /etc/sysconfig/network/ifcfg-eth0 es el siguiente:\nBOOTPROTO=\u0026#39;dhcp\u0026#39; STARTMODE=\u0026#39;auto\u0026#39; ZONE=public El parámetro BOOTPROTO, que en este caso tiene el valor dhcp indica cómo consigue su IP la interfaz. En las configuraciones de red manuales, este parámetro toma el valor static. Otros parámetros que se pueden usar en este fichero son IPADDR para indicar la IP estática de una interfaz, GATEWAY para indicar la IP del router de la red, DOMAIN para indicar un nombre de dominio o DNS1 para indicar la IP o el nombre del servidor DNS de la red.\nWicked se integra con systemd de manera que para ejecutar acciones sobre la configuración de red se pueden usar los comandos propios de systemctl indicando el servicio network.service. Por ejemplo:\nsystemctl start network.service systemctl stop network.service systemctl restart network.service Por último, cabe destacar que OpenSUSE usa el sistema de control de procesos systemd para gestionar los procesos del sistema, al igual que ocurre en otras muchas distribuciones de GNU/Linux.\nAlmaLinux Instalación de AlmaLinux AlmaLinux también ofrece la imagen iso para la instalación de la distribución en su página de descargas. Este sistema operativo es una réplica muy fidedigna de Red Hat Enterprise Linux y los menús del instalador son muy similares en los dos casos. De hecho, las únicas diferencias son algunos detalles estéticos de la hoja de estilo y que en el caso de AlmaLinux no se incluye en el resumen de la instalación la opción de registrar una licencia como ocurre en el caso de Red Hat.\nAl arrancar el instalador de AlmaLinux el sistema operativo muestra un menú de instalación casi idéntico al de RHEL, escueto y poco amigable. De entrada, sólo muestra las opciones de instalar o probar e instalar el sistema operativo. En las opciones avanzadas ya se puede comprobar si el equipo cumple con los requisitos del sistema operativo para su instalación o también arrancar el equipo en modo de recuperación.\nEn este caso, al acceder a la opción de instalación, el sistema también avisa de que existen ficheros de log disponibles en el directorio /tmp durante todo el proceso de instalación. Además, durante la instalación hay disponible una shell en la terminal TTY2.\nAl igual que en el caso de RHEL o CentOS Stream, el instalador de AlmaLinux muestra, en primer lugar un menú de selección de idioma y distribución del teclado y, a partir de ahí, muestra un menú con los diferentes apartados del proceso de instalación.\nUno de estos apartados permite seleccionar el software que se instala durante el proceso de puesta en marcha del sistema operativo. Este paso es similar al que ejecuta tasksel en el instalador de Debian. En este caso, AlmaLinux permite seleccionar entre varias opciones: una instalación para servidor con interfaz gráfica, una instalación para servidor sin la interfaz gráfica, una instalación minimalista que ofrece las funcionalidades básicas del sistema operativo, una instalación destinada a ordenadores de escritorio y portátiles con entorno de escritorio o una instalación específicamente destinada a la virtualización.\nCada una de estas opciones incluye una lista de software adicional que se puede incluir durante el proceso de instalación del sistema operativo.\nPor otra parte se puede también configurar el particionado del disco duro en el apartado destino de la instalación. En él se puede elegir entre un particionado auotmático o personalizado. También se pueden encriptar los datos del sistema durante la instalación. Desde la interfaz gráfica del instalador también se pueden elegir los discos en los que se instala el sistema operativo, crear volúmenes lógicos, añadir discos de red, etc.\nLa creación de usuarios también se hace de forma interactiva a través de la interfaz gráfica del instalador. En el menú de resumen de la instalación hay dos apartados dedicados a este punto. En uno de ellos se configura el usuario privilegiado, su nombre, contraseña, si se permite conectar a través de SSH con el nombre de usuario y la contraseña del root.\nEn el apartado de configuración de usuario no sólo se puede especificar el nombre, nombre de usuario y contraseña sino que, además, se puede indicar el directorio home del usuario o especificar un id de usuario y grupo de forma manual. Además, se puede añadir al usuario a más grupos desde este menú.\nUso de AlmaLinux De forma análoga a RHEL, el sistema operativo AlmaLinux usa el gestor de paquetes dnf o yum para la gestión del software del equipo.\n[usuario@localhost ~]$ sudo dnf update AlmaLinux 9 - AppStream 2.9 MB/s | 8.6 MB 00:02 AlmaLinux 9 - BaseOS 2.3 MB/s | 3.4 MB 00:01 AlmaLinux 9 - Extras 16 kB/s | 13 kB 00:00 Última comprobación de caducidad de metadatos hecha hace 0:00:01, el jue 28 nov 2024 14:15:57. Dependencias resueltas. ================================================================================ Paquete Arq. Versión Repositorio Tam. ================================================================================ Instalando: kernel x86_64 5.14.0-503.14.1.el9_5 baseos 2.0 M Actualizando: bpftool x86_64 7.4.0-503.14.1.el9_5 baseos 2.8 M expat x86_64 2.5.0-3.el9_5.1 baseos 115 k kernel-tools x86_64 5.14.0-503.14.1.el9_5 baseos 2.3 M kernel-tools-libs x86_64 5.14.0-503.14.1.el9_5 baseos 2.0 M libsoup x86_64 2.72.0-8.el9_5.2 appstream 387 k pam x86_64 1.5.1-22.el9_5 baseos 548 k python3-perf x86_64 5.14.0-503.14.1.el9_5 baseos 2.1 M webkit2gtk3-jsc x86_64 2.46.3-1.el9_5 appstream 4.4 M Instalando dependencias: kernel-core x86_64 5.14.0-503.14.1.el9_5 baseos 18 M kernel-modules x86_64 5.14.0-503.14.1.el9_5 baseos 36 M kernel-modules-core x86_64 5.14.0-503.14.1.el9_5 baseos 30 M Resumen de la transacción ================================================================================ Instalar 4 Paquetes Actualizar 8 Paquetes Tamaño total de la descarga: 101 M ... Actualizado: bpftool-7.4.0-503.14.1.el9_5.x86_64 expat-2.5.0-3.el9_5.1.x86_64 kernel-tools-5.14.0-503.14.1.el9_5.x86_64 kernel-tools-libs-5.14.0-503.14.1.el9_5.x86_64 libsoup-2.72.0-8.el9_5.2.x86_64 pam-1.5.1-22.el9_5.x86_64 python3-perf-5.14.0-503.14.1.el9_5.x86_64 webkit2gtk3-jsc-2.46.3-1.el9_5.x86_64 Instalado: kernel-5.14.0-503.14.1.el9_5.x86_64 kernel-core-5.14.0-503.14.1.el9_5.x86_64 kernel-modules-5.14.0-503.14.1.el9_5.x86_64 kernel-modules-core-5.14.0-503.14.1.el9_5.x86_64 ¡Listo! Este gestor de paquetes es muy similar a otros gestores de paquetes por línea de comando que se usan en otras distribuciones basadas GNU/Linux como, por ejemplo, el gestor de paquetes apt en Debian.\nEn este punto, llama la atención que mientras que la actualización de los paquetes del sistema operativo instalado usando la imagen iso de RHEL fue de 46 paquetes, en este caso AlmaLinux sólo instala o actualiza 10. Aquí reside una de las principales claves del conflicto generado a partir de la decisión de limitar el acceso a los repositorios de CentOS: las distribuciones libres basadas en Red Hat tienen más dificultades para acceder a la nueva paquetería y, por tanto, las actualizacioes de los paquetes del sistema operativo se producen en menor medida y con más retraso.\nAdemás, RHEL incluye una gran cantidad de funcionalidades adicionales sobre el sistema operativo básico que no ofrecen otras distribuciones libres como AlmaLinux y que también implican una instalación y actualización de un mayor número de paquetes en el sistema operativo.\nAl igual que RHEL y CentOS, AlmaLinux usa la herramienta cockpit para ofrecer al usuario la posibilidad de administrar el servidor desde una interfaz gráfica. A esta herramienta web se puede acceder desde cualquier navegador conectando al puerto 9090 de la máquina AlmaLinux.\nLa diferencia más llamativa entre las opciones que ofrece esta interfaz web y las versiones de la misma herramienta en RHEL y CentOS es que en este caso no aparece el menú desde el que se puede comprobar el estado de la paquetería del sistema y ejecutar las actualizaciones del mismo. Esto puede ser consecuencia, precisamente, de las limitaciones que recientemente ha puesto Red Hat para el acceso a los repositorios del proyecto CentOS a otras distribuciones derivadas.\nEl sistema de ficheros que usa, por defecto, la distribución AlmaLinux es xfs. Como ocurre durante la instalación de RHEL, aunque se ha seleccionado el particionado automático en la instalación, el sistema se ha instalado en un volumen lógico y no en una partición. Además, se ha creado una partición separada, /dev/vda1 para el directorio boot.\nS.ficheros Tipo Tamaño Usados Disp Uso% Montado en devtmpfs devtmpfs 4,0M 0 4,0M 0% /dev tmpfs tmpfs 636M 0 636M 0% /dev/shm tmpfs tmpfs 255M 5,1M 249M 2% /run /dev/mapper/almalinux-root xfs 17G 1,8G 16G 11% / /dev/vda1 xfs 960M 362M 599M 38% /boot tmpfs tmpfs 128M 0 128M 0% /run/user/1000 De la misma forma que RHEL, AlmaLinux configura los dispositivos de red del equipo usando NetworkManager. Este gestor de redes está muy extendido en distribuciones que usan, por defecto, el entorno de estrictorio de GNOME. En el caso de este sistema operativo, NetworkManager también crea un fichero por cada interfaz de red del equipo y este fichero también se almacena en el directorio /etc/NetworkManager/system-connections/ (anteriormente lo hacía en /etc/sysconfig/network-scripts/ pero esta configuración está desfasada actualmente). Como pasa en RHEL, en este directorio se almacena la configuración de cada una de las interfaces de red en un fichero diferente con el siguiente formato:\n[connection] id=enp1s0 uuid=643c642c-6e56-3f92-bd39-792f01f9f52a type=ethernet autoconnect-priority=-999 interface-name=enp1s0 timestamp=1732796007 [ethernet] [ipv4] method=auto [ipv6] addr-gen-mode=eui64 method=auto [proxy] Para gestionar los procesos del sistema, AlmaLinux usa systemd como la mayor parte de distribuciones basadas en GNU/Linux.\n[usuario@localhost ~]$ sudo systemctl restart NetworkManager [usuario@localhost ~]$ sudo systemctl status NetworkManager ● NetworkManager.service - Network Manager Loaded: loaded (/usr/lib/systemd/system/NetworkManager.service; enabled; p\u0026gt; Active: active (running) since Thu 2024-11-28 14:36:23 CET; 5s ago Docs: man:NetworkManager(8) Main PID: 45807 (NetworkManager) Tasks: 4 (limit: 7852) Memory: 7.2M CPU: 66ms CGroup: /system.slice/NetworkManager.service └─45807 /usr/sbin/NetworkManager --no-daemon nov 28 14:36:23 localhost.localdomain NetworkManager[45807]: \u0026lt;info\u0026gt; [173280098\u0026gt; nov 28 14:36:23 localhost.localdomain NetworkManager[45807]: \u0026lt;info\u0026gt; [173280098\u0026gt; nov 28 14:36:23 localhost.localdomain NetworkManager[45807]: \u0026lt;info\u0026gt; [173280098\u0026gt; nov 28 14:36:23 localhost.localdomain NetworkManager[45807]: \u0026lt;info\u0026gt; [173280098\u0026gt; nov 28 14:36:23 localhost.localdomain NetworkManager[45807]: \u0026lt;info\u0026gt; [173280098\u0026gt; nov 28 14:36:23 localhost.localdomain NetworkManager[45807]: \u0026lt;info\u0026gt; [173280098\u0026gt; nov 28 14:36:23 localhost.localdomain NetworkManager[45807]: \u0026lt;info\u0026gt; [173280098\u0026gt; nov 28 14:36:23 localhost.localdomain NetworkManager[45807]: \u0026lt;info\u0026gt; [173280098\u0026gt; nov 28 14:36:23 localhost.localdomain NetworkManager[45807]: \u0026lt;info\u0026gt; [173280098\u0026gt; nov 28 14:36:23 localhost.localdomain NetworkManager[45807]: \u0026lt;info\u0026gt; [173280098\u0026gt; "},{
  "section": "Blog",
  "slug": "/blog/servicios/2024-12-02-configuracion-balanceador-de-carga/",
  "title": "Configuración del balanceador de carga HAProxy",
  "description": "",
  "date": "November 24, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "servicios",
  "tags": "Balanceador de carga, HAProxy, Apache2, Nginx, Administración de Sistemas, servicios, Servicios de Red e Internet",
  "content":"Configuración de HAProxy como balanceador de carga Este escenario está formado por un balanceador de carga que reparte el tráfico entre dos servidores web que sirven una aplicación web escrita en PHP.\nEn el equipo que funciona como balanceador de carga se instala la herramienta HAproxy.\nsudo apt install haproxy Para configurar el balanceador de carga de manera que reparta la carga entre los servidores de forma equitativa se añade la siguiente configuración en el fichero /etc/haproxy/haproxy.cfg\nfrontend servidores_web bind *:80 mode http stats enable stats uri /ha_stats stats auth cda:cda default_backend servidores_web_backend backend servidores_web_backend mode http balance roundrobin server backend1 192.168.100.100:80 check server backend2 192.168.100.101:80 check Para poder acceder a la aplicación web se tiene que añadir la resolución estática al ficheo /etc/hosts del equipo local.\n192.168.121.120\twww.example.org De esta forma, al acceder de manera consecutiva al navegador, cada vez el balanceador redirigirá la conexión a uno de los dos servidores web del escenario.\nAdemás, la herramienta haproxy ofrece una interfaz gráfica sencilla en la que muestra algunas estadísitcas del funcionamiento del balanceador de carga. Esta herramienta gráfica es accesible a través de una navegador web en la dirección del balanceador de carga www.example.org/ht_stats.\nAunque los equipos cliente acceden al balanceador de carga, las peticiones que llegan a los servidores web lo hacen desde el balanceador de carga, por tanto, todas ellas muestran como IP de origen la IP de la red local del balanceador de carga y no las IP públicas desde las que acceden los clientes.\nComprobar el rendimiento del balanceador del carga Para comprobar el rendimiento del balanceador de carga se pueden usar herramientas como ab y hatop.\nsudo apt install apache2-utils hatop Con ab(Apache Benchmark) se pueden hacer peticiones en lote a un servidore web y la salida del comando muestra el rendimiento del servidor.\nvagrant@balanceador:~$ ab -n 1000 -c 100 http://www.example.org/app.php This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1913912 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking www.example.org (be patient) Completed 100 requests Completed 200 requests Completed 300 requests Completed 400 requests Completed 500 requests Completed 600 requests Completed 700 requests Completed 800 requests Completed 900 requests Completed 1000 requests Finished 1000 requests Server Software: Apache/2.4.62 Server Hostname: www.example.org Server Port: 80 Document Path: /app.php Document Length: 115 bytes Concurrency Level: 100 Time taken for tests: 19.640 seconds Complete requests: 1000 Failed requests: 0 Non-2xx responses: 1000 Total transferred: 283000 bytes HTML transferred: 115000 bytes Requests per second: 50.92 [#/sec] (mean) Time per request: 1964.009 [ms] (mean) Time per request: 19.640 [ms] (mean, across all concurrent requests) Transfer rate: 14.07 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 2 4.9 0 22 Processing: 104 1903 875.5 2015 4708 Waiting: 83 1903 875.6 2015 4708 Total: 104 1905 874.0 2020 4708 Percentage of the requests served within a certain time (ms) 50% 2020 66% 2426 75% 2584 80% 2672 90% 2967 95% 3284 98% 3648 99% 3867 100% 4708 (longest request) La herramienta hatop permite comprobar el rendimiento de los servidores, ver su estado, sus estadísticas y, además, permite interactuar con el balanceador de carga para conectar o desconectar algunos de los servidores web del backend para, por ejemplo, desconectarlos del balanceador y ponerlos en mantenimiento.\nHATop version 0.8.2 Wed Nov 20 11:29:10 2024 HAProxy Version: 2.6.12-1+deb12u1 (released: 2023/12/PID: 382 (proc 1) Node: balanceador (uptime 0d 0h06m47s) Pipes: [ 0/0] Connections: [ 0/262124] Procs: 1 Tasks: 14 Queue: 0 Proxies: 2 Services: 4 NAME W STATUS CHECK ACT BCK QCUR QMAX SCUR SMAX SLIM STOT \u0026gt;\u0026gt;\u0026gt; servidores_web FRONTEND 0 OPEN 0 0 0 0 0 100 262124 1000 \u0026gt;\u0026gt;\u0026gt; servidores_web_backend backend1 1 UP L4OK 1 0 0 0 0 0 0 0 backend2 1 UP L4OK 1 0 0 0 0 100 0 1000 BACKEND 2 UP 2 0 0 0 0 100 26213 1000 1-STATUS 2-TRAFFIC 3-HTTP 4-ERRORS 5-CLI ENTER=MENU SPACE=SEL [#3/#1] "},{
  "section": "Blog",
  "slug": "/blog/servicios/2024-12-02-configuracion-nginx/",
  "title": "Guía básica de configuración de Nginx",
  "description": "",
  "date": "November 24, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "servicios",
  "tags": "Servidor web, Nginx, Configuración básica, PHP, Administración de Sistemas, servicios, Servicios de Red e Internet",
  "content":"Configuración de un servidor web nginx + PHP con dos VirtualHost VirtualHost de la página 1 vagrant@servidorweb:~$ cat /etc/nginx/sites-available/pagina1.conf # Default server configuration # server { listen 80; listen [::]:80; root /srv/www/pagina1; # Add index.php to the list if you are using PHP index index.php index.html index.htm index.nginx-debian.html; server_name www.pagina1.org; location / { # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. try_files $uri $uri/ =404; } #pass PHP scripts to FastCGI server # location ~ \\.php$ { include snippets/fastcgi-php.conf; # With php-fpm (or other unix sockets): fastcgi_pass unix:/run/php/php8.2-fpm.sock; # With php-cgi (or other tcp sockets): #fastcgi_pass 127.0.0.1:9000; } # deny access to .htaccess files, if Apache\u0026#39;s document root # concurs with nginx\u0026#39;s one # #location ~ /\\.ht { #\tdeny all; #} } VirtualHost de la página 2 vagrant@servidorweb:~$ cat /etc/nginx/sites-available/pagina2.conf # Default server configuration # server { listen 80; listen [::]:80; root /srv/www/pagina2; # Add index.php to the list if you are using PHP index index.php index.html index.htm index.nginx-debian.html; server_name www.pagina2.org; location / { # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. try_files $uri $uri/ =404; } #pass PHP scripts to FastCGI server # location ~ \\.php$ { include snippets/fastcgi-php.conf; # With php-fpm (or other unix sockets): fastcgi_pass unix:/run/php/php8.2-fpm.sock; # With php-cgi (or other tcp sockets): #fastcgi_pass 127.0.0.1:9000; } # deny access to .htaccess files, if Apache\u0026#39;s document root # concurs with nginx\u0026#39;s one # #location ~ /\\.ht { #\tdeny all; #} } Creación de enlaces simbólicos en sites-enabled vagrant@servidorweb:~$ ls -l /etc/nginx/sites-enabled/ lrwxrwxrwx 1 root root 39 Nov 21 08:52 pagina1.conf -\u0026gt; /etc/nginx/sites-available/pagina1.conf lrwxrwxrwx 1 root root 39 Nov 21 08:52 pagina2.conf -\u0026gt; /etc/nginx/sites-available/pagina2.conf Redirección de www.pagina1.org a www.pagina1.org/principal Se añade la lína rewrite ^/$ $uri/principal permanent; al location de la raíz de la web.\nlocation / { # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. #try_files $uri $uri/ =404; rewrite ^/$ $uri/principal permanent; } La página www.pagina1.org/principal/documentos muestra los documentos del directorio /srv/doc Primero se crea el directorio y sus documentos:\nsudo mkdir -p /srv/doc sudo touch /srv/doc/fich{A..F}.txt Después se crea un alias en el VirtualHost que muestre los ficheros del directorio al acceder a la URL configurada.\nlocation /principal/documentos/ { alias /srv/doc; autoindex on; allow all; } Limitar el acceso a www.pagina1.org/secreto con autenticación básica Primero se crea un fichero de usuarios y contraseñas\nsudo htpasswd -c /etc/nginx/.htpasswd usuario Crear el directorio y el fichero\nsudo mkdir -p /srv/www/pagina1/secreto sudo nano /srv/www/pagina1/secreto/index.html Configurar la autenticación en el VirtualHost\nlocation /secreto { auth_basic \u0026#34;Esto es un secreto\u0026#34;; auth_basic_user_file /etc/nginx/.htpasswd; } "},{
  "section": "Blog",
  "slug": "/blog/administracion-de-sistemas/2024-12-02-instalaci%C3%B3n-desatendida-por-red/",
  "title": "Instalación desatendida por red de Debian12",
  "description": "",
  "date": "November 24, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "administracion-sistemas",
  "tags": "sistemas, debian, linux, instalación, preseed, instalación desatendida, debian installer, iventoy, PXE, TFTP, dnsmasq, administracion-sistemas, Administración de Sistemas Operativos",
  "content":"Instalación automática usando un fichero de preseed alojado en un servidor web Configuración del servidor web El fichero de preseed para la instalación desatendida de Debian se puede aportar no sólo volcando su contenido al archivo de imagen iso del instalador sino también haciéndolo accesible para el cliente en el que se instala el sistema operativo desde un servidor web alojado en la red. Para usar este método de instalación desatendida, primero es necesario contar con un fichero de preseed correctamente configurado y con un servidor web accesible desde el cliente.\nsudo apt install apache2 Este método se puede adaptar a las necesidades de la configuración del servidor web, ya sea creando un virtual host específico para alojar el fichero de preseed o estableciendo una resolución de nombres estática en la red local para que el servidor sea accesible por su nombre de host y no se necesario indicar su IP. Para el propósito de esta documentación, la configuración del servidor web se mantiene sencilla y se opta por la solución más simple: colocar el fichero de preseed en el document root por defecto.\ncp preseed.cfg /var/www/html Esto hace que el fichero sea accesible desde cualquier cliente conectado a la red que acceda a la ruta http://IP_SERVIDOR/preseed.cfg.\nAcceso al fichero de preseed desde el instalador Para que el instalador tenga acceso a este fichero el cliente tiene que arrancar con una iso que cargue el menú de instalación de Debian y, desde él, acceder a las opciones avanzadas y después a instalación automática.\nEsto lanza el proceso de instalación y, en un momento determinado, tras la configuración por DHCP del equipo y una vez que la máquina obtiene la configuración de red, se muestra un diálogo en el que se solicita la ubicación del fichero de preseed para ejecutar la instalación desatendida. En este ejemplo el cliente es una máquina virtual creada con libvirt-KVM y el servidor web está instalado en el host, así que la conexión se realiza a través de la red por defecto de libvirt-KVM.\nhttp://192.168.122.1/preseed.cfg A partir de este punto, el proceso de instalación continúa su ejecución de forma autónoma hasta finalizar con el reinicio del equipo, que en este punto ya cuenta con el nuevo sistema operativo instalado.\nInstalación desatendida desde un servidor PXE/TFTP Para esta instalación es necesario contar en el escenario con un servidor DHCP y un servidor TFTP. Ambos se pueden ejecutar en la misma máquina.\nConfiguración del servidor TFTP Como servidor TFTP la guía oficial de Debian recomienda usar tftpd-hpa para un servidor Debian GNU/Linux. Está escrito por el mismo autor del gestor de arranque syslinux, y por ello menos proclive a generar problemas.\nsudo apt install tftpd-hpa Existen dos formas de iniciar TFTP: desde el demonio del sistema o como un demonio independiente. Esta configuración se determina en el fichero /etc/default/tftpd-hpa, en el que se debe incluir la siguiente línea:\nRUN_DAEMON=\u0026#34;yes\u0026#34; Con esta orden se fuerza la ejecución del demonio. A continuación, se debe reiniciar el servicio para cargar esta nueva configuración\nsudo systemctl restart tftpd-hpa.service Creación del archivo de instalación A diferencia de las instalaciones que usan medios físicos como CD, DVD o memorias extraíbles USB, donde se usa un fichero de imagen de tipo iso arrancable para cargar e instalar el sistema operativo en el equipo, para las instalaciones por red Debian distribuye imágenes de instalación comprimidas, generalmente, con el nombre netboot.tar.gz. Esta imagen se puede descargar desde los repositorios de Debian.\nwget http://ftp.debian.org/debian/dists/bookworm/main/installer-amd64/current/images/netboot/netboot.tar.gz Para que el archivo de instalación esté disponible desde el resto de equipos conectados a la red hay que descomprimir el contenido de este archivo en el directorio que el servidor TFTP comparte con los clientes.\nEn este punto se abren dos posibilidades. La primera de ellas es modificar el contenido de este archivo de imagen de forma análoga a cuando se modifica el contenido de una imagen iso, de manera que las órdenes del fichero de preseed se carguen en el fichero initrd de la imagen comprimida y se ejecuten de forma automática durante el proceso de instalación.\nLa otra opción es instalar junto al servidor TFTP y DHCP de este equipo un servidor web y alojar en él el fichero de preseed. De esta forma, se puede llevar a cabo una instalación automatizada obteniendo el fichero por red tal y como se ha descrito en el apartado anterior. Como este procedimiento ya está documentado se sigue a continuación con la otra opción.\nPara volcar la configuración del fichero de preseed al fichero initrd del instalador de Debian hay que seguir unos pasos similares a los que se realizan para crear una imagen iso para la instalación desatendida con la diferencia de que, en este caso, no es necesario utilizar ninguna herramienta específica para descomprimir el archivo de instalación. Así, en primer lugar, se descomprime el archivo de instalación y, a continuación se descomprime también el fichero initrd.gz del directorio debian-installer.\ntar -xvf netboot.tar.gz gunzip debian-installer/amd64/initrd.gz A continuación, se vuelca el contenido del fichero de preseed con la configuración para la instalación desatendida en el fichero initrd y se vuelve a comprimir.\necho preseed.cfg | cpio -H newc -o -A -F debian-installer/amd64/initrd gzip debian-installer/amd64/initrd Note\nSi este procedimiento se realiza en un equipo diferente al servidor TFTP será necesario comprimir de nuevo el archivo de instalación para poder llevarlo al servidor y descomprimirlo en el directorio que el servidor comparte con los clientes.\nCon el archivo de instalación modificado para que ejecuta la instalación desatendida gracias a la configuración que aporta el fichero de preseed y todos los ficheros necesarios para la instalación por red ubicados en el directorio correcto del servidor TFTP (por defecto, el directorio /srv/tftp), el siguiente paso es instalar y configurar el servidor DHCP.\nConfiguración del servidor DHCP A continuación, hay que configurar el servidor DHCP para que apunte al archivo de imagen con el instalador de Debian que ofrece el servidor TFTP. Como servidor DHCP la guía oficial de Debian recomienda el uso del paquete isc-dhcp-server que instala el servidor dhcpd de ISC.\nsudo apt install isc-dhcp-server En su wiki, Debian recoge un ejemplo de configuración básico del servidor DHCP para habilitar el arranque por PXE en las máquinas cliente que se conecten a la red. En este ejemplo, el servidor TFTP y el servidor DHCP están instalados en máquinas diferentes por lo que en el escenario que se plantea aquí la configuración es un poco más sencilla. Simplemente hay que añadir a la configuración habitual del servidor DHCP la línea filename \u0026quot;pxelinux.0\u0026quot;; dentro del párrafo que identifica la red.\nDe esta manera, la configuración del fichero /etc/dhcp/dhcpd.conf sería similar a la siguiente:\noption domain-name \u0026#34;example.org\u0026#34;; option domain-name-servers ns1.example.org, ns2.example.org; default-lease-time 600; max-lease-time 7200; ddns-update-style none; subnet 10.0.0.0 netmask 255.255.255.224 { range 10.0.0.2 10.0.0.20; option routers 10.0.0.1; allow bootp; next-server 10.0.0.1; filename \u0026#34;pxelinux.0\u0026#34;; } Note\nNo se debe olvidar configurar la interfaz de escucha del servidor DHCP en el fichero /etc/default/isc-dhcp-server con la línea: INTERFACESv4=\u0026quot;enp7s0\u0026quot;.\nPara aplicar la configuración se tiene que reiniciar el servidor.\nsudo systemctl restart isc-dhcp-server.service Si la instalación de Debian requiere instalar paquetes desde los repositorios, el cliente debe tener acceso a internet. Esto se puede conseguir si el servidor DHCP/TFTP actúa también como router. Para ello, hay que activar el bit de forwarding.\necho net.ipv4.ip_forward = 1 \u0026gt; /etc/sysctl.conf sudo sysctl -p Además, también deberá contar con una regla de iptables que permite hacer NAT a los paquetes que reciba desde el cliente.\nsudo iptables -t nat -A POSTROUTING -s 10.0.0.0/24 -o enp1s0 -j MASQUERADE sudo iptables-save \u0026gt; /etc/iptables/rules.v4 Tras completar esta configuración, cualquier cliente de la red que arranque usando la opción PXE obtendrá por DHCP la configuración de red que apunta al archivo de instalación almacenado en el servidor TFTP. Cuando el cliente acceda al fichero de arranque al que apunta el servidor DHCP cargará el menú de instalación por red de Debian. Como la imagen de instalación tiene cargadas las órdenes configuradas en el fichero de preseed, al arrancar la instalación desde este menú se produce de forma desatendida.\nInstalación desatendida con dnsmasq Dnsmasq es una herramienta que funciona como un DNS, un servidor DHCP y un servidor TFTP para redes pequeñas al mismo tiempo. Esto permite reducir el flujo de trabajo para la instalación de sistemas operativos por red al tener que usar sólo una herramienta en vez de trabajar con los diferentes servidores por separado.\nPara instalar dnsmasq:\nsudo apt install dnsmasq La configuración tanto de DHCP como de TFTP se realizan en el fichero /etc/dnsmasq.conf\ninterface=enp7s0 dhcp-range=10.0.0.2,10.0.0.200,6h dhcp-boot=pxelinux.0 enable-tftp tftp-root=/srv/tftp La línea interface indica la interfaz por la que escucha y reparte direcciones el servidor DHCP, con dhcp-range se indica el rango de direcciones y el tiempo de concesión del servidor DHCP, la orden dhcp-boot apunta al fichero de arranque, la línea enable-tftp habilita el servidor TFTP y con tftp-root se apunta a la ruta donde están los ficheros alojados en el servidor TFTP.\nPara aplicar los cambios en la configuración se reinicia el servicio.\nsudo systemctl restart dnsmasq.service El contenido del directorio /srv/tftp y la configuración para que el servidor DHCP/PXE/TFTP haga de router para los clientes es igual al documentado en el punto anterior.\nAl encender por red un cliente de la red, el servidor dnsmasq le da una configuración TCP/IP y lo dirige al fichero de arranque del instalador.\niVentoy: una alternativa sencilla Una alternativa a la creación de un servidor PXE/TFTP es el uso de herramientas más sencillas como iVentoy. Esta herramienta es una versión mejorada de un servidor PXE que permite arrancar e instalar imágenes iso en diferentes máquinas de la red de manera simultánea. Se trata de una herramienta muy sencilla y fácil de usar y que se puede implantar sin hacer casi ninguna configuración. Además, iVentoy cuenta con una interfaz gráfica a la que se accede a través de un navegador web. Soporta una gran variedad de sistemas operativos y arquitecturas.\nLa herramienta iVentoy es software libre y se distribuye a través de su repositorio de GitHub en forma de archivo comprimido. Para instalarla en el servidor PXE de la red simplemente hay que descargar y descomprimir el archivo y ejecutar el script iventoy.sh que está en el directorio raíz al descomprimir este archivo.\nwget https://github.com/ventoy/PXE/releases/download/v1.0.20/iventoy-1.0.20-linux-free.tar.gz tar -xvf iventoy-1.0.20-linux-free.tar.gz cd iventoy-1.0.20/ sudo bash iventoy.sh start Tras ejecutar la herramienta se puede acceder a la interfaz gráfica en el puerto 26000 del servidor.\nusuario@preseedsrv:~/iventoy-1.0.20$ sudo bash iventoy.sh start iventoy start SUCCESS PID=1164 Please open your browser and visit http://127.0.0.1:26000 or http://x.x.x.x:26000 (x.x.x.x is any valid IP address) Desde ella se puede configurar el servidor iVentoy, establecer la configuración de DHCP, arrancar y parar el servicio y establecer una lista de equipos que tienen permiso o no para acceder al servidor.\nPara hace accesible una imagen iso a los equipos de la red a través de iVentoy simplemente hay que llevar el archivo de imagen iso al directorio iso/ dentro del directorio de iVentoy.\ncp deb12-inst-desatendida.iso iventoy-1.0.20/iso/ Desde la interfaz gráfica se puede también listar las máquinas que se han conectado al servidor para instalar una imagen desde él.\nEl uso de iVentoy aporta algunas ventajas frente a otras soluciones como la instalación de un servidor PXE/TFTP desde cero. La más evidente es que el proceso de instalación y configuración del servidor es mucho más simple en este caso puesto que no es necesario instalar cada uno de los servidores por separado y establecer la configuración específica para ellos.\nPor otra parte, iVentoy facilita el proceso de instalación desatendida de un sistema operativo en múltiples equipos porque permite distribuir imágenes iso, a diferencia del servidor PXE/TFTP que distribuye imágenes en ficheros netboot comprimidos. Esto permite que se pueda distribuir para instalar en un entorno real con múltiples equipos el mismo archivo de imagen iso que se puede instalar en una máquina virtual en un entorno local de pruebas.\n"},{
  "section": "Blog",
  "slug": "/blog/administracion-de-sistemas/2024-12-02-instalacion-desatendida-iso/",
  "title": "Instalación desatendida de Debian12",
  "description": "",
  "date": "November 21, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "administracion-sistemas",
  "tags": "sistemas, debian, linux, instalación, preseed, instalación desatendida, debian installer, administracion-sistemas, Administración de Sistemas Operativos",
  "content":"Creación del fichero de preseed Para configurar una instalación desatendida de Debian 12 se usa un fichero de configuración llamado preseed. Este fichero usa las diferentes órdenes del comando debian-installer para responder de forma automática a las preguntas que se muestran durante el proceso habitual de instalación del sistema operativo.\nLa distribución ofrece una amplia documentación sobre el procedimiento para llevar a cabo la instalación desatendida del sistema operativo. Además, también ofrece un fichero de ejemplo extensamente comentado que se puede usar como guía en el proceso de elaboración de un fichero personalizado.\nAdemás, en el punto 4 del apéndice del manual del administrador de Debian sobre instalación desatendida se desarrolla, punto por punto, cada una de las partes que debe contener este fichero.\nComo se explica en la documentación oficial, el fichero de preseed siempre debe comenzar con la línea #_preseed_V1. A continuación se incluyen las diferentes órdenes que ejecuta durante el proceso de instalación el comando debian-installer para responder a las preguntas del instalador.\nEl primer segmento del documento configura el lenguaje, país y distribución de teclas del teclado.\n### Localization # Selección del lenguale, país y configuración de \u0026#34;locale\u0026#34; d-i debian-installer/locale string es_ES # Selección del teclado d-i keyboard-configuration/xkb-keymap select es A continuación, se añaden las órdenes relacionadas con la configuración de red. Entre ellas, se establece la interfaz predeterminada para la instalación, se establece el nombre de host y de dominio de la máquina y se puede indicar que se cargue el firmware non-free si es necesario para detectar y configurar el hardware de red. Este opción puede ser necesaria para algunas tarjetas de red.\n### Network configuration # Netcfg elige automáticamente una interfaz de red con conexión para evitar que # se muestre la lista de interfaces si hay más de una d-i netcfg/choose_interface select auto # Respuestas a las preguntas sobre nombre de host y dominio d-i netcfg/get_hostname string deb-12 d-i netcfg/get_domain string gonzalonazareno.org # Disable that annoying WEP key dialog. d-i netcfg/wireless_wep string # Intenta cargar el non-free firmware si es necesario para el hardware de red. d-i hw-detect/load_firmware boolean true El siguiente apartado del fichero configura el mirror que se utiliza posteriormente en el proceso de instalación para cargar la configuración de la paquetería del sistema a través de APT.\n### Mirror settings # Mirror protocol (http por defecto): d-i mirror/country string ES d-i mirror/http/hostname string ftp.es.debian.org d-i mirror/http/directory string /debian d-i mirror/http/proxy string Después se crean los usuarios en el equipo. Existen varias opciones de configuración análogas a las que se pueden establecer de manera interactiva durante la instalación del sistema. Por ejemplo, se puede indicar que no se cree un usuario root y el usuario normal tendrá privilegios a través de sudo. También se pueden crear una cuenta para root y otra par el usuario. En ambos casos la contraseña se puede indicar en texto claro o encriptada usando un crypt hash.\nPara generar contraseña cifrada que se puede usar en el fichero de preseed se puede usar el siguiente comando:\nmkpasswd -m sha-512 Así, un ejemplo de configuración de las cuentas de usuario en el sistema puede ser el siguiente:\n### Account setup # Contraseña de root en texto claro: #d-i passwd/root-password password r00tme #d-i passwd/root-password-again password r00tme # o encriptada usando un crypt(3) hash. d-i passwd/root-password-crypted password $6$IJQob.S9vlI2AuBC$Uc9b6E3/aqIH8RwP56KPxsp1PiZ1zZYakuafyzG.XXUS/ecQtStwtM.zwcQpUwWunEQHalP.J8q/sMnQ82Zrk. # Para crear una cuenta de usuario d-i passwd/user-fullname string debian d-i passwd/username string debian # La contraseña de usuario se puede indicar en texto claro #d-i passwd/user-password password insecure #d-i passwd/user-password-again password insecure # o encriptada usando un crypt(3) hash. d-i passwd/user-password-crypted password $6$SwwB64plkjSfzkWG$m0XWCN69GBiozd3gE.we2KFZVviFYif6L0LMF6ds3ZewvsLAWknH/beeSUDr.HbC4nbtaWdA2lnI7BSKly1VS1 A continuación se configuran también el reloj y la zona horaria\n### Clock and time zone setup # Controla si el reloj de hardware se establece en UTC d-i clock-setup/utc boolean true # Este campo deve ser cualquier valor válido para $TZ; los valores válidos # se pueden consultar en el directorio /usr/share/zoneinfo/ d-i time/zone string Europe/Madrid # Controla el uso de NTP para establecer la hora del reloj durante la instalación d-i clock-setup/ntp boolean true Uno de los apartados más críticos del fichero de preseed es el del particionado del disco. Desde la configuración de este fichero se pueden elegir tres modos de particionado: el normal, que usa particiones del disco duro; el particionado con volúmenes lógicos, que usa LVM para particionar el disco; y el particionado encriptado, que genera particiones encriptadas.\nEn este caso, se usa la opción lvm para crear las particiones en un grupo de volúmenes.\nEn este fichero también se puede definir la cantidad de espacio usada por el grupo de volúmenes, en este caso, el máximo disponible.\nAdemás, también se puede configurar la eliminación automática de los LVM y RAID que existan en el disco antes de la instalación del sistema operativo.\n### Partitioning # Los modos de particionado disponibles actualmente son: # - regular: usa los tipos de particiones habituales de la arquitectura # - lvm: usa LVM para particionar el disco # - crypto: usa LVM con particiones encriptadas d-i partman-auto/method string lvm # Crear un grupo de volúmenes #d-i partman-auto-lvm/new_vg_name string vg1 # Se define la cantidad de espacio usada por el grupo de volúemenes. Puede ser # un tamaño en unidades, un porcentaje del espacio libre o la plabra # clave \u0026#39;max\u0026#39; d-i partman-auto-lvm/guided_size string max # Eliminación automática de LVM y RAID si existen # Si alguno de los discos que se van a particionar contiene una # configuración LVM previa, el usuario recibiría un aviso. Esto lo evita d-i partman-lvm/device_remove_lvm boolean true # Lo mismo ocurre con los RAID preexistentes d-i partman-md/device_remove_md boolean true # Y lo mismo con la confirmación para escribir las particiones lvm d-i partman-lvm/confirm boolean true d-i partman-lvm/confirm_nooverwrite boolean true # Esto hace que partman particione el disco automáticamente sin confirmación # usando uno de los métodos anteriores d-i partman-partitioning/confirm_write_new_label boolean true d-i partman/choose_partition select finish d-i partman/confirm boolean true d-i partman/confirm_nooverwrite boolean true d-i partman/ignore_warnings boolean true El particionado del disco se define usando lo que debian-installer llama \u0026ldquo;recetas\u0026rdquo;. Una receta es una guía que establece el número, tamaño y tipo de las particiones que se crean en el disco durante la instalación del sistema operativo.\nCon el fichero de preseed de debian-installer se pueden usar cuatro opciones de particionado: la opción atomic genera una única partición en la que se incluyen todos los ficheros del sistema, la opción home crea una partición separada de la raíz para el directorio /home y la opción multi instala el sistema operativo con particiones separadas para los directorios /home, /var y /tmp. Adicionalmente, debian-installer ofrece la opción de indicar una receta personalizada para establecer un esquema de particionado definido por el usuario.\nEn el repositorio de debian-installer hay disponible documentación adicional específica sobre el uso de las recetas personalizadas para el particionado.\nEn este caso, se define una partición efi de pequeño tamaño con sistema de ficheros fat32 que se monta en el directorio /boot/efi. Después se indica la creación de la partición /boot ya con sistema de ficheros ext4 y con un tamaño de 512M. Dentro del grupo de volúmenes se crean varios volúmenes lógicos para montar en ellos diferentes directorios del sistema. El menor tamaño se le asigna a la swap y el mayor tamaño se le asigna a la partición raíz. Con tamaños intermedios se crean también las particiones /home y /var.\n# Se puede elegir una de las tres recetas de particionado predefinidas: # - atomic: todos los ficheros en una partición # - home: partición /home separada # - multi: particiones /home, /var y /tmp separadas # o una receta de experto definida a continuación d-i partman-auto/choose_recipe select bootlvm # Receta para el particionado con LVM d-i partman-auto/expert_recipe string \\ bootlvm :: \\ 256 256 256 fat32 \\ $primary{ } $bootable{ } \\ method{ format } format{ } \\ use_filesystem{ } filesystem{ fat32 } \\ mountpoint{ /boot/efi } \\ set_flags{ boot } \\ . \\ 512 512 512 ext4 \\ $primary{ } $bootable{ } \\ method{ format } format{ } \\ use_filesystem{ } filesystem{ ext4 } \\ mountpoint{ /boot } \\ . \\ 256 256 512 linux-swap \\ $defaultignore{ } $lvmok{ } \\ lv_name{ swap } \\ in_vg { vg1 } \\ method{ swap } format{ } \\ . \\ 4096 10000 1000000 ext4 \\ $defaultignore{ } $lvmok{ } \\ lv_name{ raiz } \\ in_vg { vg1 } \\ method{ format } format{ } \\ use_filesystem{ } filesystem{ ext4 } \\ mountpoint{ / } \\ . \\ 1024 5000 10000000 ext4 \\ $defaultignore{ } $lvmok{ } \\ lv_name{ var } \\ in_vg { vg1 } \\ method{ format } format{ } \\ use_filesystem{ } filesystem{ ext4 } \\ mountpoint{ /var } \\ . \\ 1024 5000 10000000 ext4 \\ $defaultignore{ } $lvmok{ } \\ lv_name{ home } \\ in_vg { vg1 } \\ method{ format } format{ } \\ use_filesystem{ } filesystem{ ext4 } \\ mountpoint{ /home } \\ . Tras el particionado, se indican diferentes parámetros para la configuración del gestor de paquetes apt, que realiza en este punto de la instalación la primera instalación de la paquetería básica del equipo. Entre otros, se puede indicar si se deben escanear medios adicionales de instalación, si se debe instalar software que sea non-free o contrib o definir los servicios de actualización que se añadirán al fichero /etc/apt/sources.list.\n### Apt setup # Elige si se escanean medios de instalación adicionales (por defecto: false) d-i apt-setup/cdrom/set-first boolean false # Descomenta esto para usar un mirror de red d-i apt-setup/use_mirror boolean false # Instalación de non-free firmware. d-i apt-setup/non-free-firmware boolean true # Instalación de non-free and contrib software. d-i apt-setup/non-free boolean true d-i apt-setup/contrib boolean true # Descomenta esta línea si no quieres tener la entrada de la imagen de # instalación de DVD/BD en sources.list activa en el sistema instalado d-i apt-setup/disable-cdrom-entries boolean true # Elige qué servicios de actualización usar; define los mirrors a usar d-i apt-setup/services-select multiselect security, updates d-i apt-setup/security_host string security.debian.org Para terminar, se seleccionan los paquetes que instala tasksel al final del proceso de instalación del sistema operativo, se acepta o rechaza la participación en el concurso de popularidad de los paquetes de apt y se instala el gestor de arranque grub.\n### Package selection tasksel tasksel/first multiselect standard, ssh-server # Selección de la opción de participar en el concurso de popularidad de Debian popularity-contest popularity-contest/participate boolean false ### Boot loader installation # Instalación automática del grub en la partición UEFI si no hay otro sistema # operativo detectado en la máquina d-i grub-installer/only_debian boolean true # Esto hace que grup-installer instale en la partición UEFI el grub aunque haya # otro sistema operativo en la máquina, lo que es menos seguro porque puede # hacer que no arranque el otro sistema operativo d-i grub-installer/with_other_os boolean true # Debido principalmente al uso de memorias USB, no siempre se puede determinar # con seguridad la unidad de disco principal, por lo que necesita especificar # lo siguiente: #d-i grub-installer/bootdev string /dev/sda # Para instalar el cargador arranque en la unidad de disco principal # (asumiendo que no sea una memoria USB): d-i grub-installer/bootdev string default ### Finishing up the installation # Evita el último mensaje sobre la instalación completa d-i finish-install/reboot_in_progress note Creación de la iso Para llevar esta configuración a la máquina hay que incluir el fichero de preseed en una imagen iso instalable junto al sistema operativo. Como punto de partida se puede usar la imagen de instalación del sistema operativo que se puede descargar desde su página web oficial. También se puede usar, si es el caso, una imagen iso modificada. En la documentación de la herramienta debian-installer se recogen de manera detallada las instrucciones para llevar a cabo este procedimiento.\nEl primer paso es extraer el contenido de la imagen iso distribuida por Debian a un directorio del sistema para poder trabajar con sus contenidos. Esto se puede hacer de diferentes formas y usando diferentes herramientas. Una de ellas es xorriso.\nsudo apt install xorriso Esta herramienta permite trabajar de diferentes formas con ficheros de imagen iso. En este caso, se usa para extraer el contenido del fichero iso a un directorio del sistema de manera que se pueda navegar a través de él como se haría con cualquier otro esquema de directorios. Así, los contenidos del archivo de imagen se hacen accesibles y se pueden modificar para incluir en ellos la información necesaria para que el proceso de instalación se ejecute de forma automática.\nxorriso -osirrox on -indev debian-12.1.0-amd64-netinst.iso -extract / ./iso En este caso, el contenido de la imagen iso se extrae a un directorio llamado iso. Este directorio contiene todos los ficheros de la imagen iso distribuida por Debian. Para que el proceso de instalación se ejecute de forma desatendida, hay que incluir las órdenes del fichero de preseed en el fichero /install.amd/initrd de la iso. Se trata de un fichero comprimido así que hay que darle permisos de escritura y descomprimirlo. Después se vuelca el contenido del fichero de preseed al fichero initrd y, finalmente, se vuelve a comprimir. Antes de terminar, se le devuelven los permisos originales.\nchmod +w -R iso/install.amd gunzip iso/install.amd/initrd.gz echo preseed.cfg | cpio -H newc -o -A -F iso/install.amd/initrd gzip iso/install.amd/initrd chmod -w -R iso/install.amd Como se ha cambiado el contenido de un fichero de la imagen iso, el hash de verificación del fichero también será diferente, por tanto, es necesario regenerar el fichero md5sum.txt que verifica la integridad de los ficheros que componen la imagen iso. Para ello, desde el directorio de la iso se le otorgan permisos de escritura sobre el fichero al usuario, se genera un nuevo fichero con los hashes correspondientes a los ficheros actualizados y se devuelven los permisos originales.\ncd iso/ chmod +w md5sum.txt sudo rm md5sum.txt sudo find -follow -type f ! -name md5sum.txt -print0 | xargs -0 md5sum \u0026gt; md5sum.txt sudo chmod -w md5sum.txt Durante la ejecución de este comando se muestra una advertencia que no afecta al proceso.\nfind: Se ha detectado un bucle en el sistema de ficheros; ‘./debian’ es parte del mismo bucle de sistema de ficheros que ‘.’. El último paso es generar una nueva imagen iso que sea arrancable desde un equipo a partir del directorio iso con el que se ha estado trabajando. De nuevo existen múltiples herramientas para este propósito. En este caso, se usa genisoimage.\nsudo apt install genisoimage Esta herramienta permite generar un fichero de imagen arrancalbe de tipo iso a partir de un directorio.\nsudo genisoimage -r -J -b isolinux/isolinux.bin -c isolinux/boot.cat -no-emul-boot -boot-load-size 4 -boot-info-table -o preseed-debian-12.iso ../iso/ Este fichero de imagen ya contiene el conjunto de órdenes definido en el fichero de preseed, que va a hacer que la instalación del sistema operativo se lleve a cabo de principio a fin de forma destendida y sin requerir la interacción del usuario en ningún momento.\nToques finales Hay que tener en cuenta que esta configuración volcada al archivo de imagen iso usando el fichero de preseed sólo ejecuta la instalación desatendida del sistema operativo si se accede al instalador desde el modo \u0026ldquo;install\u0026rdquo; y no desde el modo de instalación gráfica. Una práctica interesante para evitar elegir un modo de instalación inadecuado accidentalmente puede ser editar el menú de arranque del instalador.\nEste menú se define el en fichero /isolinux/menu.cfg (ruta absoluta desde la raíz del archivo de imagen iso). En él cada línea define una entrada del menú del instalador. Algunas de ellas llaman a otros ficheros de configuración en los que se define más detalladamente cada opción de instalación.\nAsí, la línea include gtk.cfg llama al fichero en el que se describe la opción de instalación gráfica y la línea include txt.cfg llama al fichero en el que se describe la opción de instalación usando sólo el menú de texto. Esta opción es la que permite el correcto funcionamiento del procedimiento de instalación desatendida usando el fichero de preseed.\nPor tanto, una posible modificación del menú de la iso es la siguiente, en la que se eliminan todas las líneas que describen otras opciones de instalación como la instalación desatendida (a través de red), la instalación con audiodescripción o la instalación gráfica, que no permite que se ejecuten de forma automática las órdenes configuradas en el fichero de preseed.\nmenu hshift 4 menu width 70 menu title \u0007Debian GNU/Linux installer menu (BIOS mode) include stdmenu.cfg include txt.cfg label help menu label ^Help text help Display help screens; type \u0026#39;menu\u0026#39; at boot prompt to return to this menu endtext config prompt.cfg Este menú muestra únicamente la línea \u0026ldquo;install\u0026rdquo;, que ejecuta la instalación desatendida y la línea \u0026ldquo;help\u0026rdquo; que permite acceder a información y ayuda relevante sobre el sistema operativo y el instalador.\nEn una edición un poco más meticulosa de este fichero se pueden mantener todas las opciones compatibles con la instalación desatendida. En este caso se muestra una entrada para la opción de instalación, una entrada para el menú de alto contraste, que facilita la accesibilidad a personas con discapacidad visual y el menú de ayuda.\nPara maximizar la compatibilidad con la configuración de instalación desatendida, el menú de alto contraste también cuenta únicamente con las opciones de instalación (compatible con la configuración esteblecida en el fichero de preseed) y ayuda.\nLas opciones de instalación con audiodescripción no están presentes en este menú porque no son compatibles con la instalación desatendida configurada a través del fichero de preseed.\nmenu hshift 4 menu width 70 menu title \u0007Debian GNU/Linux Menu de instalacion desatendida (BIOS mode) include stdmenu.cfg include txt.cfg menu begin dark menu label ^Menu de instalacion en alto contraste menu title Opciones de instalacion accesible include drkmenu.cfg label mainmenu menu label ^Atras.. menu exit include drk.cfg label help menu label ^Ayuda text help Muestra la pantalla de ayuda; escribe \u0026#39;menu\u0026#39; en el prompt para volver endtext config prompt.cfg menu end label help menu label ^Ayuda text help Muestra la pantalla de ayuda; escribe \u0026#39;menu\u0026#39; en el prompt para volver endtext config prompt.cfg La edición de este fichero permite también mostrar el menú del instalador traducido, como en este ejemplo anterior. Para que todas las opciones se muestren en castellano es también necesario traducir el texto de los ficheros txt.cfg y drk.cfg, que incluyen detalles de los menús de instalación.\n"},{
  "section": "Blog",
  "slug": "/blog/implantacion-aplicaciones-web/2024-12-02-despliegue-aplicaciones-pyton/",
  "title": "Despliegue de aplicaciones escritas en Python",
  "description": "",
  "date": "November 18, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "implantacion",
  "tags": "Migración de aplicaciones, entorno de producción, Apache2, Nginx, servidor web, LEMP, LAMP, flask, django, implantacion, Implantación de Aplicaciones Web",
  "content":"Configuración del equipo de desarrollo para desplegar una aplicación Python con Django En primer lugar se crea un entorno virtual con las dependencias necesarias para que funcione el proyecto.\ncd venv python3 -m venv django pip install ~/django_tutorial/requirements.txt Para crear la base de datos con la estructura de datos definida en el proyecto django se ejecuta el comando migrate.\n(django) debian@implantacion:~$ cd ~/django_tutorial (django) debian@implantacion:~/django_tutorial$ python3 manage.py migrate Operations to perform: Apply all migrations: admin, auth, contenttypes, polls, sessions Running migrations: Applying contenttypes.0001_initial... OK Applying auth.0001_initial... OK Applying admin.0001_initial... OK Applying admin.0002_logentry_remove_auto_add... OK Applying admin.0003_logentry_add_action_flag_choices... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying auth.0007_alter_validators_add_error_messages... OK Applying auth.0008_alter_user_username_max_length... OK Applying auth.0009_alter_user_last_name_max_length... OK Applying auth.0010_alter_group_name_max_length... OK Applying auth.0011_update_proxy_permissions... OK Applying auth.0012_alter_user_first_name_max_length... OK Applying polls.0001_initial... OK Applying sessions.0001_initial... OK Para crear un usuario administrador se usa el comando createsuperuser.\n(django) debian@implantacion:~/django_tutorial$ python3 manage.py createsuperuser Username (leave blank to use \u0026#39;debian\u0026#39;): admin Email address: admin@poll.org Password: Password (again): The password is too similar to the username. This password is too short. It must contain at least 8 characters. This password is too common. Bypass password validation and create user anyway? [y/N]: y Superuser created successfully. Al intentar acceder a la administración de la aplicación se produce el siguiente error:\nDisallowedHost at /admin Invalid HTTP_HOST header: \u0026#39;172.22.202.151:8080\u0026#39;. You may need to add \u0026#39;172.22.202.151\u0026#39; to ALLOWED_HOSTS. Request Method: GET Request URL: http://172.22.202.151:8080/admin Django Version: 4.2 Exception Type: DisallowedHost Exception Value: Invalid HTTP_HOST header: \u0026#39;172.22.202.151:8080\u0026#39;. You may need to add \u0026#39;172.22.202.151\u0026#39; to ALLOWED_HOSTS. Exception Location: /home/debian/venv/django/lib/python3.11/site-packages/django/http/request.py, line 167, in get_host Python Executable: /home/debian/venv/django/bin/python3 Python Version: 3.11.2 Python Path: [\u0026#39;/home/debian/django_tutorial\u0026#39;, \u0026#39;/usr/lib/python311.zip\u0026#39;, \u0026#39;/usr/lib/python3.11\u0026#39;, \u0026#39;/usr/lib/python3.11/lib-dynload\u0026#39;, \u0026#39;/home/debian/venv/django/lib/python3.11/site-packages\u0026#39;] Server time: Mon, 25 Nov 2024 11:21:33 +0000 Para solucionarlo se incluye la IP en la lista de hosts permitidos del fichero django_tutorial/settings.py\nALLOWED_HOSTS = [\u0026#34;172.22.202.151\u0026#34;] Para ejecutar el servidor web de desarrollo se usa el comando runserver.\npython3 manage.py runserver 0.0.0.0:8080 Configurar el servidor Apache2 para servir la página web Para poder servir la página web en Apache2 hay que configurar el VirtualHost indicando el ServerName, DocumentRoot y también aportando la información necesaria para que funcione el módulo wsgi de Apache2.\nServerName polls.javi.org ServerAdmin webmaster@localhost DocumentRoot /home/debian/django_tutorial WSGIDaemonProcess django_polls python-path=/home/debian/django_tutorial:/home/debian/venv/django/lib/python3.11/site-packages WSGIProcessGroup django_polls WSGIScriptAlias / /home/debian/django_tutorial/django_tutorial/wsgi.py process-group=django_polls A continuación se usa el comando collectstatic para generar un directorio de ficheros estáticos en el directorio del proyecto con todos los ficheros estáticos. Para que este comando funcione, se debe indicar la URL base de los ficheros estáticos en el fichero settings.py\nimport os STATIC_ROOT = os.path.join(BASE_DIR, \u0026#39;static\u0026#39;) Y después se puede ejecutar el comando collectstatic\n(django) debian@implantacion:~/django_tutorial$ python3 manage.py collectstatic You have requested to collect static files at the destination location as specified in your settings: /home/debian/django_tutorial/static This will overwrite existing files! Are you sure you want to do this? Type \u0026#39;yes\u0026#39; to continue, or \u0026#39;no\u0026#39; to cancel: yes 128 static files copied to \u0026#39;/home/debian/django_tutorial/static\u0026#39;. Finalmente se crea un alias en el VirtualHost que sirve el contenido del directorio estático cuando se accede a la URL_BASE/static.\nAlias /static/ /home/debian/django_tutorial/static/ \u0026lt;Directory /home/debian/django_tutorial/static/\u0026gt; Require all granted \u0026lt;/Directory\u0026gt; Así, el contenido final del VirtualHost es el siguiente:\n\u0026lt;VirtualHost *:80\u0026gt; ServerName polls.javi.org ServerAdmin webmaster@localhost DocumentRoot /home/debian/django_tutorial WSGIDaemonProcess django_polls python-path=/home/debian/django_tutorial:/home/debian/venv/django/lib/python3.11/site-packages WSGIProcessGroup django_polls WSGIScriptAlias / /home/debian/django_tutorial/django_tutorial/wsgi.py process-group=django_polls \u0026lt;Directory /home/debian/django_tutorial\u0026gt; Require all granted \u0026lt;/Directory\u0026gt; Alias /static/ /home/debian/django_tutorial/static/ \u0026lt;Directory /home/debian/django_tutorial/static/\u0026gt; Require all granted \u0026lt;/Directory\u0026gt; ErrorLog ${APACHE_LOG_DIR}/error.log CustomLog ${APACHE_LOG_DIR}/access.log combined Migración al entorno de producción Configuración del proyecto en django Una vez que la aplicación está funcionando en el entorno local de desarrollo correctamente, se puede implantar en el entorno de producción, en este caso, un VPS. Para volcar el directorio del proyecto primero se sincroniza el repositorio en GitHub.\ngit add . git commit -am \u0026#34;Modificaciones para servir la aplicación usando Apache2\u0026#34; git push En el VPS se clona el repositorio\ngit clone https://github.com/fjhuete/django_tutorial.git A continuación se crea en el entorno de producción también un entorno virtual para trabajar con el framework django.\nsudo apt install python3-venv mkdir venv cd venv/ python3 -m venv django source django/bin/activate Con el entorno virtual activado se instalan las dependencias necesarias para el funcionamiento de la aplicación.\n(django) debian@pignite:~/venv$ cd ~/django_tutorial/ (django) debian@pignite:~/django_tutorial$ pip install -r requirements.txt En el entorno de producción la aplicación usa el SGBD MySQL en vez de sqlite. Para poder usarlo, en el entorno virtual tiene que estar instalado también el módulo para que python trabaje con mysql.\npip install mysqlclient Durante el proceso de instalación de mysqlclient se produce un error en las dependencias. Para solucionarlo, hay que instalar algunos paquetes.\nsudo apt-get install pkg-config python3-dev default-libmysqlclient-dev build-essential En este caso, la instalación de mysqlclient sí es exitosa. A continuación, hay que crear una base de datos en MariaDB a la que pueda acceder la aplicación python.\nMariaDB [(none)]\u0026gt; create database polls; Query OK, 1 row affected (0,001 sec) MariaDB [(none)]\u0026gt; create user \u0026#39;polls\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;polls\u0026#39;; Query OK, 0 rows affected (0,002 sec) MariaDB [(none)]\u0026gt; grant all privileges on polls.* to \u0026#39;polls\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;polls\u0026#39;; Query OK, 0 rows affected (0,002 sec) MariaDB [(none)]\u0026gt; flush privileges; Query OK, 0 rows affected (0,002 sec) Para que la aplicación pueda acceder a la base de datos hay que modificar la configuración del fichero settings.py del proyecto.\n# Database # https://docs.djangoproject.com/en/3.1/ref/settings/#databases DATABASES = { \u0026#39;default\u0026#39;: { \u0026#39;ENGINE\u0026#39;: \u0026#39;django.db.backends.mysql\u0026#39;, \u0026#39;NAME\u0026#39;: \u0026#39;polls\u0026#39;, \u0026#39;USER\u0026#39;: \u0026#39;polls\u0026#39;, \u0026#39;PASSWORD\u0026#39;: \u0026#39;polls\u0026#39;, \u0026#39;HOST\u0026#39;: \u0026#39;localhost\u0026#39;, \u0026#39;PORT\u0026#39;: \u0026#39;\u0026#39;, } } Además, en el fichero settings se debe indicar el nombre de los hosts permitidos para el acceso a la aplicación, en este caso, se puede usar el nombre de la aplicación.\nALLOWED_HOSTS = [\u0026#34;python.javi.org\u0026#34;] Para crear la estructura de tablas en la base de datos en el entorno de producción hay que ejecutar el comando migrate en el VPS.\n(django) debian@pignite:~/django_tutorial$ python3 manage.py migrate Operations to perform: Apply all migrations: admin, auth, contenttypes, polls, sessions Running migrations: Applying contenttypes.0001_initial... OK Applying auth.0001_initial... OK Applying admin.0001_initial... OK Applying admin.0002_logentry_remove_auto_add... OK Applying admin.0003_logentry_add_action_flag_choices... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying auth.0007_alter_validators_add_error_messages... OK Applying auth.0008_alter_user_username_max_length... OK Applying auth.0009_alter_user_last_name_max_length... OK Applying auth.0010_alter_group_name_max_length... OK Applying auth.0011_update_proxy_permissions... OK Applying auth.0012_alter_user_first_name_max_length... OK Applying polls.0001_initial... OK Applying sessions.0001_initial... OK Una vez creadas las tablas de la base de datos para rellenar el contenido hay que hacer una copia de seguridad en el entorno de desarrollo y volcarla al entorno de producción. En este caso se usan dos sistemas gestores de bases de datos diferentes pero se pueden usar los comandos dumpdata y loaddata de django para hacer este proceso de forma sencilla.\nAsí, en el entorno de desarrollo se recopila el contenido de la base de datos, se vuelca a un fichero json y se copia al VPS\npython3 manage.py dumpdata \u0026gt; polls.json scp polls.json debian@pignite.javihuete.site:/home/debian/django_tutorial En el VPS se puede volcar el contenido del fichero de respaldo json generado en el entorno de desarrollo a la base de datos MySQL que está funcionando en el entorno de producción.\n(django) debian@pignite:~/django_tutorial$ python3 manage.py loaddata polls.json Installed 56 object(s) from 1 fixture(s) Configuración del servidor de aplciaciones uwsgi Para servir aplicaciones python con el servidor de aplicaciones wsgi en Nginx el módulo uwsgi tiene que estar instalado en el entorno virtual.\n(django) debian@pignite:~/django_tutorial$ pip install uwsgi Collecting uwsgi Downloading uwsgi-2.0.28.tar.gz (816 kB) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 816.2/816.2 kB 10.3 MB/s eta 0:00:00 Preparing metadata (setup.py) ... done Installing collected packages: uwsgi DEPRECATION: uwsgi is being installed using the legacy \u0026#39;setup.py install\u0026#39; method, because it does not have a \u0026#39;pyproject.toml\u0026#39; and the \u0026#39;wheel\u0026#39; package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the \u0026#39;--use-pep517\u0026#39; option. Discussion can be found at https://github.com/pypa/pip/issues/8559 Running setup.py install for uwsgi ... done Successfully installed uwsgi-2.0.28 A continuación se configura el servidor de aplicaciones usando systemd. Primero se crea el fichero de configuración .ini para la aplicación. Este fichero está en el directorio del entorno virtual.\n[uwsgi] http = :8082 chdir = /home/debian/django_tutorial/django_tutorial wsgi-file = wsgi.py processes = 4 threads = 2 Y después la unidad de systemd que controla la aplicación. Este fichero está en el directorio /etc/systemd/system/uwsgi-polls.service.\n[Unit] Description=uwsgi-polls After=network.target [Install] WantedBy=multi-user.target [Service] User=debian Group=debian Restart=always ExecStart=/home/debian/venv/django/bin/uwsgi /home/debian/venv/django/polls.ini ExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s TERM $MAINPID WorkingDirectory=/home/debian/django_tutorial Environment=PYTHONPATH=\u0026#39;/home/debian/django_tutorial:/home/debian/venv/django/lib/python3.11/site-packages\u0026#39; PrivateTmp=true Finalmente, se habilita y se arranca el servicio.\n(django) debian@pignite:/etc/systemd/system$ cd (django) debian@pignite:~$ sudo systemctl enable uwsgi-polls.service Created symlink /etc/systemd/system/multi-user.target.wants/uwsgi-polls.service → /etc/systemd/system/uwsgi-polls.service. (django) debian@pignite:~$ sudo systemctl start uwsgi-polls.service (django) debian@pignite:~$ sudo systemctl status uwsgi-polls.service ● uwsgi-polls.service - uwsgi-polls Loaded: loaded (/etc/systemd/system/uwsgi-polls.service; enabled; preset: \u0026gt; Active: active (running) since Wed 2024-11-27 07:23:11 UTC; 6s ago Main PID: 520689 (uwsgi) Tasks: 9 (limit: 2291) Memory: 23.6M CPU: 88ms CGroup: /system.slice/uwsgi-polls.service ├─520689 /home/debian/venv/django/bin/uwsgi /home/debian/venv/djan\u0026gt; ├─520690 /home/debian/venv/django/bin/uwsgi /home/debian/venv/djan\u0026gt; ├─520691 /home/debian/venv/django/bin/uwsgi /home/debian/venv/djan\u0026gt; ├─520692 /home/debian/venv/django/bin/uwsgi /home/debian/venv/djan\u0026gt; └─520693 /home/debian/venv/django/bin/uwsgi /home/debian/venv/djan\u0026gt; Configuración de Nginx como proxy inverso Para que Nginx dirija el tráfico al servidor de aplicaciones uwsgi se crea un VirtualHost con la siguiente configuración:\nserver { listen 443 ssl; server_name python.javihuete.site; ssl_certificate /etc/letsencrypt/live/javihuete.site/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/javihuete.site/privkey.pem; ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers HIGH:!aNULL:!MD5; root /home/debian/django_tutorial; location / { proxy_pass http://localhost:8082; }\tlocation /static/ { alias /home/debian/django_tutorial/static/; } error_log /var/log/nginx/python_error.log; access_log /var/log/nginx/python_access.log; } Para habilitarlo se crea un enlace simbólico en el directorio sites-enabled.\nsudo ln -s ../sites-available/python El VirtualHost debe contener la directiva location que establezca un alias desde la ruta /static/ a la ruta en la que se encuentra el contenido estático en el directorio django_tutorial.\nlocation /static/ { alias /home/debian/django_tutorial/static/; } Para evitar que se muestre información sensible de la aplicación en caso de error, en el entorno de producción el valor DEBUG en el fichero settings.py se debe cambiar a False.\n# SECURITY WARNING: don\u0026#39;t run with debug turned on in production! DEBUG = False Modificaciones en la aplicación Modificación de la página principal Para modificar el contenido de la página principal se añade una línea en el fichero index.html, que está en django_tutorial/polls/templates/polls/index.html.\nEn ese caso, se añade la línea\n\u0026lt;h2\u0026gt;Práctica de Implantación de Javi Huete\u0026lt;/h2\u0026gt; Para desplegar este cambio en producción desde el entorno de desarrollo se actualiza el repositorio de la aplicación en GitHub.\ngit commit -am \u0026#34;Modificada la página inicial de la aplicación\u0026#34; git push Y se sincronizan los cambios en el repositorio del servidor en producción.\ndebian@pignite:~/django_tutorial$ git pull Actualizando 16c8380..0d693ff Fast-forward .gitignore | 1 + polls/templates/index.html | 2 +- 3 files changed, 3 insertions(+), 1 deletion(-) Modificación de la imagen de fondo de la aplicación La imagen de fondo está en la ruta django_tutorial/static/polls/images/background.jpg. Para modificarla se copia una nueva imagen a este directorio y se le pone ese mismo nombre.\nPara llevar esta modificación al entorno de producción, como en el caso anterior, se actualiza el repositorio en GitHub.\ndebian@implantacion ❯ git add . debian@implantacion ❯ git commit -am \u0026#34;Añadida una nueva imagen para el fondo de la aplicación\u0026#34; [master 08ea1fe] Añadida una nueva imagen para el fondo de la aplicación 2 files changed, 0 insertions(+), 0 deletions(-) create mode 100644 static/polls/images/background.jpg.old debian@implantacion ❯ git push Enumerando objetos: 11, listo. Contando objetos: 100% (11/11), listo. Comprimiendo objetos: 100% (6/6), listo. Escribiendo objetos: 100% (6/6), 3.31 KiB | 3.31 MiB/s, listo. Total 6 (delta 1), reusados 0 (delta 0), pack-reusados 0 remote: Resolving deltas: 100% (1/1), completed with 1 local object. To github.com:fjhuete/django_tutorial.git 97a0a07..08ea1fe master -\u0026gt; master Y desde el VPS se sincroniza con el repositorio remoto.\n(django) debian@pignite:~/django_tutorial$ git pull remote: Enumerating objects: 11, done. remote: Counting objects: 100% (11/11), done. remote: Compressing objects: 100% (5/5), done. remote: Total 6 (delta 1), reused 6 (delta 1), pack-reused 0 (from 0) Desempaquetando objetos: 100% (6/6), 3.29 KiB | 1.65 MiB/s, listo. Desde https://github.com/fjhuete/django_tutorial 97a0a07..08ea1fe master -\u0026gt; origin/master Actualizando 97a0a07..08ea1fe Fast-forward static/polls/images/background.jpg | Bin 46418 -\u0026gt; 2879 bytes static/polls/images/background.jpg.old | Bin 0 -\u0026gt; 46418 bytes 2 files changed, 0 insertions(+), 0 deletions(-) create mode 100644 static/polls/images/background.jpg.old Creación de una nueva tabla en la base de datos Para crear una nueva tabla en la base de datos de la aplicación hay que modificar el modelo. Este modelo se encuentra definido en el fichero django_tutorial/polls/models.py.\nPara añadir una nueva tabla a la base de datos hay que crear en el modelo una nueva clase.\nclass Categoria(models.Model): Abr = models.CharField(max_length=4) Nombre = models.CharField(max_length=50) def __str__(self): return self.Abr+\u0026#34; - \u0026#34;+self.Nombre Para aplicar este cambio a la base de datos del entorno de desarrollo se debe crear una nueva migración y, después, aplicarla.\ndebian@implantacion ❯ python3 manage.py makemigrations Migrations for \u0026#39;polls\u0026#39;: polls/migrations/0002_categoria.py - Create model Categoria debian@implantacion ❯ python3 manage.py migrate Operations to perform: Apply all migrations: admin, auth, contenttypes, polls, sessions Running migrations: Applying polls.0002_categoria... OK En este punto la base de datos debe contar ya con la nueva tabla pero para poder gestionarla desde el administrador gráfico de django es necesario seguir un par de pasos más para añadir el nuevo modelo a la página de administración. Primero en el fichero polls/admin.py hay que importar la nueva clase Categoria junto a las anteriores (Choice y Question).\nfrom .models import Choice, Question, Categoria Y, al final de este fichero, tras a la línea admin.site.register(Question, QuestionAdmin) se añade la línea admin.site.register(Categoria).\nInfo\nPara que esta modificación sea efectiva en el entorno de produción (que usa el módulo wsgi de Apache2 para ejectuar el código python de la aplicación) el repositorio debe ser propiedad del usuario www-data para que la aplicación pueda acceder a la base de datos. En el caso del entorno de producción (que usa el servidor de aplicaciones uwsgi y un servidor web Nginx) el repositorio puede ser propoiedad de otro usuario.\nDe nuevo, para aplicar esta modificación a la aplicación en producción se actualiza el repositorio en GitHub.\ndebian@implantacion ❯ git add . debian@implantacion ❯ git commit -am \u0026#34;Modificación para añadir una nueva tabla a la aplicación\u0026#34; [master d7da468] Modificación para añadir una nueva tabla a la aplicación 3 files changed, 30 insertions(+), 1 deletion(-) create mode 100644 polls/migrations/0002_categoria.py debian@implantacion ❯ git push Enumerando objetos: 12, listo. Contando objetos: 100% (12/12), listo. Comprimiendo objetos: 100% (7/7), listo. Escribiendo objetos: 100% (7/7), 1020 bytes | 1020.00 KiB/s, listo. Total 7 (delta 4), reusados 0 (delta 0), pack-reusados 0 remote: Resolving deltas: 100% (4/4), completed with 4 local objects. To github.com:fjhuete/django_tutorial.git 08ea1fe..d7da468 master -\u0026gt; master Y desde el servidor en producción se sincroniza el directorio de la aplicación con el nuevo contenido del repositorio.\n(django) debian@pignite:~/django_tutorial$ git pull remote: Enumerating objects: 12, done. remote: Counting objects: 100% (12/12), done. remote: Compressing objects: 100% (3/3), done. remote: Total 7 (delta 4), reused 7 (delta 4), pack-reused 0 (from 0) Desempaquetando objetos: 100% (7/7), 1000 bytes | 333.00 KiB/s, listo. Desde https://github.com/fjhuete/django_tutorial 08ea1fe..d7da468 master -\u0026gt; origin/master Actualizando 08ea1fe..d7da468 Fast-forward polls/admin.py | 3 ++- polls/migrations/0002_categoria.py | 21 +++++++++++++++++++++ polls/models.py | 7 +++++++ 3 files changed, 30 insertions(+), 1 deletion(-) create mode 100644 polls/migrations/0002_categoria.py En este caso, la modificación realizada en el entorno de desarrollo implica un cambio en la estructura de la base de datos. Para replicarlo en el servidor en producción hay que usar el comando migrate de django.\n(django) debian@pignite:~/django_tutorial$ python3 manage.py migrate Operations to perform: Apply all migrations: admin, auth, contenttypes, polls, sessions Running migrations: Applying polls.0002_categoria... OK Tras aplicar todos estos cambios se reinicia el servidor de aplicaciones uwsgi.\nsudo systemctl restart uwsgi-polls.service Y el cambio ya es también efectivo en el servidor en producción.\n"},{
  "section": "Blog",
  "slug": "/blog/implantacion-aplicaciones-web/2024-11-18-migracion-aplicaciones-php/",
  "title": "Migración de aplicaciones web PHP al entorno de producción",
  "description": "",
  "date": "November 18, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "implantacion",
  "tags": "Migración de aplicaciones, entorno de producción, Apache2, Nginx, servidor web, LEMP, LAMP, implantacion, Implantación de Aplicaciones Web",
  "content":"Este supuesto parte de un servidor Apache2 en un entorno de pruebas con dos aplicaciones PHP instaladas: Moodle y NextCloud. En este post se document la migración de estas aplicaciones a un servidor Nginx en producción.\nInstalación del servidor LEMP y de las dependencias de los CMS: En primer lugar se tienen que instalar en el VPS los paquetes necesarios para configurar el servidor LEMP: nginx, mariadb-server y php.\nAdemás, se instalan otros paquetes que corresponden a las dependencias necesarias para poder instalar en el servidor los CMS de Moodle y NextCloud.\nsudo apt install php php-curl php-cli php-mysql php-gd php-gmp libmagickcore-dev php-redis php-memcached php-common php-xml php-json php-intl php-pear php-dev php-common php-mbstring php-zip php-soap php-bz2 php-bcmath php-imagick nginx mariadb-server -y Creación de los hosts virtuales en el VPS A continuación, se crean los hosts virtuales en el servidor web. En nginx esta configuración se guarda en un fichero con el nombre del virtual host en el directorio /etc/nginx/sites-available. En este fichero se indica el nombre del servidor para cada virtual host, el document root pero también es importante incluir en la lista de documentos de index que el servidor debe buscar el documento index.php que usan los CMS que se están instalando en este caso.\nEl siguiente documento corresponde al virtual host de Moodle:\ndebian@pignite:/etc/nginx/sites-available$ cat moodle # Virtual Host configuration for www.javihuete.site # # You can move that to a different file under sites-available/ and symlink that # to sites-enabled/ to enable it. # server { listen 80; listen [::]:80; server_name www.javihuete.site; root /var/www/moodle; index index.php index.html index.htm index.nginx-debian.html; location / { try_files $uri $uri/ =404; } # pass PHP scripts to FastCGI server # location ~ \\.php$ { #\tinclude snippets/fastcgi-php.conf; # # With php-fpm (or other unix sockets): fastcgi_pass unix:/run/php/php8.2-fpm.sock; #\t# With php-cgi (or other tcp sockets): #\tfastcgi_pass 127.0.0.1:9000; } } Y este documento configura el virtual host de NextCloud:\ndebian@pignite:/etc/nginx/sites-available$ cat nextcloud # Virtual Host configuration for cloud.javihuete.site # # You can move that to a different file under sites-available/ and symlink that # to sites-enabled/ to enable it. # server { listen 80; listen [::]:80; server_name cloud.javihuete.site; root /var/www/nextcloud; index index.php index.html index.htm index.nginx-debian.html; location / { try_files $uri $uri/ =404; } # pass PHP scripts to FastCGI server # location ~ \\.php$ { include snippets/fastcgi-php.conf; # # With php-fpm (or other unix sockets): fastcgi_pass unix:/run/php/php8.2-fpm.sock; # # With php-cgi (or other tcp sockets): # fastcgi_pass 127.0.0.1:9000; } } En nginx no existe un comando que ponga los virtual host en producción como el comando a2ensite de apache. Para hacerlo, en este caso hay que crear un enlace simbólico al fichero de configuración en el directorio /etc/nginx/sites-enabled de forma manual.\ndebian@pignite:/etc/nginx/sites-enabled$ sudo ln ../sites-available/moodle debian@pignite:/etc/nginx/sites-enabled$ sudo ln ../sites-available/nextcloud Compresión de los ficheros de los document root, copia al VPS y descompresión de los ficheros y creación del document root Para trasladar los contenidos del document root de cada uno de los CMS al VPS, es necesario comprimir los directorios en el servidor de pruebas y copiar el archivo comprimido al VPS.\ndebian@apache2:/var/www$ zip -r moodle moodle debian@apache2:/var/www$ zip -r nextcloud nextcloud debian@apache2:/var/www$ scp moodle.zip debian@pignite.javihuete.site:/home/debian debian@apache2:/var/www$ scp nextcloud.zip debian@pignite.javihuete.site:/home/debian Después, el contenido del archivo comprimido se extrae y se copia en el document root correspondiente del VPS.\ndebian@pignite:~$ sudo cp moodle.zip /var/www/ debian@pignite:/var/www$ sudo unzip moodle.zip debian@pignite:~$ sudo cp nextcloud.zip /var/www/ debian@pignite:/var/www$ sudo unzip nextcloud.zip Creación de la base de datos en el VPS Para que cada CMS pueda acceder a su base de datos correspondiente, se crea una base de datos para cada uno con su correspondiente usuario y contraseña.\nMariaDB [(none)]\u0026gt; create database moodle -\u0026gt; ; Query OK, 1 row affected (0,001 sec) MariaDB [(none)]\u0026gt; create user \u0026#39;moodle\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;contraseña\u0026#39;; Query OK, 0 rows affected (0,001 sec) MariaDB [(none)]\u0026gt; grant all privileges on moodle.* to \u0026#39;moodle\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;contraseña\u0026#39;; Query OK, 0 rows affected (0,001 sec) MariaDB [(none)]\u0026gt; flush privileges; Query OK, 0 rows affected (0,001 sec) MariaDB [(none)]\u0026gt; create database nextcloud; Query OK, 1 row affected (0,001 sec) MariaDB [(none)]\u0026gt; create user \u0026#39;nextcloud\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;contraseña\u0026#39;; Query OK, 0 rows affected (0,002 sec) MariaDB [(none)]\u0026gt; grant all privileges on nextcloud.* to \u0026#39;nextcloud\u0026#39;@\u0026#39;localhost\u0026#39; identified by \u0026#39;contraseña\u0026#39;; Query OK, 0 rows affected (0,001 sec) MariaDB [(none)]\u0026gt; flush privileges; Query OK, 0 rows affected (0,001 sec) Realización del backup de la base de datos y copia al VPS Para dar contenido a la base de datos creada previamente se crea un copia de la base de datos que está funcionando en el servidor de pruebas y se copia el fichero de respaldo al servidor VPS.\ndebian@mysql:~$ mysqldump -u moodle -p moodle \u0026gt; moodle.sql debian@mysql:~$ scp moodle.sql debian@pignite.javihuete.site:/home/debian moodle.sql 100% 1685KB 3.8MB/s 00:00 debian@mysql:~$ mysqldump -u cloud -p nextcloud \u0026gt; nextcloud.sql Enter password: debian@mysql:~$ scp nextcloud.sql debian@pignite.javihuete.site:/home/debian nextcloud.sql 100% 3455KB 4.5MB/s 00:00 En el VPS se rellenan las tablas de cada una de las bases de datos a partir del contenido del fichero de respaldo generado en el servidor local.\ndebian@pignite:~$ mysql -u moodle -p moodle \u0026lt; moodle.sql Enter password: debian@pignite:~$ mysql -u nextcloud -p nextcloud \u0026lt; nextcloud.sql Enter password: Modificación de las credenciales en el fichero de configuración del CMS Para que los CMS puedan acceder a la base de datos hay que modificar los ficheros de configuración en los que se hace referencia a la ubicación de la base de datos a la que debe acceder el CMS. En el servidor local, la base de datos estaba en un servidor diferente al servidor web y, por tanto, este dato era la dirección IP del servidor de base de datos. Al pasar al VPS, la base de datos y el servidor web están en el mismo equipo y, por tanto, este campo del fichero de configuración tiene que apuntar al localhost. En estos ficheros de configuración también es necesario indicar correctamente el dominio del VPS, que es diferente al que se ha usado previamente en el servidor local de pruebas.\nEn Moodle el fichero de configuración está en /var/www/moodle/config.php.\ndebian@pignite:/var/www$ sudo nano moodle/config.php \u0026lt;?php // Moodle configuration file unset($CFG); global $CFG; $CFG = new stdClass(); $CFG-\u0026gt;dbtype = \u0026#39;mariadb\u0026#39;; $CFG-\u0026gt;dblibrary = \u0026#39;native\u0026#39;; $CFG-\u0026gt;dbhost = \u0026#39;localhost\u0026#39;; $CFG-\u0026gt;dbname = \u0026#39;moodle\u0026#39;; $CFG-\u0026gt;dbuser = \u0026#39;moodle\u0026#39;; $CFG-\u0026gt;dbpass = \u0026#39;contraseña\u0026#39;; $CFG-\u0026gt;prefix = \u0026#39;mdl_\u0026#39;; $CFG-\u0026gt;dboptions = array ( \u0026#39;dbpersist\u0026#39; =\u0026gt; 0, \u0026#39;dbport\u0026#39; =\u0026gt; 3306, \u0026#39;dbsocket\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;dbcollation\u0026#39; =\u0026gt; \u0026#39;utf8mb4_general_ci\u0026#39;, ); $CFG-\u0026gt;wwwroot = \u0026#39;http://www.javihuete.site\u0026#39;; $CFG-\u0026gt;dataroot = \u0026#39;/var/www/moodledata\u0026#39;; $CFG-\u0026gt;admin = \u0026#39;admin\u0026#39;; $CFG-\u0026gt;directorypermissions = 0777; require_once(__DIR__ . \u0026#39;/lib/setup.php\u0026#39;); Y en NextCloud el fichero de configuración está en /var/www/nextcloud/config/config.php\ndebian@pignite:/var/www$ sudo nano nextcloud/config/config.php \u0026lt;?php $CONFIG = array ( \u0026#39;instanceid\u0026#39; =\u0026gt; \u0026#39;editado\u0026#39;, \u0026#39;passwordsalt\u0026#39; =\u0026gt; \u0026#39;editado\u0026#39;, \u0026#39;secret\u0026#39; =\u0026gt; \u0026#39;editado\u0026#39;, \u0026#39;trusted_domains\u0026#39; =\u0026gt; array ( 0 =\u0026gt; \u0026#39;cloud.javihuete.site\u0026#39;, ), \u0026#39;datadirectory\u0026#39; =\u0026gt; \u0026#39;/var/www/nextcloud/data\u0026#39;, \u0026#39;dbtype\u0026#39; =\u0026gt; \u0026#39;mysql\u0026#39;, \u0026#39;version\u0026#39; =\u0026gt; \u0026#39;30.0.1.2\u0026#39;, \u0026#39;overwrite.cli.url\u0026#39; =\u0026gt; \u0026#39;http://cloud.javihuete.site\u0026#39;, \u0026#39;dbname\u0026#39; =\u0026gt; \u0026#39;nextcloud\u0026#39;, \u0026#39;dbhost\u0026#39; =\u0026gt; \u0026#39;localhost\u0026#39;, \u0026#39;dbport\u0026#39; =\u0026gt; \u0026#39;\u0026#39;, \u0026#39;dbtableprefix\u0026#39; =\u0026gt; \u0026#39;oc_\u0026#39;, \u0026#39;mysql.utf8mb4\u0026#39; =\u0026gt; true, \u0026#39;dbuser\u0026#39; =\u0026gt; \u0026#39;cloud\u0026#39;, \u0026#39;dbpassword\u0026#39; =\u0026gt; \u0026#39;contraseña\u0026#39;, \u0026#39;installed\u0026#39; =\u0026gt; true, ); En el caso de Moodle, también es necesario configurar el fichero /etc/php/8.2/fpm/php.ini para añadir la siguiente línea:\n; How many GET/POST/COOKIE input variables may be accepted max_input_vars = 5000 Registrar las nuevas entradas del DNS Finalmente, para que estos servicios sean accesibles desde el exterior, hay que añadir dos registros de tipo CNAME en el DNS que apunten a la máquina en la que están instalados los servidores.\nResolución de problemas En el caso de la instalación de Moodle al no contar con el módulo php de Apache se produce un problema al cargar el CSS de la aplicación. Esto se debe a que Moodle usa rutas amigables y nginx no está configurado por defecto para interpretar este tipo de url que, en el caso de Moodle, contienen ficheros .php en una parte intermedia de la ruta. Para solucionar el error hay que configurar la conexión con el servidor de aplicaciones en el virtual host de moodle de la siguiente forma:\nlocation ~ [^/]\\.php(/|$) { include fastcgi_params; fastcgi_split_path_info ^(.+\\.php)(/.*)$; fastcgi_pass unix:/var/run/php/php7.4-fpm.sock; # Ajusta la versión de PHP si es diferente fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_param PATH_INFO $fastcgi_path_info; } La línea fastcgi_split_path_info ^(.+\\.php)(/.*)$; es la que permite que Nginx interprete estas rutas que incluyen una referencia a un fichero .php en mitad de la URL y no sólo al final.\nPor su parte, en NextCloud se deben solucionar algunos errores como, por ejemplo, desactivar la opción \u0026ldquo;output_buffering\u0026rdquo; del fichero php.ini, agragar en el fichero de configuración del virtual host la configuración que permite a Nginx interpretar las rutas /.well-known o incluir también en este fichero las líneas que permiten al Nginx servir ficheros .mjs usando MIME.\nAdemás, NextCloud también verifica la integridad de todos los ficheros que conforman la aplicación. De esta manera, si durante la copia desde el servidor local al VPS se ha dejado de copiar algún fichero oculto como el .htaccess o el .user.ini o se ha añadido un nuevo fichero no verificado como el info.php, la aplicación muestra un error. Para resolverlo sólo hay que descargar la misma versión de NextCloud que esté instalada, buscar los ficheros que faltan y colocarlos en el directorio correspondiente. Si algún fichero no está firmado, también se tendrá que eliminar para evitar que se muestre este error.\n"},{
  "section": "Blog",
  "slug": "/blog/administracion-bases-de-datos/2024-11-16-interconexion-postgres/",
  "title": "Interconexión entre dos servidores Postgres",
  "description": "",
  "date": "November 17, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "administracion-bbdd",
  "tags": "bases de datos, PostgreSQL, interconexion de servidores, administracion-bbdd, Administración de Sistemas Gestores de Bases de Datos",
  "content":"Enlace entre dos servidores Postgres Configuración del acceso remoto al servidor Postgres En primer lugar es necesario contar con dos servidores diferentes y que en ambos esté instalado el SGBD Postgres. Además, es necesario configurar la conexión remota en ambos casos. Para ello se editan los ficheros de configuración /etc/postgresql/15/main/pg_hba.conf y /etc/postgresql/15/main/postgresql.conf y se añaden las siguientes líneas:\n#En el ficheero /etc/postgresql/15/main/postgresql.conf listen_addresses = \u0026#39;*\u0026#39; #En el fichero /etc/postgresql/15/main/pg_hba.conf host all all 10.0.0.0/24 scram-sha-256 host all all all scram-sha-256 Una vez que ambos servidores están configurados e instalados hay que crear los usuarios y las bases de datos en cada uno de ellos y añadirles contenido.\ndebian@postgres:~$ sudo su root@postgres:/home/debian# su postgres postgres@postgres:/home/debian$ psql postgres=# create user uno with password \u0026#39;uno\u0026#39;; CREATE ROLE postgres=# create database bd1; CREATE DATABASE postgres=# grant all privileges on database bd1 to uno; GRANT debian@postgres:~$ psql -W bd1 uno bd1=\u0026gt; create schema scott; CREATE SCHEMA bd1=\u0026gt; create table scott.dept ( deptno integer, dname text, loc text, constraint pk_dept primary key (deptno) ); CREATE TABLE bd1=\u0026gt; create table scott.emp ( empno integer, ename text, job text, mgr integer, hiredate date, sal integer, comm integer, deptno integer, constraint pk_emp primary key (empno), constraint fk_mgr foreign key (mgr) references scott.emp (empno), constraint fk_deptno foreign key (deptno) references scott.dept (deptno) ); CREATE TABLE bd1=\u0026gt; insert into scott.dept (deptno, dname, loc) values (10, \u0026#39;ACCOUNTING\u0026#39;, \u0026#39;NEW YORK\u0026#39;), (20, \u0026#39;RESEARCH\u0026#39;, \u0026#39;DALLAS\u0026#39;), (30, \u0026#39;SALES\u0026#39;, \u0026#39;CHICAGO\u0026#39;), (40, \u0026#39;OPERATIONS\u0026#39;, \u0026#39;BOSTON\u0026#39;); INSERT 0 4 bd1=\u0026gt; insert into scott.emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7369, \u0026#39;SMITH\u0026#39;, \u0026#39;CLERK\u0026#39;, 7902, \u0026#39;1980-12-17\u0026#39;, 800, NULL, 20), (7499, \u0026#39;ALLEN\u0026#39;, \u0026#39;SALESMAN\u0026#39;, 7698, \u0026#39;1981-02-20\u0026#39;, 1600, 300, 30), (7521, \u0026#39;WARD\u0026#39;, \u0026#39;SALESMAN\u0026#39;, 7698, \u0026#39;1981-02-22\u0026#39;, 1250, 500, 30), (7566, \u0026#39;JONES\u0026#39;, \u0026#39;MANAGER\u0026#39;, 7839, \u0026#39;1981-04-02\u0026#39;, 2975, NULL, 20), (7654, \u0026#39;MARTIN\u0026#39;, \u0026#39;SALESMAN\u0026#39;, 7698, \u0026#39;1981-09-28\u0026#39;, 1250, 1400, 30), (7698, \u0026#39;BLAKE\u0026#39;, \u0026#39;MANAGER\u0026#39;, 7839, \u0026#39;1981-05-01\u0026#39;, 2850, NULL, 30), (7782, \u0026#39;CLARK\u0026#39;, \u0026#39;MANAGER\u0026#39;, 7839, \u0026#39;1981-06-09\u0026#39;, 2450, NULL, 10), (7788, \u0026#39;SCOTT\u0026#39;, \u0026#39;ANALYST\u0026#39;, 7566, \u0026#39;1982-12-09\u0026#39;, 3000, NULL, 20), (7839, \u0026#39;KING\u0026#39;, \u0026#39;PRESIDENT\u0026#39;, NULL, \u0026#39;1981-11-17\u0026#39;, 5000, NULL, 10), (7844, \u0026#39;TURNER\u0026#39;, \u0026#39;SALESMAN\u0026#39;, 7698, \u0026#39;1981-09-08\u0026#39;, 1500, 0, 30), (7934, \u0026#39;MILLER\u0026#39;, \u0026#39;CLERK\u0026#39;, 7782, \u0026#39;1982-01-23\u0026#39;, 1300, NULL, 10); commit; INSERT 0 14 WARNING: there is no transaction in progress COMMIT debian@postgres2:~$ sudo su root@postgres2:/home/debian# su postgres postgres@postgres2:/home/debian$ psql postgres=# create user dos with password \u0026#39;dos\u0026#39;; CREATE ROLE postgres=# create database bd2; CREATE DATABASE postgres=# grant all privileges on database bd2 to dos; GRANT debian@postgres2:~$ psql -W bd2 dos bd2=\u0026gt; create schema scott; CREATE SCHEMA bd2=\u0026gt; create table scott.dept ( deptno integer, dname text, loc text, constraint pk_dept primary key (deptno) ); CREATE TABLE bd2=\u0026gt; create table scott.emp ( empno integer, ename text, job text, mgr integer, hiredate date, sal integer, comm integer, deptno integer, constraint pk_emp primary key (empno), constraint fk_mgr foreign key (mgr) references scott.emp (empno), constraint fk_deptno foreign key (deptno) references scott.dept (deptno) ); CREATE TABLE bd2=\u0026gt; insert into scott.dept (deptno, dname, loc) values (10, \u0026#39;ACCOUNTING\u0026#39;, \u0026#39;NEW YORK\u0026#39;), (20, \u0026#39;RESEARCH\u0026#39;, \u0026#39;DALLAS\u0026#39;), (30, \u0026#39;SALES\u0026#39;, \u0026#39;CHICAGO\u0026#39;), (40, \u0026#39;OPERATIONS\u0026#39;, \u0026#39;BOSTON\u0026#39;); INSERT 0 4 bd2=\u0026gt; insert into scott.emp (empno, ename, job, mgr, hiredate, sal, comm, deptno) values (7369, \u0026#39;SMITH\u0026#39;, \u0026#39;CLERK\u0026#39;, 7902, \u0026#39;1980-12-17\u0026#39;, 800, NULL, 20), (7499, \u0026#39;ALLEN\u0026#39;, \u0026#39;SALESMAN\u0026#39;, 7698, \u0026#39;1981-02-20\u0026#39;, 1600, 300, 30), (7521, \u0026#39;WARD\u0026#39;, \u0026#39;SALESMAN\u0026#39;, 7698, \u0026#39;1981-02-22\u0026#39;, 1250, 500, 30), (7566, \u0026#39;JONES\u0026#39;, \u0026#39;MANAGER\u0026#39;, 7839, \u0026#39;1981-04-02\u0026#39;, 2975, NULL, 20), (7654, \u0026#39;MARTIN\u0026#39;, \u0026#39;SALESMAN\u0026#39;, 7698, \u0026#39;1981-09-28\u0026#39;, 1250, 1400, 30), (7698, \u0026#39;BLAKE\u0026#39;, \u0026#39;MANAGER\u0026#39;, 7839, \u0026#39;1981-05-01\u0026#39;, 2850, NULL, 30), (7782, \u0026#39;CLARK\u0026#39;, \u0026#39;MANAGER\u0026#39;, 7839, \u0026#39;1981-06-09\u0026#39;, 2450, NULL, 10), (7788, \u0026#39;SCOTT\u0026#39;, \u0026#39;ANALYST\u0026#39;, 7566, \u0026#39;1982-12-09\u0026#39;, 3000, NULL, 20), (7839, \u0026#39;KING\u0026#39;, \u0026#39;PRESIDENT\u0026#39;, NULL, \u0026#39;1981-11-17\u0026#39;, 5000, NULL, 10), (7844, \u0026#39;TURNER\u0026#39;, \u0026#39;SALESMAN\u0026#39;, 7698, \u0026#39;1981-09-08\u0026#39;, 1500, 0, 30), (7934, \u0026#39;MILLER\u0026#39;, \u0026#39;CLERK\u0026#39;, 7782, \u0026#39;1982-01-23\u0026#39;, 1300, NULL, 10); commit; INSERT 0 14 WARNING: there is no transaction in progress COMMIT Configuración de la interconexión entre servidores Postgres Para permitir la interconexión entre ambos servidores es necesario crear un enlace con la orden create extension dblink;\nbd1=# create extension dblink schema scott; CREATE EXTENSION bd2=# create extension dblink schema scott; CREATE EXTENSION Una vez que se ha habilitado el enlace en ambas bases de datos se puede acceder desde un servidor al otro para consultar la información almacenada en él.\nbd1=\u0026gt; select * from dblink(\u0026#39;dbname=bd2 host=10.0.0.47 user=dos password=dos\u0026#39;,\u0026#39;select * from scott.dept\u0026#39;) as dept (deptno integer, dname text, loc text); Pero la búsqueda devuelve el siguiente error:\nERROR: function dblink(unknown, unknown) does not exist Para solucionarlo se ejecuta esta orden:\nset search_path to scott; Al repetir la consulta, se obtiene el resultado.\nbd1=\u0026gt; select * from dblink(\u0026#39;dbname=bd2 host=10.0.0.47 user=dos password=dos\u0026#39;,\u0026#39;select * from scott.dept\u0026#39;) as dept (deptno integer, dname text, loc text); deptno | dname | loc --------+------------+---------- 10 | ACCOUNTING | NEW YORK 20 | RESEARCH | DALLAS 30 | SALES | CHICAGO 40 | OPERATIONS | BOSTON (4 rows) De la misma forma, si se ejecuta la misma consulta en el servidor 2, se puede recuperar esta información del servidor 1.\nbd2=\u0026gt; set search_path to scott; SET bd2=\u0026gt; select * from dblink(\u0026#39;dbname=bd1 host=10.0.0.134 user=uno password=uno\u0026#39;,\u0026#39;select * from scott.dept\u0026#39;) as dept (deptno integer, dname text, loc text); deptno | dname | loc --------+------------+---------- 10 | ACCOUNTING | NEW YORK 20 | RESEARCH | DALLAS 30 | SALES | CHICAGO 40 | OPERATIONS | BOSTON (4 rows) "},{
  "section": "Blog",
  "slug": "/blog/administracion-bases-de-datos/2024-11-16-interconexion-oracle/",
  "title": "Interconexión entre dos servidores Oracle",
  "description": "",
  "date": "November 16, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "administracion-bbdd",
  "tags": "bases de datos, oracle, interconexion de servidores, administracion-bbdd, Administración de Sistemas Gestores de Bases de Datos",
  "content":"Enlace entre dos servidores Oracle Configuración de acceso remoto al servidor Antes de configurar la conexión entre dos servidores Oracle es necesario garantizar que es posible conectarse de forma remota desde un cliente a cada uno de ellos. Para permitir este tipo de conexiones hay un fichero que es imprescindible configurar: el fichero listener.ora.\nEste fichero se encuentra en el directorio /opt/oracle/homes/OraDBHome21cEE/network/admin/listener.ora y contiene la información de la interfaz y el puerto por el que escucha el servidor. En el caso del servidor 1, el contenido de este fichero es el siguiente:\nLISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = oracleserver)(PORT = 1521)) (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521)) ) ) SID_LIST_LISTENER= (SID_LIST= (SID_DESC= (GLOBAL_DBNAME=ORCLCDB) (ORACLE_HOME=/opt/oracle/product/21c/dbhome_1) (SID_NAME=ORCLCDB)) ) Para poder indicar en el host el nombre del servidor en lugar de su dirección IP es necesario también añadir el el fichero /etc/hosts una línea en la que se asocien ambos datos.\n127.0.0.1\tlocalhost 127.0.1.1\toracleserver ::1\tlocalhost ip6-localhost ip6-loopback ff02::1\tip6-allnodes ff02::2\tip6-allrouters 10.0.0.179\toracleserver Con esta configuración, ya es posible conectarse desde un cliente remoto.\ndebian@oracle2:~$ sqlplus usuario/usuario@//10.0.0.179:1521/ORCLCDB SQL*Plus: Release 12.2.0.1.0 Production on Sun Oct 20 11:06:40 2024 Copyright (c) 1982, 2016, Oracle. All rights reserved. Hora de Ultima Conexion Correcta: Dom Oct 20 2024 11:06:24 +00:00 Conectado a: Oracle Database 21c Enterprise Edition Release 21.0.0.0.0 - Production SQL\u0026gt; Adicionalmente, si el en fichero tnsnames del cliente remoto se añade una configuración similar a esta, la cadena de conexión se hace más sencilla. Este fichero se encuentra en el directorio /opt/oracle/homes/OraDBHome21cEE/network/admin/tnsnames.ora (ver resolución de errores).\nORCLCDB= (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = 10.0.0.179)(PORT = 1521)) ) (CONNECT_DATA = (SERVICE_NAME = ORCLCDB) ) ) De esta manera, el cliente ya tiene acceso al servidor indicando, simplemente, el nombre del servicio configurado en el fichero tnsnames.ora.\ndebian@oracle2:~$ sqlplus usuario/usuario@ORCLCDB SQL*Plus: Release 12.2.0.1.0 Production on Sun Oct 20 11:24:29 2024 Copyright (c) 1982, 2016, Oracle. All rights reserved. Hora de Ultima Conexion Correcta: Dom Oct 20 2024 11:08:24 +00:00 Conectado a: Oracle Database 21c Enterprise Edition Release 21.0.0.0.0 - Production SQL\u0026gt; Configuración del segundo servidor Ahora que el primer servidor es accesible desde otro cliente de la red local, es momento de configurar el segundo servidor. Para facilitar el proceso de configuración previa a la instalación del servidor, se puede usar un script de configuración y posteriormente se puede instalar un paquete .deb convertido usando la herramienta alien a partir del paquete .rpm que distribuye Oracle.\ndebian@oracle2:~$ sudo dpkg -i oracle-database-ee-21c_1.0-2_amd64.deb (Leyendo la base de datos ... 27566 ficheros o directorios instalados actualmente.) Preparando para desempaquetar oracle-database-ee-21c_1.0-2_amd64.deb ... ln: fallo al crear el enlace simbólico \u0026#39;/bin/awk\u0026#39;: El fichero ya existe Desempaquetando oracle-database-ee-21c (1.0-2) ... Configurando oracle-database-ee-21c (1.0-2) ... [INFO] Executing post installation scripts... [INFO] Oracle home installed successfully and ready to be configured. To configure a sample Oracle Database you can execute the following service configuration script as root: /etc/init.d/oracledb_ORCLCDB-21c configure Procesando disparadores para libc-bin (2.36-9+deb12u8) ... Antes de configurar el nuevo servicio se añaden al fichero .bashrc las variables necesarias para el funcionamiento de Oracle.\nexport ORACLE_HOME=/opt/oracle/product/21c/dbhome_1 export ORACLE_SID=ORCLCDB export ORACLE_BASE=/opt/oracle export LD_LIBRARY_PATH=$ORACLE_HOME/lib:$LD_LIBRARY_PATH export PATH=$ORACLE_HOME/bin:$PATH export NLS_LANG=SPANISH_SPAIN.UTF8 Y se ejecuta como root el script de configuración que indica el instalador de Oracle.\ndebian@oracle2:~$ sudo /etc/init.d/oracledb_ORCLCDB-21c configure Configuring Oracle Database ORCLCDB. Preparar para funcionamiento de base de datos 8% completado Copiando archivos de base de datos 31% completado Creando e iniciando instancia Oracle 32% completado 36% completado 40% completado 43% completado 46% completado Terminando creación de base de datos 51% completado 54% completado Creando Bases de Datos de Conexión 58% completado 77% completado Ejecutando acciones posteriores a la configuración 100% completado Creación de la base de datos terminada. Consulte los archivos log de /opt/oracle/cfgtoollogs/dbca/ORCLCDB para obtener más información. Información de Base de Datos: Nombre de la Base de Datos Global:ORCLCDB Identificador del Sistema (SID):ORCLCDB Para obtener información detallada, consulte el archivo log \u0026#34;/opt/oracle/cfgtoollogs/dbca/ORCLCDB/ORCLCDB.log\u0026#34;. Database configuration completed successfully. The passwords were auto generated, you must change them by connecting to the database using \u0026#39;sqlplus / as sysdba\u0026#39; as the oracle user. Para poder acceder a sqlplus con el usuario debian es necesario que esté incluido en el grupo dba.\nsudo usermod -a -G dba debian Configuración de la conexión entre servidores Como en el caso del otro servidor, para permitir la conexión remota desde otro equipo de la red también se debe configurar el fichero listener.ora. En el caso de este segundo servidor, su contenido es el siguiente:\nLISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = oracle2)(PORT = 1521)) (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521)) ) ) SID_LIST_LISTENER= (SID_LIST= (SID_DESC= (GLOBAL_DBNAME=ORCLCDB) (ORACLE_HOME=/opt/oracle/product/21c/dbhome_1) (SID_NAME=ORCLCDB)) ) Y para poder usar el hostname en el parámetro host, el fichero /etc/hosts tiene que recoger la IP a la que corresponde ese hostname.\n127.0.0.1\tlocalhost 127.0.1.1\toracle2 ::1\tlocalhost ip6-localhost ip6-loopback ff02::1\tip6-allnodes ff02::2\tip6-allrouters 10.0.0.26\toracle2 Tras realizar esta configuración en el servidor 2 ya se puede acceder a la base de datos recién creada desde el servidor 1.\ndebian@oracleserver:~$ sqlplus dos/dos@//10.0.0.26:1521/ORCLCDB SQL*Plus: Release 21.0.0.0.0 - Production on Dom Oct 20 12:11:00 2024 Version 21.3.0.0.0 Copyright (c) 1982, 2021, Oracle. All rights reserved. Hora de Última Conexión Correcta: Dom Oct 20 2024 12:10:38 +00:00 Conectado a: Oracle Database 21c Enterprise Edition Release 21.0.0.0.0 - Production Version 21.3.0.0.0 SQL\u0026gt; Demostración del funcionamiento de la interconexión entre servidores Oracle Para demostrar el funcionamiento de la interconexión entre servidores se usa, en este caso, el esquema Scott. En el servidor 1 se crea y rellena la tabla de departamentos.\nSQL\u0026gt; connect uno/uno Conectado. SQL\u0026gt; CREATE TABLE DEPT 2 ( 3 DEPTNO NUMBER(2), 4 DNAME VARCHAR2(14), 5 LOC VARCHAR2(13), 6 CONSTRAINT PK_DEPT PRIMARY KEY (DEPTNO) 7 ); Tabla creada. SQL\u0026gt; INSERT INTO DEPT VALUES (10, \u0026#39;ACCOUNTING\u0026#39;, \u0026#39;NEW YORK\u0026#39;); INSERT INTO DEPT VALUES (20, \u0026#39;RESEARCH\u0026#39;, \u0026#39;DALLAS\u0026#39;); INSERT INTO DEPT VALUES (30, \u0026#39;SALES\u0026#39;, \u0026#39;CHICAGO\u0026#39;); 1 fila creada. SQL\u0026gt; 1 fila creada. SQL\u0026gt; 1 fila creada. SQL\u0026gt; INSERT INTO DEPT VALUES (40, \u0026#39;OPERATIONS\u0026#39;, \u0026#39;BOSTON\u0026#39;); 1 fila creada. En el servidor 2 se crea y rellena la tabla de empleados.\nSQL\u0026gt; connect dos/dos Conectado. SQL\u0026gt; CREATE TABLE EMP 2 ( 3 EMPNO NUMBER(4), 4 ENAME VARCHAR2(10), 5 JOB VARCHAR2(9), 6 MGR NUMBER(4), 7 HIREDATE DATE, 8 SAL NUMBER(7, 2), 9 COMM NUMBER(7, 2), 10 DEPTNO NUMBER(2), 11 CONSTRAINT PK_EMP PRIMARY KEY (EMPNO) 12 ); Tabla creada. SQL\u0026gt; INSERT INTO EMP VALUES(7369, \u0026#39;SMITH\u0026#39;, \u0026#39;CLERK\u0026#39;, 7902,TO_DATE(\u0026#39;17-DIC-1980\u0026#39;, \u0026#39;DD-MON-YYYY\u0026#39;), 800, NULL, 20); INSERT INTO EMP VALUES(7369, \u0026#39;SMITH\u0026#39;, \u0026#39;CLERK\u0026#39;, 7902,TO_DATE(\u0026#39;17-DIC-1980\u0026#39;, \u0026#39;DD-MON-YYYY\u0026#39;), 800, NULL, 20); INSERT INTO EMP VALUES(7499, \u0026#39;ALLEN\u0026#39;, \u0026#39;SALESMAN\u0026#39;, 7698,TO_DATE(\u0026#39;20-FEB-1981\u0026#39;, \u0026#39;DD-MON-YYYY\u0026#39;), 1600, 300, 30); INSERT INTO EMP VALUES(7521, \u0026#39;WARD\u0026#39;, \u0026#39;SALESMAN\u0026#39;, 7698,TO_DATE(\u0026#39;22-FEB-1981\u0026#39;, \u0026#39;DD-MON-YYYY\u0026#39;), 1250, 500, 30); INSERT INTO EMP VALUES(7566, \u0026#39;JONES\u0026#39;, \u0026#39;MANAGER\u0026#39;, 7839,TO_DATE(\u0026#39;2-ABR-1981\u0026#39;, \u0026#39;DD-MON-YYYY\u0026#39;), 2975, NULL, 20); 1 fila creada. SQL\u0026gt; 1 fila creada. SQL\u0026gt; 1 fila creada. SQL\u0026gt; 1 fila creada. SQL\u0026gt; INSERT INTO EMP VALUES(7654, \u0026#39;MARTIN\u0026#39;, \u0026#39;SALESMAN\u0026#39;, 7698,TO_DATE(\u0026#39;28-SEP-1981\u0026#39;, \u0026#39;DD-MON-YYYY\u0026#39;), 1250, 1400, 30); 1 fila creada. SQL\u0026gt; INSERT INTO EMP VALUES(7698, \u0026#39;BLAKE\u0026#39;, \u0026#39;MANAGER\u0026#39;, 7839,TO_DATE(\u0026#39;1-MAY-1981\u0026#39;, \u0026#39;DD-MON-YYYY\u0026#39;), 2850, NULL, 30); 1 fila creada. SQL\u0026gt; INSERT INTO EMP VALUES(7782, \u0026#39;CLARK\u0026#39;, \u0026#39;MANAGER\u0026#39;, 7839,TO_DATE(\u0026#39;9-JUN-1981\u0026#39;, \u0026#39;DD-MON-YYYY\u0026#39;), 2450, NULL, 10); 1 fila creada. SQL\u0026gt; INSERT INTO EMP VALUES(7788, \u0026#39;SCOTT\u0026#39;, \u0026#39;ANALYST\u0026#39;, 7566,TO_DATE(\u0026#39;09-DIC-1982\u0026#39;, \u0026#39;DD-MON-YYYY\u0026#39;), 3000, NULL, 20); 1 fila creada. SQL\u0026gt; INSERT INTO EMP VALUES(7839, \u0026#39;KING\u0026#39;, \u0026#39;PRESIDENT\u0026#39;, NULL,TO_DATE(\u0026#39;17-NOV-1981\u0026#39;, \u0026#39;DD-MON-YYYY\u0026#39;), 5000, NULL, 10); 1 fila creada. SQL\u0026gt; INSERT INTO EMP VALUES(7844, \u0026#39;TURNER\u0026#39;, \u0026#39;SALESMAN\u0026#39;, 7698,TO_DATE(\u0026#39;8-SEP-1981\u0026#39;, \u0026#39;DD-MON-YYYY\u0026#39;), 1500, 0, 30); 1 fila creada. SQL\u0026gt; INSERT INTO EMP VALUES(7876, \u0026#39;ADAMS\u0026#39;, \u0026#39;CLERK\u0026#39;, 7788,TO_DATE(\u0026#39;12-ENE-1983\u0026#39;, \u0026#39;DD-MON-YYYY\u0026#39;), 1100, NULL, 20); 1 fila creada. SQL\u0026gt; INSERT INTO EMP VALUES(7900, \u0026#39;JAMES\u0026#39;, \u0026#39;CLERK\u0026#39;, 7698,TO_DATE(\u0026#39;3-DIC-1981\u0026#39;, \u0026#39;DD-MON-YYYY\u0026#39;), 950, NULL, 30); 1 fila creada. SQL\u0026gt; INSERT INTO EMP VALUES(7902, \u0026#39;FORD\u0026#39;, \u0026#39;ANALYST\u0026#39;, 7566,TO_DATE(\u0026#39;3-DIC-1981\u0026#39;, \u0026#39;DD-MON-YYYY\u0026#39;), 3000, NULL, 20); 1 fila creada. Desde alguno de los dos servidores se crea la interconexión al otro.\nSQL\u0026gt; create database link empleados 2 connect to dos 3 identified by dos 4 using \u0026#39;ORCL2\u0026#39;; Enlace con la base de datos creado. Tras establecer esta configuración para la interconexión entre los servidores de bases de datos de Oracle aparece este error al intentar consultar la tabla de un servidor desde el otro.\nSQL\u0026gt; SELECT ename from emp@empleados; SELECT ename from emp@empleados * ERROR en línea 1: ORA-12504: TNS:el listener no ha recibido el SERVICE_NAME en CONNECT_DATA La interconexión también se puede crear haciendo referencia a la IP del servidor.\nSQL\u0026gt; create database link empleados connect to dos identified by dos using \u0026#39;//10.0.0.26:1521/ORCLCDB\u0026#39;; Enlace con la base de datos creado. Usando este formato en la cadena de conexión ya es posible hacer consultas desde un servidor de la base de datos usando la información almacenada en el otro.\nSQL\u0026gt; select ename 2 from emp@empleados 3 where deptno = (select deptno 4 from dept 5 where dname = \u0026#39;SALES\u0026#39;); ENAME ------------------------------ ALLEN WARD MARTIN BLAKE TURNER JAMES 6 filas seleccionadas. Resolución de errores El error mencionado anteriormente se produce por un problema con la ubicación del fichero tnsnames.ora. Este fichero se instala en diferentes ubicaciones del servidor al instalar Oracle. Sin embargo, el servidor sólo usa uno de estos ficheros para establecer las conexiones. En este caso el fichero que se estaba editando (/opt/oracle/homes/OraDBHome21cEE/network/admin/tnsnames.ora) no coincidía con el que estaba usando el servidor (/opt/oracle/product/21c/dbhome_1/network/admin/tnsnames.ora).\nSolucionar este problema es tan sencillo como copiar el fichero de configuración en la ubicación correcta.\nsudo cp /opt/oracle/homes/OraDBHome21cEE/network/admin/tnsnames.ora /opt/oracle/product/21c/dbhome_1/network/admin/tnsnames.ora Tras ubicar correctamente el fichero, ambos servidores de Oracle se pueden comunicar usando el nombre configurado en el fichero tnsnames.ora.\nSQL\u0026gt; drop database link empleados; Enlace con la base de datos borrado. SQL\u0026gt; create database link empleados 2 connect to dos 3 identified by dos 4 using \u0026#39;ORCL2\u0026#39;; Enlace con la base de datos creado. SQL\u0026gt; select ename 2 from emp@empleados 3 where deptno = (select deptno 4 from dept 5 where dname = \u0026#39;SALES\u0026#39;); ENAME ------------------------------ ALLEN WARD MARTIN BLAKE TURNER JAMES 6 filas seleccionadas. "},{
  "section": "Blog",
  "slug": "/blog/servicios/2024-12-02-configuracion-proxy-inverso/",
  "title": "Configuración de un proxy inverso en Apache2 y Nginx",
  "description": "",
  "date": "November 16, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "servicios",
  "tags": "Proxy, Proxy inverso, Apache2, Nginx, Administración de Sistemas, servicios, Servicios de Red e Internet",
  "content":"Configuración de un proxy inverso En un escenario formado por dos máquinas una de ellas funciona a modo de proxy inverso y la otra como servidor web. En el servidor se crean dos virtual host diferentes con un nombre diferenciado y document root también separados.\nUso de Apache2 como proxy inverso Existen diferentes formas de implementar un proxy inverso. Una de ellas es usar un servidor web como Apache2. Para poder usar el servidor web de Apache como proxy inverso hay que activar los módulos proxy y proxy_http.\na2enmod proxy proxy_http Para acceder a las dos páginas diferentes del servidor web se crean en el proxy dos virtual host en los que se comenta la línea del document root y se añade la línea de proxy:\nProxyPass \u0026#34;/\u0026#34; \u0026#34;http://interno.example1.org/\u0026#34; Para que las redirecciones de las web alojadas en el servidor web funcionan correctamente, el document root tiene que incluir también la línea ProxyPassReverse.\nProxyPassReverse \u0026#34;/\u0026#34; \u0026#34;http://interno.example1.org/\u0026#34; Para acceder a las páginas alojadas en el servidor web bajo un único dominio como, por ejemplo, www.servidor.org/app1 y www.servidor.org/app2 el proxy se debe configurar en un único virtualhost en el que se define el dominio y dos entradas de proxy, una para cada una de las páginas.\nProxyPass \u0026#34;/app1/\u0026#34; \u0026#34;http://interno.example1.org/\u0026#34; ProxyPassReverse \u0026#34;/app1/\u0026#34; \u0026#34;http://interno.example1.org/\u0026#34; ProxyPass \u0026#34;/app2/\u0026#34; \u0026#34;http://interno.example2.org/\u0026#34; ProxyPassReverse \u0026#34;/app2/\u0026#34; \u0026#34;http://interno.example2.org/\u0026#34; Uso de Nginx como proxy inverso Al igual que Apache2, el servidor web Nginx también puede funcionar como proxy inverso. En este caso, para acceder a las dos páginas del servidor web desde dos dominios diferentes, la máquina que funciona como proxy inverso debe contar con un virtual hosta para cada una de ellas. En este virtual host debe estar presente la directiva de proxy.\nlocation / { proxy_pass http://interno.example1.org/; } Info\nLa directiva proxy_pass en Nginx ya hace que las redirecciones desde las páginas del servidor web funcionen correctamente y no necesita la configuración de ninguna directiva adicional.\nComo en el caso anterior, para acceder a las páginas alojadas en el servidor web bajo un único dominio el proxy se debe configurar también en un único virtualhost en el que se define el dominio y dos entradas de proxy, una para cada una de las páginas, en este caso, usando la directiva location.\nlocation /app1/ { proxy_pass http://interno.example1.org/; include proxy_params; } location /app2/ { proxy_pass http://interno.example2.org/; include proxy_params; } "},{
  "section": "Blog",
  "slug": "/blog/servicios/2024-12-02-configuracion-proxy/",
  "title": "Configuración de un proxy inverso en Apache2",
  "description": "",
  "date": "November 12, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "servicios",
  "tags": "Proxy, Proxy inverso, Apache2, Administración de Sistemas, servicios, Servicios de Red e Internet",
  "content":"Configuración de un proxy inverso en Apache2 En este ejemplo práctico se muestra la configuración del proxy para el acceso a dos páginas (www.app1.org y www.app2.org) para que las redirecciones funcionen, de manera que al acceder a www.app1.org/directorio se redirija a www.app1.org/nuevodirectorio.\nPara permitir el acceso a las páginas de la red interna se tienen que activar los módulos necesarios de Apache\nsudo a2enmod proxy proxy_http Después se crea un virtualhost en el directorio /etc/apache2/sites-available para cada página en el que se indica la línea de proxy inverso para que se produzca el acceso al servidor interno.\n\u0026lt;VirtualHost *:80\u0026gt; ServerName www.app1.org ServerAdmin webmaster@localhost ProxyPass \u0026#34;/\u0026#34; \u0026#34;http://interno.example1.org/\u0026#34; ProxyPassReverse \u0026#34;/\u0026#34; \u0026#34;http://interno.example1.org/\u0026#34; ErrorLog ${APACHE_LOG_DIR}/error.log CustomLog ${APACHE_LOG_DIR}/access.log combined \u0026lt;/VirtualHost\u0026gt; Después hay que activar los virtual host\nsudo a2ensite app1 sudo a2ensite app2 sudo systemctl reload apache2 Desde el cliente se crea el direccionamiento estático en el fichero /etc/hosts y se puede acceder al destino desde el navegador del host.\n"},{
  "section": "Blog",
  "slug": "/blog/administracion-de-sistemas/2024-12-02-manejo-de-modulos/",
  "title": "Manejo y modificación de módulos del kernel ",
  "description": "",
  "date": "November 12, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "administracion-sistemas",
  "tags": "sistemas, debian, linux, kernel, módulos, sysctl, comandos, administracion-sistemas, Administración de Sistemas Operativos",
  "content":"Ejercicios de manejo de módulos Comprueba los módulos cargados en tu equipo Los módulos cargados en el equipo se pueden listar con el comando lsmod.\nlsmod Module Size Used by ip6t_REJECT 16384 6 nf_reject_ipv6 20480 1 ip6t_REJECT rpcsec_gss_krb5 36864 0 nfsv4 1052672 0 dns_resolver 16384 1 nfsv4 nfs 520192 1 nfsv4 fscache 380928 1 nfs netfs 57344 1 fscache veth 36864 0 nft_masq 16384 1 vhost_net 36864 9 vhost 57344 1 vhost_net vhost_iotlb 16384 1 vhost tap 28672 1 vhost_net tun 61440 19 vhost_net snd_seq_dummy 16384 0 snd_hrtimer 16384 1 snd_seq 90112 7 snd_seq_dummy snd_seq_device 16384 1 snd_seq xt_CHECKSUM 16384 5 xt_MASQUERADE 20480 12 xt_conntrack 16384 4 ipt_REJECT 16384 18 nf_reject_ipv4 16384 1 ipt_REJECT xt_tcpudp 20480 0 nft_compat 20480 45 nft_chain_nat 16384 3 nf_nat 57344 3 nft_masq,nft_chain_nat,xt_MASQUERADE nf_conntrack 188416 4 xt_conntrack,nf_nat,nft_masq,xt_MASQUERADE nf_defrag_ipv6 24576 1 nf_conntrack nf_defrag_ipv4 16384 1 nf_conntrack nf_tables 303104 983 nft_compat,nft_masq,nft_chain_nat nfnetlink 20480 2 nft_compat,nf_tables qrtr 49152 2 bridge 311296 0 stp 16384 1 bridge llc 16384 2 bridge,stp binfmt_misc 28672 1 intel_rapl_msr 20480 0 intel_rapl_common 32768 1 intel_rapl_msr nls_ascii 16384 1 nls_cp437 20480 1 x86_pkg_temp_thermal 20480 0 intel_powerclamp 20480 0 vfat 24576 1 fat 90112 1 vfat coretemp 20480 0 kvm_intel 380928 6 kvm 1146880 1 kvm_intel irqbypass 16384 27 kvm ghash_clmulni_intel 16384 0 ath9k 143360 0 cryptd 28672 1 ghash_clmulni_intel ath9k_common 24576 1 ath9k sha512_ssse3 49152 0 sha512_generic 16384 1 sha512_ssse3 ath9k_hw 512000 2 ath9k_common,ath9k snd_hda_codec_realtek 172032 1 snd_hda_codec_generic 98304 1 snd_hda_codec_realtek ledtrig_audio 16384 1 snd_hda_codec_generic ath 36864 3 ath9k_common,ath9k,ath9k_hw mac80211 1175552 1 ath9k snd_hda_codec_hdmi 81920 1 sha256_ssse3 32768 1 libarc4 16384 1 mac80211 snd_hda_intel 57344 2 snd_intel_dspcfg 36864 1 snd_hda_intel snd_intel_sdw_acpi 20480 1 snd_intel_dspcfg snd_hda_codec 184320 4 snd_hda_codec_generic,snd_hda_codec_hdmi,snd_hda_intel,snd_hda_codec_realtek sha1_ssse3 32768 0 cfg80211 1146880 4 ath9k_common,ath9k,ath,mac80211 pcspkr 16384 0 rapl 20480 0 snd_hda_core 122880 5 snd_hda_codec_generic,snd_hda_codec_hdmi,snd_hda_intel,snd_hda_codec,snd_hda_codec_realtek iTCO_wdt 16384 0 intel_pmc_bxt 16384 1 iTCO_wdt snd_hwdep 16384 1 snd_hda_codec snd_pcm 159744 4 snd_hda_codec_hdmi,snd_hda_intel,snd_hda_codec,snd_hda_core rfkill 36864 6 ath9k,cfg80211 mei_hdcp 24576 0 snd_timer 49152 3 snd_seq,snd_hrtimer,snd_pcm iTCO_vendor_support 16384 1 iTCO_wdt intel_cstate 20480 0 snd 126976 16 snd_hda_codec_generic,snd_seq,snd_seq_device,snd_hda_codec_hdmi,snd_hwdep,snd_hda_intel,snd_hda_codec,snd_hda_codec_realtek,snd_timer,snd_pcm soundcore 16384 1 snd watchdog 45056 1 iTCO_wdt intel_uncore 217088 0 at24 28672 0 sg 40960 0 mei_me 53248 1 evdev 28672 11 mei 159744 3 mei_hdcp,mei_me nfsd 704512 5 auth_rpcgss 159744 2 nfsd,rpcsec_gss_krb5 msr 16384 0 nfs_acl 16384 1 nfsd lockd 131072 2 nfsd,nfs grace 16384 2 nfsd,lockd sunrpc 692224 21 nfsd,nfsv4,auth_rpcgss,lockd,rpcsec_gss_krb5,nfs_acl,nfs parport_pc 40960 1 ppdev 24576 0 efi_pstore 16384 0 lp 20480 0 parport 69632 3 parport_pc,lp,ppdev fuse 176128 7 configfs 57344 1 loop 32768 0 ip_tables 36864 0 x_tables 61440 8 xt_conntrack,nft_compat,xt_tcpudp,xt_CHECKSUM,ipt_REJECT,ip_tables,xt_MASQUERADE,ip6t_REJECT autofs4 53248 2 xfs 1957888 3 btrfs 1794048 0 zstd_compress 294912 1 btrfs efivarfs 24576 1 raid10 65536 0 raid456 180224 0 async_raid6_recov 24576 1 raid456 async_memcpy 20480 2 raid456,async_raid6_recov async_pq 20480 2 raid456,async_raid6_recov async_xor 20480 3 async_pq,raid456,async_raid6_recov async_tx 20480 5 async_pq,async_memcpy,async_xor,raid456,async_raid6_recov xor 24576 2 async_xor,btrfs raid6_pq 122880 4 async_pq,btrfs,raid456,async_raid6_recov libcrc32c 16384 6 nf_conntrack,nf_nat,btrfs,nf_tables,xfs,raid456 crc32c_generic 16384 0 raid1 53248 0 raid0 24576 0 multipath 20480 0 linear 20480 0 md_mod 192512 6 raid1,raid10,raid0,linear,raid456,multipath dm_mod 184320 6 hid_generic 16384 0 usbhid 65536 0 hid 159744 2 usbhid,hid_generic i915 3055616 73 sd_mod 65536 4 t10_pi 16384 1 sd_mod crc64_rocksoft 20480 1 t10_pi crc64 20480 1 crc64_rocksoft crc_t10dif 20480 1 t10_pi crct10dif_generic 16384 0 drm_buddy 20480 1 i915 i2c_algo_bit 16384 1 i915 drm_display_helper 184320 1 i915 cec 61440 2 drm_display_helper,i915 ahci 49152 3 rc_core 69632 1 cec libahci 49152 1 ahci ttm 94208 1 i915 libata 401408 2 libahci,ahci drm_kms_helper 212992 2 drm_display_helper,i915 xhci_pci 24576 0 xhci_hcd 315392 1 xhci_pci scsi_mod 286720 3 sd_mod,libata,sg crct10dif_pclmul 16384 1 crct10dif_common 16384 3 crct10dif_generic,crc_t10dif,crct10dif_pclmul ehci_pci 20480 0 ehci_hcd 102400 1 ehci_pci drm 614400 18 drm_kms_helper,drm_display_helper,drm_buddy,i915,ttm i2c_i801 36864 0 i2c_smbus 20480 1 i2c_i801 crc32_pclmul 16384 0 scsi_common 16384 3 scsi_mod,libata,sg r8169 94208 0 lpc_ich 28672 0 realtek 36864 1 crc32c_intel 24576 1 mdio_devres 16384 1 r8169 usbcore 348160 5 xhci_hcd,ehci_pci,usbhid,ehci_hcd,xhci_pci libphy 180224 3 r8169,mdio_devres,realtek usb_common 16384 3 xhci_hcd,usbcore,ehci_hcd fan 20480 0 video 65536 1 i915 wmi 36864 1 video button 24576 0 Cuenta el número de módulos disponibles en el núcleo que estás usando sudo find /lib/modules/$(uname -r) -type f -iname \u0026#39;*.ko\u0026#39; | wc -l 4024 En el kernel instalado en el equipo hay disponibles un total de 4024 módulos.\nConecta un lápiz USB y observa la salida de la instrucción sudo dmesg Al conectar un dispoisitivo USB al equipo, se cargan en memoria los módulos del kernel que contienen los drivers necesarios para gestionar el dispositivo. En este caso, se observa en la salida del comando sudo dmesg cómo se cargan los módulos usb 2-1, usb-storage, scsi host4 o usbcore. Además, se muestran algunos de los pocesos relacionados con la detección, identificación y montaje del nuevo dispositivo.\nsudo dmesg ... [14561.684067] usb 2-1: new high-speed USB device number 5 using xhci_hcd [14562.325600] usb 2-1: New USB device found, idVendor=125f, idProduct=1036, bcdDevice= 1.00 [14562.325605] usb 2-1: New USB device strings: Mfr=1, Product=2, SerialNumber=3 [14562.325607] usb 2-1: Product: USB Flash Drive [14562.325609] usb 2-1: Manufacturer: USB 2.0 [14562.325610] usb 2-1: SerialNumber: 9701b097f311bd [14563.248344] usb-storage 2-1:1.0: USB Mass Storage device detected [14563.249769] scsi host4: usb-storage 2-1:1.0 [14563.251217] usbcore: registered new interface driver usb-storage [14563.358101] usbcore: registered new interface driver uas [14564.280602] scsi 4:0:0:0: Direct-Access USB 2.0 USB Flash Drive 0.00 PQ: 0 ANSI: 2 [14564.281193] sd 4:0:0:0: Attached scsi generic sg2 type 0 [14564.281424] sd 4:0:0:0: [sdb] 7897088 512-byte logical blocks: (4.04 GB/3.77 GiB) [14564.281802] sd 4:0:0:0: [sdb] Write Protect is off [14564.281807] sd 4:0:0:0: [sdb] Mode Sense: 00 00 00 00 [14564.282150] sd 4:0:0:0: [sdb] Asking for cache data failed [14564.282156] sd 4:0:0:0: [sdb] Assuming drive cache: write through [14564.350308] sdb: [14564.419487] sd 4:0:0:0: [sdb] Attached SCSI removable disk [14569.357025] FAT-fs (sdb): Volume was not properly unmounted. Some data may be corrupt. Please run fsck. Elimina el módulo correspondiente a algún dispotivo no esencial y comprueba qué ocurre. Vuelve a cargarlo Cuando se descarga de memoria el módulo ath9k, que está relacionado con los drivers de la tarjeta de red inalámbrica.\nsudo modprobe -r ath9k La ejecución del comando sudo dmesg muestra la siguiente línea:\n[17980.371067] ath9k: ath9k: Driver unloaded Si se vuelve a cargar el módulo en memoria\nsudo modprobe ath9k Se vuelve a cargar la información relacionada con la tarjeta de red inalámbrica en el sistema.\n[18041.354113] ath: EEPROM regdomain: 0x809c [18041.354117] ath: EEPROM indicates we should expect a country code [18041.354118] ath: doing EEPROM country-\u0026gt;regdmn map search [18041.354118] ath: country maps to regdmn code: 0x52 [18041.354119] ath: Country alpha2 being used: CN [18041.354120] ath: Regpair used: 0x52 [18041.355354] ieee80211 phy1: Selected rate control algorithm \u0026#39;minstrel_ht\u0026#39; [18041.379127] ieee80211 phy1: Atheros AR9287 Rev:2 mem=0x000000009cd2f86f, irq=17 [18041.579207] ath9k 0000:04:00.0 wlp4s0: renamed from wlan0 Selecciona un módulo que esté en uso en tu equipo y configura el arranque para que no se cargue automáticamente Una forma de configurar el kernel para que no cargue automáticamente un módulo en el arranque es usando el directorio /etc/modprobe.d/\u0026lt;modulo\u0026gt;.conf. Por ejemplo, en el caso del módulo ath9k habría que crea el fichero /etc/modprobe.d/ath9k.conf y en él añadir la siguiente línea:\nblacklist ath9k Realmente, el nombe del fichero dentro del directorio /etc/modprobe.d/ no es relevante. De esta manera, si hay una lista más o menos amplia de módulos cuya carga automática en el arranque se quiere evitar se puede crear un fichero /etc/modprobe.d/blacklis.conf y en él añadir una línea con el contenido blacklist \u0026lt;módulo\u0026gt; por cada uno de los módulos a los que se quiera aplicar esta configuración.\nCarga el módulo loop, obtén información de qué es y para qué sirve. Lista el contenido de /sys/modules/loop/parameters y configura el equipo para que se puedan cargar como máximo 12 dispositvos loop la próxima vez que se arranque Tras cargar el módulo loop con el comando modprobe se puede comprobar que, efectivamente, este módulo está cargado con el comando lsmod.\nsudo modprobe loop sudo lsmod | grep loop loop 32768 0 El comando modinfo devuelve cierta infomación sobre el módulo loop. Se trata del módulo que gestiona los dispositivos de tipo loop en el sistema. Este módulo no tiene dependencias y tiene tres parámetros: max_loop, que indica el número máximo de dispositivos de tipo loop que se pueden habilitar en el equipo, max_part, que indica el número máximo de particiones que puede tener cada uno de estos dispositivos y hw_queue_depth, que indica la profundida de la cola de cada dispositivo y que, por defecto, tiene un valor de 128.\nsudo modinfo loop filename: /lib/modules/6.1.0-26-amd64/kernel/drivers/block/loop.ko alias: devname:loop-control alias: char-major-10-237 alias: block-major-7-* license: GPL depends: retpoline: Y intree: Y name: loop vermagic: 6.1.0-26-amd64 SMP preempt mod_unload modversions sig_id: PKCS#7 signer: Debian Secure Boot CA sig_key: 32:A0:28:7F:84:1A:03:6F:A3:93:C1:E0:65:C4:3A:E6:B2:42:26:43 sig_hashalgo: sha256 signature: 9A:13:9A:8A:39:48:35:B1:0C:B1:32:B9:F6:58:16:95:98:7C:1A:8F: 37:7A:44:CB:6B:B6:8D:80:B6:60:83:B3:4B:9E:0F:AB:62:50:12:0A: 5F:4D:FB:56:7F:02:DA:3E:93:7F:5C:EB:9A:7F:E7:DB:37:BD:BC:2F: 47:78:64:8C:52:F0:EE:DE:8A:2E:56:FB:6F:64:40:EC:95:FB:41:76: AE:28:8F:61:39:F9:20:7B:F3:EA:B5:D7:4A:11:DA:BD:CF:A1:33:1D: 2B:9D:F8:99:1F:12:09:6F:1F:B2:32:79:E4:A6:2C:3A:09:B7:9B:02: 13:25:0D:0F:71:38:4D:2B:31:10:78:4E:9E:0B:03:8C:6A:1D:93:FB: 1F:2F:DC:35:CF:10:26:C2:40:E0:CA:50:D2:1F:93:EA:8A:5C:48:42: E7:D5:B3:F7:7C:15:95:49:B3:13:E6:89:D6:E9:44:C3:6D:BF:AF:CF: 6F:A2:72:18:2C:69:6E:60:AA:E6:1A:5E:B7:D2:AC:68:D6:4D:66:8B: 06:2E:E3:F0:D1:C5:CF:9C:7C:69:FD:5E:3A:F0:64:CE:6C:CF:88:F1: 62:AB:9B:B8:6D:B9:7A:87:84:7D:0A:4A:AF:CC:F3:E1:4D:15:C2:6A: 43:98:8D:58:68:5A:36:5E:03:EF:0F:60:46:AC:57:C3 parm: max_loop:Maximum number of loop devices parm: max_part:Maximum number of partitions per loop device (int) parm: hw_queue_depth:Queue depth for each hardware queue. Default: 128 Estos parámetros también se pueden acceder listando el contenido del dierctorio /sys/module/loop/parameters/.\nsudo ls -l /sys/module/loop/parameters/ total 0 -r--r--r-- 1 root root 4096 oct 24 14:23 hw_queue_depth -r--r--r-- 1 root root 4096 oct 24 14:23 max_loop -r--r--r-- 1 root root 4096 oct 24 14:23 max_part El parámetro max_loop del módulo loop define la cantidad de dispositivos de tipo loop que se pueden montar de forma simultánea en el equipo. En este caso, tiene un valor de 8.\nsudo cat /sys/module/loop/parameters/max_loop 8 Para que se puedan montar, como máximo, 12 dispositivos de tipo loop, este parámetro debe tomar el valor 12. Para cambiar el valor de este parámetro y, además, hacerlo de forma persistente, se debe usar un fichero de configuración almacenado en el directorio /etc/modprobe.d. En él, se crea un fichero con el mismo nombre del módulo y la extensión .conf y que debe tener como contendio el nuevo valor del parámetro.\nnano /etc/modprobe.d/loop.conf options loop max_loop=12 Para que esta modificación sea efectiva, se debe actualizar el initramfs y reiniciar el equipo.\nsudo update-initramfs -u sudo reboot Tras reiniciar el contenido del fichero en el que se almacena la información de este parámtro se ha actualizado.\nsudo cat /sys/module/loop/parameters/max_loop 12 Ejercicios de modificación de parámetros del kernel Deshabilita apparmor en el arranque AppArmor es un servicio que limita la cantidad de recursos a los que puede tener acceso un determinado programa. Esta limitación se establece a través de perfiles que se cargan en el kernel\nComo otros muchos servicios en Debian, AppArmor se puede gestionar a través del comando systemctl. Así, para deshabilitar apparmor en el arranque se puede ejecutar el siguiente comando:\n❯ sudo systemctl disable apparmor Synchronizing state of apparmor.service with SysV service script with /lib/systemd/systemd-sysv-install. Executing: /lib/systemd/systemd-sysv-install disable apparmor Removed \u0026#34;/etc/systemd/system/sysinit.target.wants/apparmor.service\u0026#34;. Deshabilita si es posible el Kernel Mode Setting (KSM) de la tarjeta gráfica KSM (Kernel Samepage Merging) es una característica de ahorro de memoia habilitada con el parámetro CONFIG_KSM=y del kernel incluida desde el kernel 2.6.32. Esta característica, usada por KVM, permite a varias máquinas virtuales compartir páginas de memoria idénticas. Estas páginas de memoria compartidas suelen ser librerías comunes a todas las máquinas u otros tipos de información idéntica frecuentemente usada por varias máquinas.\nAlgunos de los parámetros del kernel, incluidos alguno relacionados con KSM, se pueden modificar en el directorio /proc/sys pero estas modificaciones no son persistentes a reinicios.\nEstos parámetros también se pueden gestionar usando el comando sysctl. Además, este comando cuenta con la peculiaridad de que permite modificar los valores del kernel durante la ejecución, es decir, en caliente. Los parámetros que puede gestiona el comando sysctl están listados en el directorio /proc/sys/.\nEn este caso, no es posible deshabilitar la característica KSM del kernel puesto que no está incluída en el kernel de este equipo. Al buscar los parámetros relacionados con KSM en el directorio /proc/sys no se muestra ninguno disponible.\n❯ sudo find /proc/sys -iname \u0026#39;*ksm*\u0026#39; Cambia provisionalmente la swappiness para que la swap de tu equipo se active cuando se use más de un 90% de la RAM Swappiness también es una característica del kernel que se puede modificar. El valor de este parámetro se almacena en el directorio /proc/sys. Para encontrar dónde se alamacena este parámetro se puede hacer una búsqueda en este directorio.\n❯ sudo find /proc/sys -iname \u0026#39;*swappiness*\u0026#39; /proc/sys/vm/swappiness Se puede conocer el valor que tiene este parámetro del kernel consultado el contenido de este fichero.\n❯ cat /proc/sys/vm/swappiness 60 Con esta configuración, la swap del equipo se activa cuando se usa más del 60% de la RAM. Para modificar este valor se puede usar el comando sysctl.\n❯ sudo sysctl vm.swappiness=90 vm.swappiness = 90 Tras ejecutar este comando, el valor de este parámetro del kernel se ha modificado en el fichero /proc/sys.\n❯ cat /proc/sys/vm/swappiness 90 Pero esta configuración no es persistente al reinicio y sólo se aplica hasta el próximo apagado de la máquina.\nHaz que el cambio de la swappiness sea permanente Existen varias formas de hacer persistente al reinicio esta configuración. Una de las más comunes consiste en utilizar el fichero /etc/sysctl.conf. En este fichero se pueden configurar los valores de los parámetros del kernel que se cargan en cada reinicio del equipo.\nEn este caso, se puede añadir el nuevo valor de este parámetro a este fichero para hacer esta configuración permanente.\n❯ echo \u0026#34;vm.swappiness=90\u0026#34; \u0026gt;\u0026gt; /etc/sysctl.conf Tras ejecutar este comando, este parámetro del kernel toma su nuevo valor en el fichero de configuración de sysctl.\n❯ cat /etc/sysctl.conf | grep \u0026#39;swappiness\u0026#39; vm.swappiness=90 Para que esta nueva configuración sea efectiva hay que volver a carga el fichero sysctl.conf.\n❯ sudo sysctl -p vm.swappiness = 90 La salida del comando muestra la lista de parámetros que se han modificado al cargar el nuevo fichero de configuración de parámetros del kernel. En este caso, sólo se muestar el nuevo valo de la swappiness.\nMuestra el valor del bit de forward para IPv6 El bit de forward para las redes IPv6 se puede configurar para cada una de las interfaces de red de forma independiente o de forma general para todas ellas.\n❯ find /proc/sys -iname \u0026#39;forwarding\u0026#39; | grep ipv6 /proc/sys/net/ipv6/conf/all/forwarding /proc/sys/net/ipv6/conf/br-intra/forwarding /proc/sys/net/ipv6/conf/br-intra2/forwarding /proc/sys/net/ipv6/conf/br0/forwarding /proc/sys/net/ipv6/conf/default/forwarding /proc/sys/net/ipv6/conf/enp2s0/forwarding /proc/sys/net/ipv6/conf/lo/forwarding /proc/sys/net/ipv6/conf/lxcbr0/forwarding /proc/sys/net/ipv6/conf/veth0zlkeI/forwarding /proc/sys/net/ipv6/conf/vethigCamC/forwarding /proc/sys/net/ipv6/conf/vethj7iUWu/forwarding /proc/sys/net/ipv6/conf/virbr0/forwarding /proc/sys/net/ipv6/conf/virbr1/forwarding /proc/sys/net/ipv6/conf/virbr2/forwarding /proc/sys/net/ipv6/conf/virbr3/forwarding /proc/sys/net/ipv6/conf/virbr4/forwarding /proc/sys/net/ipv6/conf/virbr5/forwarding /proc/sys/net/ipv6/conf/virbr6/forwarding /proc/sys/net/ipv6/conf/vnet0/forwarding /proc/sys/net/ipv6/conf/vnet1/forwarding /proc/sys/net/ipv6/conf/vnet16/forwarding /proc/sys/net/ipv6/conf/vnet17/forwarding /proc/sys/net/ipv6/conf/vnet18/forwarding /proc/sys/net/ipv6/conf/vnet19/forwarding /proc/sys/net/ipv6/conf/vnet2/forwarding /proc/sys/net/ipv6/conf/vnet20/forwarding /proc/sys/net/ipv6/conf/vnet21/forwarding /proc/sys/net/ipv6/conf/wlp4s0/forwarding Para conocer si el bit de forward de cada una de estas interfaces está activado se puede consultar el valor de cada uno de estos ficheros, que será 0 si el bit no está activado o 1 si el bit está activado. En este caso, por ejemplo, el bit de forward para las interfaces IPv6 no está activado.\n❯ cat $(find /proc/sys -iname \u0026#39;forwarding\u0026#39; | grep ipv6) 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Deshabilita completamente las Magic Sysrq en el arranque y vuelve a habilitarlas después de reiniciar Las Magic Sysrq es una combinación de teclas \u0026ldquo;mágica\u0026rdquo; a las que el kernel responde independientemente de lo que esté haciendo siempre y cuando no esté bloqueado. Esta combinación de teclas se activa a través del parámetro del kernel CONFIG_MAGIC_SYSRQ. El fichero /proc/sys/kernel/sysrq contiene el valor de este parámetro.\nEn este fichero se puede configura uno de los siguientes valores:\n0 = disable sysrq completely 1 = enable all functions of sysrq 2 = 0x2 - enable control of console logging level 4 = 0x4 - enable control of keyboard (SAK, unraw) 8 = 0x8 - enable debugging dumps of processes etc. 16 = 0x10 - enable sync command 32 = 0x20 - enable remount read-only 64 = 0x40 - enable signalling of processes (term, kill, oom-kill) 128 = 0x80 - allow reboot/poweroff 256 = 0x100 - allow nicing of all RT tasks ❯ cat /proc/sys/kernel/sysrq 438 Actualmente, el valor de este parámtro en el kernel es 438. Es decir, esta combinación de teclas está configurada de manera que permite las características habilitadas por los valores 256, 128, 32, 16, 4 y 2.\nPara deshabilitar las Magic Sysrq se puede cambiar el valor de este fichero a 0. Sin embargo, para que esta configuración sea persistente a los reinicios de la máquina, este parámetro se debe espcifica en el fichero /etc/sysctl.conf.\nEn el fichero /etc/sysctl.conf está especificado el mismo valor que en el fichero /proc/sys/kernel/sysrq aunque esta líea está comentada.\n❯ sudo cat /etc/sysctl.conf | grep sysrq # 0=disable, 1=enable all, \u0026gt;1 bitmask of sysrq functions # See https://www.kernel.org/doc/html/latest/admin-guide/sysrq.html #kernel.sysrq=438 Para deshabilitar esta característica del kernel se puede editar este fichero, descomentar esta línea y sustituir el valor 438 por 0.\n❯ sudo cat /etc/sysctl.conf | grep sysrq # 0=disable, 1=enable all, \u0026gt;1 bitmask of sysrq functions # See https://www.kernel.org/doc/html/latest/admin-guide/sysrq.html kernel.sysrq=0 Para que esta modificación sea efectiva, hay que cargar la nueva configuración del fichero.\n❯ sudo sysctl -p kernel.sysrq = 0 vm.swappiness = 90 Tras reiniciar el equipo se puede devolver la configuración al valor por defecto en el fichero de configuración.\n❯ sudo cat /etc/sysctl.conf | grep sysrq # 0=disable, 1=enable all, \u0026gt;1 bitmask of sysrq functions # See https://www.kernel.org/doc/html/latest/admin-guide/sysrq.html kernel.sysrq=438 ❯ sudo sysctl -p kernel.sysrq = 438 vm.swappiness = 90 ❯ cat /proc/sys/kernel/sysrq 438 "},{
  "section": "Blog",
  "slug": "/blog/implantacion-aplicaciones-web/2024-11-10-configuracion-apache2-fpmphp/",
  "title": "Configuración de Apache2 con fpm-php",
  "description": "",
  "date": "November 10, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "implantacion",
  "tags": "PHP, Apache2, fpm-php, LAMP, implantacion, Implantación de Aplicaciones Web",
  "content":"Primero se comprueba si el módulo PHP de Apache2 está instalado y se desinstala.\napache2ctl -M | grep php a2dismod php8.2 Para instalar fpm-php\napt install php8.2-fpm php8.2 Para que Apache2 use fpm-php se activan los módulos proxy_fcgi y setenvif\na2enmod proxy_fcgi setenvif Se puede configurar el servidor de aplicaciones en todos el host virtual en /etc/apache2/sites-available/.conf\n#Por TCP ProxyPassMatch ^/(.*\\.php)$ fcgi://127.0.0.1:9000/var/www/\u0026lt;host\u0026gt;/$1 #Por socket UNIX ProxyPassMatch ^/(.*\\.php)$ unix:/run/php/php8.2-fpm.sock|fcgi://127.0.0.1/var/www/\u0026lt;host\u0026gt; O para todos los hosts del servidor web en el fichero /etc/apache2/conf-available\n#Por TCP SetHandler \u0026#34;proxy:fcgi://127.0.0.1:9000\u0026#34; #Por socket UNIX SetHandler \u0026#34;proxy:unix:/run/php/php8.2-fpm.sock|fcgi://localhost\u0026#34; "},{
  "section": "Blog",
  "slug": "/blog/servicios/2024-11-10-configuracion-servidor-san/",
  "title": "Configuración de un servidor SAN",
  "description": "",
  "date": "November 10, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "servicios",
  "tags": "SAN, Almacenamiento, Dispositivos de bloque, iSCSI, tgt, Administración de Sistemas, servicios, Servicios de Red e Internet",
  "content":"Gestión de volúmenes en el servidor SAN El servidor SAN cuenta con 3 discos duros de 2G cada uno. A partir de estos discos se crea un Raid5 y se convierte en un grupo de volúmenes. En este grupo de volúmenes se crean un volumen de 1G que se comparte con un cliente GNU/Linux y dos volúmenes de 512M que se comparten con un cliente Windows.\nmdadm --create /dev/md0 --level=5 --raid-devices=3 /dev/vdb /dev/vdc /dev/vdd mdadm --detail --scan --verbose \u0026gt;\u0026gt; /etc/mdadm/mdadm.conf update-initramfs -u -k all vgcreate vg1 /dev/md0 lvcreate -L 1G -n lv1 vg1 lvcreate -L 512M -n lv2 vg1 lvcreate -L 512M -n lv3 vg1 Creación de un target para compartir con un cliente GNU/Linux Creación del target en el servidor SAN El primer paso es crear el target en el servidor SAN. Es necesario instalar previamente la herramienta tgtadm del paquete tgt.\nsudo apt install tgt sudo tgtadm --lld iscsi --op new --mode target --tid 1 -T iqn.2024-10.org.javi:target1 Además, para compartir el volumen lógico con el cliente hay que añadirlo como Unidad Lógica (LUN) al target recién creado.\nsudo tgtadm --lld iscsi --op new --mode logicalunit --tid 1 --lun 1 -b /dev/vg1/lv1 Ahora hay disponible en el servidor un target con una LUN que se puede compartir.\nvagrant@san:~$ sudo tgtadm --lld iscsi --op show --mode target Target 1: iqn.2024-10.org.javi:target1 System information: Driver: iscsi State: ready I_T nexus information: LUN information: LUN: 0 Type: controller SCSI ID: IET 00010000 SCSI SN: beaf10 Size: 0 MB, Block size: 1 Online: Yes Removable media: No Prevent removal: No Readonly: No SWP: No Thin-provisioning: No Backing store type: null Backing store path: None Backing store flags: LUN: 1 Type: disk SCSI ID: IET 00010001 SCSI SN: beaf11 Size: 1074 MB, Block size: 512 Online: Yes Removable media: No Prevent removal: No Readonly: No SWP: No Thin-provisioning: No Backing store type: rdwr Backing store path: /dev/vg1/lv1 Backing store flags: Account information: ACL information: Antes de acceder al target desde el cliente (192.168.0.5) hay que hacer que esté disponible a través de la red.\nsudo tgtadm --lld iscsi --op bind --mode target --tid 1 -I 192.168.0.5 Esta configuración desaparece con el apagado de la máquina. Para hacerla persistente a reinicios se debe volcar a un fichero de configuración. Esta operación se puede realizar con la herramienta tgt-admin.\ntgt-admin --dump \u0026gt; /etc/tgt/conf.d/san.conf Configuración del volumen en el cliente Para configurar un target como volumen en el cliente es necesario usar la herramienta iscasiadm, disponible en el paquete open-iscsi. La instalación de esta herramienta genera el fichero de configuración /etc/iscsi/initiatorname.iscsi, que crea un initiator en el cliente para permitirle usar los volúmenes que comparte el servidor.\nsudo apt install open-iscsi Antes de configurar la conexión, es necesario conocer cuáles son los targets que ofrece el servidor SAN (192.168.0.4) disponibles en la red para el cliente.\nvagrant@cliente:~$ iscsiadm --mode discovery --type sendtargets --portal 192.168.0.4 192.168.0.4:3260,1 iqn.2024-10.org.javi:target1 Con el nombre del target que se recibe desde el servidor se puede configurar la conexión.\nvagrant@cliente:~$ iscsiadm --mode node -T iqn.2024-10.org.javi:target1 --portal 192.168.0.4 --login Logging in to [iface: default, target: iqn.2024-10.org.javi:target1, portal: 192.168.0.4,3260] Login to [iface: default, target: iqn.2024-10.org.javi:target1, portal: 192.168.0.4,3260] successful. El volumen ya está disponible en el cliente.\nvagrant@cliente:~$ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTS sda 8:0 0 1G 0 disk También se puede crear un sistema de ficheros en este disco duro.\nvagrant@cliente:~$ sudo mkfs.ext4 /dev/sda mke2fs 1.47.0 (5-Feb-2023) Creating filesystem with 262144 4k blocks and 65536 inodes Filesystem UUID: 631106dd-f545-4129-840c-f4e4560504bd Superblock backups stored on blocks: 32768, 98304, 163840, 229376 Allocating group tables: done Writing inode tables: done Creating journal (8192 blocks): done Writing superblocks and filesystem accounting information: done Montar el volumen de forma persistente en el cliente usando systemd mount Para que el proceso de descubrimiento y login del target sea persistente a los reinicios es necesario comprobar que el parámetro node.startup del fichero de configuración /etc/iscsi/iscsid.conf tiene el valor automatic.\n#***************** # Startup settings #***************** # To request that the iscsi service scripts startup a session, use \u0026#34;automatic\u0026#34;: node.startup = automatic # # To manually startup the session, use \u0026#34;manual\u0026#34;. The default is manual. #node.startup = manual Además, hay que añadir el nodo.\nvagrant@cliente:~$ iscsiadm --mode node -T iqn.2024-10.org.javi:target1 --portal 192.168.0.4 -o new New iSCSI node [tcp:[hw=,ip=,net_if=,iscsi_if=default] 192.168.0.4,3260,-1 iqn.2024-10.org.javi:target1] added Y, en el registro del nodo cambiar el valor del parámetro discovery.sendtargets.use_discoveryd a Yes.\nvagrant@cliente:~$ iscsiadm --mode node -T iqn.2024-10.org.javi:target1 --portal 192.168.0.4 -n discovery.sendtargets.use_discoveryd -v Yes Por último, se debe establecer también un valor al parámetro discovery.sendtargets.discoveryd_poll_inval. En este caso, 30.\niscsiadm --mode node -T iqn.2024-10.org.javi:target1 --portal 192.168.0.4 -n discovery.sendtargets.discoveryd_poll_inval -v 30 Una vez que el volumen es accesible desde el cliente se puede crear un punto de montaje con systemd para hacerlo persistente. Systemd es un demonio que gestiona y adminisra el sistema y los servicios, entre ellos, el montaje de discos.\nPara hacer un montaje persisten con systemd es necesario un archivo de montaje que se crea en el directorio /etc/systemd/system/\u0026lt;nombre\u0026gt;.mount.\nAl igual que en el fichero /etc/fstab, en el fichero de montaje se pueden especificar el punto de montaje del disco, el sistema de ficheros que usa y las opciones de montaje.\nsudo nano /etc/systemd/system/san.mount [Unit] Description=Nuevo disco montado-san After=iscsid.service Requires=iscsid.service [Mount] What=/dev/sda Where=/san Type=ext4 Options=defaults [Install] WantedBy=multi-user.target Para que systemd detecte los cambios se reinicia el daemon.\nsudo systemctl daemon-reload Una vez que el montaje del dispositivo está configurado a través de systemctl este volumen se puede montar con el siguiente comando:\nsudo systemctl start san.mount Para hacer persistente a los reinicios el montaje del dispositivo simplemente hay que habilitarlo de la misma forma que se habilitan otros servicios en systemctl.\nvagrant@cliente:~$ sudo systemctl enable san.mount Created symlink /etc/systemd/system/multi-user.target.wants/san.mount → /etc/systemd/system/san.mount. Además, se pueden usar otras funciones de systemctl como el status para ver el estado del dispositivo. Así, tras reiniciar el cliente, se puede comprobar que el dispositivo se ha vuelto a montar correctamente.\nvagrant@cliente:~$ sudo systemctl status san.mount ● san.mount - Nuevo disco montado-san Loaded: loaded (/etc/systemd/system/san.mount; enabled; preset: enabled) Active: active (mounted) since Fri 2024-11-01 19:20:34 CET; 22s ago Where: /san What: /dev/sda Tasks: 0 (limit: 1098) Memory: 160.0K CPU: 4ms CGroup: /system.slice/san.mount nov 01 19:20:34 cliente systemd[1]: Mounting san.mount - Nuevo disco montado-san... nov 01 19:20:34 cliente systemd[1]: Mounted san.mount - Nuevo disco montado-san. Creación de un target para compartir con un cliente Windows Creación del target en el servidor SAN El target que se va a compartir con el cliente Windows cuenta con dos unidades lógicas de 512M cada una.\nsudo tgtadm --lld iscsi --op new --mode target --tid 2 -T iqn.2024-11.org.javi:target2 sudo tgtadm --lld iscsi --op new --mode logicalunit --tid 2 --lun 1 -b /dev/vg1/lv2 sudo tgtadm --lld iscsi --op new --mode logicalunit --tid 2 --lun 2 -b /dev/vg1/lv3 sudo tgtadm --lld iscsi --op bind --mode target --tid 2 -I 192.168.0.6 La autenticación CHAP se puede habilitar a través de la línea de comandos con la herramienta tgtadm pero la herramienta tgt-admin no es capaz de volcar esta información al fichero de configuración persistente, así que para poder configurar la autenticación es necesrio editar directamente el fichero de configuración.\nEn la declaración del target en este fichero hay que añadir el parámetro incominguser que tiene dos valores. El primero de ellos es el usuario y el segundo la contraseña.\nsudo tgt-admin --dump \u0026gt; /etc/tgt/conf.d/san.conf sudo nano /etc/tgt/conf.d/san.conf \u0026lt;target iqn.2024-11.org.javi:target2\u0026gt; backing-store /dev/vg1/lv2 backing-store /dev/vg1/lv3 initiator-address 192.168.0.6 incominguser usuario usuariousuario \u0026lt;/target\u0026gt; Para cargar esta modificación en el fichero hay que reiniciar el servicio.\nsudo systemctl restart tgt Configuración del volumen en el cliente Para configurar un volumen compartido en un cliente Windows se usa la herramienta iSCSI initiator, que está instalada en el sistema operativo por defecto.\nAl iniciar esta herramienta se muestra un mensaje en el que se avisa de que el servicio iSCSI de Microsoft no se ha activado y pregunta si se quiere iniciar. Tras iniciar el servicio se abre la herramienta del iniciador o cliente iscsi en la que se puede configurar una nueva conexión.\nCon esta herramienta se puede establecer una conexión rápida al servidor iscsi con la que se puede detectar un destino e inicar sesión en él indicando el nombre de domino o la dirección IP del servidor.\nTras detectar los targets creados en el servidor y compartidos con el cliente, estos se muestran en la lista de destinos detectados. Para conectarse al target hay que seleccionarlo y pulsar el botón \u0026ldquo;conectar\u0026rdquo;.\nEste botón abre una ventana emergente en la que se establece la conexión al servidor SAN. En esta ventana hay que seleccionar las opciones avanzadas y marcar la casilla de autenticación CHAP. Igualmente, es necesario indicar también el nombre de usuario y la contraseña que se han establecido para este target en la configuración del servidor. El cliente iscsi de Windows requiere que estas contraseñas tengan una longitud de, al menos, 12 caracteres.\nTras establecer la conexión, en la herramienta de administración de discos ya aparecen los dos volúmenes asociados al target compartido por el servidor. Desde esta herramienta se pueden formatear y montar en el cliente Windows.\nEn este caso se formatean como dos nuevos volúmenes simples identificados por las letras E: y F:. Tras montarlos y formatearlos ya son accesibles y utilizables desde el cliente y se puede comenzar a almacenar ficheros en ellos.\n"},{
  "section": "Blog",
  "slug": "/blog/implantacion-aplicaciones-web/2024-11-10-configuracion-protoclo-https-acceso-aplicacion-web/",
  "title": "Configuración del protocolo HTTPS para el acceso a una aplicación web",
  "description": "",
  "date": "November 10, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "implantacion",
  "tags": "HTTPS, Apache2, Let's Encrypt, Certbot, Nginx, servidor web, implantacion, LEMP, Implantación de Aplicaciones Web",
  "content":"Solicitud de los certificados con Let\u0026rsquo;s Encrypt Para solicitar un certificado se usa la herramienta Certbot.\nsudo apt install certbot Para solicitar un certificado de tipo comodín (para todos los virtual hosts de un dominio) se debe usar la opción manual del modo certonly.\nsudo certbot certonly --manual -d *.javihuete.site La salida de este comando indica un registro DNS de tipo TXT que se debe añadir en nuestro DNS. Tras verificar nuestra identidad a través de este método se recibe el certificado en el VPS.\nEste tipo de certificación no habilita la renovación automática en el servidor web, así que antes de que expire el certificado se debe renovar de forma manual.\nNEXT STEPS: - This certificate will not be renewed automatically. Autorenewal of --manual certificates requires the use of an authentication hook script (--manual-auth-hook) but one was not provided. To renew this certificate, repeat this same certbot command before the certificate\u0026#39;s expiry date. Configuración de HTTPS en Nginx La configuración HTTPS de las aplicaciones desplegadas en el servidor web de Nginx se puede establecer para todos los virtual host en el fichero /etc/nginx/conf.d/default.conf o en cada uno de los ficheros de configuración de cada virtual host en /etc/nginx/sites-available.\nEn el fichero de configuración se sustituyen las líneas que indicaban que el virtual host escucha por el puerto 80 por estas líneas que hacen que escuche por el puerto 443 y habilita así la conexión https.\nserver { listen 443 ssl; server_name www.javihuete.site; ssl_certificate /etc/letsencrypt/live/javihuete.site/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/javihuete.site/privkey.pem; ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers HIGH:!aNULL:!MD5; ...; } Para evitar errores en el acceso por HTTP se puede añadir una redirección desde el puerto 80 al 443 en el mismo virtualhost o en otro dedicado exclusivamente a esta redirección\nserver { listen 80; server_name www.javihuete.site; server_tokens off; return 301 https://$server_name$request_uri; } Solución de errores Si en la configuración de la aplicación web se especifica la URL base de la aplicación, puede ser necesario cambiar el valor de este parámetro para que la aplicación use, por defecto, https en vez de http.\nPor ejemplo, en el caso de Moodle, en el fichero /var/www/moodle/config.php hay que hacer este tipo de modificación.\n$CFG-\u0026gt;wwwroot = \u0026#39;https://www.javihuete.site\u0026#39;; $CFG-\u0026gt;dataroot = \u0026#39;/var/www/moodledata\u0026#39;; "},{
  "section": "Blog",
  "slug": "/blog/servicios/2024-11-10-funcionamiento-basico-ansible/",
  "title": "Funcionamiento básico de ansible",
  "description": "",
  "date": "November 10, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "servicios",
  "tags": "Ansible, Dev-Ops, Infraestructura como código, Orquestación, Administración de Sistemas, servicios, Servicios de Red e Internet",
  "content":"Instalación de Ansible Ansible se puede instalar desde los repositorios de Debian\nsudo apt install ansible Preparación de la máquina En este ejemplo se usa una máquina virtual con un usuario sin privilegios que puede acceder por ssh y que puede usar sudo sin indicar la contraseña.\nFicheros de configuración Inventario Incluye una declaración de los grupos y máquinas que se van a configurar y algunas variables para identificarlas.\nall: children: servidores: hosts: ansible: ansible_ssh_host: 172.22.200.46 ansible_ssh_user: debian ansible_ssh_private_key_file: /home/javi/.ssh/id_rsa Fichero de configuración En él se indica la ruta al fichero de inventario.\n[defaults] inventory = hosts host_key_checking = False El parámetro host_key_checking = False evita los mensajes de advertencia cuando se reutilizan direcciones IP.\nProbar conexión Para probar la conexión a una máquina Ansible usa el módulo ping.\nansible -m ping all ansible | SUCCESS =\u0026gt; { \u0026#34;ansible_facts\u0026#34;: { \u0026#34;discovered_interpreter_python\u0026#34;: \u0026#34;/usr/bin/python3\u0026#34; }, \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } Actualizar el playbook El playbook es el fichero que contiene las reglas que ejecuta ansible en la máquina objetivo.\nEn este caso, Ansible actualiza el sistema de paquetes, instala git y apache2, copia un fichero a la máquina remota, copia una plantilla al directorio /var/www/html.\n- hosts: all become: true tasks: # Actualizamos paquetes - name: Actualizamos el sistema apt: update_cache=yes upgrade=yes # Instalar paquetes - name: \u0026#34;Instalar paquetes con apt\u0026#34; ansible.builtin.apt: pkg: - apache2 - git # Copia un fichero a la máquina remota - name: \u0026#34;Copiar fichero a la máquina remota\u0026#34; copy: src: files/foo.conf dest: /etc/ owner: root group: root mode: \u0026#39;0644\u0026#39; # Copia un template a un fichero - name: \u0026#34;Copiar un tamplate a un fichero de la máquina remota\u0026#34; template: src: template/index.j2 dest: /var/www/html/index.html owner: www-data group: www-data mode: 0644 Ejecutar el playbook ansible-playbook site.yaml "},{
  "section": "Blog",
  "slug": "/blog/administracion-de-sistemas/2024-12-02-trabajo-kernel-linux/",
  "title": "Trabajo con el kernel de Linux",
  "description": "",
  "date": "November 2, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "administracion-sistemas",
  "tags": "sistemas, debian, linux, kernel, apt, paquetes, comandos, administracion-sistemas, Administración de Sistemas Operativos",
  "content":"Trabajo con kernel Linux Actualizar el kernel a través del gestor de paquetes Ver la versión actual del kernel\n❯ uname -r 6.1.0-25-amd64 Comprobar las versiones disponibles del kernel\n❯ apt policy linux-image-amd64 linux-image-amd64: Installed: (none) Candidate: 6.10.11-1 Version table: 6.10.11-1 500 500 http://deb.debian.org/debian testing/main amd64 Packages 6.1.106-3 500 500 http://deb.debian.org/debian bookworm/main amd64 Packages Ver los kerneles instalados en el sistema\n❯ dpkg --list | grep linux-image ii linux-image-6.1.0-25-amd64 6.1.106-3 amd64 Linux 6.1 for 64-bit PCs (signed) Instalar el kernel\n❯ sudo apt policy linux-image-amd64 Tras reiniciar el equipo, el sistema carga el nuevo kernel recién instalado.\nPara desinstalar el kernel se debe arrancar el equipo con un kernel diferente al que se desinstala y, posteriormente, desinstalarlo desde el gestor de paquetes.\n❯ sudo apt remove --purge linux-image-6.10.11-amd64 La instalación de un kernel genera los ficheros config, initrd.img y vmlinuz en el directorio /boot/.\n❯ ls -l /boot/ total 47244 -rw-r--r-- 1 root root 259508 Aug 26 21:47 config-6.1.0-25-amd64 drwxr-xr-x 5 root root 4096 Oct 8 13:27 grub -rw-r--r-- 1 root root 39925056 Oct 4 09:30 initrd.img-6.1.0-25-amd64 -rw-r--r-- 1 root root 83 Aug 26 21:47 System.map-6.1.0-25-amd64 -rw-r--r-- 1 root root 8177600 Aug 26 21:47 vmlinuz-6.1.0-25-amd64 Compilar el kernel desde el código fuente Descargar el código fuente\n❯ wget https://cdn.kernel.org/pub/linux/kernel/v6.x/linux-6.11.2.tar.xz Es un archivo pesado que tarda más de 30 segundos en descomprimirse.\n❯ time tar -xf linux-6.11.2.tar.xz real\t0m32.098s user\t0m13.602s sys\t0m7.698s El directorio generado tras descomprimir el archivo contiene múltiples ficheros .c y .h con el código fuente del kernel. En total son casi 60.000 ficheros de código fuente. Además, se puede contar el número de líneas de código fuente que componen el kernel.\n❯ find . -iname \u0026#34;*.[ch]\u0026#34; | wc -l 59558 ❯ find . -iname \u0026#34;*.[ch]\u0026#34; -exec cat {} \\; | grep \u0026#34;[;|#]\u0026#34; | wc -l 15863403 "},{
  "section": "Blog",
  "slug": "/blog/administracion-bases-de-datos/2024-10-21-instalacion-mysql-debian/",
  "title": "Instalación de MySQL en Debian",
  "description": "",
  "date": "October 21, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "administracion-bbdd",
  "tags": "bases de datos, mysql, Debian 12, bookworm, instalacion, Oracle, administracion-bbdd, Administración de Sistemas Gestores de Bases de Datos",
  "content":"Instalación MySQL en Debian 12 En teoría MySQL se puede instalar de forma directa desde los repositorios de Debian. Sin embargo, el gestor de paquetes apt no tiene acceso al paquete mysql-server a través del repositorio de la rama estable (bookworm) de Debian. Oracle ofrece un paquete .deb instalable en su web de descargas, que hay que configurar para que el gestor de paquetes apt pueda instalar la versión deseada de MySQL. El paquete que ofrece Oracle instala tanto el servidor como el cliente en la misma máquina.\nusuario@mysql:~$ wget https://dev.mysql.com/get/mysql-apt-config_0.8.32-1_all.deb usuario@mysql:~$ sudo dpkg -i mysql-apt-config_0.8.32-1_all.deb Al ejecutar la instalación comienza un proceso interactivo en el que se deben elegir las diferentes opciones de configuración del paquete. En primer lugar, hay que indicar el producto que se va a configurar durante la instalación, en este caso, el servidor MySQL. Posteriormente, hay que indicar la versión para la instalación. En este caso se elige la versión 8.4, que es la versión estable con soporte a largo plazo actualmente.\nTras configurar estas dos opciones en el paquete, hay que salir del menú interactivo y ejecutar una actualización de la paquetería del sistema. Posteriormente se instala el paquete mysql-server con el gestor de paquetes apt.\nusuario@mysql:~$ sudo apt update usuario@mysql:~$ sudo apt install mysql-server Este proceso de instalación también es interactivo. En él hay que indicar la contraseña del usuario root del SGBD. La configuración del acceso remoto a este servidor se realiza en el fichero /etc/mysql/mysql.conf.d/mysqld.cnf añadiendo la siguiente línea.\nbind-address = 0.0.0.0 En versiones posteriores a la 8.0, esta línea no aparece por defecto en el fichero de configuración y se debe añadir dentro de la sección [mysqld]. Para hacer efectiva la configuración se reinicia el servicio.\nMientras que Postgres permite especificar la conexión remota desde una IP concreta o desde una red, el fichero de configuración de MySQL sólo permite indicar si la conexión será desde la máquina local o desde cualquier otra IP.\nPara evitar el acceso de máquinas que no estén conectadas a la red local es necesario añadir una regla de cortafuegos en el servidor.\nusuario@mysql:~$ sudo iptables -A INPUT -s 192.168.122.0/24 -p tcp --destination-port 3306 -j ACCEPT usuario@mysql:~$ sudo iptables -A INPUT -p tcp --destination-port 3306 -j DROP Con la primera regla se permite el tráfico dirigido al puerto 3306, por el que escucha MySQL siempre que la IP de destino sea una IP de la red local. Con la siguiente regla se impide el paso de cualquier otra comunicación dirigida a ese puerto. Para hacer persistente esta configuración se usa el paquete iptables-persistent.\nroot@mysql:~$ iptables-save \u0026gt;\u0026gt; /etc/iptables/rules.v4 Con esta configuración cualquier cliente de la red local puede acceder de forma remota al servidor MySQL instalado en esta máquina. Para ello, el cliente necesita una herramienta que le permita conectarse al servidor como, por ejemplo, mysql-client. Para instalarlo hay que seguir un procedimiento similar al de la instalación del servidor. En primer lugar, se descarga e instala el paquete para la configuración del respositorio de MySQL, disponible en su web de descargas. Posteriormente, se actualiza la paquetería del sistema y, por último, se instala el paquete mysql-cliente, que cuenta con la herramienta cliente para acceder de manera remota al servidor MySQL.\nusuario@clientesBBDD:~$ wget https://dev.mysql.com/get/mysql-apt-config_0.8.32-1_all.deb usuario@clientesBBDD:~$ sudo dpkg -i mysql-apt-config_0.8.32-1_all.deb usuario@clientesBBDD:~$ sudo apt update usuario@clientesBBDD:~$ sudo apt install mysql-client Es posible que durante la instalación del cliente, como ocurre en el caso del servidor, haya que instalar algunas dependencias de forma sencilla con el gestor de paquetes APT. Finalmente, tras concluir el proceso, el cliente puede acceder de forma remota al servidor.\nusuario@clientesBBDD:~$ mysql -h 192.168.122.47 -u usuario -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 15 Server version: 8.4.2 MySQL Community Server - GPL Copyright (c) 2000, 2024, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. mysql\u0026gt; "},{
  "section": "Blog",
  "slug": "/blog/administracion-de-sistemas/2024-09-30-conceptos-basicos-apt/",
  "title": "Conceptos de gestión de paquetería en Debian",
  "description": "",
  "date": "September 30, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "administracion-sistemas",
  "tags": "sistemas, debian, linux, apt, dpkg, paquetes, comandos, administracion-sistemas, Administración de Sistemas Operativos",
  "content":"Trabajo con apt, aptitude, dpkg Qué acciones consigo al realizar apt update y apt upgrade El comando apt update revisa los repositorios del sistema operativo en busca de nuevas versiones de los paquetes instalados en el equipo. Posteriormente, el comando apt upgrade ejecuta la actualización de aquellos paquetes de los que haya una versión más reciente disponible.\nAntes de instalar un nuevo paquete o de actualizar a su versión más reciente, el gestor de paquetes apt consulta el fichero Releases del repositorio para comprobar que el hash corresponde al del propio paquete y garantizar así que no ha sido modificado desde que se distribuye por parte del mantenedor hasta que llega al equipo del usuario.\nLista la relación de paquetes que pueden ser actualizados. ¿Qué información puedes sacar a tenor de lo mostrado en el listado? Los paquetes que pueden ser actualizados se consultan con el comando apt list --upgradable. La salida de este comando devuelve el nombre del paquete junto a otra información relevante como la rama del SO a la que pertenece el paquete, la versión, la fecha de actualización, etc.\nIndica la versión instalada, candidata así como la prioridad del paquete openssh-client La versión instalada de openssh-client en mi equipo es la 1:9.2p1-2+deb12u3 y la candidata es la misma versión, lo que quiere decir que el paquete está actualizado en el equipo. La prioridad de este paquete es de 500 desde los repositorios de debian, es decir, el gestor de paquetería instala el paquete si no hay una versión disponible en la rama principal o si no hay una versión más reciente instalada.\n❯ apt policy openssh-client openssh-client: Instalados: 1:9.2p1-2+deb12u3 Candidato: 1:9.2p1-2+deb12u3 Tabla de versión: *** 1:9.2p1-2+deb12u3 500 500 http://deb.debian.org/debian bookworm/main amd64 Packages 100 /var/lib/dpkg/status ¿Cómo puedes sacar información de un paquete oficial instalado o que no este instalado? Para obtener información de un paquete instalado en el equipo la fuente más completa suele ser el manual, al que se puede acceder con el comando man seguido del nombre del paquete. Si el paquete no está instalado en el equipo aún se puede consultar información acerca de él a través de comandos como apt show, que muestra el nombre del paquete, la versión más reciente, la prioridad, la sección a la que pertenece, el nombre y contacto del mantenedor, el tamaño que ocupa una vez instalado, así como sus dependencias, paquetes recomendados y sugeridos. Además, también muestra información sobre la fuente del repositorio desde la que apt descarga el paquete y una pequeña descripción de lo que hace la herramienta.\nSaca toda la información que puedas del paquete openssh-client que tienes actualmente instalado en tu máquina De forma resumida, se puede acceder a una información básica muy útil sobre el paquete openssh-client con el comando apt-show openssh-client:\n❯ apt show openssh-client Package: openssh-client Version: 1:9.2p1-2+deb12u3 Priority: standard Section: net Source: openssh Maintainer: Debian OpenSSH Maintainers \u0026lt;debian-ssh@lists.debian.org\u0026gt; Installed-Size: 5.919 kB Provides: ssh-client Depends: adduser, passwd, libc6 (\u0026gt;= 2.36), libedit2 (\u0026gt;= 2.11-20080614-0), libfido2-1 (\u0026gt;= 1.8.0), libgssapi-krb5-2 (\u0026gt;= 1.17), libselinux1 (\u0026gt;= 3.1~), libssl3 (\u0026gt;= 3.0.13), zlib1g (\u0026gt;= 1:1.1.4) Recommends: xauth Suggests: keychain, libpam-ssh, monkeysphere, ssh-askpass Conflicts: sftp Breaks: openssh-sk-helper Replaces: openssh-sk-helper, ssh, ssh-krb5 Homepage: https://www.openssh.com/ Tag: implemented-in::c, interface::commandline, interface::shell, network::client, protocol::sftp, protocol::ssh, role::program, security::authentication, security::cryptography, uitoolkit::ncurses, use::login, use::transmission, works-with::file Download-Size: 991 kB APT-Manual-Installed: yes APT-Sources: http://deb.debian.org/debian bookworm/main amd64 Packages Description: Cliente del protocolo \u0026#34;Secure Shell\u0026#34; (SSH) para acceso seguro a máquinas remotas Esta es la versión adaptable de OpenSSH, una implementación libre del protocolo «Secure Shell» como especifica el grupo de trabajo secsh del IETF. . Ssh (Secure Shell) es una aplicación para acceder y ejecutar comandos en una máquina remota. Provee conexiones encriptadas y seguras entre dos huéspedes no certificados en una red sin seguridad. Las conexiones a través de X11 y puertos arbitrarios TCP/IP también pueden ser transportados a un canal seguro. Puede ser usado para proveer a las aplicaciones de un canal de comunicación seguro. . Este paquete proporciona los clientes de ssh, scp y sftp, los programas sh-agent y ssh-add para hacer más comoda la autenticación de clave pública, y las utilidades ssh-keygen, ssh-keyscan, ssh-copy-id y ssh-argv0. . En algunos países puede ser ilegal utilizar cualquier tipo de cifrado sin un permiso especial. . ssh reemplaza a las aplicaciones no seguras rsh, rcp y rlogin, obsoletas para la mayoría de los propósitos. La salida de este comando devuelve información como el nombre del paquete (openssh-client), la versión más reciente (1:9.2p1-2+deb12u3), la prioridad para la instalación (standard), la sección del SO a la que pertenece (red), la fuente (openssh), el mantenedor (el equipo de mantenedores de OpenSSH de Debian), el tamaño del paquete instalado (5.919 kB), la herramienta que ofrece (ssh-client), los paquetes de los que depende (adduser, passwd, libc6 (\u0026gt;= 2.36), libedit2 (\u0026gt;= 2.11-20080614-0), libfido2-1 (\u0026gt;= 1.8.0), libgssapi-krb5-2 (\u0026gt;= 1.17), libselinux1 (\u0026gt;= 3.1~), libssl3 (\u0026gt;= 3.0.13), zlib1g (\u0026gt;= 1:1.1.4)), los paquetes cuya instalación recomienda (xauth), los paquetes cuya instalación sugiere (keychain, libpam-ssh, monkeysphere, ssh-askpass), los paquetes con los que pueden generarse conflictos (sftp), los paquetes que rompe (openssh-sk-helper) y los paquetes que reemplaza (openssh-sk-helper, ssh, ssh-krb5), así como la web del proyecto (https://www.openssh.com/), algunas etiquetas para identificar el paquete, el tamaño de la descarga (991 kB), si el manual está instalado (en este caso, sí), la fuente del repositorio (http://deb.debian.org/debian bookworm/main amd64 Packages) y la descripción del paquete.\nSe puede acceder a una información mucho más extensa de la herramienta a través del comando man ssh.\nAdemás, parte de la información recogida en la salida del comando apt show se puede acceder de otras formas. Por ejemplo, para conseguir la información sobre los paquetes de los que depende openssh-client se puede ejecutar el comando apt depends openssh-client.\n❯ apt depends openssh-client openssh-client Depende: adduser Depende: passwd Depende: libc6 (\u0026gt;= 2.36) Depende: libedit2 (\u0026gt;= 2.11-20080614-0) Depende: libfido2-1 (\u0026gt;= 1.8.0) Depende: libgssapi-krb5-2 (\u0026gt;= 1.17) Depende: libselinux1 (\u0026gt;= 3.1~) Depende: libssl3 (\u0026gt;= 3.0.13) Depende: zlib1g (\u0026gt;= 1:1.1.4) Entra en conflicto: \u0026lt;sftp\u0026gt; Rompe: \u0026lt;openssh-sk-helper\u0026gt; Recomienda: xauth Sugiere: keychain Sugiere: \u0026lt;libpam-ssh\u0026gt; Sugiere: \u0026lt;monkeysphere\u0026gt; Sugiere: ssh-askpass ksshaskpass kwalletcli lxqt-openssh-askpass ssh-askpass-fullscreen ssh-askpass-gnome Reemplaza: \u0026lt;openssh-sk-helper\u0026gt; Reemplaza: ssh Reemplaza: \u0026lt;ssh-krb5\u0026gt; Una información a la que no se puede acceder a través de apt show es la de las dependencias inversas del paquete. En este caso, con el comando apt rdepends openssh-client se puede obtener esta lista de paquetes que dependen del propio openssh-client.\n❯ apt rdepends openssh-client openssh-client Reverse Depends: Reemplaza: openssh-server (\u0026lt;\u0026lt; 1:7.9p1-8) Depende: arb |Depende: zssh Recomienda: xpra Depende: xen-tools Depende: x2goserver Depende: x2goclient |Recomienda: waypipe Recomienda: vorta Depende: vagrant Recomienda: unison-2.52-gtk Recomienda: unison-2.52 Recomienda: unison-2.51+4.13.1-gtk Recomienda: unison-2.51+4.13.1 Recomienda: tsung Depende: python3-tomahawk Sugiere: tla Recomienda: task-ssh-server |Depende: taktuk Recomienda: python3-jarabe Depende: ssvnc |Depende: sshuttle Depende: sshfs Depende: ssh-tools Depende: ssh-import-id Depende: ssh-cron Depende: ssh-contact-client Depende: ssh-agent-filter Depende: snapd Sugiere: smokeping Sugiere: slack |Recomienda: sisu Recomienda: simple-tpm-pk11 Depende: sidedoor Depende: secpanel Recomienda: seahorse Depende: python3-sahara-plugin-vanilla Depende: python3-sahara-plugin-spark Sugiere: rsync |Recomienda: rsnapshot Recomienda: rsbackup-graph Recomienda: rsbackup |Depende: rancid Depende: pssh |Depende: pkg-perl-tools Depende: piuparts-slave-from-git-deps Depende: piuparts-slave Recomienda: pdudaemon |Depende: pdsh Depende: python3-parallax Depende: oz Recomienda: ostree-push Depende: openstack-cluster-installer-openstack-ci Recomienda: openssh-known-hosts |Depende: ssh-askpass-gnome Depende: ssh (\u0026gt;= 1:9.2p1-2+deb12u3) Depende: openssh-tests (= 1:9.2p1-2+deb12u3) Depende: openssh-sftp-server (= 1:9.2p1-2+deb12u3) Depende: openssh-server (= 1:9.2p1-2+deb12u3) Depende: git-annex (\u0026gt;= 1:5.6p1) |Depende: openmpi-bin Sugiere: oar-user Depende: oar-server Depende: oar-node Depende: python3-nova Depende: network-manager-ssh Depende: mussh Depende: mssh Depende: mosh Recomienda: mercurial |Recomienda: lxsession Sugiere: lsh-server Depende: live-task-standard Recomienda: live-task-recommended Depende: libnetapp-perl |Depende: libnet-ssh-perl |Depende: libnet-sftp-foreign-perl |Depende: libnet-scp-perl Depende: libnet-openssh-perl Depende: libguestfs0 Mejora: libconfig-model-openssh-perl Recomienda: lftp Recomienda: lava-server Depende: lava |Depende: lam-runtime Recomienda: python3-labgrid Recomienda: kwalletcli Depende: ksshaskpass |Depende: keychain Recomienda: hollywood Depende: hash-slinger Depende: gitolite3 Rompe: git (\u0026lt;\u0026lt; 1:6.8) |Depende: ansible Depende: ganeti-3.0 |Sugiere: gabedit |Sugiere: gabedit |Depende: fssync Recomienda: freedombox Recomienda: fence-agents Recomienda: fdroidserver Recomienda: fai-server Sugiere: duply |Recomienda: dupload Sugiere: dropbear-bin Recomienda: python3-dput Sugiere: dput |Recomienda: dish Recomienda: diffoscope-minimal Recomienda: diffoscope Recomienda: debvm Sugiere: debian-goodies Recomienda: cvs Depende: cockpit-tests Depende: clusterssh Sugiere: clonezilla |Recomienda: ckermit Mejora: chkrootkit Depende: ceph-mgr-cephadm Recomienda: btrbk Recomienda: barman-cli Recomienda: barman |Recomienda: backuppc Sugiere: backup-manager Depende: backintime-common Mejora: autossh |Depende: autossh Depende: apt-dater |Depende: ansible-core Finalmente, cabe destacar que con el comando apt-rdepends openssh-client se puede obtener información recursiva sobre las dependencias del paquete, es decir, se puede conocer de qué paquetes dependen aquellos paquetes de los que, a su vez, depende openssh-client.\n❯ apt-rdepends openssh-client Reading package lists... Done Building dependency tree... Done Reading state information... Done openssh-client Depends: adduser Depends: libc6 (\u0026gt;= 2.36) Depends: libedit2 (\u0026gt;= 2.11-20080614-0) Depends: libfido2-1 (\u0026gt;= 1.8.0) Depends: libgssapi-krb5-2 (\u0026gt;= 1.17) Depends: libselinux1 (\u0026gt;= 3.1~) Depends: libssl3 (\u0026gt;= 3.0.13) Depends: passwd Depends: zlib1g (\u0026gt;= 1:1.1.4) adduser Depends: passwd passwd Depends: libaudit1 (\u0026gt;= 1:2.2.1) Depends: libc6 (\u0026gt;= 2.36) Depends: libcrypt1 (\u0026gt;= 1:4.1.0) Depends: libpam-modules Depends: libpam0g (\u0026gt;= 0.99.7.1) Depends: libselinux1 (\u0026gt;= 3.1~) Depends: libsemanage2 (\u0026gt;= 2.0.32) libaudit1 Depends: libaudit-common (\u0026gt;= 1:3.0.9-1) Depends: libc6 (\u0026gt;= 2.33) Depends: libcap-ng0 (\u0026gt;= 0.7.9) libaudit-common libc6 Depends: libgcc-s1 libgcc-s1 Depends: gcc-12-base (= 12.2.0-14) Depends: libc6 (\u0026gt;= 2.35) gcc-12-base libcap-ng0 Depends: libc6 (\u0026gt;= 2.33) libcrypt1 Depends: libc6 (\u0026gt;= 2.36) libpam-modules PreDepends: debconf (\u0026gt;= 0.5) PreDepends: debconf-2.0 PreDepends: libaudit1 (\u0026gt;= 1:2.2.1) PreDepends: libc6 (\u0026gt;= 2.34) PreDepends: libcrypt1 (\u0026gt;= 1:4.3.0) PreDepends: libdb5.3 PreDepends: libpam-modules-bin (= 1.5.2-6+deb12u1) PreDepends: libpam0g (\u0026gt;= 1.4.1) PreDepends: libselinux1 (\u0026gt;= 3.1~) debconf debconf-2.0 libdb5.3 Depends: libc6 (\u0026gt;= 2.34) libpam-modules-bin Depends: libaudit1 (\u0026gt;= 1:2.2.1) Depends: libc6 (\u0026gt;= 2.34) Depends: libcrypt1 (\u0026gt;= 1:4.3.0) Depends: libpam0g (\u0026gt;= 0.99.7.1) Depends: libselinux1 (\u0026gt;= 3.1~) libpam0g Depends: debconf (\u0026gt;= 0.5) Depends: debconf-2.0 Depends: libaudit1 (\u0026gt;= 1:2.2.1) Depends: libc6 (\u0026gt;= 2.34) libselinux1 Depends: libc6 (\u0026gt;= 2.34) Depends: libpcre2-8-0 (\u0026gt;= 10.22) libpcre2-8-0 Depends: libc6 (\u0026gt;= 2.34) libsemanage2 Depends: libaudit1 (\u0026gt;= 1:2.2.1) Depends: libbz2-1.0 Depends: libc6 (\u0026gt;= 2.34) Depends: libselinux1 (\u0026gt;= 3.4) Depends: libsemanage-common (\u0026gt;= 3.4-1) Depends: libsepol2 (\u0026gt;= 3.4) libbz2-1.0 Depends: libc6 (\u0026gt;= 2.4) libsemanage-common libsepol2 Depends: libc6 (\u0026gt;= 2.33) libedit2 Depends: libbsd0 (\u0026gt;= 0.1.3) Depends: libc6 (\u0026gt;= 2.33) Depends: libtinfo6 (\u0026gt;= 6) libbsd0 Depends: libc6 (\u0026gt;= 2.34) Depends: libmd0 (\u0026gt;= 1.0.3-2) libmd0 Depends: libc6 (\u0026gt;= 2.33) libtinfo6 Depends: libc6 (\u0026gt;= 2.34) libfido2-1 Depends: libc6 (\u0026gt;= 2.36) Depends: libcbor0.8 (\u0026gt;= 0.8.0) Depends: libssl3 (\u0026gt;= 3.0.0) Depends: libudev1 (\u0026gt;= 183) Depends: zlib1g (\u0026gt;= 1:1.1.4) libcbor0.8 Depends: libc6 (\u0026gt;= 2.14) libssl3 Depends: libc6 (\u0026gt;= 2.34) libudev1 Depends: libc6 (\u0026gt;= 2.34) zlib1g Depends: libc6 (\u0026gt;= 2.14) libgssapi-krb5-2 Depends: libc6 (\u0026gt;= 2.33) Depends: libcom-err2 (\u0026gt;= 1.43.9) Depends: libk5crypto3 (\u0026gt;= 1.20) Depends: libkrb5-3 (= 1.20.1-2+deb12u2) Depends: libkrb5support0 (\u0026gt;= 1.15~beta1) libcom-err2 Depends: libc6 (\u0026gt;= 2.17) libk5crypto3 Depends: libc6 (\u0026gt;= 2.33) Depends: libkrb5support0 (\u0026gt;= 1.20) libkrb5support0 Depends: libc6 (\u0026gt;= 2.34) libkrb5-3 Depends: libc6 (\u0026gt;= 2.34) Depends: libcom-err2 (\u0026gt;= 1.43.9) Depends: libk5crypto3 (\u0026gt;= 1.20) Depends: libkeyutils1 (\u0026gt;= 1.5.9) Depends: libkrb5support0 (= 1.20.1-2+deb12u2) Depends: libssl3 (\u0026gt;= 3.0.0) libkeyutils1 Depends: libc6 (\u0026gt;= 2.14) Saca toda la información que puedas del paquete openssh-client candidato a actualizar en tu máquina En caso de que el paquete no estuviese instalado, el comando apt show también mostraría toda la información relativa al paquete de la versión candidata a la actualización. Para conocer la versión candidata se puede ejecutar apt policy openssh-client.\n❯ apt policy openssh-client openssh-client: Instalados: 1:9.2p1-2+deb12u3 Candidato: 1:9.2p1-2+deb12u3 Tabla de versión: *** 1:9.2p1-2+deb12u3 500 500 http://deb.debian.org/debian bookworm/main amd64 Packages 100 /var/lib/dpkg/status Para conocer más información sobre diferentes versiones de un mismo paquete se puede usar también el comando rmadison, que muestra información sobre la versión de un paquete disponibles para las ramas del SO desde la oldoldstable hasta la unstable.\n❯ rmadison openssh-client openssh-client | 1:7.9p1-10+deb10u2 | oldoldstable | amd64, arm64, armhf, i386 openssh-client | 1:8.4p1-2~bpo10+1 | buster-backports | amd64, arm64, armel, armhf, i386, mips, mips64el, mipsel, ppc64el, s390x openssh-client | 1:8.4p1-5+deb11u3 | oldstable | amd64, arm64, armel, armhf, i386, mips64el, mipsel, ppc64el, s390x openssh-client | 1:9.2p1-2+deb12u3 | stable | amd64, arm64, armel, armhf, i386, mips64el, mipsel, ppc64el, s390x openssh-client | 1:9.8p1-8 | testing | amd64, arm64, armel, armhf, i386, mips64el, ppc64el, riscv64, s390x openssh-client | 1:9.9p1-1 | unstable | amd64, arm64, armel, armhf, i386, mips64el, ppc64el, riscv64, s390x Por tanto, la versión candidata para la instalación del paquete depende de las ramas cuyos repositorios estén presentes en el fichero sources.list, así como de la configuración de la preferencia de cada uno de estos repositorios.\nEn este caso, la versión instalada y la candidata coinciden porque en el fichero sources.list sólo se recoge el repositorio de la rama stable de Debian12 pero si se incorporasen los repositorios de otras ramas como la backports o la testing, la versión candidata sería posterior a la instalada.\nLista todo el contenido referente al paquete openssh-client actual de tu máquina. Utiliza para ello tanto dpkg como apt Con el comando dpkg -L openssh-client se puede conocer la ubicación en el sistema de todos los ficheros que forman parte del paquete.\n❯ dpkg -L openssh-client /. /etc /etc/ssh /etc/ssh/ssh_config /etc/ssh/ssh_config.d /usr /usr/bin /usr/bin/scp /usr/bin/sftp /usr/bin/ssh /usr/bin/ssh-add /usr/bin/ssh-agent /usr/bin/ssh-argv0 /usr/bin/ssh-copy-id /usr/bin/ssh-keygen /usr/bin/ssh-keyscan /usr/lib /usr/lib/openssh /usr/lib/openssh/agent-launch /usr/lib/openssh/ssh-keysign /usr/lib/openssh/ssh-pkcs11-helper /usr/lib/openssh/ssh-sk-helper /usr/lib/systemd /usr/lib/systemd/user /usr/lib/systemd/user/graphical-session-pre.target.wants /usr/lib/systemd/user/ssh-agent.service /usr/share /usr/share/apport /usr/share/apport/package-hooks /usr/share/apport/package-hooks/openssh-client.py /usr/share/doc /usr/share/doc/openssh-client /usr/share/doc/openssh-client/NEWS.Debian.gz /usr/share/doc/openssh-client/OVERVIEW.gz /usr/share/doc/openssh-client/README /usr/share/doc/openssh-client/README.Debian.gz /usr/share/doc/openssh-client/README.dns /usr/share/doc/openssh-client/README.tun.gz /usr/share/doc/openssh-client/changelog.Debian.gz /usr/share/doc/openssh-client/changelog.gz /usr/share/doc/openssh-client/copyright /usr/share/lintian /usr/share/lintian/overrides /usr/share/lintian/overrides/openssh-client /usr/share/man /usr/share/man/man1 /usr/share/man/man1/scp.1.gz /usr/share/man/man1/sftp.1.gz /usr/share/man/man1/ssh-add.1.gz /usr/share/man/man1/ssh-agent.1.gz /usr/share/man/man1/ssh-argv0.1.gz /usr/share/man/man1/ssh-copy-id.1.gz /usr/share/man/man1/ssh-keygen.1.gz /usr/share/man/man1/ssh-keyscan.1.gz /usr/share/man/man1/ssh.1.gz /usr/share/man/man5 /usr/share/man/man5/ssh_config.5.gz /usr/share/man/man8 /usr/share/man/man8/ssh-keysign.8.gz /usr/share/man/man8/ssh-pkcs11-helper.8.gz /usr/share/man/man8/ssh-sk-helper.8.gz /usr/bin/slogin /usr/lib/systemd/user/graphical-session-pre.target.wants/ssh-agent.service /usr/share/man/man1/slogin.1.gz Esta salida se puede filtrar con el comando grep para mostrar únicamente aquellos binarios que se incluyen en el paquete.\n❯ dpkg -L openssh-client | grep bin /usr/bin /usr/bin/scp /usr/bin/sftp /usr/bin/ssh /usr/bin/ssh-add /usr/bin/ssh-agent /usr/bin/ssh-argv0 /usr/bin/ssh-copy-id /usr/bin/ssh-keygen /usr/bin/ssh-keyscan /usr/bin/slogin Con herramientas del gestor de paquetes apt se puede acceder a información recogida en ejercicios anteriores usando, por ejemplo, el comando apt show, apt depends para conocer las dependencias del paquete, apt rdepends para conocer las dependencias inversas o apt-rdepends para conocer las dependencias de forma recursiva.\nListar el contenido de un paquete sin la necesidad de instalarlo o descargarlo Para listar el contenido de un paquete independientemente de si está o no instalado en el sistema se puede usar el comando apt-file find.\n❯ apt-file find openssh-client openssh-client: /usr/share/apport/package-hooks/openssh-client.py openssh-client: /usr/share/doc/openssh-client/NEWS.Debian.gz openssh-client: /usr/share/doc/openssh-client/OVERVIEW.gz openssh-client: /usr/share/doc/openssh-client/README openssh-client: /usr/share/doc/openssh-client/README.Debian.gz openssh-client: /usr/share/doc/openssh-client/README.dns openssh-client: /usr/share/doc/openssh-client/README.tun.gz openssh-client: /usr/share/doc/openssh-client/changelog.Debian.gz openssh-client: /usr/share/doc/openssh-client/changelog.gz openssh-client: /usr/share/doc/openssh-client/copyright openssh-client: /usr/share/lintian/overrides/openssh-client openssh-client-ssh1: /usr/share/doc/openssh-client-ssh1/NEWS.Debian.gz openssh-client-ssh1: /usr/share/doc/openssh-client-ssh1/README openssh-client-ssh1: /usr/share/doc/openssh-client-ssh1/README.Debian.gz openssh-client-ssh1: /usr/share/doc/openssh-client-ssh1/changelog.Debian.gz openssh-client-ssh1: /usr/share/doc/openssh-client-ssh1/changelog.gz openssh-client-ssh1: /usr/share/doc/openssh-client-ssh1/copyright openssh-server: /usr/share/doc/openssh-client/examples/ssh-session-cleanup.service ❯ apt-file find tldr | grep tldr: tldr: /usr/bin/tldr-hs tldr: /usr/share/doc/tldr/buildinfo_amd64.gz tldr: /usr/share/doc/tldr/changelog.Debian.amd64.gz tldr: /usr/share/doc/tldr/changelog.Debian.gz tldr: /usr/share/doc/tldr/changelog.gz tldr: /usr/share/doc/tldr/copyright tldr: /usr/share/man/man1/tldr-hs.1.gz Simula la instalación del paquete openssh-client Se puede simular la instalación de un paquete con la opción -s del comando apt install.\n❯ sudo apt install -s openssh-client Leyendo lista de paquetes... Hecho Creando árbol de dependencias... Hecho Leyendo la información de estado... Hecho Inst openssh-client (1:8.9p1-3 Ubuntu:22.04/jammy [amd64]) Conf openssh-client (1:8.9p1-3 Ubuntu:22.04/jammy [amd64]) En caso de que se genere algún conflicto o problema durante la instalación, la salida de este comando informa al respecto. En este caso, como esto no ocurre, simplemente muestra la información sobre el paquete que se instalaría si se ejecuta el comando sin la opción -s.\n¿Qué comando te informa de los posible bugs que presente un determinado paquete? El comando apt-listbugs muestra el informe de fallos de un determinado paquete. Con la opción -s se puede filtrar por el nivel de gravedad del bug reportado.\n❯ apt-listbugs -s all list openssh-client Obteniendo informes de fallo... Finalizado Analizando información Encontrada/Corregida... Finalizado Fallos important del paquete openssh-client (→ ) \u0026lt;Pendientes\u0026gt; b1 - #1038150 - openssh-client: Please add the openssh-client group rename from \u0026#34;ssh\u0026#34; to \u0026#34;_ssh\u0026#34; to the bookworm release notes b2 - #250311 - ssh: pubkey auth fails between 3.8.1p1-3 and 3.4(woody) b3 - #314596 - Cannot ssh OUT from host as non-root user b4 - #337484 - openssh-client: ssh-add displays password with bad permissions on /dev/tty b5 - #341042 - ssh: Slow Connections Due to Bogus IPv6 name resolution b6 - #391964 - warn if client-requested locale not available on server? b7 - #415697 - openssh-client: portforwarding with either -R or -L fails with module tun loaded b8 - #513071 - Regression: for some hosts etch can connect but lenny can\u0026#39;t (password auth) … b270 - #911758 - ssh-add doesn\u0026#39;t recognize PKCS#11 URL b271 - #538197 - openssh-client: [sftp] support multiple args: \u0026lt;command\u0026gt; \u0026lt;item\u0026gt; \u0026lt;item\u0026gt; ... Fallos minor del paquete openssh-client (→ ) \u0026lt;Corregidos en alguna versión\u0026gt; b272 - #1001186 - ssh-agent: SSH_AUTH_SOCK temporary directory uses 6 template chars out of 12 (Corregido: openssh/1:9.3p1-1) Resumen: openssh-client(272 fallos) Otras herramientas como bts también permiten acceder a la web de Debian para conocer la lista de bugs que se han reportado respecto a un determinado paquete.\nSalida del comando bts bugs openssh-client\rDespués de realizar un apt update \u0026amp;\u0026amp; apt upgrade. Si quisieras actualizar únicamente los paquetes que tienen de cadena openssh. ¿Qué procedimiento seguirías?. Realiza esta acción, con las estructuras repetitivas que te ofrece bash, así como con el comando xargs Justo después de realizar una actualización de la paquetería del sistema con apt update \u0026amp;\u0026amp; apt upgrade no habría ningún paquete relacionado con openssh que actualizar porque todos estarían ya en su versión más reciente.\nSin embargo, si se quieren mantener actualizaciones posteriores de estos paquetes tras un tiempo habría que usar de nuevo el comando apt update para consultar las nuevas versiones disponibles en los repositorios. Con los repositorios actualizados, se debería consular la lista de paquetes disponibles para actualizar con apt list --upgradable. Además, la salida de este comando se puede filtrar usando grep para eliminar de la lista todos aquellos paquetes que no estén relacionados con openssh. Finalmente, con el comando xargs se puede pasar esta lista de paquetes como argumentos al comando apt upgrade para ejecutar la actualización de los paquetes listado.\nEste flujo de trabajo se podría ejecutar en una única línea de comando redireccionando los diferentes comentarios a través de tuberías: apt update \u0026amp;\u0026amp; apt list --upgradable | grep openssh | xargs apt upgrade.\nOtra forma de conseguir que sólo los paquetes relacionados con openssh se actualicen es marcar el resto de paquetes del sistema como manuales o retenidos. De esta manera, cuando se ejecuta un apt upgrade del sistema, sólo los paquetes relacionados con openssh, marcados como auto, se actualizarán.\n¿Cómo encontrarías qué paquetes dependen de un paquete específico? Con el comando apt rdepends se puede saber cuáles son las dependencias inversas de un paquete, es decir, qué paquetes dependen de él.\n❯ apt rdepends openssh-client openssh-client Reverse Depends: Reemplaza: openssh-server (\u0026lt;\u0026lt; 1:7.9p1-8) Depende: arb |Depende: zssh Recomienda: xpra Depende: xen-tools Depende: x2goserver Depende: x2goclient |Recomienda: waypipe Recomienda: vorta Depende: vagrant Recomienda: unison-2.52-gtk Recomienda: unison-2.52 Recomienda: unison-2.51+4.13.1-gtk Recomienda: unison-2.51+4.13.1 Recomienda: tsung Depende: python3-tomahawk Sugiere: tla Recomienda: task-ssh-server |Depende: taktuk Recomienda: python3-jarabe Depende: ssvnc |Depende: sshuttle Depende: sshfs Depende: ssh-tools Depende: ssh-import-id Depende: ssh-cron Depende: ssh-contact-client Depende: ssh-agent-filter Depende: snapd Sugiere: smokeping Sugiere: slack |Recomienda: sisu Recomienda: simple-tpm-pk11 Depende: sidedoor Depende: secpanel Recomienda: seahorse Depende: python3-sahara-plugin-vanilla Depende: python3-sahara-plugin-spark Sugiere: rsync |Recomienda: rsnapshot Recomienda: rsbackup-graph Recomienda: rsbackup |Depende: rancid Depende: pssh |Depende: pkg-perl-tools Depende: piuparts-slave-from-git-deps Depende: piuparts-slave Recomienda: pdudaemon |Depende: pdsh Depende: python3-parallax Depende: oz Recomienda: ostree-push Depende: openstack-cluster-installer-openstack-ci Recomienda: openssh-known-hosts |Depende: ssh-askpass-gnome Depende: ssh (\u0026gt;= 1:9.2p1-2+deb12u3) Depende: openssh-tests (= 1:9.2p1-2+deb12u3) Depende: openssh-sftp-server (= 1:9.2p1-2+deb12u3) Depende: openssh-server (= 1:9.2p1-2+deb12u3) Depende: git-annex (\u0026gt;= 1:5.6p1) |Depende: openmpi-bin Sugiere: oar-user Depende: oar-server Depende: oar-node Depende: python3-nova Depende: network-manager-ssh Depende: mussh Depende: mssh Depende: mosh Recomienda: mercurial |Recomienda: lxsession Sugiere: lsh-server Depende: live-task-standard Recomienda: live-task-recommended Depende: libnetapp-perl |Depende: libnet-ssh-perl |Depende: libnet-sftp-foreign-perl |Depende: libnet-scp-perl Depende: libnet-openssh-perl Depende: libguestfs0 Mejora: libconfig-model-openssh-perl Recomienda: lftp Recomienda: lava-server Depende: lava |Depende: lam-runtime Recomienda: python3-labgrid Recomienda: kwalletcli Depende: ksshaskpass |Depende: keychain Recomienda: hollywood Depende: hash-slinger Depende: gitolite3 Rompe: git (\u0026lt;\u0026lt; 1:6.8) |Depende: ansible Depende: ganeti-3.0 |Sugiere: gabedit |Sugiere: gabedit |Depende: fssync Recomienda: freedombox Recomienda: fence-agents Recomienda: fdroidserver Recomienda: fai-server Sugiere: duply |Recomienda: dupload Sugiere: dropbear-bin Recomienda: python3-dput Sugiere: dput |Recomienda: dish Recomienda: diffoscope-minimal Recomienda: diffoscope Recomienda: debvm Sugiere: debian-goodies Recomienda: cvs Depende: cockpit-tests Depende: clusterssh Sugiere: clonezilla |Recomienda: ckermit Mejora: chkrootkit Depende: ceph-mgr-cephadm Recomienda: btrbk Recomienda: barman-cli Recomienda: barman |Recomienda: backuppc Sugiere: backup-manager Depende: backintime-common Mejora: autossh |Depende: autossh Depende: apt-dater |Depende: ansible-core Este comando devuelve, además, información sobre aquellos paquetes que recomiendan o sugieren la instalación del comando consultado así como aquellos paquetes en los que puede generar conflictos o que puede romper. También se muestran los paquetes a los que sustituye o mejora el paquete consultado.\n¿Cómo procederías para encontrar el paquete al que pertenece un determinado fichero? La opción -S o --search del comando dpkg permite encontrar el paquete al que pertenece un determinado fichero. De forma inversa a la ejecución del comando dpkg con la opción -L, que muestra la lista de ficheros que tienen relación con un paquete indicado, la opción -S de este comando permite pasarle como argumento una expresión o cadena de búsqueda que corresponda a la ruta a un fichero. La salida del comando dpkg con la opción -S mostrará el paquete al que pertenece ese fichero.\n❯ dpkg -S /usr/bin/ssh openssh-client: /usr/bin/ssh Otra forma de obtener el mismo resultado es usando el comando apt-find seguido de la ruta al fichero cuyo paquete se quiere conocer. La salida de este comando es similar a la del comando anteriormente citado aunque, en este caso, el filtro es mucho más laxo y se muestran todos aquellos paquetes en los que hay algún fichero que coincida, en parte, con la cadena introducida. Esto convierte a esta opción en una herramienta de búsqueda mucho más genérica, mientras que la búsqueda con dpkg -S es más precisa.\n❯ apt-file search /usr/bin/ssh hash-slinger: /usr/bin/sshfp lsh-utils: /usr/bin/ssh-conv node-sshpk: /usr/bin/sshpk-conv node-sshpk: /usr/bin/sshpk-sign node-sshpk: /usr/bin/sshpk-verify openssh-client: /usr/bin/ssh openssh-client: /usr/bin/ssh-add openssh-client: /usr/bin/ssh-agent openssh-client: /usr/bin/ssh-argv0 openssh-client: /usr/bin/ssh-copy-id openssh-client: /usr/bin/ssh-keygen openssh-client: /usr/bin/ssh-keyscan openssh-client-ssh1: /usr/bin/ssh-keygen1 openssh-client-ssh1: /usr/bin/ssh1 python3-sshtunnel: /usr/bin/sshtunnel rsendmail: /usr/bin/sshsendmail slurm-client: /usr/bin/sshare slurm-client-emulator: /usr/bin/sshare-emulator ssh-agent-filter: /usr/bin/ssh-agent-filter ssh-agent-filter: /usr/bin/ssh-askpass-noinput ssh-askpass-fullscreen: /usr/bin/ssh-askpass-fullscreen ssh-audit: /usr/bin/ssh-audit ssh-contact-client: /usr/bin/ssh-contact ssh-cron: /usr/bin/ssh-cron ssh-import-id: /usr/bin/ssh-import-id ssh-import-id: /usr/bin/ssh-import-id-gh ssh-import-id: /usr/bin/ssh-import-id-lp ssh-tools: /usr/bin/ssh-certinfo ssh-tools: /usr/bin/ssh-diff ssh-tools: /usr/bin/ssh-facts ssh-tools: /usr/bin/ssh-force-password ssh-tools: /usr/bin/ssh-hostkeys ssh-tools: /usr/bin/ssh-keyinfo ssh-tools: /usr/bin/ssh-ping ssh-tools: /usr/bin/ssh-version sshcommand: /usr/bin/sshcommand sshesame: /usr/bin/sshesame sshfs: /usr/bin/sshfs sshpass: /usr/bin/sshpass sshuttle: /usr/bin/sshuttle ssvnc: /usr/bin/sshvnc ¿Que procedimientos emplearías para liberar la caché en cuanto a descargas de paquetería? Los paquetes descargados a través del gestor de paquetes apt se almacenan en una caché junto a sus dependencias en el directorio var/cache/apt/archive. Esta información se almacena en el disco duro del equipo incluso cuando la instalación del paquete ha terminado de forma satisfactoria.\nEsta caché facilita y agiliza el proceso de reinstalar o reconfigurar paquetes ya que el sistema sólo tiene que acceder a los ficheros de instalación almacenado en la caché y no necesita buscarlos y descargarlos de los repositorios de Debian, sin embargo, en ocasiones, la caché de apt puede ocupar mucho espacio y puede ser necesario limpiarla. Para ello apt ofrece el comando apt clean, que borra todo el contenido del directorio en el que se almacenan los paquetes y dependencias instalados por apt.\nAsimismo, la herramienta apt autoclean permite borrar sólo los paquetes de este directorio que se han quedado obsoletos pero mantiene aquellos que están actualizados y, por tanto, el sistema aún puede necesitar.\nRealiza la instalación del paquete keyboard-configuration pasando previamente los valores de los parámetros de configuración como variables de entorno Para instalar paquetes de forma no interactiva se pueden usar los comandos dpkg y debconf. El comando debconf permite conocer cuáles son los parámetros que se deben configurar durante la instalación de un paquete. También permite reconfigurar la instalación para volver a elegir los parámetros necesarios en caso de que la configuración en el momento de la instalación no sea la adecuada.\nEn primer lugar, es necesario conocer cuáles son los parámetros que se solicitan durante la instalación de un determinado paquete. Una vez conocida esta información, se puede configurar el proceso de instalación desatendido con dpkg y debconf seleccionando la opción noninteractive.\nPosteriormente, se deben exportar los parámetros como variables de entorno usando export seguido del nombre del parámetro y el valor de la variable. La configuración desatendida de debconf y dpkg tomará estas variables como parámetros para la instalación y configuración del paquete.\nEl gestor de paquetes apt también permite configurar una instalación a través de variables de entorno de una manera similar. Tras exportar las variables de entorno se ejecuta el comando DEBIAN_FRONTEND=noninteractive apt install -y. Con la variable DEBIAN_FRONTEND=noninteractive se indica al gestor de paquetes que debe leer los parámetros de las variables de entorno.\nReconfigura el paquete locales de tu equipo, añadiendo una localización que no exista previamente. Comprueba a modificar las variables de entorno correspondientes para que la sesión del usuario utilice otra localización Para reconfigurar el paquete locale se pueden usar las herramientas del paquete debconf-utils. El comando debconf-set-selections permite modificar las variables de un paquete instalado y dpkg-reconfigure también ofrece la posibilidad de reconfigurar un paquete. En este caso, se pueden reconfigura el paquete locale para añadir una nueva localización.\n❯ sudo dpkg-reconfigure --frontend Dialog --priority low locales debconf: Please do not capitalize the first letter of the debconf frontend. Generating locales (this might take a while)... en_US.UTF-8... done es_ES.UTF-8... done Generation complete. Tras reconfigurar el paquete y añadir una nueva localización, ésta se puede modificar en el fichero de configuración /etc/default/locale o, de forma más genérica, se puede generar y exportar la variable de entorno con la orden ${LC_ALL=en_US.UTF-8}; export LC_ALL.\n❯ sudo nano /etc/default/locale ❯ locale -a C C.utf8 en_US.utf8 es_ES.utf8 POSIX Interrumpe la configuración de un paquete y explica los pasos a dar para continuar la instalación Si se interrumpe la instalación de un paquete en el proceso de configuración, se puede continuar el proceso usando el comando dpkg --configure -a. Con este comando se configurar los paquetes que se han desempaquetado en el proceso de instalación interrumpido pero no se han llegado a configurar. dpkg --configure desempaqueta los ficheros de configuración y restaura los ficheros de configuración de los paquetes cancelados. Posteriormente ejecuta los scripts postinstalación del paquete, en caso de que existan.\nExplica la instrucción que utilizarías para hacer una actualización completa de todos los paquetes de tu sistema de manera completamente no interactiva Para actualizar toda la paquetería del sistema de forma no interactiva se puede ejecutar el comando sudo apt update \u0026amp;\u0026amp; sudo apt upgrade -y.\nCon este flujo, en primer lugar se revisa la información sobre actualizaciones disponible en los repositorios con el comando apt update. Cuando la ejecución de este comando es exitosa, se ejecuta la actualización de la paquetería con el comando apt upgrade. Con al opción -y, se contesta afirmativamente a todas las preguntas interactivas del comando.\nBloquea la actualización de determinados paquetes Para bloquear la actualización de determinados paquetes se usa el comando apt-mark. Con este comando se pueden marcar como instalados manualmente determinados paquetes, lo que evita que se actualicen de forma automática. Si, además, se marcan como retenidos, estos paquetes no se actualizan nunca. Por ejemplo, para bloquear la actualización automática del paquete git se puede ejecutar el siguiente comando:\n❯ sudo apt-mark manual git git set to manually installed. Para evitar que el paquete wget se actualice en cualquier caso se puede ejecutar el siguiente comando:\n❯ sudo apt-mark hold wget wget set on hold. Trabajo con ficheros .deb Descarga un paquete sin instalarlo, es decir, descarga el fichero .deb correspondiente. Indica diferentes formas de hacerlo El fichero .deb de un paquete se puede descargar usando el comando apt download:\n❯ apt download mdadm Get:1 http://deb.debian.org/debian bookworm/main amd64 mdadm amd64 4.2-5 [443 kB] Fetched 443 kB in 0s (3,791 kB/s) o con el comando wget indicando la url de descarga desde la web del repositorio de Debian:\n❯ wget \u0026#34;http://ftp.es.debian.org/debian/pool/main/m/mdadm/mdadm-udeb_4.2-5_amd64.udeb\u0026#34; ¿Cómo puedes ver el contenido, que no extraerlo, de lo que se instalará en el sistema de un paquete deb? Para ver el contenido de un paquete .deb sin llegar a desempaquetarlo se puede usar la opción -t del comando ar.\n❯ ar -t mdadm_4.2-5_amd64.deb debian-binary control.tar.xz data.tar.xz Para ver el contenido del paquete con más detalle es necesario desempaquetarlo.\n❯ ar -x mdadm_4.2-5_amd64.deb Una vez desempaquetado, con el comando tar se puede listar, sin extraer, todo el contenido de cada uno de los archivos incluidos en el paquete.\n❯ tar -tf data.tar.xz ./ ./etc/ ./etc/cron.d/ ./etc/cron.d/mdadm ./etc/cron.daily/ ./etc/cron.daily/mdadm ./etc/init.d/ ./etc/init.d/mdadm ./etc/init.d/mdadm-waitidle ./etc/logcheck/ ./etc/logcheck/ignore.d.server/ ./etc/logcheck/ignore.d.server/mdadm ./etc/logcheck/violations.d/ ./etc/logcheck/violations.d/mdadm ./etc/mdadm/ ./etc/modprobe.d/ ./etc/modprobe.d/mdadm.conf … ./usr/share/mdadm/ ./usr/share/mdadm/checkarray ./usr/share/mdadm/mdcheck ./usr/share/mdadm/mkconf ./lib/systemd/system/mdadm-waitidle.service ./lib/systemd/system/mdadm.service Sobre el fichero .deb descargado, utiliza el comando ar. ar permite extraer el contenido de una paquete deb. Indica el procedimiento para visualizar con ar el contenido del paquete deb. Con el paquete que has descargado y utilizando el comando ar, descomprime el paquete. ¿Qué información dispones después de la extracción?. Indica la finalidad de lo extraído Tras desempaquetar el paquete .deb:\n❯ ar -x mdadm_4.2-5_amd64.deb Los contenidos del paquete se muestran en el directorio tras desempaquetar el paquete.\n❯ ls -l total 876 -rw-r--r-- 1 usuario usuario 15156 Sep 27 10:03 control.tar.xz -rw-r--r-- 1 usuario usuario 427708 Sep 27 10:03 data.tar.xz -rw-r--r-- 1 usuario usuario 4 Sep 27 10:03 debian-binary En el archivo control.tar.xz se encuentran todos los ficheros de control del paquete. Entre ellos los scripts que se ejecutan antes y después de la instalación, las plantillas, los ficheros de configuración o el fichero md5sums con los hashes de verificación de las versiones de los ficheros del paquete.\n❯ tar -tf control.tar.xz ./ ./conffiles ./config ./control ./md5sums ./postinst ./postrm ./preinst ./prerm ./templates ./triggers Por su parte, en el archivo data.tar.xz se recogen los ficheros de configuración, binarios, ficheros de servicios y otro tipo de ficheros que componen la parte fundamental del paquete y que son, en definitiva, los que se encargan de que la herramienta instalada cumpla su función.\nIndica el procedimiento para descomprimir lo extraído por ar del punto anterior. ¿Qué información contiene? Para descomprimir el contenido de cada archivo .tar.xz del paquete desempaquetado anteriormente se puede usar el comando tar con la opción -x, para indicar que se debe realizar la descompresión y la opción -f para indicar el nombre del archivo que se debe descomprimir.\n❯ tar -xf control.tar.xz ❯ tar -xf data.tar.xz ❯ ls -l total 964 -rw-r--r-- 1 usuario usuario 181 feb 24 2023 conffiles -rwxr-xr-x 1 usuario usuario 1161 feb 24 2023 config -rw-r--r-- 1 usuario usuario 808 feb 24 2023 control -rw-r--r-- 1 usuario usuario 15156 sep 27 12:22 control.tar.xz -rw-r--r-- 1 usuario usuario 427708 sep 27 12:22 data.tar.xz -rw-r--r-- 1 usuario usuario 4 sep 27 12:22 debian-binary drwxr-xr-x 8 usuario usuario 4096 feb 24 2023 etc drwxr-xr-x 4 usuario usuario 4096 feb 24 2023 lib -rw-r--r-- 1 usuario usuario 5060 feb 24 2023 md5sums -rw-r--r-- 1 usuario usuario 443056 feb 24 2023 mdadm_4.2-5_amd64.deb -rwxr-xr-x 1 usuario usuario 5279 feb 24 2023 postinst -rwxr-xr-x 1 usuario usuario 1734 feb 24 2023 postrm -rwxr-xr-x 1 usuario usuario 455 feb 24 2023 preinst -rwxr-xr-x 1 usuario usuario 485 feb 24 2023 prerm drwxr-xr-x 2 usuario usuario 4096 feb 24 2023 sbin -rw-r--r-- 1 usuario usuario 25872 feb 24 2023 templates -rw-r--r-- 1 usuario usuario 82 feb 24 2023 triggers drwxr-xr-x 3 usuario usuario 4096 feb 24 2023 usr Listando el contenido del directorio de trabajo tras descomprimir los ficheros del paquete se puede comprobar que, como se había adelantado en el ejercicio anterior, el archivo control contiene ficheros de utilidad para gestionar la instalación del paquete. Entre estos ficheros, algunos son importantes para verificar la seguridad e integridad de los ficheros que forman parte del paquete mientras que algunos otros incluyen órdenes relacionadas con el proceso de instalación como scripts que se ejecutan antes o después de la instalación. También incluye ficheros que contienen las diferentes variables que se deben configurar para el correcto funcionamiento del paquete.\nPor su parte, en el archivo data se incluyen todos los ficheros que forman parte de la herramienta instalada con este paquete, es decir, desde sus ficheros de configuración, binarios que se pueden ejecutar a través de la línea de comandos, ficheros de ayuda y manual, ficheros para permitir a la bash autocompletar el comando al tabular, los ficheros para generar los daemons necesarios para el correcto funcionamiento de la herramienta, etc. En definitiva, este directorio contiene todos los ficheros necesarios para el funcionamiento del paquete descargado tras su instalación.\nTrabajo con repositorios Añade a tu fichero sources.list los repositorios de bookworm-backports y sid deb http://deb.debian.org/debian/ bookworm main non-free-firmware deb-src http://deb.debian.org/debian/ bookworm main non-free-firmware deb http://deb.debian.org/debian/ bookworm-backports main non-free-firmware deb http://deb.debian.org/debian/ sid main non-free-firmware Configura el sistema APT para que los paquetes de debian bookworm tengan mayor prioridad y por tanto sean los que se instalen por defecto Para configurar el orden de prioridad de instalación del sistema APT se puede configurar el fichero /etc/apt/preferences. Por defecto, este fichero no existe en el equipo y hay que crearlo.\nPara que los paquetes de debian bookworm (stable) tengan la mayor prioridad se debe añadir la siguiente configuración:\nPackage: * Pin: release a=stable Pin_Priority: 500 Configura el sistema APT para que los paquetes de bookworm-backports tengan mayor prioridad que los de unstable Para que los paquetes de la rama bookworm-backports tengan mayor prioridad que los de la rama unstable en el gestor de paquetes APT se puede añadir la siguiente configuración al fichero /etc/apt/preferences.\nPackage: * Pin: release a=stable-backports Pin_Priority: 100 Package: * Pin: release a=unstable Pin_Priority: 1 ¿Cómo añades la posibilidad de descargar paquetería de la arquitectura i386 en tu sistema. ¿Que comando has empleado?. Lista arquitecturas no nativas. ¿Cómo procederías para desechar la posibilidad de descargar paquetería de la arquitectura i386? Para añadir la posibilidad de descargar paquetería de la arquitectura i386 en el sistema Debian con arquitectura nativa amd64 se puede usar el comando dpkg.\n❯ sudo dpkg --add-architecture i386 Para listar las arquitecturas no nativas habilitadas en el sistema, el comando dpkg ofrece la opción --print-foreign-architecutres.\n❯ dpkg --print-foreign-architectures i386 Finalmente, para eliminar una determinada arquitectura de la lista de arquitecturas no nativas añadidas al sistema se usa la opción --remove-architecture del mismo comando.\n❯ sudo dpkg --remove-architecture i386 Si se han instalado paquetes de la arquitectura no nativa configurada en el sistema se puede generar un conflicto al intentar eliminar esta opción mientras estos paquetes están instalados. Por eso, es necesario desinstalar los paquetes de esta arquitectura antes de eliminarla de la lista. Para la arquitectura i386, por ejemplo, esto se puede hacer con el comando apt purge “.*:i386”.\nLa lista de arquitecturas no nativas que se configuran en un sistema Debian se almacena en el directorio /var/lib/dpkg/arch.\nSi quisieras descargar un paquete, ¿cómo puedes saber todas las versiones disponible de dicho paquete? Para conocer las versiones disponibles de un paquete en los repositorios de Debian en cada rama de la distribución se puede ejecutar el comando rmadison. A este comando se le debe indicar el nombre del paquete y devuelve una lista con todas las versiones disponibles para cada una de las ramas de Debian.\n❯ rmadison openssh-client openssh-client | 1:7.9p1-10+deb10u2 | oldoldstable | amd64, arm64, armhf, i386 openssh-client | 1:8.4p1-2~bpo10+1 | buster-backports | amd64, arm64, armel, armhf, i386, mips, mips64el, mipsel, ppc64el, s390x openssh-client | 1:8.4p1-5+deb11u3 | oldstable | amd64, arm64, armel, armhf, i386, mips64el, mipsel, ppc64el, s390x openssh-client | 1:9.2p1-2+deb12u3 | stable | amd64, arm64, armel, armhf, i386, mips64el, mipsel, ppc64el, s390x openssh-client | 1:9.8p1-8 | testing | amd64, arm64, armel, armhf, i386, mips64el, ppc64el, riscv64, s390x openssh-client | 1:9.9p1-1 | unstable | amd64, arm64, armel, armhf, i386, mips64el, ppc64el, riscv64, s390x Indica el procedimiento para descargar un paquete del repositorio stable El gestor de paquetes APT utiliza la opción -t para recibir la rama de Debian de la que se debe instalar un paquete determinado como argumento. En este caso, para instalar un paquete del repositorio stable se puede usar o no la opción -t, puesto que la rama stable es la rama desde la que se descargan los paquetes por defecto. De esta forma, estos dos comandos se pueden usar de forma indistinta.\nsudo apt install openssh-client sudo apt install openssh-client -t stable sudo apt install openssh-client -t bookworm Cabe destacar que, para que una rama de la distribución esté disponible como argumento para la opción -t de este comando, la rama debe estar incluida en el fichero sources.list. De esta manera, las opciones para un sistema en el que las ramas configuradas en este fichero son la stable, la stable-security y la stable-updates, los argumentos que acepta la opción -t del comando son esas tres ramas.\n❯ apt install -t bookworm bookworm-updates stable stable-updates bookworm-security now stable-security Indica el procedimiento para descargar un paquete del repositorio de bookworm-backports Dando por supuesto que la rama configuada en el fichero sources.list y con prioridad más alta es la stable o bookworm, para descargar paquetes de la rama bookworm-backports se debe indicar este parámetro con la opción -t del comando apt install.\nsudo apt install openssh-client -t bookworm-backports Indica el procedimiento para descargar un paquete del repositorio de sid Para que un paquete se instale desde la rama unstable o sid de los repositorios de debian se puede usar uno de estos dos parámetros en la opción -t del comando apt-install:\nsudo apt install openssh-client -t sid sudo apt install openssh-client -t unstable Indica el procedimiento para descargar un paquete de arquitectura i386 Si se necesita instalar el paquete para una arquitectura no nativa del sistema operativo, esta opción también se puede indicar a través del comando apt-install.\nsudo apt install openssh-client:i386 Trabajo con directorios /var/lib/apt/lists/ Este directorio almacena información sobre los paquetes de los repositorios de Debian. Este directorio se rellena con la actualización de la paquetería a través del comando apt update. A él acceden otros comandos del gestor de paquete apt para recuperar información relativa a los paquetes del sistema, como apt-cache o apt install.\n/var/lib/dpkg/available Este es el fichero en el que dpkg almacena un registro de los paquetes disponibles para el sistema. Se trata de un fichero que funciona a modo de cache para el gestor de paquetes dpkg. El gestor de paquetes apt usa una caché diferente.\n/var/lib/dpkg/status El fichero status almacena información sobre el estado de los paquetes del sistema. La herramienta dpkg accede a este fichero para saber si un paquete debe ser desempaquetado, configurado o eliminado.\n/var/cache/apt/archives/ En este directorio se almacena la información relativa a los paquetes descargados y actualizados a través del gestor de paquetes apt. Cumple una función similar a la que tiene el fichero available de la herramienta dpkg. Este directorio almacena toda la información incluso después de que los paquetes se hayan instalado con éxito. Varios comandos del gestor de paquetes apt acceden a este directorio para recuperar la información que necesitan para mostrarla o para instalar o actualizar paquetes.\n/var/log/apt/history.log Este es un fichero de log en el que se almacena información sobre los paquetes que se han instalado, actualizado o desinstalado a través del gestor de paquetes apt. Otras herramientas para la gestión de paquetes como dpkg tienen sus propios archivos de log, de manera que la información sobre los paquetes gestionados con una de estas herramientas no aparecen en el log de las otras.\n"},{
  "section": "Blog",
  "slug": "/blog/redes/2024-05-28-configurar-vlan-bridge-linux/",
  "title": "Configurar redes virtuales (VLAN) en bridges Linux",
  "description": "",
  "date": "May 28, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "redes, Planificación y Administración de Redes, router, router Linux, bridge, virtualización, VLAN",
  "content":"Este post pretende demostrar el funcionamiento y guiar en la configuración de redes virtuales en un bridge creado en una máquina Debian. Parte del escenario creado en el post anterior, en el que se cuenta con un bridge en el equipo anfitrión que incluye la interfaz que conecta la máquina anfitriona con la Internet (ens3) y una interfaz virtual (tap0) que se ha usado para comprobar la conectividad de la máquina virtual creada en la demostración del funcionamiento del bridge.\nTambién existe en la máquina anfitriona un fichero de imagen qcow2 con una versión comprimida de un sistema operativo debian 12 ya instalado.\nPor tanto, para crear y configurar las dos máquinas virtuales necesarias para el desarrollo de esta parte de la práctica se usa la funcionalidad de aprovisionamiento ligero (thin provisioning) de las imágenes qcow2, que permite usar una imagen base para la creación de varias máquinas virtuales sin tener que repetir el proceso de instalación del sistema operativo en cada una de ellas.\nA partir de la imagen comprimida creada en la parte anterior de la práctica, deb12-min.qcow2, se pueden crear nuevos ficheros de imagen de aprovisionamiento ligero para las máquinas necesarias para esta parte de la práctica. En una primera aproximación, se necesitan dos máquinas con dos interfaces de red cada una. Por tanto, se crean dos nuevos ficheros de imagen a partir del fichero base.\nqemu-img create -b deb12-min.qcow2 -F qcow2 -f qcow2 deb12-01.qcow2 qemu-img create -b deb12-min.qcow2 -F qcow2 -f qcow2 deb12-02.qcow2. Antes de lanzar las nuevas máquinas virtuales se deben configurar también sus interfaces de red. El primer ejercicio pide que ambas máquinas tengan conectividad hacia la red principal a través del bridge br0. Para ello, es necesario que cada una tenga asociada una interfaz virtual tap y que ambas interfaces formen parte de este bridge. Por tanto, se crean dos interfaces de tipo tap propiedad del usuario debian.\nip tuntap add mode tap user debian ip tuntap add mode tap user debian ip tuntap list En primer lugar, las máquinas virtuales deben tener conexión no sólo entre ellas sino también hacia la red principal, por tanto, estas interfaces se deben incluir en el bridge br0 y se deben levantar. ip l set dev tap0 up y ip l set dev tap up.\nbrctl addif br0 tap0 brctl addif br0 tap1 ip l set dev tap0 up ip l set dev tap up Finalmente, cada interfaz necesita una dirección MAC aleatoria que se puede asignar a una variable.\nmac0=$(echo \u0026#34;02:\u0026#34;`openssl rand -hex 5 | sed \u0026#39;s/\\(..\\)/\\1:/g; s/.$//\u0026#39;`) mac1=$(echo \u0026#34;02:\u0026#34;`openssl rand -hex 5 | sed \u0026#39;s/\\(..\\)/\\1:/g; s/.$//\u0026#39;`) Con los ficheros de imagen qcow2 y las interfaces en el bridge se pueden lanzar las máquina virtuales necesarias para este caso práctico.\n#Debian1 kvm -m 512 -hda deb12-01.qcow2 -device virtio-net,netdev=n0,mac=$mac0 -netdev tap,id=n0,ifname=tap0,script=no,downscript=no \u0026amp; #Debian2 kvm -m 512 -hda deb12-0.qcow2 -device virtio-net,netdev=n0,mac=$mac1 -netdev tap,id=n0,ifname=tap1,script=no,downscript=no \u0026amp; Tip\nEl carácter \u0026amp; al final de cada comando hace que se ejecuten en segundo plano. De esta manera, desde una sola ventana de la terminal se pueden ejecutar varias máquinas virtuales.\nLas dos máquinas arrancan sus interfaces de red con una dirección IP en la misma red de la máquina anfitriona obtenida por DHCP: 172.22.5.225/16 para debian1 y 172.22.3.77/16 para debian2. Ambas se pueden comunicar entre ellas y con Internet a través de la red principal.\nSupuestos para trabajar con las VLAN Creación del bridge br1 sin conectividad con el exterior Para que un bridge no tenga conectividad con el exterior sólo hay que tener en cuenta que no cuenta con ninguna interfaz conectada a Internet. En este caso, la única interfaz que tiene conexión a Internet es la ens18 del equipo anfitrión, por tanto, no debe formar parte de este bridge.\nHay dos formas de crear este segundo bridge: a través de brctl addbr br1 o, para hacerlo persistente a los reinicios, editando el fichero de configuración /etc/network/interfaces.\nAñadir una segunda interfaz a las máquinas virtuales y conectarlas a br1 Para que la máquinas virtuales creadas en el ejercicio anterior se conecten a través del nuevo bridge necesitan una segunda interfaz. El procedimiento para generarlas es el mismo que se ha seguido hasta ahora.\nip tuntap add mode tap user debian ip tuntap add mode tap user debian ip tuntap list ip l set dev tap2 up ip l set dev tap3 up Además, para que estas interfaces permitan a las máquinas virtuales conectarse a través del bridge br1, se deben añadir ambas.\nbrctl addif br1 tap2 brctl addif br1 tap3 brctl show Finalmente, cada interfaz necesita una dirección MAC para poder asociarse a una máquina virtual.\nmac0=$(echo \u0026#34;02:\u0026#34;`openssl rand -hex 5 | sed \u0026#39;s/\\(..\\)/\\1:/g; s/.$//\u0026#39;`) mac1=$(echo \u0026#34;02:\u0026#34;`openssl rand -hex 5 | sed \u0026#39;s/\\(..\\)/\\1:/g; s/.$//\u0026#39;`) Para que las máquinas estén efectivamente conectadas a estas interfaces, se deben lanzar con estos comandos, que presentan ciertas modificaciones respecto a los empleados en el ejercicio anterior:\n#Debian1 kvm -m 512 -hda deb12-01.qcow2 -device virtio-net,netdev=n0,mac=$mac0 -netdev tap,id=n0,ifname=tap0,script=no,downscript=no -device virtio-net,netdev=n0,mac=$mac2 -netdev tap,id=n0,ifname=tap2,script=no,downscript=no \u0026amp; #Debian2 kvm -m 512 -hda deb12-0.qcow2 -device virtio-net,netdev=n0,mac=$mac1 -netdev tap,id=n0,ifname=tap1,script=no,downscript=no -device virtio-net,netdev=n0,mac=$mac3 -netdev tap,id=n0,ifname=tap3,script=no,downscript=no \u0026amp; Con esta configuración debian1 y debian2 están conectadas tanto entre ellas a través de los bridges br0 y br1 como hacia el exterior a través de br0.\nCrear dos máquinas virtuales con una interfaz de red De nuevo, los pasos que se deben seguir para crear dos máquinas virtuales con una interfaz de red cada una son los mismos que se han repetido en ejercicios anteriores de esta práctica.\nPrimero, se tienen que crear y levantar las interfaces:\nip tuntap add mode tap user debian ip tuntap add mode tap user debian ip l set dev tap4 up ip l set dev tap5 up Después, se generan los ficheros de imagen para estas máquinas:\nqemu-img create -b deb12-min.qcow2 -F qcow2 -f qcow2 deb12-03.qcow2 qemu-img create -b deb12-min.qcow2 -F qcow2 -f qcow2 deb12-04.qcow2 Posteriormente, se tienen que generar direcciones MAC aleatorias necesarias para la creación de la máquina virtual. Y finalmente, se ejecuta la máquina virtual.\nmac4=$(echo \u0026#34;02:\u0026#34;`openssl rand -hex 5 | sed \u0026#39;s/\\(..\\)/\\1:/g; s/.$//\u0026#39;`) mac5=$(echo \u0026#34;02:\u0026#34;`openssl rand -hex 5 | sed \u0026#39;s/\\(..\\)/\\1:/g; s/.$//\u0026#39;`) #Debian3 kvm -m 512 -hda deb12-03.qcow2 -device virtio-net,netdev=n0,mac=$mac4 -netdev tap,id=n0,ifname=tap4,script=no,downscript=no \u0026amp; #Debian4 kvm -m 512 -hda deb12-04.qcow2 -device virtio-net,netdev=n0,mac=$mac5 -netdev tap,id=n0,ifname=tap5,script=no,downscript=no \u0026amp; Conectar debian1 con debian3 y debian2 con debian4 en el bridge br1 usando una VLAN Para conectar las cuatro máquinas en el bridge br1 todas ellas tienen que tener alguna de sus interfaces en este bridge. Por tanto, el primer paso imprescindible para realizar este ejercicio es añadir al bridge br1 las interfaces de debian3 y debian4.\nbrctl addif br1 tap4 brctl addif br1 tap5 Posteriormente hay que activar en este bridge la funcionalidad de filtrado por vlan.\nip l set br0 type bridge vlan_filtering 1 Además, hay que indicar la VLAN a la que pertenece cada una de las interfaces del bridge br1. Para cumplir con los requisitos del ejercicio, debian1 y debian3 deben pertenecer a una VLAN, por ejemplo, la VLAN 2 y debian2 y debian4 a otra, por ejemplo, la VLAN 3. Así, debian1 y debian 3 se añaden a la VLAN 2:\nbridge vlan add dev tap1 vid 2 pvid untagged master bridge vlan add dev tap4 vid 2 pvid untagged master Y debian2 y debian4 a la VLAN 3:\nbridge vlan add dev tap3 vid 3 pvid untagged master bridge vlan add dev tap5 vid 3 pvid untagged master En primer lugar se tratará de demostrar la conectividad entre debian1 y debian3 a través de br1. Para ello, se configuran las interfaces de estas máquinas virtuales forman parte de este bridge. En debian1 es la ens4 y en debian3 la ens3. Se es asigna manualmente una dirección IP en el fichero de configuración /etc/network/interfaces: la 192.168.0.10 para debian1 y la 192.168.0.30 para debian3.\nDe la misma forma se puede demostrar la conectividad entre debian2 y debian2 a través de br1 configurando las interfaces de estas máquinas virtuales que forman parte de este bridge (ens4 en debian2 y ens3 en debian4). Se asigna manualmente una dirección IP en el fichero de configuración /etc/network/interfaces: la 192.168.0.20 para debian2 y la 192.168.0.40 para debian4.\nFinalmente, se demuestra que no hay conectividad entre debian3 y debian4, que pertenecen a VLAN diferentes en el bridge br1.\nFinalmente, cabe destacar que tanto debian1 como debian2 (en la imagen) pueden conectarse a Internet a través del bridge br0, debian3 y debian4 (en la imagen), que no forman parte de ese bridge, no pueden hacerlo.\n"},{
  "section": "Blog",
  "slug": "/blog/redes/2024-05-28-configurar-bonding-bridge-linux/",
  "title": "Configurar una agregación de enlaces (bonding) en bridges Linux",
  "description": "",
  "date": "May 28, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "redes, Planificación y Administración de Redes, router, router Linux, bridge, virtualización, bonding",
  "content":"Una agregación de enlaces, link aggregation o port bonding combina varias interfaces de red de forma paralela para aumentar el ancho de banda de una conexión y aportar redundancia ante fallos de una de ellas.\nEn este post se reutilizará la máquina virtual debian1, empleada en una entrada anterior. Esta máquina ya cuenta con dos interfaces de red: ens3 y ens4, conectadas a las interfaces tap0 y tap1 de la máquina anfitriona. Estas interfaces están conectadas bridges diferentes y pertenecen a VLAN diferentes. Por tanto, para preparar el escenario para este ejercicio, se debe eliminar la interfaz tap1 de la VLAN 2 y se debe desconectar del bridge br1 y conectarse a br0.\nAsí, en primer lugar se saca la interfaz tap1 de la VLAN 2 y se deja únicamente en la VLAN por defecto a la que pertenecen todas las interfaces.\nbridge vlan del dev tap1 vid 2 pvid untagged master Después, se lleva esta interfaz del bridge br1 a br0 para eliminarla del bridge br1 y para conectarla al bridge br0.\nbrctl delif br1 tap1 brctl addif br0 tap1 Tras realizar estas modificaciones, la máquina debian1 está conectada al bridge br0 a través de dos interfaces diferentes: tap0 y tap1.\nConfiguración de la agregación de enlaces entre las dos interfaces Para configurar el bonding en debian1 se arranca la máquina con el comando usado en el post anterior:\nkvm -m 512 -hda deb12-01.qcow2 -device virtio-net,netdev=n0,mac=$mac0 -netdev tap,id=n0,ifname=tap0,script=no,downscript=no -device virtio-net,netdev=n0,mac=$mac2 -netdev tap,id=n0,ifname=tap2,script=no,downscript=no \u0026amp; Desde esta máquina, con conexión a Internet a través del bridge br0, que cuenta con la interfaz ens18 de la máquina anfitriona, se actualiza la paquetería y se instala el paquete ifenslave.\nsudo apt update sudo apt install ifenslave Después, se puede configurar el bonding en el fichero /etc/network/interfaces. En este caso se debe declarar la interfaz de tipo bonding, por ejemplo, bond0 y configurar los diferentes parámetros como los de cualquier otra interfaz como la IP, máscara de red o puerta de enlace pero también parámetros propios de las interfaces de tipo bonding como las interfaces que forman parte del bonding o el modo.\nauto bond0 iface bond0 inet static address 172.22.0.28 netmask 255.255.0.0 network 172.22.0.0 gateway 172.22.0.1 bond-slaves ens3 ens4 bond-mode 4 Para conseguir que el bonding tenga redundancia ante fallos y mejore el ancho de banda disponible, se configura la interfaz en el modo de bonding 4, que utiliza el estándar 802.3ad para la agregación de enlaces. Este estándar permite configurar bonding con alta disponibilidad y aumento de la velocidad.\nAl establecer esta configuración y reiniciar el servicio networking de la máquina virtual, se levanta la interfaz bond0 y toma la IP indicada en la configuración:\n"},{
  "section": "Blog",
  "slug": "/blog/redes/2024-05-28-funcionamiento-basico-linux-bridge/",
  "title": "Funcionamiento básico de Linux Bridge",
  "description": "",
  "date": "May 28, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "redes, Planificación y Administración de Redes, router, router Linux, bridge, virtualización",
  "content":"Un bridge o puente en Linux es un dispositivo de red virtual que permite que las máquinas virtuales alojadas en una máquina física usen su tarjeta de red. En este post se muestra un ejemplo de configuración de un Bridge en una máquina Debian.\nConfiguración de un bridge en una máquina Debian Para configurar un Bridge en Linux que permita que la interfaz externa se pueda utilizar por máquinas virtuales se debe conocer, en primer lugar, el nombre de esta interfaz. En este caso, es ens3. Con esta información se puede crear un primer bridge que incluya esta interfaz. Para ello, se crea primero un bridge. A continuación, se le añade la interfaz externa del equipo físico.\nbrctl addbr br0 brctl addif br0 ens3 Cuando se añade la interfaz al bridge, el equipo se desconecta de la red porque la interfaz bridge no está funcionando en ese momento. Para solucionarlo, sólo hay que levantar la interfaz\nip l set dev br0 up Además se le puede asignar una dirección IP al bridge:\nip a add 10.0.0.166/24 dev br0 De esta manera, el direccionamiento queda definido en el dispositivo br0 y la interfaz ens3 está incluida como un puerto del mismo.\nSin embargo, con esta configuración la máquina no se puede volver a conectar a la red y la interfaz ens3 queda inutilizada. Ante la imposibilidad de solucionar este problema, se opta por intentar hacer la práctica en otra máquina.\nEn este caso, tras instalar el paquete bridge-utils, se crea el bridge br0 directamente desde el fichero de configuración /etc/network/interfaces. De esta forma, además, la configuración del bridge se hace persistente a los reinicios.\nauto br0 iface br0 inet dhcp bridge_ports ens18 Y, posteriormente se levanta la interfaz con ifup br0:\nifup br0 La configuración establecida en el fichero se aplica, de manera que con el comando brctl show ya se puede ver el bridge br0 en el sistema:\nAdemás, la interfaz toma una configuración TCP/IP por DHCP y obtiene su propia dirección IP con la que la máquina tiene acceso a Internet.\nFuncionamiento del bridge con una máquina virtual Para comprobar el funcionamiento del bridge con una máquina virtual es necesario crear una en el equipo local en el que se ha creado el bridge. Primero se debe descargar el fichero de imagen .iso del sistema operativo que va a usar la máquina virtual.\nwget https://cdimage.debian.org/debian-cd/current/amd64/iso-cd/debian-12.5.0-amd64-netinst.iso A continuación se usa kvm para crear una imagen qcow2 de este sistema. Para poder trabajar con el virtualizador qemu/kvm en la máquina Debian primero se deben instalar los paquetes necesarios.\napt install qemu-utils qemu-system-x86 qemu-system-gui Una vez que las herramientas de qemu/kvm se han instalado en el equipo se puede convertir la imagen ISO de Debian a un fichero de imagen de tipo qcow2.\nqemu-img create -f qcow2 deb12.qcow2 10G Info\nPara una información más detallada sobre la instalación de las herramientas de virutalización qemu/kvm y VirtManager puedes consultar este post.\nEl siguiente paso es crear una interfaz de tipo tap y después se añade la interfaz al bridge.\ntuntap add mode tap user user brctl addif br0 tap0 ip l set dev tap0 up Posteriormente, se genera una MAC aleatoria para la máquina virtual.\nmac0=$(echo \u0026#34;02:\u0026#34;`openssl rand -hex 5 | sed \u0026#39;s/\\(..\\)/\\1:/g; s/.$//\u0026#39;`) Con esta información, ya se puede crear la máquina virtual.\nkvm -m 512 -hda deb12.qcow2 -cdrom debian-12.5.0-amd64-netinst.iso -device virtio-net,netdev=n0,mac=$MAC0 -netdev tap,id=n0,ifname=tap0,script=no,downscript=no Este comando lanza una ventana para la instalación del sistema operativo de la máquina virtual:\nTras la instalación de la máquina virtual, ésta cuenta con una interfaz, ens3, que ha solicitado una dirección IP por DHCP en el arranque:\nY a través de la cual se puede conectar a Internet:\n"},{
  "section": "Blog",
  "slug": "/blog/redes/2024-05-21-tuneles-ipv6-6to4/",
  "title": "Túneles IPv6: túneles 6to4",
  "description": "",
  "date": "May 21, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "GNS3, redes, Planificación y Administración de Redes, router, router Linux, Cisco, IPv6, túeneles IPv6, túneles 6to4",
  "content":"En este post se muestra, a través de un ejemplo práctico, el funcionamiento de los túneles IPv6. Estos túneles permiten que el tráfico que va de una a otra dirección IPv6 pase por redes que funcionan usando el portocolo IPv4.\nEn este caso práctico se usa un escenario formado por 4 PC, 3 routers y un switch:\nLos PC se conectan a los routers por IPv6. Los routers se comunican entre ellos por IPv4. Para facilitar la comprensión de esta documentación se asignan direcciones tanto IPv4 como IPv6 estáticas a cada equipo según corresponda. Estas son las direcciones de cada una de las interfaces de los dispositivos de la red:\nPC1 e0: 2001:db8:1::102 PC2 e0: 2001:db8:1::103 PC3 e0: 2001:db8:2::202 PC4 e0: 2001:db8:3::302 R1 f0/0: 2001:db8:1::101 f0/1: 110.0.0.1 f1/0: 120.0.0.1 R2 f0/0: 2001:db8:2::201 f0/1: 110.0.0.2 f1/0: 130.0.0.2 R3 f0/0: 2001:db8:3::301 f0/1: 120.0.0.2 f1/0: 130.0.0.1 Configuración de los equipos Se puede tomar como ejemplo para la configuración de los PC el caso de PC1. En este caso se usan VPCS de GNS3, así que para asignarle una dirección IPv6 estática se usa el comando ip 2001:db8:1::102. Esto le da una dirección global. La dirección de enlace local se genera automáticamente al arrancar la tarjeta de red a partir de su MAC.\nPara configurar las direcciones a cada interfaz de los routers se usa el procedimiento habitual en el caso de los routers Cisco. Tomando como ejemplo el router R1, se accede a la terminal de configuración de cada una de las interfaces y, desde ellas, se asigna la dirección correspondiente.\nR1(config)#interface fastEthernet 0/0 R1(config-if)#ipv6 address 2001:db8:1::101/64 R1(config-if)#no shutdown R1(config-if)#exit R1(config)#interface fastEthernet 0/1 R1(config-if)#ip address 110.0.0.1 255.255.255.0 R1(config-if)#no shutdown R1(config-if)#exit R1(config)#interface fastEthernet 1/0 R1(config-if)#ip address 120.0.0.1 255.255.255.0 R1(config-if)#no shutdown R1(config-if)#end R1#wr Configuración de túneles 6to4 en Cisco Antes de configurar los túneles en los diferentes routers del escenario es necesario calcular las direcciones IP que deben usar estas interfaces a partir de la dirección IPv4 asignada a las mismas. Las direcciones de los túneles 6to4 comienzan con el prefijo 2002. A continuación se calculan 8 bytes a partir de la dirección IPv4 asociada a la interfaz en la que tiene origen el túnel. Estos 8 bytes son la traducción a hexadecimal de la dirección IPv4.\nAdemás, estas direcciones se pueden calcular usando los siguientes comandos en el router Cisco:\nR1(config)#ipv6 general-prefix prefijo 6to4 fastEthernet 0/1 R1(config)#do show ipv6 general-prefix Así, las direcciones IPv6 que deben usar los túneles en el escenario son:\nR1: f0/1: 2002:6E00:1::1/64 f1/0: 2002:7800:1::1/64 R2: f0/1: 2002:6E00:1::2/64 f1/0: 2002:8200:1::2/64 R3: f0/1: 2002:7800:1::2/64 f1/0: 2002:8200:1:1/64 Túenel entre R1 y R3 Para configurar un túnel 6to4 entre el router R1 y el router R3 en Cisco, en primer lugar, desde la terminal de configuración se crea el túnel con el comando:\nR1(config)#interface tunnel 0 Posteriormente se asigna la dirección IPv6 al túnel. Los túneles 6to4 siempre tienen una dirección que comienza por 2002::/16.\nR1(config-if)#ipv6 address 2002:7800:1::1/64 A continuación, se asigna el túnel a la interfaz que recibe los mensajes usando el protocolo IPv6.\nR1(config-if)#tunnel source fastEthernet 1/0 Finalmente, se establece el modo del túnel. El modo ipv6op especifica que el protocolo encapsulado es IPv6 y que IPv4 funciona como el protocolo de encapsulamiento y, a la vez, como el protocolo de transporte.\nR1(config-if)#tunnel mode ipv6ip 6to4 R1(config-if)#end R1#wr Tras configurar el túnel, se añaden las líneas necesarias a la tabla de enrutamiento:\nR1(config)#ipv6 route 2001:db8:3::302/64 tunnel 0 2002:7800:2::1 Por otra parte, se repite el proceso en el router R3 para configurar el túnel desde R3 hasta R1:\nR3(config)#interface tunnel 0 R3(config-if)#ipv6 address 2002:6E00:1::1/64 R3(config-if)#tunnel source fastEthernet 0/1 R3(config-if)#tunnel mode ipv6ip 6to4 R3(config-if)#end R3#wr Y, posteriormente se enruta el túnel:\nR3(config)#ipv6 route 2001:db8:1::102/64 tunnel 0 2002:7800:1::1 Con esta configuración, ya se puede establecer la comunicación entre PC1 y PC4 a través del túnel IPv6 que conecta el router R1 con el router R3.\nTúnel entre R1 y R2 Para permitir el tráfico IPv6 entre los routers R1 y R2 se debe configurar un túnel en cada dirección entre estos dos dispositivos. En el router R2 se debe configurar un túnel de la misma manera que en el caso anterior:\nR2(config)#interface tunnel 0 R2(config-if)#ipv6 address 2002:6E00:1::2/64 R2(config-if)#tunnel source fastEthernet 0/1 R2(config-if)#tunnel mode ipv6ip 6to4 R2(config-if)#end R2#wr En este caso, la línea que se debe añadir a la tabla de enrutamiento es la siguiente:\nR2(config)#ipv6 route 2001:db8:1::102/64 tunnel 0 2002:6E00:1::1 En el sentido opuesto, en el router R1 se configura un segundo túnel que lo conecte al router 2:\nR1(config)#interface tunnel 1 R1(config-if)#ipv6 address 2002:6E00:1::1/64 R1(config-if)#tunnel source fastEthernet 0/1 R1(config-if)#tunnel mode ipv6ip 6to4 En este paso de la configuración se produce el siguiente mensaje de error:\nEsto se debe a que en los routers Cisco no se puede configurar más de un túnel 6to4 en cada router. De esta forma, la práctica planteada no se puede seguir desarrollando en este escenario.\nConfiguración de túeneles 6to4 en routers Linux Para facilitar la comprensión de esta documentación, el escenario contará con el mismo direccionamiento que el ejemplo anterior.\nPor tanto, la configuración aplicable a los routers es la siguiente:\nR1 R2 R3 #Static config for ens4 auto ens4 iface ens4 inet6 static address 2001:db8:1::101 netmask 64 auto ens5 iface ens5 inet static address 110.0.0.1 netmask 255.255.255.0 gateway 110.0.0.2 auto ens6 iface ens6 inet static address 120.0.0.1 netmask 255.255.255.0 gateway 120.0.0.2 #Static config for ens4 auto ens4 iface ens4 inet6 static address 2001:db8:1::201 netmask 64 auto ens5 iface ens5 inet static address 110.0.0.2 netmask 255.255.255.0 gateway 110.0.0.1 auto ens6 iface ens6 inet static address 130.0.0.2 netmask 255.255.255.0 gateway 130.0.0.1 #Static config for ens4 auto ens4 iface ens4 inet6 static address 2001:db8:1::301 netmask 64 auto ens5 iface ens5 inet static address 120.0.0.2 netmask 255.255.255.0 gateway 120.0.0.1 auto ens6 iface ens6 inet static address 130.0.0.1 netmask 255.255.255.0 gateway 130.0.0.2 Además, en todos los routers del escenario se activa el bit de forwarding tanto para IPv4 como para IPv6 añadiendo o descomentando las siguientes líneas en el fichero /etc/sysctl.conf:\nnet.ipv4.ip_forward=1 net.ipv6.conf.all.forwarding=1 Túnel entre R1 y R3 Para establecer la conexión entre R1 y R3 a través de IPv6 se debe crear un túnel en cada uno de estos dos routers que lo una con el otro. En el router R1 se define el túnel:\nip tunnel add tunel0 mode sit ttl 64 remote 120.0.0.2 local 120.0.0.1 El parámetro ttl 64 indica que este es el valor inicial que se coloca en la cabecera IPv4 a la entrada del túnel. Se añade la dirección IPv6 del túnel calculada a partir de la IPv4 de la interfaz:\nip a add 2002:7800:1::1/64 dev tunel0 Después se levanta la interfaz:\nip l set tunel0 up Y finalmente se enrutan los paquetes dirigidos a la red del PC4, conectado al router R3, a través del túnel:\nip -6 route add 2001:db8:3::/64 dev tunel0 En sentido opuesto, se define el túnel que va desde R3 hasta R1:\nip tunnel add tunel0 mode sit ttl 64 remote 120.0.0.1 local 120.0.0.2 [ 1536.696601] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver ip a add 2002:7800:1::2/64 dev tunel0 ip l set tunel0 up ip -6 route add 2001:db8:1::/64 dev tunel0 Tras establecer esta configuración, PC1 puede comunicarse con PC4 a través del túnel:\nY PC4 también usa el túnel para llegar a PC1:\nTúnel entre R1 y R2 Para conectar los routers R1 y R2 se deben crear los siguientes túneles:\nR1 R2 ip tunnel add tunel1 mode sit ttl 64 remote 110.0.0.2 local 110.0.0.1 ip a add 2002:6E00:1::1/64 dev tunel1 ip l set tunel1 up ip -6 route add 2001:db8:2::/64 dev tunel1 ip tunnel add tunel0 mode sit ttl 64 remote 110.0.0.1 local 110.0.0.2 [ 2726.493888] sit: IPv6, IPv4 and MPLS over IPv4 tunneling driver ip a add 2002:6E00:1::2/64 dev tunel0 ip l set tunel0 up ip -6 route add 2001:db8:1::/64 dev tunel0 Túnel entre R2 y R3 Para establecer una comunicación a través del protocolo IPv6 entre R2 y R3 se necesitan otros dos túneles.\nR2 R3 ip tunnel add tunel1 mode sit ttl 64 remote 130.0.0.1 local 130.0.0.2 ip a add 2002:8200:1::2/64 dev tunel1 ip l set tunel1 up ip -6 route add 2001:db8:3::/64 dev tunel1 ip tunnel add tunel1 mode sit ttl 64 remote 130.0.0.2 local 130.0.0.1 ip a add 2002:8200:1::1/64 dev tunel1 ip l set tunel1 up ip -6 route add 2001:db8:2::/64 dev tunel1 Demostración del funcionamiento de los túeneles En una captura de tráfico entre R1 y R3 se aprecia cómo se añade una segunda cabecera del nivel de red al datagrama. Una de ellas usa el protocolo IPv6 y otra el IPv4. En el resumen de la información las IP de origen y destino se mantienen siempre como las IPv6 originales del mensaje pero, en un análisis un poco más profundo se encuentra la cabecera IPv4 que tiene como IP de origen la IPv4 del túnel 6to4 y como destino, la IPv4 del otro extremo del router.\nEn el ejemplo seleccionado en esta captura, el paquete incluye una cabecera IPv6 que tiene como IP de origen la 2001:db8:1::102, correspondiente al PC1 y como destino la 2001:db8:3::302, correspondiente al PC4. Sin embargo, esa cabecera está dentro de otra, un nivel superior, que usa el protocolo IPv4 y que tiene como IP de origen la 120.0.0.1, correspondiente al router R1 y como destino la 120.0.0.2, correspondiente al router R3.\nUn ejemplo similar se puede replicar entre R1 y R2. En este punto, el paquete de petición echo desde PC1 hasta PC3 tiene como dirección de origen la IPv6 2001:db8:1::102, correspondiente al PC1 y como destino la 2001:db8:2::202, correspondiente al PC3. En cambio, una consulta más detallada de las cabeceras del nivel de red demuestra que, además, el paquete incluye una cabecera IPv4 que tiene como dirección de origen la 110.0.0.1, correspondiente al router R1 y como destino la 110.0.0.2, correspondiente al router R2.\nFinalmente, el tráfico entre R2 y R3 a través del túnel presenta un comportamiento similar. En la captura de tráfico se puede comprobar cómo los paquetes echo request salen desde el PC4 con la dirección de origen 2001:db8:3::302 y se dirigen a la dirección 2001:db8:2::202, correspondiente al PC3. Sin embargo, al llegar al router R3, el paquete se encapsula dentro de una nueva cabecera IPv4 que tiene como IP de origen la de R3, la 130.0.0.1, como dirección de destino la 130.0.0.2, correspondiente al router R2.\n"},{
  "section": "Blog",
  "slug": "/blog/sistemas/2024-05-17-politicas-grupo-active-directory-windows/",
  "title": "Creación de política de grupo en Windows Active Directory",
  "description": "",
  "date": "May 17, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "sistemas",
  "tags": "sistemas, comandos, PowerShell, Windows, Active Directory, Directorio Activo, políticas de grupo, GPO, Implantación de Sistemas Operativos",
  "content":"Una directiva de grupo es un conjunto de reglas que controlan el entorno de trabajo de cuentas de usuario y cuentas de equipo. La directiva de grupo permite gestionar y configurar de forma centralizada sistemas operativos, aplicaciones y configuración de los usuarios en un entorno de Directorio Activo.\nPolítica de despliegue de software Supuesto: Una empresa quiere implantar un entorno apto para el teletrabajo y todos los usuarios necesitan contar con un software que les permita realizar videoconferencias. La empresa ha contratado una licencia de Zoom y toda la plantilla debe contar en sus equipos con un cliente de escritorio de Zoom Meetings.\nEn primer lugar, desde la web del proveedor se descarga el fichero MSI para la instalación del cliente de escritorio de Zoom. Posteriormente, el fichero de instalación se almacena en una carpeta compartida con todos los equipos del dominio.\nPara instalar el software en el próximo inicio de sesión de cada usuario del dominio se crea una política de grupo en el dominio y, en ella, se especifica un paquete de instalación de software.\nPosteriormente se indica en las propiedades del paquete que instale la aplicación durante el inicio de sesión.\nDe esta manera queda configurada esta directiva de grupo en el controlador de dominio y se aplicará a todos los usuarios del dominio que inicien sesión.\nPor último, antes de iniciar sesión en el cliente, se fuerza la actualización de las directivas de grupo.\ngpupdate /force Al iniciar sesión, cada usuario ya tendrá instalado el cliente de escritorio de Zoom Meetings en su equipo.\nPolítica de configuración del sistema Supuesto: La plantilla de la empresa tiene dificultades para acceder al recurso compartido en el que se almacenan todos los datos con los que deben trabajar. Para solucionar el problema se creará una directiva de grupo que genere un acceso directo en el escritorio de ese volumen compartido.\nEn este caso no es necesario descargar ningún instalador. Los primeros pasos son similares a los del caso anterior: desde el controlador de dominio se accede al editor de directivas de grupo y se genera una nueva directiva. En este caso, desde la carpeta de preferencias se elige la opción de accesos directos y se crea un nuevo. Se la plica la configuración necesaria, se indica el nombre, ruta de destino y se le asigna un icono:\nNuevamente, se fuerza la actualización de la directiva y, al iniciar sesión, el usuario contará con un acceso directo al recurso compartido en su escritorio.\n"},{
  "section": "Blog",
  "slug": "/blog/redes/2024-05-14-ipv6-router-linux-cisco/",
  "title": "Así funciona IPv6: configuración en router Linux y Cisco",
  "description": "",
  "date": "May 14, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "GNS3, redes, Planificación y Administración de Redes, router, router Linux, Cisco, IPv6, SLAAC, DHCPv6, Wireshark",
  "content":"IPv6 es una actualización del protocolo IPv4 que nace ante la escasez de direcciones que IPv4 permite. Las direcciones IPv6 están formada por 32 caracteres hexadecimales en grupos de cuatro caracteres separados por el carácter dos puntos (:). En este post se recogen varios ejemplos prácticos del funcionamiento de este protocolo.\nDirección IPv6 de enlace local El funcionamiento de las direcciones IPv6 de enlace local se puede comprobar en un escenario simulado en GNS3 con dos máquinas Debian conectadas al mismo switch.\nPara conseguir una dirección IPv6 es necesario encender las interfaces que, en estas máquinas, están apagadas por defecto. Para ello, se usa el comando sudo ip l set ens4 up e inmediatamente después ya se puede consultar la dirección IPv6 de enlace local de cada máquina.\nPC1\rPC2\rPara comprobar la conectividad entre ambos equipos se puede hacer un ping, por ejemplo, de PC1 a PC2 con el comando ping6 -c 3 fe80::ea4:e8ff:fe35:0.\nDirecciones globales por SLAAC con un router Linux En este caso, se añade una tercera máquina Debian al escenario que funciona como router.\nPara que esta nueva máquina funcione como router se debe activar el bit de forwarding para IPv6 descomentando la línea net.ipv6.conf.all.forwarding=1 en el fichero /etc/sysctl.conf.\nAdemás, para que el router pueda ofrecer la información sobre el prefijo de red necesaria para que las máquinas generen su IPv6 global mediante SLAAC, debe tener instalado y configurado un daemon que cumpla este propósito. En este caso, se usa radvd. Este daemon se instala con el gestor de paquetes apt:\nsudo apt install radvd Al comprobar el estado del daemon tras la instalación con systemctl status radvd, la salida del comando muestra una advertencia sobre la ausencia del fichero de configuración. En este caso, la instalación no genera los ficheros de configuración necesarios para la gestión del daemon y se deben crear a mano.\nEste fichero de configuración se debe alojar en la ubicación /etc/radvd.conf y contiene información como el nombre de la interfaz, los intervalos mínimos y máximos en los que el router debe enviar mensajes Router Advertisement o el prefijo que debe indicar a las máquinas de la red que lo soliciten con una estructura como esta:\ninterface ens4 { MinRtrAdvInterval 3; MaxRtrAdvInterval 4; AdvSendAdvert on; AdvManagedFlag on; prefix 2001:db8::/64 { AdvValidLifetime 14300; AdvPreferredLifetime 14200; } ; }; Tras aplicar esta configuración y reiniciar el daemon, se ejecuta con éxito.\nAl volver a consultar la dirección IPv6 de las máquinas conectadas a la red, éstas ya cuentan con una dirección global:\nPC1\rPC2\rDe nuevo, para comprobar la conectividad, se puede hacer un ping, esta vez a la dirección global de PC2 desde PC1, por ejemplo con ping6 -c 3 2001:db8::ea4:e8ff:fe35:0:\nFinalmente, para hacer persistente esta configuración en las interfaces de las máquinas se añade la siguientes líneas al fichero /etc/network/interfaces:\nauto ens4 iface ens4 inet6 auto Servidor DHCPv6 en router Linux Las direcciones IPv6 de la red también se pueden otorgar a las máquinas a través de DHCPv6. Para ello, el router debe contar con un servidor DHCPv6, en este caso, dhcp6s.\nAntes de comenzar la instalación del servidor y la configuración por DHCPv6 de las máquinas de la red, los comandos sudo systemctl stop radvd.service y sudo systemctl disable radvd.service paran y deshabilitan el daemon configurado en el punto anterior.\nEl servidor DHCPv6 dhcp6s requiere ser configurado tras su instalación:\nsudo apt install wide-dhcp6-server El instalador lanza un asistente de configuración que guía el proceso. En primer lugar, se configura la interfaz por la que el servidor escucha las peticiones DHCP. A continuación se debe completar la configuración editando el fichero /etc/wide-dhcpv6/dhcp6s.conf a partir de los ejemplos recogidos en el directorio /usr/share/doc/wide-dhcpv6-server/examples.\nEste fichero de ejemplo se puede copiar a la ubicación en el directorio /etc con el comando sudo cp /usr/share/doc/wide-dhcpv6-server/examples/dhcp6s.conf.sample /etc/wide-dhcpv6/dhcp6s.conf. Entre las opciones de configuración que permite el servidor, están la de indicar una dirección de DNS a las máquinas, asignar un pool de direcciones IPv6 que puede ofrecer o reservar direcciones estáticas a equipos concretos. En este caso, se configura un pool que concede direcciones desde la 2001:db8:1:2::1000 a la 2001:db8:1:2::2000 durante 3600 segundos. Además, indica a todas las máquinas que la dirección del DNS es la 2001:db8::35.\noption domain-name-servers 2001:db8:2::45; interface ens4 { address-pool pool1 3600; }; pool pool1 { range 2001:db8:1:2::1000 to 2001:db8:1:2::2000 ; }; Para que los clientes puedan recibir la configuración IPv6 que ofrece este servidor deben tener instalado el paquete dhcp6c.\nsudo apt install wide-dhcpv6-client. En este caso se debe indicar durante el proceso de instalación la interfaz por la que el cliente solicitará las direcciones IPv6.\nEl paquete del cliente también genera ejemplos de configuración durante la instalación, en este caso, en el directorio /usr/share/doc/wide-dhcpv6-client/examples/. Desde este fichero de ejemplo, se puede copiar y adaptar el siguiente contenido al fichero de configuración:\ninterface ens4 { send ia-na 0; send rapid-commit; send domain-name-servers; }; id-assoc na { }; Con esta configuración el cliente devuelve los siguientes errores al intentar obtener una dirección IPv6 desde el servidor DHCP.\nOtra opción para otorgar direcciones por DHCPv6 es el servidor DHCPv6 Kea, del ISC. Para instalar este servidor se debe añadir primero el repositorio al sistema con el comando\ncurl -1sLf \\ \u0026#39;https://dl.cloudsmith.io/public/isc/kea-2-0/setup.deb.sh\u0026#39; \\ | sudo -E bash. A continuación se puede instalar el servidor.\nsudo apt install isc-kea-dhcp6-server La configuración del servidor se establece en el fichero /etc/kea/kea-dhcp6.conf. Comienza con las siguientes líneas, en las que se indica al servidor por qué interfaces debe escuchar.\n\u0026#34;Dhcp6\u0026#34;: { \u0026#34;interfaces-config\u0026#34;: { \u0026#34;interfaces\u0026#34;: [ens4] }, A continuación, se indica en qué tipo de base de datos debe almacenar la información sobre las direcciones concedidas.\n\u0026#34;lease-database\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;memfile\u0026#34;, “persist”: true, \u0026#34;lfc-interval\u0026#34;: 3600 }, Posteriormente se puede indicar cómo debe gestionar el servidor las concesiones que han expirado.\n\u0026#34;expired-leases-processing\u0026#34;: { \u0026#34;reclaim-timer-wait-time\u0026#34;: 10, \u0026#34;flush-reclaimed-timer-wait-time\u0026#34;: 25, \u0026#34;hold-reclaimed-time\u0026#34;: 3600, \u0026#34;max-reclaim-leases\u0026#34;: 100, \u0026#34;max-reclaim-time\u0026#34;: 250, \u0026#34;unwarned-reclaim-cycles\u0026#34;: 5 }, Además, en este fichero se establece una configuración genérica para el tiempo de las concesiones, en la que se puede indicar el tiempo que debe esperar el servidor antes de renovar una concesión, el tiempo de vida de la concesión por defecto y el tiempo válido, entre otros parámetros.\n\u0026#34;renew-timer\u0026#34;: 1000, \u0026#34;rebind-timer\u0026#34;: 2000, \u0026#34;preferred-lifetime\u0026#34;: 3000, \u0026#34;valid-lifetime\u0026#34;: 4000, En el campo option-data se puede añadir otra información relacionada con la configuración IP que se concede a las máquinas cliente como, por ejemplo, las direcciones de DNS o la opción unicast (“code”: 12) que indica la dirección IPv6 por la que escucha el router.\n\u0026#34;option-data\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;dns-servers\u0026#34;, \u0026#34;data\u0026#34;: \u0026#34;2001:db8:2::45, 2001:db8:2::100\u0026#34; }, { \u0026#34;code\u0026#34;: 12, \u0026#34;data\u0026#34;: \u0026#34;2001:db8::1\u0026#34; }, Después se define también la subred con la que trabaja el servidor con la opción “subnet6”. En ella se define el prefijo de la red que se usa en las direcciones que se otorgan a los clientes, así como los pools de direcciones que el servidor puede asignar. Este campo también cuenta con la opción “option-data” que se aplica sólo a las máquinas de la subred y que sobrescribe la configuración general si se usa. Además, permite reservar direcciones IPv6 para determinados clientes.\n\u0026#34;subnet6\u0026#34;: [ { \u0026#34;subnet\u0026#34;: \u0026#34;2001:db8:1::/64\u0026#34;, \u0026#34;pools\u0026#34;: [ { \u0026#34;pool\u0026#34;: \u0026#34;2001:db8:1::/80\u0026#34; } ] } ] } }. El servidor isc-dhcp también cuenta con soporte para IPv6. Este servidor se instala con sudo apt install isc-dhcp-server y se configura en el fichero /etc/dhcp/dhcpd6.conf. En este fichero se indican valores como el tiempo por defecto de las concesiones, el tiempo de vida de la concesión o el tiempo de renovación por defecto. Además, también se indica en este fichero el DNS por defecto. Finalmente, se declara la subred con su prefijo y el rango de direcciones que el servidor podrá conceder dentro de esa red.\ndefault-lease-time 2592000; preferred-lifetime 604800; option dhcp-renewal-time 3600; option dhcp-rebinding-time 7200; option dhcp6.name-servers 2001:db8:2::45, 2001:db8:2::100; subnet6 2001:db8:1::/64 { interface ens4; range6 2001:db8:1::1000 2001:db8:1::2000; } Adicionalmente, en el fichero /etc/default/isc-dhcp-server hay que descomentar la linea que indica la ruta al fichero de configuración para el servidor y añadir las interfaces por las que este servidor escucha.\nDHCPDv6_CONF=/etc/dhcp/dhcpd6.conf OPTIONS=\u0026#34;-6\u0026#34; INTERFACESv6=\u0026#34;ens4\u0026#34; También hay que crear el fichero que el servidor usa como base de datos para almacenar la información sobre las concesiones que ofrece a los equipos de la red con sudo touch /var/lib/dhcp/dhcpd6.leases. Además, se asigna a la interfaz por la que escucha el servidor una IPv6 estática con el mismo prefijo de las direcciones que concede el servidor DHCPv6 pero fuera del rango de direcciones configurado:\nauto ens4 iface ens4 inet6 static address 2001:db8:1::1 netmask 64 Finalmente, al arrancar el servidor con sudo dhcpd -6 -cf /etc/dhcp/dhcpd6.conf, comienza a funcionar.\nSin embargo, el servidor continúa devolviendo un error. Este error parece estar relacionado con un proceso que ya existe como se muestra en la siguiente línea de la salida del comando sudo service isc-dhcp-server status:\nSolucionarlo es bastante sencillo: sólo hay que eliminar el fichero asociado al proceso existente y volver a iniciar el servidor.\nsudo rm -r /var/run/dhcpd6.pid sudo service isc-dhcp-server start El proceso de autoconfiguración de direcciones por SLAAC En la siguiente captura de Wireshark se muestra el proceso de autoconfiguración de la dirección IPv6 del PC1 usando SLAAC:\nAntes del encendido de la tarjeta de red, la captura de tráfico detecta varios mensajes Router Advertisement (paquetes 9 y 10) desde la IPv6 del router. Estos son los mensajes que el daemon están enviando constantemente a la red para indicar al resto de equipos el prefijo de red que deben usar al asignarse direcciones IPv6.\nCuando se enciende la tarjeta de red, el PC1 envía varios mensajes, entre ellos, dos mensajes multicast. En concreto, el que forma parte del proceso de autoconfiguración por SLAAC es el paquete número 15 de la captura, un mensaje enviado a la IPv6 ff02::2, la dirección multicast que se usa para comunicarse con los routers de la red, y que contiene un mensaje Router Solicitation, en el que se solicita la información necesaria para generar la IPv6 global.\nTras la solicitud del PC1, se captura un paquete, el número 16, que también es de tipo Router Advertisement pero que, a diferencia del resto de paquetes de este tipo, no se dirige a la dirección ff02::1, dirección multicast que envía los mensajes a todos los nodos de la red, sino a la fe80::e42:f1ff:fef4:0, es decir, la IPv6 de enlace local del PC1 desde la que ha solicitado el prefijo de red para configurar su dirección global en el mensaje Router Solicitation anterior. Por tanto, el mensaje número 16 en la captura es la respuesta del router al mensaje número 15.\nDespués de eso, se siguen sucediendo mensajes Router Advertisement, nuevamente dirigidos a la dirección multicast ff02::1 porque el router los envía de forma automática pero el PC1 ya ha generado su IPv6 a partir del prefijo que el router le ha facilitado en su respuesta al mensaje Router Solicitation.\nTambién es relevante en el proceso de autoconfiguración el paquete número 18 en esta captura de tráfico. Se trata de un mensaje Neighbor Solicitation que el PC1 envía a la dirección de nodo solicitado para comprobar que la dirección que se ha configurado a partir del prefijo aportado por el router no se repite en la red. Como se puede comprobar, ningún otro equipo de la red contesta este mensaje, por tanto, esto significa que esta dirección IPv6 no está duplicada en la red y PC1 la puede usar.\nEl proceso de autoconfiguración de direcciones por DHCPv6 En la siguiente captura de tráfico se muestra el proceso de autoconfiguración de la dirección IPv6 del PC2 usando DHCPv6:\nAntes de solicitar una configuración IPv6 con sudo dhclient -6, por el cable que conecta al PC2 con el router R1 circulan varios mensajes de tipo multicast como los neigbor solicitation o los router solicitation.\nCuando el PC2 solicita una configuración IPv6 al servidor DHCP, envía un mensaje de tipo solicit (paquete 9 de la captura). Este mensaje es de tpo multicast y se envía a la dirección IPv6 reservada ff02::1:2. Esta dirección reservada se usa para hacer llegar el mensaje a todos los dispositivos de la red. Con este mensaje, el ordenador solicita la respuesta de algún equipo de la red que tenga instalado un servidor DHCPv6 en funcionamiento.\nEl siguiente mensaje registrado en la captura (paquete 10) es un mensaje advertise, en el que el router contesta la solicitud del PC2. En este caso se trata de un mensaje de tipo unicast que tiene como origen la IP de enlace local del router y como destino la IP de enlace local del PC. Con este mensaje, el router informa al PC2 de que tiene un servidor DHCPv6 que puede atender su petición.\nEn este mensaje, el servidor DHCP ya incluye información sobre la dirección IPv6 que ofrece al ordenador (2001:db8:1::2000, la última del rango), así como el tiempo de concesión de la configuración.\nEstos paquetes también incluyen un identificador del cliente y un identificador del servidor que cuenta con información como el DUID de cada uno de los equipos (un identificador único en numeración hexadecimal), el tipo de conexión, la fecha y hora del mensaje o la dirección MAC de cada uno de los equipos.\nPosteriormente, el PC2 envía un mensaje request al router, también de tipo multicast y dirigido a la misma dirección que el anterior. Con este segundo mensaje, el ordenador solicita al servidor DHCP del router la configuración de IPv6 ofrecida en la respuesta anterior.\nFinalmente, el servidor DHCPv6 del router contesta con un mensaje de tipo reply en el que, definitivamente, concede la configuración IPv6 indicada al PC2, como se puede ver en el paquete número 12 de la captura.\nEl resto de paquetes capturados corresponden a mensajes multicast de tipo neigbor solicitation o advertisement o router solicitation que no forman parte de la comunicación por la que el servidor DHCPv6 concede una dirección al PC.\nAcceder a un servidor web con IPv6 El PC2 cuenta con un servidor web Apache. Se puede acceder a él desde el PC1 usando el comando curl pero para hacerlo es necesario usar la dirección IPv6 global de PC2 puesto que el servidor web no responde peticiones que lleguen a la dirección de enlace local aunque lo hagan por la misma interfaz y desde maquinas de la misma red.\nPara que PC1 pueda llegar es necesario configurar la entrada por defecto de las tablas de enrutamiento de los ordenadores.\nsudo ip -6 route add default via fe80::ede:a4ff:fec9:0 dev ens4 Para comunicarse con el router los equipos de la red usan su dirección de enlace local.\nUna vez que la red esta enrutada, el PC1 puede acceder al servidor web del PC2 usando su dirección global con el comando curl.\ncurl \u0026#39;http://[2001:db8:1::2000]\u0026#39; Info\nLas direcciones IPv6 se cierran entre corchetes en las URL.\nAcceder al servidor web desde otra red sin hacer NAT Una nueva máquina se conecta a otra interfaz del router.\nPara poder acceder al servidor web de PC2 esta máquina necesita una dirección IPv6 de una red diferente a la de los PC1 y 2:\nip l set dev ens4 up sudo ip -6 a add 2001:db8:2::abba dev ens4 También necesita una línea en su tabla de enrutamiento que le indique que, por defecto, debe enviar todos los mensajes al router R1:\nsudo ip -6 route add default via fe80::ede:a4ff:fec9:1 dev ens4 Además, la interfaz del router que da al PC3 tiene que contar con una dirección global /64 de la misma red que el ordenador en la interfaz que conecta a ambos dispositivos:\nsudo ip -6 a add 2001:db8:2::1/64 dev ens5 Con estas condiciones, el PC3 ya puede acceder al servidor web del PC2 desde una red diferente, pasando por un router intermedio y sin necesidad de hacer NAT en ningún punto del recorrido:\ncurl \u0026#39;http://[2001:db8:1::2000]\u0026#39; Configuración de SLAAC en un router Cisco Para poder trabajar con IPv6 en routers Cisco se debe habilitar la opción IPv6 unicast routing:\nR1(config)#ipv6 unicast-routing. Después se asigna la dirección global a la interfaz del router que se conecta a la red a cuyos equipos tiene que enviar la información necesaria a través de SLAAC.\nR1#conf t R1(config)#interface fastEthernet 0/0 R1(config-if)#ipv6 address 2001:db8:1::1/64 R1(config-if)#no shutdown R1(config-if)#end R1#wr Tras arrancar la interfaz, el router ha rellenado automáticamente su tabla de enrutamiento (show ipv6 route) con la información de la red a la que está conectado.\nAl reiniciar las tarjetas de red de los equipos, ambos renuevan sus direcciones IPv6 usando el protocolo SLAAC y, con estas nuevas direcciones, pueden comunicarse entre ellos a través de sus IPv6 globales.\nA diferencia de lo que ocurre en los routers Linux, donde se necesita configurar un daemon para habilitar el protocolo SLAAC para la autoconfiguración de las direcciones IPv6 por parte de los equipos de la red, en los routers Cisco esta opción se incluye por defecto y comienza a funcionar en cuanto se habilita y configura el direccionamiento IPv6 en el router.\nSin embargo, de esta forma no se puede enviar información sobre el DNS a los equipos de la red cómo sí permite el daemon radvd en los routers Linux. Para poder comunicar esta información a los equipos de la red, los routers Cisco usan un método llamado DHCPv6 stateless, que combina el proceso de autoconfiguración de direcciones IPv6 por SLAAC con el protocolo DHCPv6 sólo para trasladar información sobre la dirección del DNS. En este caso, el direccionamiento se otorga por SLAAC y no por DHCPv6.\nPara habilitar esta función se crea, en primer lugar, un pool DHCPv6:\nR1(config)# ipv6 dhcp pool IPV6-STATELESS Después se indica, dentro del pool, la dirección IPv6 del DNS que se va a indicar a los equipos de la red como preferido:\nR1(config-dhcpv6)# dns-server 2001:db8:1::45 Finalmente, se asigna el pool a la interfaz por la que el router contesta las peticiones de la red. Desde el modo de configuración de la interfaz se asignan las direcciones IPv6 de enlace local y global de la interfaz (si no las tenía previamente asignadas) y se vincula el pool DHCPv6 configurado anteriormente. Además, para que el DHCPv6 funcione en modo stateless es necesario activar la bandera other-config, que cambia el bit O de los paquetes DHCP de 0 a 1:\nR1(config)# interface fastEthernet 0/0 R1(config-if)# description Link to LAN R1(config-if)# ipv6 address fe80::1 link-local R1(config-if)# ipv6 address 2001:db8:1::1/64 R1(config-if)# ipv6 nd other-config-flag R1(config-if)# ipv6 dhcp server IPV6-STATELESS R1(config-if)# no shut R1(config-if)# end Con esta configuración los equipos de la red reciben una dirección IPv6 por SLAAC pero, además, reciben también la información necesaria para configurar su servidor DNS por defecto.\nConfiguración de DHCPv6 en un router Cisco La configuración del servidor DHCPv6 en los routers Cisco para conceder direcciones IPv6 así como una dirección del servidor DNS por defecto es similar a la contemplada en el apartado anterior durante la configuración del direccionamiento por SLAAC con DHCPv6 stateless.\nEn este caso, para que le servidor DHCPv6 conceda también direcciones IPv6, se debe usar el modo stateful. La principal diferencia en la configuración del router está en las banderas que se deben activar al asignar el pool DHCP a la interfaz de escucha del router. De esta forma, en primer lugar, tras activar IPv6 en el router se crea un nuevo pool DHCP:\nR1(config)# ipv6 dhcp pool IPV6-STATEFUL En él se indica el prefijo a partir del cuál se deben generar las direcciones IPv6 que se otorgan a los equipos de la red y la dirección del servidor DNS por defecto:\nR1(config-dhcpv6)# address prefix 2001:db8:1::/64 R1(config-dhcpv6)# dns-server 2001:db8:1::45 Y, finalmente, se asocia el pool DHCP a la interfaz por la que el servidor escucha las peticiones de los equipos de la red local. En este caso, como el modo del servidor es stateful se cambia la bandera M de 0 a 1 con ipv6 nd managed-config-flag, así como la bandera A con el comando ipv6 nd prefix default no-autoconfig. Esta bandera indica al cliente que no use SLAAC para autoconfigurar su dirección IPv6, sino que tome la que le concede el servidor DHCPv6, de manera que evita posibles problemas derivados de las interferencias entre ambos protocolos. Además, en este paso también se puede asignar una dirección de enlace local y una dirección global a la interfaz, si no las tenía asignadas previamente y se une el pool a ella con ipv6 dhcp server:\nR1(config)# interface fastEthernet 0/0 R1(config-if)# description Link to LAN R1(config-if)# ipv6 address fe80::1 link-local R1(config-if)# ipv6 address 2001:db8:1::1/64 R1(config-if)# ipv6 nd managed-config-flag R1(config-if)# ipv6 nd prefix default no-autoconfig R1(config-if)# ipv6 dhcp server IPV6-STATEFUL R1(config-if)# no shut R1(config-if)# end Así, el router funciona como servidor DHCPv6 y concede una configuración IPv6 completa a los clientes de la red local que la soliciten.\n"},{
  "section": "Blog",
  "slug": "/blog/sistemas/2024-05-07-gestion-recursos-compartidos-active-directory-windows-powershell/",
  "title": "Gestión de recursos compartidos en Windows Active Directory con cmd y Powershell",
  "description": "",
  "date": "May 7, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "sistemas",
  "tags": "sistemas, comandos, PowerShell, Windows, recursos compartidos, Active Directory, Directorio Activo, cmd, controlador de dominio, Implantación de Sistemas Operativos",
  "content":"Active Directory o Directorio Activo es un servicio de directorio de Windows en el que un equipo servidor comparte recursos como usuarios, grupos o directorios con los equipos clientes que se conectan a él.\nEn este post se muestra cómo se puede compartir un directorio en el controlador de dominio desde la cmd y desde la PowerShell.\nCompartir un directorio en el controlador de dominio desde cmd En primer lugar, se crea el directorio.\nmkdir C:\\RecursoCompartido Para establecer el directorio como recurso compartido:\nnet share recursoCompartido=C:\\RecursoCompartido El recurso compartido es visible para el cliente.\nCompartir un directorio en el controlador de dominio desde PowerShell Tras crear el directorio, se establece como recurso compartido\nNew-SmbShare -Name recursoCompartido -Path C:\\Compartido\\ Después, se concede permiso de lectura al grupo de usuarios de dominio y se revocan el resto de permisos.\nGrant-SmbShareAccess -Name recursoCompartido -AccountName \u0026#39;DOMA\\Usuarios del dominio\u0026#39; -AccessRight Read Revoke-SmbShareAccess -Name recursoCompartido -AccountName \u0026#39;Todos\u0026#39; El recurso compartido ya es visible para el cliente. Posteriormente, se crea una unidad con el recurso compartido.\nNew-PSDrive -Name Y -PSProvider FileSystem -Root \\\\DC1DOMA\\recursoCompartido -Persist Y, finalmente, el cliente puede mapear el recurso y acceder a él.\nNew-SmbMapping -LocalPath Y: -RemotPath \\\\DC1DOMA\\recursoCompartido "},{
  "section": "Blog",
  "slug": "/blog/fundamentos-hardware/2024-05-06-manejo-uso-comando-mkisofs-ejemplos/",
  "title": "Manejo y uso del comando mkisofs",
  "description": "",
  "date": "May 6, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "fundamentos-hardware",
  "tags": "Fundamentos de Hardware, debian, linux, instalación, mkisofs, comandos, file system, iso",
  "content":"El comando mkisofs o genisoimage es un programa que genera sistemas de ficheros de tipo ISO. Este comando genera registros usando el protocolo SUSP (System Use Sharing Protocol) especificado por el Rock Ridge Interchange Protocol para trasladar los ficheros de un sistema de ficheros con formato ISO9660 a una máquina Unix, incluyendo información sobre nombres de ficheros largos, UID/GID, permisos POSIX, enlaces simbólicos, dispositivos de bloques.\nGenisoimage usa la imagen de un árbol de directorios y genera una imagen binara y la escribe en un dispositivo de bloques en formato ISO9660. Además, trunca y modifica los nombres de fichero para evitar inconsistencias en la creación de la imagen ISO. Este comando no está diseñado para comunicarse directamente con el grabador en el caso de que la imagen se quiera grabar en un disco y es necesario usar herramientas específicas para llevar a cabo este proceso como wodim.\nSi se especifican varias rutas al usar mkisofs, los ficheros que conforman cada una de ellas se unirán en el sistema de ficheros de tipo imagen.\nSintaxis La sintaxis del comando genisoimage es\ngenisoimage [options] [-o filename] pathspec [pathspec …] Opciones -nobak, -no-bak. Excluye los ficheros de backup. -e FILE, -efi-boot FILE. Establece el nombre de la imagen de arranque EFI. -G FILE, -generic-boot FILE. Estable el nombre de la imagen de arranque genérica. -dir-mode mode. Establece los permisos de todos los directorios. -file-mode mode. Establece los permisos de todos los ficheros. -f, -follow-links. Mantiene los enlaces simbólicos. -gid gid. Establece el grupo como propietario de todos los ficheros. -root DIR. Establece el directorio raíz. -iso-level LEVEL. Establece el nivel ISO9660 del 1 al 3 o 4 para ISO9660 versión 2. -l, -full-iso9660-filenames. Permite nombres de fichero de hasta 31 caracteres. -max-iso9660-filenames. Permite nombres de fichero de hasta 37 caracteres (no cumple con la norma ISO9660). -allow-limited-size. Permite un tamaño de ficheros diferente para ficheros grandes. -allow-leading-dots, -ldots, -L, -allow-leading-dots. Permite los ficheros que empiezan por un punto (‘.’) (no cumple con la norma ISO9660). -log-file LOG_FILE. Redirige los mensajes a un fichero de log indicado. -m GLOBFILE, -exclude GLOBFILE. Excluye el fichero indicado. -exclude-list FILE. Excluye los ficheros incluidos en la lista. -new-dir-mode mode. Establece los permisos para los nuevos directorios. -o FILE, -output FILE. Indica el nombre del fichero en el que se guarda la imagen. -path-list FILE. Fichero con la lista de rutas que se deben procesar. -print-size. Muestra el tamaño estimado del sistema de ficheros y sale. -s TYPE, -sectype TYPE. Establece el tipo de sector de la imagen ISO (data/xa1/raw…). -sort FILE. Ordena los ficheros según las reglas proporcionadas. -split-output. Divide la imagen en ficheros de aproximadamente 1GB. -stream-media-size #. Establece el tamaño del dispositivo en el que se quiere grabar la imagen en sectores. -sysid ID. Establece el ID del sistema. -T, -translation-table. Genera una tabla de traducción para los sistemas que no comprenden nombres de ficheros largos. -table-name TABLE_NAME. Indica una tabla de traducción para los sistemas que no comprenden nombres de ficheros largos. -uid uid. Establece el usuario como propietario de todos los ficheros. -U, -untranslated-filenames. Allow Untranslated filenames (for HPUX \u0026amp; AIX - violates ISO9660). Forces -l, -d, -N, -allow-leading-dots, -relaxed-filenames, -allow-lowercase, -allow-multidot. -allow-lowercase. Permite caracteres en minúscula (no cumple con la norma ISO9660). -allow-multidot. Permite más de un punto en el nombre de los ficheros como .tar.gz (no cumple con la norma ISO9660). -use-fileversion LEVEL. Usa la versión indicada del sistema de ficheros. -v, -verbose. Modo verboso. -version. Muestra la versión. -V ID, -volid ID, -volset ID. Establece el ID del volumen. -volset-size #. Establece el tamaño del volumen. -hard-disk-boot. Indica que es la imagen es de un disco duro. -no-boot. Indica que la imagen no es arrancable. Ejemplos de uso Para crear una imagen iso llamada imagen.iso del directorio raíz.\ngenisoimage -o imagen.iso / Para usar la extensión Rock Ridge al crear una imagen.\ngenisoimage -o imagen.iso -R / Para dar a todos los ficheros permisos, al menos, de lectura y cambiar su propietario al root.\ngenisoimage -o imagen.iso -r / "},{
  "section": "Blog",
  "slug": "/blog/sistemas/2024-05-05-gestion-dispositivos-almacenamiento-powershell/",
  "title": "Gestión de dispositivos de almacenamiento con Powershell",
  "description": "",
  "date": "May 5, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "sistemas",
  "tags": "sistemas, comandos, PowerShell, Windows, dispositivos de almacenamiento, sistema de ficheros, Implantación de Sistemas Operativos",
  "content":"El módulo Storage de la PowerShell de Windows contiene múltiple cmdlets para gestionar los dispositivos de almacenamiento del sistema. En este post se recoge una lista de cmdlets de este módulo que cumplen diferentes funciones para realizar este trabajo.\nGet-Disk Definición Muestra los discos visibles en el sistema operativo\nSintaxis Get-Disk [opciones] Opciones Alguna de las opciones más relevantes de este comando son:\n-FriendlyName. Muestra el disco que corresponde con el nombre indicado. -Number. Muestra el disco que corresponde al número indicado. Ejemplos de uso Mostrar todos los discos:\nGet-Disk Mostrar un disco en concreto:\nGet-Disk -Number 1 Get-Partition Definición Lista todas las particiones visibles en todos los discos del sistema\nSintaxis Get-Partition [opciones] Opciones Entre las opciones más relevantes están:\n-DiskNumber. Muestras las particiones asociadas a un disco -DriveLetter. Muestra las particiones asociadas a un volumen -PartitionNumber. Muestra las particiones que correspondan con el número de partición indicado. Ejemplos de uso Para ver todas las particiones de todos los discos\nGet-Partition Para ver todas las particiones de un disco\nGet-Partition -DiskNumber 2 Para ver todas las particiones asociadas a un volumen\nGet-Partition -DriveLetter C Resize-Partition Definición Redimensiona una partición y el sistema de ficheros que contiene\nSintaxis Resize-Partition [opciones] Opciones Entre las opciones más relevantes de este comando están:\n-DiskID. Identifica el ID de la partición que se quiere redimensionar. -DiskNumber. Identifica el número del disco en el que está la partición. -DriveLetter. Indica el volumen al que pertenece la partición. Ejemplos de uso Para redimensionar una partición a un nuevo tamaño\nResize-Partition -DiskNumber 1 -PartitionNumber 3 -Size 8GB Para aumentar una partición al máximo tamaño posible\nResize-Partition -DiskNumber 1 -PartitionNumber 3 -Size $size.SizeMax Get-PartitionsupportedSize Definición Devuelve información sobre el tamaño de las particiones soportados por cada disco\nSintaxis Get-PartitionsupportedSize [opciones] Opciones Algunas de las opciones más relevantes de este comando son:\n-DiskId. Identifica el ID del disco que se quiere inspeccionar. -DiskNumber. Identifica el número del disco que se quiere inspeccionar. -PartitionaNumber. Identifica el número de la partición que se quiere analizar. Ejemplos de uso Para conocer el tamaño máximo que puede alcanzar una partición:\nGet-PartitionSupportedSizes -DiskNumber 0 -PartitionNumber 4 New-Partition Definición Crea una partición en un disco existente\nSintaxis New-Partition [opciones] Opciones Entre las opciones más relevantes de este comando están:\n-DiskId. Identifica el ID del disco que se quiere particionar. -DiskNumber. Identifica el número del disco que se quiere particionar. -Size. Indica el tamaño de la nueva partición. -AssingDriveLetter. Asigna una letra a la nueva partición automáticamente. -UseMaximunSize. Usa todo el espacio disponible en el disco para la nueva partición. Ejemplos de uso Para crear una nueva partición de un tamaño determinado\nNew-Partition -DiskNumber 1 -Size 512MB Para crear una nueva partición que use todo el espacio disponible en un disco\nNew-Partition -DiskNumber 1 -UseMaximumSize Para crear una nueva partición y asignarle una letra automáticamente\nNew-Partition -DiskNumber 1 -AssignDirveLetter Initialize-Disk Definición Crea una tabla de particiones en un disco para inicializarlo\nSintaxis Initialize-Disk [opciones] Opciones Entre las opciones más relevantes de este comando están:\n-Number. Indica el número del disco. -PartitionStyle. Determina el tipo de tabla de particionado. -VirtualDisk. Inicializa un disco virtual. Ejemplos de uso Para crear una tabla de particiones GPT en un disco\nInitialize-Disk -Number 1 -PartitionStyle GPT Remove-Partition Definición Elimina una partición\nSintaxis Remove-Partition [opciones] Opciones Entre las opciones más relevantes de este comando están:\n-DiskNumber. Indica el número del disco. -DriveLetter. Indica la letra del volumen. -PartitionNumber. Indica el número de la partición. Ejemplos de uso Para eliminar una partición\nRemove-Partition -DiskNumber 1 -PartitionNumber 4 Format-Volume Definición Da formato a un volumen\nSintaxis Format-Volume [opciones] Opciones Algunas de las más destacadas de este comando son:\n-FileSystemLabel. Añade una etiqueta al sistema de ficheros. -Partition. Indica la partición. -DriveLetter. Indica la letra del volumen. -FileSystem. Indica el sistema de ficheros con el que se formatea. Ejemplos de uso Para formatear el volumen D\nFormat-Volume -Driveletter D Para un disco en FAT32\nFormat-Volume -Driveletter F -Filesystem FAT32 -Force Add-PartitionAccessPath Definición Añade una letra o un punto de montaje a una partición\nSintaxis Add-PartitionAccessPath [opciones] Opciones Entre las opciones más relevantes de este comando se encuentran:\n-DiskNumber. Indica el número del disco. -PartitionNumber. Indica el número de la partición. -AccessPath. Indica le letra que se le asigna a la partición Ejemplos de uso Añadir una letra a una partición\nAdd-PartitionAccessPath -DiskNumber 1 -PartitionNumber 2 -AccesPath F: Set-Disk Definición Actualiza los atributos de los discos duros del sistema\nSintaxis Set-Disk [opciones] Opciones Algunas de las opciones más relevantes de este comando son:\n-Number. Indica el número de un disco. -Path. Indica la ruta o letra de un disco. -IsOffline. Indica que un disco no está activado. - -IsReadOnly. Indica que un disco es de sólo lectura. Ejemplos de uso Para poner un disco en activo\nSet-Disk -Number 5 -IsOffline $False Para hacer que se pueda escribir en un disco que es de sólo lectura\nSet-Disk -Number 4 -IsReadOnly $False Para poner un disco offline\nSet-Disk -Number 1 -IsOffline $True Clear-Disk Definición Elimina la información de la tabla de particiones de un volumen. También elimina la información que contiene el disco.\nSintaxis3 Clear-Disk [opciones] Opciones Entre las opciones más relevantes de este comando están:\n-Number. Indica el número del disco. -RemoveData. Elimina el contenido del disco. -RemoveOEM. Elimina las particiones de tipo OEM de la tabla de particiones. Ejemplos de uso Para eliminar la tabla de particiones de un disco\nClear-Disk -Number 1 Para eliminar la tabla de particiones y el contenido de un disco que ya contiene datos\nClear-Disk -Number 1 -RemoveData Optimize-Volume Definición Optimiza un volumen\nSintaxis Optimize-Volume [opciones] Opciones Entre las opciones más relevantes de este comando están:\n-DirveLetter. Para indicar la letra del volumen. -Analyz. Para analizar un volumen. -Defrag. Para desfragmentar un volumen. -FileSystemLabel. Para indicar la etiquete del sistema de ficheros. Ejemplos de uso Para analizar el estado de optimización de un disco.\nOptimize-Volume -DriveLetter C -Analyze -Verbose Para desfragmentar un volumen.\nOptimize-Volume -DriveLetter C -Defrag -Verbose Repair-Volume Definición Analiza y repara volúmenes.\nSintaxis Repair-Volume [opciones] Opciones Entre las opciones más relevantes de este comando están:\n-FileSystemLabel. Indica la etiqueta el sistema de ficheros. -DriveLetter. Indica la letra del volumen -OfflineScanAndFix. Modo de reparación en el que se analiza y repara un disco que no está montado en el sistema. -Scan. Modo en el que se analiza un disco. Puede estar online en el sistema. -SpotFix. Modo en el que se pone un disco offline por un breve periodo de tiempo durante el que se reparan los errores identificados. Ejemplos de uso Para analizar un volumen.\nRepair-Volume -DriveLetter C -Scan Para poner un volumen en modo offline y reparar todos sus errores.\nRepair-Volume -DriveLetter F -OfflineScanAndFix Para reparar de forma rápida y puntual un error concreto en un volumen.\nRepair-Volume -DriveLetter F -SpotFix Get-VirtualDisk Definición Lista todos los discos virtuales.\nSintaxis Get-VirtualDisk [opciones] Opciones Algunas opciones de este comando son:\n-FriendlyName. Indica el nombre comprensible del disco virtual -Name. Indica el nombre del disco virutal -IsSnapshot. Indica si es una snapshot Ejemplos de uso Para mostrar la lista de discos virtuales\nGet-VirtualDisk New-VirtualDisk Definición Crea un nuevo disco virtual en el espacio de almacenamiento indicado.\nSintaxis New-VirtualDisk [opciones] Opciones Algunas opciones de este comando son:\n-StoragePoolName. Indica el nombre del almacenamiento. -FriendlyName. Indica el nombre comprensible. -Size. Indica el tamaño -UseMaximumSize. Usa todo el tamaño disponible -PhysicalDisksToUse. Indica los discos físicos en los que se almacena la información del disco virtual. -PhysicalDiskRedundancy. Indica el tipo de redundancia entre los discos físicos que forman parte del disco virtual. Ejemplos de uso Para crear un disco duro virtual.\nNew-VirtualDisk -StoragePoolFriendlyName Datos -FriendlyName Datos -Size 5GB Set-VirtualDisk Definición Modifica los atributos de un disco virtual existente.\nSintaxis Set-VirtualDisk [opciones] Opciones Algunas opciones de este comando son:\n-NewFriendlyName. Indica el nuevo nombre comprensible del disco virtual. -Usage. Indica el tipo de uso del disco virtual. -OtherUsageDescription. Añade información sobre el uso del disco virtual. -PhysicalDiskRedundancy. Indica el tipo de redundancia de los discos físicos que forman parte del disco virtual. Ejemplos de uso Para cambiar el nombre comprensible de un disco virtual.\nSet-VirtualDisk -FriendlyName Datos -NewFriendlyName DatosActualizados Resize-VirtualDisk Definición Redimensiona un disco virtual\nSintaxis Resize-VirtualDisk [opciones] Opciones Algunas opciones de este comando son:\n-FriendlyName. Indica el nombre comprensible del disco. -Name. Indica el nombre del disco. -Size. Indica el tamaño del disco. Ejemplos de uso Para redimensionar un disco virtual\nResize-VirtualDisk -FirendlyName Datos -Size (8GB) Show-VirtualDisk Definición Hace que un disco virtual esté disponible.\nSintaxis Show-VirtualDisk [opciones] Opciones Algunas opciones de este comando son:\n-FriendlyName. Indica el nombre comprensible del disco. -Name. Indica el nombre del disco virtual. -TargetPortAddress. Indica la dirección del puerto de destino. -InitiatorAddress. Indica la dirección de origen. Ejemplos de uso Para hacer un disco virtual accesible a la máquina local.\n$initiatorport = (Get-InitiatorPort) $targetport = (Get-TrgetPort) Show-VirtualDisk -FriendlyName \u0026#39;Datos\u0026#39; -TargetPortAddress $targetport.NodeAddress -InitiatorAddress $initiatorport.NodeAddress "},{
  "section": "Blog",
  "slug": "/blog/redes/2024-04-22-enrutamiento-dinamico-cisco-gns3-ospf/",
  "title": "Enrutamiento dinámico con OSPF usando routers Cisco en GNS3",
  "description": "",
  "date": "April 22, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "GNS3, redes, Planificación y Administración de Redes, router, Cisco, OSPF",
  "content":"OSPF (Open Shortest Path First), \u0026ldquo;Abrir el camino más corto primero\u0026rdquo; en español, es un protocolo de red para enrutamiento dinámico que usa el algoritmo Dijkstra, para calcular la ruta más corta entre dos nodos.\nA continuación se muestra el funcionamiento del protocolo de enrutamiento dinámico OSPF en este escenario basado en la saga \u0026ldquo;Los juegos del hambre\u0026rdquo;.\nEl direccionamiento IP de los VPCS del escenario es el siguiente:\nMarvel: 10.0.1.2 Glimmer: 10.0.1.3 Cato: 10.0.2.2 Clover: 10.0.2.3 Thresh: 10.0.11.2 Rue: 10.0.11.3 Peeta: 10.0.12.2 Katniss: 10.0.12.3 El direccionamiento IP de los routers del escenario es el siguiente:\nR1 f0/0: 10.0.1.1 f0/1: 172.23.0.1 f1/0: 192.168.1.2 R2 f0/0: 10.0.11.1 f0/1: 172.23.0.2 f1/0: 172.24.0.1 f1/1: 192.168.11.2 R3 f0/0: 10.0.2.1 f0/1: 172.25.0.1 f1/0: 192.168.2.2 R4 f0/0: 10.0.12.1 f0/1: 172.24.0.2 f1/0: 192.168.12.2 f1/1: 172.25.0.2 R5 f0/0: 192.168.11.1 f0/1: 192.168.12.1 f1/0: 192.168.1.1 f1/1: 192.168.2.1 f2/0: 10.0.13.1 Configurar OSPF en un router Cisco La configuración del protocolo OSPF en los routers Cisco requiere acceder al modo config terminal del router y, desde él, ejecutar en primer lugar el comando router ospf \u0026lt;id\u0026gt; en el que se inicia un proceso OSPF y se le asigna un identificador. Este comando abre el modo config-router. Entonces se indica un identificador para el router con el comando router-id \u0026lt;n.n.n.n\u0026gt; y se añaden las diferentes interfaces a las que se aplica este protocolo con el comando network \u0026lt;ip\u0026gt; \u0026lt;máscara comodín\u0026gt;.\nPor ejemplo, en el caso del router R1 en este escenario se accede al modo config-rotuer con router ospf 1 y, a continuación, se indica un identificador al router con router-id 1.1.1.1. Finalmente, se añade la información sobre todas las redes a las que este dispositivo está conectado:\nR1#config terminal R1(config)#router ospf 1 R1(config-router)#router-id 1.1.1.1 R1(config-router)#network 10.0.1.0 0.0.0.255 area 0 R1(config-router)#network 172.23.0.0 0.0.0.255 area 0 R1(config-router)#network 192.168.1.0 0.0.0.255 area 0 La misma configuración se establece también pero indicando los valores correspondientes al resto de routers del escenario.\nRutas elegidas por el protocolo OSPF Tras configurar el OSPF en todos los routers del escenario, las tablas de enrutamiento de cada uno de ellos sufren modificaciones y, además contienen nueva información. Ahora las entradas de las tablas de enrutamiento son de dos tipos. Aquellas que se refieren a una dirección a la que el router está directamente conectado se marcan como C (conected) y el resto se marcan con una O (OSPF). Además, cada entrada incluye información del coste de la ruta. En una primera aproximación al uso de OSPF se establece en todos los routers la misma distancia por defecto para todas las rutas: 110. Junto a este valor de distancia, cada entrada de la tabla de enrutamiento recoge el número de saltos necesarios para llegar a la dirección de destino.\nPor ejemplo, en la tabla de enrutamiento del router R1 las rutas a las redes 172.23.0.0/24 y 192.168.1.0/24 está marcadas como conectadas. El resto de destinos se descubren y añaden a la tabla de enrutamiento gracias al protocolo OSPF. Todas las rutas que no están conectadas directamente a este dispositivo muestran una distancia administrativa por defecto de 110. Mientras que algunas de ellas cuentan con 2 saltos, otras requieren tres para llegar al destino. Además, en varios casos como ocurre con la red 172.25.0.0/24 o la 192.168.11.0/24 la tabla de enrutamiento de este router recoge dos opciones diferentes para llegar al mismo destino con diferente latencia.\nDe la tabla de enrutamiento de R1 se desprende que el protocolo OSPF optaría por usar el router R5 en todos los casos en los que el mensaje necesita atravesar un router intermedio para llegar a su destino puesto que estas son las rutas que presentan una menor latencia.\nSe puede comprobar que las rutas recogidas en la tabla de enrutamiento se están cumpliendo de manera efectiva al comunicar, por ejemplo, el router R1 con el router R4. En este caso, el mensaje viaja desde el router R1 al R5 y, posteriormente, llega a R4.\nSi se traza la ruta desde R1 hasta la interfaz f1/1 del router R4, el router R1 devuelve dos posibles caminos: a través del router R2 (172.23.0.2 y 172.24.0.2) o a través del router R5 (192.168.1.1 y 192.168.2.2).\nUn análisis similar se puede hacer de la tabla de enrutamiento que OSPF genera en el router R2: se puede observar que el protocolo de enrutamiento dinámico ha priorizado aquellas rutas en las que el mensaje puede llegar a su destino en menos saltos, por ejemplo, para ir del router R2 al R4 no pasa por R5.\nAsí se demuestra si se traza el recorrido de un paquete desde el router R2 al router R4. El mensaje va de R2 a R4 directamente a través de la interfaz f1/0 (R2) y f0/0 (R4).\nEn este caso, si se traza el camino hasta otra interfaz del router R4, por ejemplo la f1/1 (172.25.0.2) el router R2 sólo devuelve una ruta porque cualquier otra tendría más saltos y, por lo tanto, un mayor coste.\nCambios en las rutas cuando deja de funcionar el router R5 Uno de los objetivos principales del enrutamiento dinámico es mantener la disponibilidad de las conexiones, de manera que los mensajes puedan llegar a su destino independientemente de si alguno de los dispositivos que, en principio, debería atravesar está estropeado o no funciona en un momento determinado.\nEn este caso, si se apaga uno de los routers del escenario, por ejemplo el router R5, todo el resto de dispositivos de la red recibe, poco segundos después, esta información:\nPara garantizar que se pueden mantener las comunicaciones entre todos los equipos con, OSPF modifica las tablas de enrutamiento de los routers, de manera que busca alternativas para encaminar los mensajes.\nPor ejemplo, en la tabla de enrutamiento del router R1 desaparecen todas las referencias a las direcciones de R5 y se sustituyen por otras IP de alguno de los otros routers a los que está conectado para establecer rutas alternativas a todos los destinos de la red.\nEn este caso, al repetir el análisis de la ruta entre el router R1 y R4 se pueden encontrar diferencias significativas. Por ejemplo, si se usa la interfaz f1/0 de R4 (192.168.12.2) directamente conectada al router R5, el protocolo de enrutamiento encuentra una vía alternativa a través de la interfaz f0/0, conectada a R2. Así, el mensaje puede llegar a su destino atravesando R2 en vez de R5.\nEsa misma es la ruta que elige para llegar a la interfaz f1/1 de R4 (172.25.0.2), que está directamente conectada al router R3. En este caso, a diferencia del ejemplo anterior en el que había dos opciones posibles para hacer esta ruta, como R5 está apagado, el análisis del recorrido del mensaje con trace siempre muestra la única ruta disponible.\nDe la misma manera, el resto de routers también eliminan de sus tablas de enrutamiento las referencias a las rutas que atraviesan R5 y que sí recogían en un primer momento.\nCambio del coste de las rutas Para cambiar el coste de las rutas en los routers Cisco hay que asignar un nuevo coste a cada interfaz individualmente usando el comando ip ospf cost \u0026lt;coste\u0026gt; desde el modo de configuración de interfaz. Por defecto, el coste se calcula dividiendo 100.000.000 entre el ancho de banda en bps de la conexión porque, en esta configuración, el término de coste está orientado a la velocidad de conexión. Pero hay otros criterios que pueden influir en el coste que se le asigna a una ruta como la propiedad de la línea, el número de saltos, la latencia, etc. Por eso, el coste de cada interfaz se puede modificar manualmente.\nPor ejemplo, si el router R5 vuelve a funcionar envía a todo el resto de routers del escenario varios paquetes en su proceso de arranque. Los demás reciben esta información y algunos de ellos vuelven a modificar sus tablas de enrutamiento para recuperar aquellas rutas que usan este dispositivo.\nPara modificar el coste de conectarse a cada interfaz, se accede a cada una de ellas a través de interface FastEthernet \u0026lt;id\u0026gt; y, desde el modo config-if se ejecuta el comando ip ospf cost 120 que, en este caso, asigna un coste de 120 a la conexión a esa interfaz del router R5. El comando se tiene que repetir en la interfaz del otro router a la que esté conectada esa tarjeta de red para asignar el coste de la ruta. En este caso, en la interfaz f1/0 del router R1.\nEn este escenario, el ejemplo analizado en casos anteriores devuelve un resultado diferente: ante el alto coste de la ruta que conecta el router R1 con R5, el protocolo OSPF usa una ruta alternativa que lleva el mensaje desde R1 a R2, desde R2 a R5 y, finalmente, desde R5 llega a su destino en R4. En este caso, el protocolo prefiere usar una ruta con una distancia administrativa mayor, puesto que conlleva dos saltos entre routers en vez de uno, pero que tiene un coste menor puesto que el coste entre R1 y R5 es 120 mientras que el coste tanto entre R2 y R5 como entre R5 y R4 es 1.\nComandos de administración de OSPF en Cisco En los routers Cisco existen varios comandos para comprobar el correcto funcionamiento del OSPF tanto durante su configuración como durante su fase en producción.\nPor ejemplo, show running-config muestra la configuración del router. A diferencia de lo que ocurre con este mismo comando en FRR en los routers Linux, en el caso de los routers Cisco muestra toda la configuración del router y no sólo la de OSPF. Además, show ip protocols muestra información sobre los protocolos que se aplican en el router. En el caso del OSPF se recoge el identificador del router junto con el número de áreas de las que forma parte y el número de rutas a las que está conectado. Además, lista esas redes y muestra los routers desde los que obtiene la información con su identificador, distancia administrativa y última actualización.\nCon show ip ospf interface se puede obtener información sobre cómo afecta el OSPF a cada interfaz. Esta información incluye la IP, el identificador del router, el coste de la ruta, el identificador del router designado en esa ruta, el identificador del router de respaldo designado, los intervalos de tiempo tanto de Hello como Dead, el tiempo restante para el siguiente mensaje de Hello, una lista de vecinos adyacentes, el estado de la conexión, etc. Este comando se puede particularizar añadiendo un nombre de interfaz concreta para ver sólo la información relativa a esa interfaz o con show ip ospf interface brief para mostrar la información de forma más resumida.\nSobre los vecinos se puede obtener información con show ip ospf neighbor. De forma muy similar a lo que ocurre en los routers Linux con FRR, este comando muestra en una tabla el identificador del vecino, el estado de la conexión, el intervalo de “Dead” y la dirección y la interfaz por la que se conecta el router a cada vecino adyacente.\nAdemás, es muy práctico revisar las tablas de enrutamiento con show ip route para ver cómo les afecta OSPF en cada momento.\n"},{
  "section": "Blog",
  "slug": "/blog/redes/2024-04-22-enrutamiento-dinamico-linux-gns3-ospf/",
  "title": "Enrutamiento dinámico con OSPF usando routers Linux en GNS3",
  "description": "",
  "date": "April 22, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "GNS3, redes, Planificación y Administración de Redes, router, router Linux, OSPF",
  "content":"En este post se muestra el funcionamiento del protocolo de enrutamiento dinámico OSPF, un protocolo de red para enrutamiento dinámico que usa el algoritmo Dijkstra, para calcular la ruta más corta entre dos nodos de la red, en los routers Linux de este escenario basado en la saga \u0026ldquo;Los juegos del hambre\u0026rdquo;.\nLas direcciones IP de los diferentes ordenadores son:\nMarvel: 10.0.1.2 Glimmer: 10.0.1.3 Cato: 10.0.2.2 Clover: 10.0.2.3 Thresh: 10.0.11.2 Rue: 10.0.11.3 Peeta: 10.0.12.2 Katniss: 10.0.12.3 Las interfaces de los routers tienen las siguientes direcciones IP:\nR1 f0/0: 11.0.1.1 f0/1: 173.23.0.1 f1/0: 193.168.1.2 R2 f0/0: 11.0.11.1 f0/1: 173.23.0.2 f1/0: 173.24.0.1 f1/1: 193.168.11.2 R3 f0/0: 11.0.2.1 f0/1: 173.25.0.1 f1/0: 193.168.2.2 R4 f0/0: 11.0.12.1 f0/1: 173.24.0.2 f1/0: 193.168.12.2 f1/1: 173.25.0.2 R5 f0/0: 193.168.11.1 f0/1: 193.168.12.1 f1/0: 193.168.1.1 f1/1: 193.168.2.1 f2/0: 11.0.13.1 Configurar OSPF en un router Linux Configurar OSPF desde ficheros Para poder usar el protocolo OSPF en un router Linux es necesario instalar un paquete que permita gestionar este tipo de protocolos de enrutamiento dinámico. La mayoría de paquetes que cumplen esta función se basan en Zebra, un proyecto que no cuenta con mantenimiento en la actualidad. Uno de estos paquetes es Quagga, que actualmente tampoco está ya disponible en los repositorios de Debian y que ha sido sustituido por FRR (FRRouting), que también se basa en Zebra.\nPara instalar FRR se actualiza el gestor de paquetes y se ejecuta la instalación:\nsudo apt update \u0026amp;\u0026amp; sudo apt install frr -y. En este paquete, FRR gestiona la comunicación entre routers vecinos para mantener actualizado el protocolo de enrutamiento dinámico que se emplee en cada caso. Por su parte, Zebra, gestiona y actualiza la tabla de enrutamiento del dispositivo a partir de la información obtenida y procesada por el protocolo de enrutamiento.\nEl fichero /etc/frr/daemons cuenta con una lista de todos los daemos disponibles en FRR en la que se pueden activar o desactivar. En este caso, para activar el protocolo de OSPF el fichero tiene que contener la línea\nospfd=yes. Tras activar los daemons necesarios (en este caso Zebra está activado por defecto porque debe estar habilitado siempre para el correcto funcionamiento del enrutamiento dinámico) se debe configurar cada uno de ellos a través de sus ficheros de configuración. Una forma de hacerlo es aprovechar los ficheros de ejemplo que se incluyen en /usr/share/doc/frr/examples/ durante la instalación del paquete frr.\nPor ejemplo, en el caso de Zebra, se puede copiar el fichero de ejemplo con cp /usr/share/doc/frr/examples/zebra.conf.sample /etc/frr/zebra.conf y editar su contenido. En este fichero se indican las direcciones IP de cada una de las interfaces del router. En el caso de R1, este fichero contiene las siguientes líneas:\ninterface ens4 10.0.1.1/24 interface ens5 172.23.0.1/24 interface ens6 193.168.1.2/24 También se debe seguir un procedimiento similar para configurar el protocolo OSPF en cada router. En este caso, se puede copiar el fichero de ejemplo con cp /usr/share/doc/frr/examples/ospfd.conf.sample /etc/frr/ospfd.conf. En este fichero se almacena la información relacionada con el OSPF en este router: id del router, redes y área a la que pertenece cada una de ellas. Siguiendo con el ejemplo de R1, el fichero contiene estas líneas:\nrouter ospf ospf router-id 1.1.1.1 network 10.0.1.0/24 area 0 network 173.23.0.0/24 area 0 network 193.168.1.0/24 area 0 Además, en ambos ficheros se debe indicar un hostname y contraseña para poder configurar y monitorizar el funcionamiento del protocolo de enrutamiento dinámico posteriormente. Esta información se incluye en ambos ficheros:\nhostname ospfd password zebra enable password zebra De esta manera, queda configurado el OSPF en el router R1.\nEsta configuración se repite en todos los routers del escenario para conseguir que puedan actualizar sus tablas de enrutamiento usando este protocolo de enrutamiento dinámico.\nConfigurar OSPF desde vtysh La configuración de los ficheros tal y como se desarrolla en el apartado anterior no da el resultado esperado y no consigue que el protocolo OSPF se ponga en funcionamiento en los routers Linux. Una alternativa a la configuración desde los ficheros es el uso de la terminal vtysh que incorpora el paquete FRR y que usa comandos muy similares a los que usan los routers Cisco.\nPara acceder a la terminal se ejecuta el comando vtysh desde un usuario que forme parte del grupo frrvty o como usuario privilegiado. Esto hace que cambie el prompt de la terminal, que muestra un mensaje de bienvenida. Desde esta nueva terminal se pueden ejecutar los comandos de configuración de OSPF en FRR.\nTomando de nuevo como ejemplo el router R1, en primer lugar, se accede a la configuración del router y se activa el modo OSPF y, posteriormente, se añade un identificador del router:\ndebian(config)# router ospf debian(config-router)# router-id 1.1.1.1 Posteriormente, se aporta la información de cada interfaz: su dirección IP y máscara de red. Es este punto también se puede indicar un coste a cada interfaz o un período de “saludo” o de “muerte”.\ndebian(config-router)# interface ens5 debian(config-if)# ip address 173.23.0.1/24 debian(config-if)# interface ens6 debian(config-if)# ip address 193.168.1.2/24 Finalmente, se vuelve al modo de configuración de router para añadir las redes que el protocolo debe incluir en la tabla de enrutamiento.\ndebian(config)# router ospf debian(config-router)# router 1.1.1.1 debian(config-router)# network 173.23.0.0/24 area 0.0.0.0 debian(config-router)# network 193.168.1.0/24 area 0.0.0.0 Para terminar se guardan los cambios almacenados en la memoria en el fichero /etc/frr/frr.conf con el comando write memory.\ndebian# write memory De la misma manera, los comandos para aplicar la configuración del OSPF en el router R2 son:\ndebian(config)# router ospf debian(config-router)# router-id 2.2.2.2 debian(config-router)# interface ens5 debian(config-if)# ip address 173.23.0.2/24 debian(config-if)# interface ens6 debian(config-if)# ip address 173.24.0.1/24 debian(config-if)# interface ens7 debian(config-if)# ip address 193.168.11.2/24 debian(config-if)# router ospf debian(config-router)# router 2.2.2.2 debian(config-router)# network 173.23.0.0/24 area 0.0.0.0 debian(config-router)# network 173.24.0.0/24 area 0.0.0.0 debian(config-router)# network 193.168.11.0/24 area 0.0.0.0 debian(config-router)# end debian# write memory En el caso de R3:\ndebian(config)# router ospf debian(config-router)# router-id 3.3.3.3 debian(config-router)# interface ens5 debian(config-if)# ip address 173.25.0.1/24 debian(config-if)# interface ens6 debian(config-if)# ip address 193.168.2.2/24 debian(config-if)# router ospf debian(config-router)# router 3.3.3.3 debian(config-router)# network 173.25.0.0/24 area 0.0.0.0 debian(config-router)# network 193.168.2.0/24 area 0.0.0.0 debian(config-router)# end debian# wr Para R4:\ndebian(config)# router ospf debian(config-router)# router-id 4.4.4.4 debian(config-router)# interface ens5 debian(config-if)# ip address 173.24.0.2/24 debian(config-if)# interface ens6 debian(config-if)# ip address 193.168.12.2/24 debian(config-if)# interface ens7 debian(config-if)# ip address 173.25.0.2/24 debian(config-if)# router ospf debian(config-router)# router 4.4.4.4 debian(config-router)# network 173.24.0.0/24 area 0.0.0.0 debian(config-router)# network 173.25.0.0/24 area 0.0.0.0 debian(config-router)# network 193.168.12.0/24 area 0.0.0.0 debian(config-router)# end debian# wr Y, por último, los comandos para R5 son:\ndebian# configure terminal debian(config)# router ospf debian(config-router)# router-id 5.5.5.5 debian(config-router)# interface ens4 debian(config-if)# ip address 193.168.11.1/24 debian(config-if)# interface ens5 debian(config-if)# ip address 193.168.12.1/24 debian(config-if)# interface ens6 debian(config-if)# ip address 193.168.1.1/24 debian(config-if)# interface ens7 debian(config-if)# ip address 193.168.2.1/24 debian(config-if)# router ospf debian(config-router)# router 5.5.5.5 debian(config-router)# network 193.168.1.0/24 area 0.0.0.0 debian(config-router)# network 193.168.2.0/24 area 0.0.0.0 debian(config-router)# network 193.168.11.0/24 area 0.0.0.0 debian(config-router)# network 193.168.12.0/24 area 0.0.0.0 debian(config-router)# end debian# wr Rutas elegidas por el protocolo Tras aplicar esta configuración a través de la terminal virtual vtysh, todos los routers se reconocen entre sí y empiezan a modificar sus tablas de enrutamiento.\nEn las tablas de enrutamiento que genera el protocolo OSPF se indica la IP de la red de destino junto con el coste (entre corchetes), el área y las direcciones IP asignadas a las interfaces por las que un mensaje puede salir hacia ese destino desde cada router. En este caso, OSPF usa como coste por defecto 10 y el coste aumenta con cada salto. De manera que para llegar desde el router R5 (en la última captura) hasta la red 193.168.12.0/24, por ejemplo, el coste es 10 porque sólo hay un salto y el router R5 y R4 (el de destino) están directamente conectados. En cambio, para llegar a la red 173.23.0.0/24 lo puede hacer a través del router R1 (193.168.1.2) o del router R2 (193.168.11.2) pero siempre implica dos saltos, por lo que el coste de esta ruta es 20.\nComo se puede observar en estas tablas de enrutamiento, el protocolo es capaz de reconocer todas las rutas que permiten llegar a un destino determinado desde cada router. Esto es clave para poder aplicar una de las características de OSPF: el balanceo de tráfico. Gracias a que el protocolo puede plantear rutas alternativas se puede dirigir parte del tráfico por cada una de ellas para evitar que una se sobrecargue mientras el resto queda libre.\nAl retomar los ejemplos del punto 1 de esta práctica en este escenario con routers Linux, se puede comprobar que para llegar al router R4, los paquetes que salen desde el router R1 toman diferentes caminos según la interfaz de destino. Así, para llegar a la interfaz con la IP 193.168.12.2, los paquetes atraviesan el router R5:\nEn cambio, para llegar a la interfaz con la IP 173.25.0.2 los paquetes que salen desde el router R1 toman la ruta que atraviesa el router R2:\nCambios en las rutas cuando deja de funcionar el router R5 A diferencia de lo que ocurre en los routers Cisco, en el caso de los routers Linux no se notifica a través de un mensaje en la terminal cuando un router se desconecta de la red o deja de funcionar y, por tanto, deja de enviar mensajes de saludo OSPF a sus vecinos. Pero aunque la terminal no muestre una notificación en forma de texto el router sí recibe esta información y es capaz de adaptar su tabla de enrutamiento.\nSi se toma como ejemplo el caso de R1, se puede observar cómo su tabla de enrutamiento pasa de esto:\nA esto:\nEl cambio es evidente: el protocolo ha buscado rutas alternativas para llegar a todos los destinos de la red sin tener que pasar por el router R5 y, por tanto, ha eliminado todas las referencias a las IP de ese router de la tabla de enrutamiento de R1.\nPara comprobar si el cambio en la tabla de enrutamiento es realmente efectivo, se puede trazar el recorrido que hace un paquete desde R1 hasta la interfaz del router R4 con la IP 193.168.12.2, directamente conectada al router R5. En el punto anterior, este mismo tráfico atravesaba R5. Con R5 apagado, el protocolo lo redirige a través del rotuer R2:\nCambio del coste de las rutas Del mismo modo que en los routers Cisco, desde la terminal vtysh de frr se puede modificar el coste de una ruta usando los mismos comandos. Por ejemplo, para aumentar el coste de la ruta entre R4 y R5 de 10 (por defecto) a 100 hay que indicar el nuevo coste en cada una de las interfaces que conecta esta ruta.\nEn primer lugar, en en la interfaz ens6 del router R4:\ndebian(config)# interface ens6 debian(config-if)# ip ospf cost 100 Y después, en la interfaz ens5 del router R5:\ndebian(config)# interface ens5 debian(config-if)# ip ospf cost 100 Al guardar esta configuración, el resto de routers del escenario actualizan de nuevo sus tablas de enrutamiento. Por una parte, en las tablas de R4 y R5, el coste de esta ruta ha aumentado a 100:\nEn cambio, las tablas de enrutamiento de otros routers del escenario como, por ejemplo, la de R1, reciben esta información y se actualizan sumando, al nuevo coste de la ruta entre R4 y R5 el coste de llegar a ella. Así, el coste de la ruta que va desde R1 a R4 a través del router R5 es ahora no de 110:\nAdemás del coste, en las tablas de enrutamiento de cada router se muestra también la distancia administrativa (110 por defecto para todas las interfaces, en este caso) entre el router y cada destino, de manera que, en caso de que fuese necesario, el protocolo podría tener en cuenta varios criterios para calcular la mejor ruta para que el mensaje llegue a su destino de la forma más eficiente posible.\nEn este caso, de nuevo, el protocolo elige pasar por R2 para llegar desde R1 a R4 para poder evitar así la ruta con mayor coste del escenario, la que va de R5 a R4:\nComandos de administración de OSPF en Linux Tanto durante el proceso de configuración como en fase de producción, el paquete FRR permite el uso de comandos de administración del protocolo OSPF muy similares a los que implementan los routers Cisco. Si bien es cierto que los comandos para la configuración de OSPF desde la terminal virtual vtysh son prácticamente idénticos, en el caso de los comandos de administración hay alguna diferencia.\nEl comando show running-config permite visualizar el contenido del fichero de configuración con la declaración de las interfaces y el router así como con la definición de las redes de las que forma parte.\nCon show ip ospf neighbor se puede ver cuáles son los routers a los que está directamente conectado el router que se analiza. En Linux con FRR este comando devuelve una tabla en la que se muestra el ID del router vecino, el estado de la conexión, el intervalo del temporizador “Dead”, la dirección IP y la interfaz a la que está conectado cada uno de ellos, entre otra información.\nSi el estado de la conexión se FULL, la adyacencia se ha completado exitosamente. Pero esta tabla puede mostrar otros estados. Por ejemplo, si un router tiene un vecino configurado manualmente pero nunca ha recibido paquetes hello desde él, el estado de la conexión será “inactivo”. Los routers vecinos que están en un estado inicial muestran un estado de conexión INIT. En este caso, el router que se analiza ha recibido paquetes de su vecino pero aún no ha podido establecer una comunicación bidireccional. Si ya se ha establecido una comunicación bidireccional pero no se ha completado la adyacencia, el estado de la conexión es 2-WAY.\nJunto al estado de conexión se muestran las etiquetas DR o BDR, que indican si el router es un router designado (DR) o un router de respaldo de un router designado (BDR).\nLa base de datos de OSPF se puede acceder con el comando show ip ospf database. En ella se almacena información sobre el estado de los enlaces tanto entre routers como entre redes. En primer lugar, la tabla de estado de los enlaces entre routers lista el identificador de todos los routers almacenados en la base de datos junto con la antigüedad del registro y el número de conexiones que tiene cada uno de ellos. A continuación, también se listan todas las redes a las que se puede acceder desde el router analizado junto al identificador del router que da a esas redes.\nPara obtener información sobre las rutas cargadas por el protocolo OSPF se pueden usar comandos como show ip route, show ip route ospf (que sólo muestra aquellas rutas que se han añadido a la tabla de enrutamiento a través de OSPF) o show ip ospf route. En el caso de los routers Linux, también se puede consultar la tabla de enrutamiento con el comando ip route sin necesidad de acceder a la terminal virtual de FRR.\n"},{
  "section": "Blog",
  "slug": "/blog/sistemas/2024-04-14-instancia-basada-volumen-openstack/",
  "title": "Cómo crear una instancia basada en un volumen en OpenStack",
  "description": "",
  "date": "April 14, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "sistemas",
  "tags": "sistemas, debian, linux, comandos, sistema de ficheros, virtualización, OpenStack, Implantación de Sistemas Operativos",
  "content":"OpenStack es un proyecto de cloud computing (computación en la nube) de software libre y código abierto. Ofrece una estructura como servicio (IaaS) y permite virtualizar equipos en los servidores en los que esté configurado. En este post se muestra, a través de un ejemplo práctico cómo se puede crear una instancia basada en un volumen en OpenStack y cómo se puede volcar el contenido de un sistema a un nuevo volumen con mayor capacidad de almacenamiento.\nCreación y configuración de la instancia en OpenStack Creación del volumen Para crear un volumen en Openstack se usa la opción “crear volumen” del menú volúmenes y en la ventana emergente se indica el nombre del volumen, la descripción, el tamaño y, para cargar en él la imagen de un sistema operativo, se marca la opción “Imagen” del menú “origen del volumen” y, a continuación, se elige la imagen que se debe cargar en el volumen, en este caso, la de Debian 12.\nCreación de la instancia Para crear la instancia a partir del volumen anterior, se lanza una instancia de la forma habitual desde el botón “lanzar instancia” del menú “computación” → “instancias” de la forma habitual con la excepción de que en la ventana “origen” se selecciona la opción “volumen” como origen de arranque y se asigna al volumen creado anteriormente.\nComo sabor se usa, en este caso, el m1.normal, que está optimizado para funcionar con un disco de 10GB, el tamaño del volumen que se está usando.\nInfo\nLos sabores (flavour) pueden variar entre cada instalación de OpenStack.\nConfiguración de la instancia Para garantizar el acceso a la instancia a pesar de los posibles problemas que puedan suceder durante la práctica se pueden tomar varias medidas. La primera de ellas es poner contraseña tanto al root como al usuario Debian.\npasswd debian passwd root Además, se puede configurar el fichero /etc/default/grub de manera que el menú de arranque aparezca durante unos segundos antes de iniciar la máquina para poder seleccionar la opción de arrancar en el modo recuperación si fuese necesario.\nGRUB_DEFAULT=0 GRUB_TIMEOUT=5 Creación y configuración de un nuevo disco en OpenStack Creación del nuevo disco Para crear un nuevo disco duro, en este caso de 30GB, se repite el procedimiento seguido anteriormente indicando esta vez el nuevo tamaño del disco y que el origen es un volumen vacío.\nPara poder trabajar con él, se asocia a la instancia que se está usando para esta práctica desde el menú “gestionar asociaciones” del volumen o desde el menú “asociar volumen” de la instancia, de manera que en el sistema aparece este nuevo volumen con el nombre vdb:\nInfo\nEl proceso de particionado y configuración de un disco duro se explica con más detalle en este otro post.\nParticionado del disco En primer lugar, conviene determinar el tamaño que se debe asignar a cada una de las particiones. Como referencia, se puede tomar el particionado hecho en prácticas anteriores con características similares. Adaptando estos tamaños a un disco de 30GB se puede determinar que los siguientes tamaños son adecuados para cada partición, sin tener más información sobre el uso que va a tener este sistema en producción:\n/boot/efi: 100MB /boot: 2 GB /: 10GB /home: 5GB /var: 5GB /usr: 6GB swap: 2GB Para trasladar esta información a la tabla de particiones del nuevo disco duro se pueden usar comandos como fdisk o gdisk. En este caso, se usa fdisk para particionar el disco. Para ello se crea en primer lugar una nueva tabla de particiones con el comando g. Posteriormente, se crea cada partición y se le asigna su número, primer sector y tamaño con el comando n.\nTras crear todas las particiones necesarias, se les puede asignar un tipo con el comando t hasta terminar con esta información en la tabla de particiones del disco:\nAsignación del sistema de ficheros Para continuar volcando el sistema al nuevo disco, el siguiente paso es asignar a cada partición un sistema de ficheros acorde al contenido que debe almacenar. En este caso, todas las particiones tienen un sistema de ficheros de tipo ext4 excepto la partición UEFI, que cuenta con un sistema de ficheros FAT32 y la partición swap, que se debe configurar como tal.\nEmpezando con la partición EFI, el comando mkfs.vfat -F 32 -n EFI /dev/vdb1 permite asignarle un sistema de ficheros FAT32 a esta partición. Para el resto de particiones, se usa el comando mkfs.ext4, por ejemplo, para la partición boot se usa mkfas.ext4 -L boot /dev/vdb2, para la partición raíz del sistema se usa mkfas.ext4 -L sistema /dev/vdb3, para la partición home el comando es mkfas.ext4 -L home /dev/vdb4 y así sucesivamente con el resto de particiones.\nFinalmente, para dotar de un sistema de ficheros de tipo swap a la partición swap se usa el comando mkswap -L swap /dev/vdb7.\nFinalmente, el disco queda particionado de esta forma:\nMontaje del nuevo disco Para volcar la información del sistema al nuevo disco hay dos opciones: montarlo en el propio sistema o generar una nueva instancia en la que se monten los dos volúmenes como discos duros y copiar la información de uno a otro. En este caso, se monta el nuevo disco duro en la instancia que ya está funcionando. Para ello se crean en el directorio /mnt un nuevo directorio para cada una de las particiones del disco con el comando mkdir -p /mnt/vdb/vdb{1..7} y con mount -v /dev/vdbn /mnt/vdb/vdbn (donde n es el número de la partición) se montan todas ellas en el directorio /mnt de la instancia.\nDe esta manera, todas las particiones quedan montadas en el sistema:\nVolcado de la información al nuevo disco Con el nuevo disco montado en el sistema se puede comenzar a volcar la información desde el disco original al nuevo volumen. Para ello se usará el comando cp.\ncp -ra /var/* /mnt/vdb/vdb5 cp -ra /usr/* /mnt/vdb/vdb6 cp -ra /home/* /mnt/vdb/vdb4 Para los directorios /boot y /EFI se debe tener en cuenta que el segundo está dentro del primero, de manera que los comandos que se deben ejecutar son:\ncp -ra /boot/* /mnt/vdb/vdb2 cp -ra /boot/efi/* /mnt/vdb/vdb1 Puesto que el contenido de /boot/efi ya está en la partición vdb1, no es necesario que ese directorio esté duplicado dentro de la partición vdb2, así que se puede eliminar.\nrm -r /mnt/vdb/vdb2/efi/ Por último, sólo queda volcar el contenido del directorio raíz al nuevo disco duro. En este caso, no se puede hacer un copiado masivo de todo el directorio puesto que alguno de los directorios que contiene generarían un bucle de copia recursiva que colapsaría el sistema. Por ejemplo, se debe evitar copiar el director /mnt al nuevo disco puesto que éste ya está montado en el propio directorio /mnt. Además, tampoco se deben volver a copiar al nuevo disco duro los directorios que ya tienen su propia partición.\nDe esta manera, se puede ejecutar el volcado del contenido del directorio raíz al nuevo disco duro de manera un poco más compleja a través del uso de una secuencia de comandos:\ncp -ra /bin /mnt/vdb/vdb3 cp -ra /dev /mnt/vdb/vdb3 cp -ra /etc /mnt/vdb/vdb3 cp -ra /lib* /mnt/vdb/vdb3 cp -ra /media /mnt/vdb/vdb3 cp -ra /opt /mnt/vdb/vdb3 cp -ra /proc /mnt/vdb/vdb3 cp -ra /r* /mnt/vdb/vdb3 cp -ra /s* /mnt/vdb/vdb3 Configuración del fichero fstab El último paso para tener una réplica del volumen original en el nuevo disco duro de 30GB es configurar el fichero fstab del nuevo sistema, que está alojado en el directorio /mnt/vdb/vdb3/etc/fstab. En él se deben modificar los puntos de montaje de las particiones del volumen original por los puntos de montajes de las nuevas particiones del disco duro de 30GB. Esto se puede hacer redirigiendo la salida del comando blkid al fichero para guardar los UUID de todas las particiones y editándolo posteriormente en un editor de texto como nano. Con el siguiente comando se consigue redirigir al fichero fstab, en primer lugar, sólo las líneas relativas a las particiones del nuevo disco de 30GB (vdb) y, además, sólo el campo necesario de cada partición: el UUID.\nblkid | grep vdb | cut -d “ “ -f 3 Creación de una instancia basada en el nuevo volumen en Openstack Tras configurar el sistema y volcarlo al nuevo volumen, este disco se puede desasociar de la instancia y usar para generar una nueva.\nEn primer lugar, en el menú “desasociar un volumen” se selecciona la opción correspondiente al volumen de 30GB. Además, para que este volumen se pueda usar como origen de nuevas instancias se debe marcar como arrancable. Esto se puede hacer desde el menú “editar volumen” la ventana de volúmenes. En él se debe marcar la opción “arrancable”, que indica que el volumen puede ser usado para iniciar un instancia.\nPosteriormente, se lanza una nueva instancia siguiendo los mismos pasos que anteriormente pero eligiendo esta vez como origen de la instancia el volumen sobre el que se ha estado trabajando previamente.\nEn este punto se produce un incidencia relevante: la nueva instancia no se puede crear porque es necesario actualizar el sistema de arranque en el nuevo disco. Al intentar ejecutar una actualización del grupo, faltan las variables EFI, que, en este caso, no están presentes en la imagen que se usa para la creación de instancias en Openstack.\nSin variables EFI no se puede actualizar el grub para que se adapte al sistema volcado en el nuevo disco. Esta incidencia hace inviable la práctica en este escenario.\nInfo\nLas imágenes en las que se basan las instancias de OpenStack son diferentes en cada instalación y este error puede no aparecer en otros casos.\nNote\nPara continuar el ejemplo práctico planteado al inicio del post se migra el trabajo a la plataforma de virtualización Proxmox.\nVolcado del sistema al nuevo disco en Proxmox Particionado del nuevo disco El particionado y volcado del contenido del disco de 10GB al de 30GB se hace en Proxmox de forma análoga a la empleada en el caso de Openstack, ya documentado anteriormente en este post.\nDe esta manera, se pueden establecer los siguientes tamaños de particiones, teniendo en cuenta que, en este caso, el nuevo disco es de 32GB:\n/boot/efi: 100MB /boot: 2 GB /: 12GB /home: 5GB /var: 5GB /usr: 6GB swap: 2GB Para trasladar esta información a la tabla de particiones del nuevo disco duro se vuelve a usar fdisk para particionar el disco. Para ello se crea en primer lugar una nueva tabla de particiones con el comando g. Posteriormente, se crea cada partición y se le asigna su número, primer sector y tamaño con el comando n. Tras crear todas las particiones necesarias, se les puede asignar un tipo con el comando t hasta terminar con esta información en la tabla de particiones del disco:\nAsignación del sistema de ficheros Para continuar volcando el sistema al nuevo disco, el siguiente paso es asignar a cada partición un sistema de ficheros acorde al contenido que debe almacenar. En este caso, todas las particiones tienen un sistema de ficheros de tipo ext4 excepto la partición UEFI, que cuenta con un sistema de ficheros FAT32 y la partición swap, que se debe configurar como tal.\nmkfs.vfat -F 32 -n EFI /dev/vdb1 mkfs.ext4 -L boot /dev/vdb2 mkfs.ext4 -L sistema /dev/vdb3 mkfs.ext4 -L home /dev/vdb4 mkfs.ext4 -L var /dev/vdb5 mkfs.ext4 -L usr /dev/vdb6 mkswap -L swap /dev/vdb7 Finalmente, el disco queda particionado de esta forma:\nMontaje del nuevo disco Para volcar la información del sistema al nuevo disco hay dos opciones: montarlo en el propio sistema o generar una nueva instancia en la que se monten los dos volúmenes como discos duros y copiar la información de uno a otro. En este caso, se monta el nuevo disco duro en la instancia que ya está funcionando. Para ello se crean en el directorio /mnt un nuevo directorio para cada una de las particiones del disco con el comando mkdir -p /mnt/destino{efi,boot,sistema,home,var} y con mount -v /dev/vdbn /mnt/destino/partición (donde n es el número de la partición y partición el nombre descriptivo de su contenido) se montan todas ellas en el directorio /mnt de la instancia.\nDe esta manera, todas las particiones quedan montadas en el sistema:\nVolcado de la información al nuevo disco Con el nuevo disco montado en el sistema se puede comenzar a volcar la información desde el disco original al nuevo volumen. Para ello se usarán los comandos rsync y cp.\ncp -ra /var/* /mnt/destino/var cp -ra /usr/* /mnt/destino/usr cp -ra /home/* /mnt/destino/home Para los directorios /boot y /EFI se debe tener en cuenta que el segundo está dentro del primero, de manera que los comandos que se deben ejecutar son:\nrsync -ra --exclude=efi /boot/* /mnt/destino/boot cp -ra /boot/efi/* /mnt/destino/efi Puesto que el contenido de /boot/efi ya está dentro del directorio /boot, no es necesario que ese directorio esté duplicado dentro de la partición vdb2, así que se puede no copiar excluyéndolo con la opción --exclude del comando rsync.\nPor último, sólo queda volcar el contenido del directorio raíz al nuevo disco duro. En este caso, no se puede hacer un copiado masivo de todo el directorio puesto que alguno de los directorios que contiene generarían un bucle de copia recursiva que colapsaría el sistema. Por ejemplo, se debe evitar copiar el director /mnt al nuevo disco puesto que éste ya está montado en el propio directorio /mnt. Además, tampoco se deben volver a copiar al nuevo disco duro los directorios que ya tienen su propia partición.\nDe esta manera, se puede ejecutar el volcado del contenido del directorio raíz al nuevo disco duro usando el comando rsync, que permite excluir parte de los ficheros del origen:\nrsync -ra --exclude ‘boot’ --exclude ‘home’ --exclude ‘mnt’ --exclude ‘usr’ --exclude ‘var’ /* /mnt/destino/sistema/. Configuración del fichero fstab El último paso para tener una réplica del volumen original en el nuevo disco duro de 30GB es configurar el fichero fstab del nuevo sistema, que está alojado en el directorio /mnt/destino/sistema/etc/fstab. En él se deben modificar los puntos de montaje de las particiones del volumen original por los puntos de montajes de las nuevas particiones del disco duro de 30GB. Esto se puede hacer redirigiendo la salida del comando blkid al fichero para guardar los UUID de todas las particiones y editándolo posteriormente en un editor de texto como nano. Con blkid | grep vdb | cut -d “ “ -f 3 se consigue redirigir al fichero fstab, en primer lugar, sólo las líneas relativas a las particiones del nuevo disco de 30GB (vdb) y, además, sólo el campo necesario de cada partición: el UUID.\nActualización del arranque Para actualizar el arranque del sistema en el nuevo disco se debe cambiar el directorio raíz del sistema al directorio del nuevo disco /mnt/destino/sistema. Antes de ejecutar el comando chroot es necesario montar los directorios del sistema /dev, /proc y /sys con la opción \u0026ndash;bind.\nmount --bind /dev /mnt/destino/sistema/dev/ mount --bind /proc /mnt/destino/sistema/proc/ mount --bind /sys /mnt/destino/sistema/sys/ Con chroot /mnt se cambia la raíz temporalmente al nuevo disco duro:\nAdemás, antes de poder usar el nuevo disco duro como sistema se debe actualizar el arranque con el comando update-grub.\nPosteriormente, el comando efibootmgr permite actualizar las entradas del menú de arranque del firmware de la EFI.\nEn este punto de la instalación se puede apagar el equipo y modificar el orden de arranque en la interfaz de Proxmox para iniciar la máquina virtual con el nuevo disco duro. Al experimentar errores en el arranque y comprobar que el sistema no era capaz de arrancar desde el nuevo disco se buscan posibles inconsistencias en los ficheros de configuración del grub. Y, aunque en el fichero /boot/grub/grub.cfg la entrada del menú de arranque ya recoge el UUID del disco duro de 32GB tras la actualización de grub:\nEn el fichero /boot/efi/EFI/debian/grub.cfg el UUID del dispositivo con el que arranca el equipo no se había actualizado y esto estaba provocando que el sistema arrancase desde el disco duro original.\nTas actualizar esta línea del fichero, ahora la máquina arranca desde el disco duro de 32GB sin el disco original de 10GB.\n"},{
  "section": "Blog",
  "slug": "/blog/redes/2024-04-12-cortafuegos-firewall-iptables-gns3/",
  "title": "Configuración de reglas de cortafuegos en router Linux usando iptables",
  "description": "",
  "date": "April 12, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "GNS3, redes, Planificación y Administración de Redes, router, router Linux, cortafuegos, iptables, los juegos del hambre, hunger games, sinsajo",
  "content":"Existen diferentes formas de implementar un cortafuegos en una red, ya sea por nodos o de forma perimetral. En ocasiones se puede dedicar un dispositivo exclusivamente para esta finalidad pero los routers también pueden cumplir esta función. En este post se muestra cómo configurar reglas de cortafuegos en routers Linux en este escenario basado en la saga \u0026ldquo;Los juegos del hambre\u0026rdquo;, que ya sirvió de inspiración para este otro post.\nEn este caso, todos los ordenadores que tienen el nombre de un participante masculino tienen instalado un servidor SSH, un servidor web y un cliente de base de datos. Los ordenadores que tienen nombre de una participante femenina cuentan con un servidor de base de datos. Además, la máquina del Distrito 13 aloja tanto un servidor web como un servidor de base de datos.\nDireccionamiento del escenario Las direcciones IP de los diferentes ordenadores son:\nMarvel: 10.0.1.2 Glimmer: 10.0.1.3 Cato: 10.0.2.2 Clover: 10.0.2.3 Thresh: 10.0.11.2 Rue: 10.0.11.3 Peeta: 10.0.12.2 Katniss: 10.0.12.3 Las interfaces de los routers tienen las siguientes direcciones IP:\nR1 f0/0: 11.0.1.1 f0/1: 173.23.0.1 f1/0: 193.168.1.2 R2 f0/0: 11.0.11.1 f0/1: 173.23.0.2 f1/0: 173.24.0.1 f1/1: 193.168.11.2 R3 f0/0: 11.0.2.1 f0/1: 173.25.0.1 f1/0: 193.168.2.2 R4 f0/0: 11.0.12.1 f0/1: 173.24.0.2 f1/0: 193.168.12.2 f1/1: 173.25.0.2 R5 f0/0: 193.168.11.1 f0/1: 193.168.12.1 f1/0: 193.168.1.1 f1/1: 193.168.2.1 f2/0: 11.0.13.1 Para asignar una dirección IP estática a cada una de las máquinas que componen el escenario, se debe editar el fichero de configuración /etc/network/interfaces. En él se indica la dirección IP de cada una de las interfaces del dispositivo, su máscara de red y puerta de enlace.\nPor ejemplo, el fichero /etc/network/interfaces de Marvel debe incluir las siguientes líneas:\n#Static config for ens4 auto ens4 iface ens4 inet static address 10.0.1.2 netmask 255.255.255.0 gateway 10.0.1.1 dns-nameservers 10.0.1.1 De la misma manera, el fichero /etc/network/interfaces del router R1 debe incluir estas líneas:\n#Static config for ens4 auto ens4 iface ens4 inet static address 10.0.1.1 netmask 255.255.255.0 #Static config for ens5 auto ens5 iface ens5 inet static address 173.23.0.1 netmask 255.255.255.0 #Static config for ens6 auto ens6 iface ens6 inet static address 193.168.1.2 netmask 255.255.255.0 En el caso de los routers, como tienen más de una tarjeta de red, no se puede indicar la puerta de enlace en este fichero puesto que los sistemas Linux sólo pueden aceptar una puerta de enlace por dispositivo y no se puede indicar una diferente para cada una de las redes a las que pertenecen los routers.\nAsí se configuran todas las tarjetas de red de todos los dispositivos del escenario.\nActivar el bit de forwarding Para configurar las máquinas Linux para que funcionen como router es necesario poner a 1 el bit de forwarding. Esto se puede conseguir de varias formas, tanto de manera temporal como persistente. En este caso, para hacerlo de manera persistente y conseguir que la configuración no se modifique a través de los reinicios de las diferentes máquinas, se usa la opción de incluir la línea net.ipv4.ip_forward = 1 en el fichero de configuración /etc/sysctl.conf. Para activar esta línea al fichero se puede editar el mismo con un editor de texto y descomentarla o, de manera más sencilla, usar un echo para redireccionar el texto al fichero y anexarlo al final de su contenido: echo “net.ipv4.ip_forward = 1” » /etc/sysctl.conf.\nEste paso se repite en todos los router.\nEnrutamiento del escenario Tablas de enrutamiento Ordenadores Marvel Destino Siguiente router Interfaz de salida 10.0.1.0/24 0.0.0.0 ens4 0.0.0.0 10.0.1.1 ens4 Glimmer Destino Siguiente router Interfaz de salida 10.0.1.0/24 0.0.0.0 ens4 0.0.0.0 10.0.1.1 ens4 Cato Destino Siguiente router Interfaz de salida 10.0.2.0/24 0.0.0.0 ens4 0.0.0.0 10.0.2.1 ens4 Clove Destino Siguiente router Interfaz de salida 10.0.2.0/24 0.0.0.0 ens4 0.0.0.0 10.0.2.1 ens4 Thresh Destino Siguiente router Interfaz de salida 10.0.11.0/24 0.0.0.0 ens4 0.0.0.0 10.0.11.1 ens4 Rue Destino Siguiente router Interfaz de salida 10.0.11.0/24 0.0.0.0 ens4 0.0.0.0 10.0.11.1 ens4 Peeta Destino Siguiente router Interfaz de salida 10.0.12.0/24 0.0.0.0 ens4 0.0.0.0 10.0.12.1 ens4 Katniss Destino Siguiente router Interfaz de salida 10.0.12.0/24 0.0.0.0 ens4 0.0.0.0 10.0.12.1 ens4 Distrito 13 Destino Siguiente router Interfaz de salida 10.0.13.0/24 0.0.0.0 ens4 0.0.0.0 10.0.13.1 ens4 Routers R1 Destino Siguiente router Interfaz de salida 10.0.1.0 0.0.0.0 ens4 173.23.0.0 0.0.0.0 ens5 173.24.0.0 173.23.0.2 ens5 173.25.0.0 193.168.1.1 ens6 193.168.1.0 0.0.0.0 ens6 193.168.2.0 173.23.0.2 ens5 193.168.11.0 193.168.1.1 ens6 193.168.12.0 193.168.1.1 ens6 R2 Destino Siguiente router Interfaz de salida 10.0.11.0 0.0.0.0 ens4 173.23.0.0 0.0.0.0 ens5 173.24.0.0 0.0.0.0 ens6 173.25.0.0 173.24.0.2 ens6 193.168.1.0 173.23.0.1 ens5 193.168.2.0 193.168.11.1 ens7 193.168.11.0 0.0.0.0 ens7 193.168.12.0 173.24.0.2 ens6 R3 Destino Siguiente router Interfaz de salida 10.0.2.0 0.0.0.0 ens4 173.23.0.0 193.168.2.1 ens6 173.24.0.0 173.25.0.2 ens5 173.25.0.0 0.0.0.0 ens5 193.168.1.0 193.168.2.1 ens6 193.168.2.0 0.0.0.0 ens6 193.168.11.0 193.168.2.1 ens6 193.168.12.0 173.25.0.2 ens5 R4 Destino Siguiente router Interfaz de salida 10.0.12.0 0.0.0.0 ens4 173.23.0.0 173.24.0.1 ens5 173.24.0.0 0.0.0.0 ens5 173.25.0.0 0.0.0.0 ens7 193.168.1.0 193.168.12.1 ens6 193.168.2.0 173.24.0.1 ens5 193.168.11.0 193.168.12.1 ens6 193.168.12.0 0.0.0.0 ens6 R5 Destino Siguiente router Interfaz de salida 10.0.13.0 0.0.0.0 ens8 173.23.0.0 193.168.1.2 ens6 173.24.0.0 193.168.11.2 ens4 173.25.0.0 193.168.2.2 ens7 193.168.1.0 0.0.0.0 ens6 193.168.2.0 0.0.0.0 ens7 193.168.11.0 0.0.0.0 ens4 193.168.12.0 0.0.0.0 ens5 Configuración del enrutamiento en los routers Linux Para trasladar la información de las tablas de enrutamiento a las máquinas Linux tanto de los participantes como a los routers existen varias opciones. La primera de ellas es añadir líneas a la tabla de enrutamiento usando el comando ip route add pero esta forma de volcar al información conlleva un problema: al reiniciar el equipo, la información se pierde.\nPara hacer persistente la configuración de la tabla de enrutamiento se puede atender a otras alternativas. Por ejemplo, se puede guardar en el directorio /etc/network/if-up.d un script que añada las líneas de la tabla de enrutamiento cada vez que el estado de una interfaz del router cambie de apagado (down) a encendido (up).\nOtra posibilidad es añadir esta información al fichero de configuración /etc/network/interfaces. Por ejemplo, este fichero en el caso del PC de Marvel quedaría así:\n#Static config for ens4 auto ens4 iface ens4 inet static address 10.0.1.2 netmask 255.255.255.0 gateway 10.0.1.1 dns-nameservers 10.0.1.1 up ip route add default via 10.0.1.1 Y en el router R1 contendría la siguiente información:\n#Static config for ens4 auto ens4 iface ens4 inet static address 10.0.1.1 netmask 255.255.255.0 #Static config for ens5 auto ens5 iface ens5 inet static address 173.23.0.1 netmask 255.255.255.0 up ip route add 173.24.0.0/24 via 173.23.0.2 up ip route add 193.168.2.0/24 via 173.23.0.2 #Static config for ens6 auto ens6 iface ens6 inet static address 193.168.1.2 netmask 255.255.255.0 up ip route add 173.25.0.0/24 via 193.168.1.1 up ip route add 193.168.11.0/24 via 193.168.1.1 up ip route add 193.168.12.0/24 via 193.168.1.1 De esta manera, se configuran las tablas de enrutamiento de todos los dispositivos del escenario.\nConfiguración del NAT NAT en R1 En este escenario, cada router tiene una interfaz que da a una red privada y dos o más interfaces que dan a Internet. Por tanto, la configuración NAT se vuelve algo más compleja.\nEn cada router, se deben aplicar tantas reglas SNAT como interfaces con IP públicas tengan, de manera que todos los paquetes que los atraviesan modifiquen su contenido de IP de origen tanto si salen por una interfaz o por otra.\nPor ejemplo, en el caso del router R1, es necesario aplicar dos reglas de SNAT correspondientes a cada una de sus dos interfaces públicas:\niptables -t nat -A POSTROUTING -s 10.0.1.0/24 -o ens5 -j SNAT --to 173.23.0.1 iptables -t nat -A POSTROUTING -s 10.0.1.0/24 -o ens6 -j SNAT --to 193.168.1.2 De esta manera, en los paquetes que salen por la interfaz ens5 hacia el router R2 se modifica su IP de origen de la 10.0.1.2 ó 10.0.1.3 a la 173.23.0.1. En el caso de que los paquetes salgan del router por la interfaz ens6 hacia el router R5, la IP de origen cambia de la 10.0.1.2 ó 10.0.1.3 a la 193.168.1.2.\nEn el caso del DNAT, en cambio, parece que la opción más adecuada es eliminar del comando de iptables la opción -i, que especifica la interfaz de entrada de los paquetes, de manera que todos los paquetes que lleven como puerto de destino uno de los puertos por los que escuchan los diferentes servidores instalados en la red, cambian su IP de destino por la IP del equipo que ofrece ese servicio, independientemente de la interfaz por la que el router reciba ese paquete.\nPor ejemplo, en el router R1, se pueden añadir las siguientes reglas DNAT:\niptables -t nat -A PREROUTING -p tcp --dport 8085 -i ens5 -j DNAT --to 10.0.1.2:80 iptables -t nat -A PREROUTING -p tcp --dport 8085 -i ens6 -j DNAT --to 10.0.1.2:80 iptables -t nat -A PREROUTING -p tcp --dport 443 -i ens5 -j DNAT --to 10.0.1.2 iptables -t nat -A PREROUTING -p tcp --dport 443 -i ens6 -j DNAT --to 10.0.1.2 iptables -t nat -A PREROUTING -p tcp --dport 2222 -i ens5 -j DNAT --to 10.0.1.2:22 iptables -t nat -A PREROUTING -p tcp --dport 2222 -i ens6 -j DNAT --to 10.0.1.2:22 iptables -t nat -A PREROUTING -p tcp --dport 5432 -i ens5 -j DNAT --to 10.0.1.3 iptables -t nat -A PREROUTING -p tcp --dport 5432 -i ens6 -j DNAT --to 10.0.1.3 Con esta configuración, todos los paquetes dirigidos al servidor web (puertos 80 y 443) cambian su IP de destino de la 173.23.0.1 ó la 193.168.1.2 a la 10.0.1.2, la del ordenador que aloja este servidor; los dirigidos al servidor SSH (puerto 22) modifican su IP de destino de la 173.23.0.1, si llegan desde el router R2, ó la 193.168.1.2, si llegan desde el router R5, a la 10.0.1.2; y los dirigidos al servidor Postgres (puerto 5432) la modifican de una de las dos IP públicas del router a la privada de la máquina que cuenta con ese servidor: la 10.0.1.3.\nComo último paso para aplicar a cada router la configuración NAT necesaria para permitir el acceso a todos los participantes a todos los servicios del escenario, se puede hacer que las reglas NAT sean persistentes en el sistema. Para ello, es imprescindible contar con un fichero que almacene el contenido de las tablas con las que trabaja iptables. Para volcar esta información se usa el comando iptables-save:\niptables-save \u0026gt; /etc/iptables/rules.v4. La información contenida en este fichero se puede recuperar usando el comando iptables-restore. Para hacerlo de forma automatizada, se puede incluir este comando en un script con permiso de ejecución con el siguiente contenido:\n#!/usr/bin/env bash iptables-restore \u0026lt; /etc/iptables/rules.v4 De esta manera, al ejecutar el script, se carga en memoria toda la información almacenada en el fichero de reglas de iptables que, en este caso, se llama rules.v4 y está almacenado en el directorio /etc/iptables/.\nPara terminar de configurar este proceso y garantizar que la configuración de iptables se cargue de forma totalmente automática en cada reinicio del sistema, se puede crear, además, un servicio que se encargue de ejecutar este script cada vez que arranque al máquina. Para crear un servicio hay que generar un fichero en el directorio /etc/systemd/system/ con el nombre del servicio, en este caso, iptables.service, por ejemplo.\nEn este fichero, se guarda la configuración del servicio:\n[Unit] Description=Reglas de iptables After=systemd-sysctl.service [Service] Type=oneshot ExecStart=/usr/local/bin/iptables.sh [Install] WantedBy=multi-user.target Y, tras haberlo creado, se habilita y se activa.\nsystemctl enable systemctl start Es importante tener en cuenta que cada vez que se modifique el contenido de las tablas de iptables se debe volcar la nueva configuración al fichero rules.v4, que será la que el servicio creado restaurará tras cada reinicio.\nPara hacer posible la comunicación entre todos los participantes a través de las IP públicas, la configuración NAT se tiene que implementar en todos los routers del escenario.\nNAT en R2 Las reglas SNAT y DNAT son muy similares para todos los routers. Por ejemplo, el SNAT para el router R2 se configura con las reglas:\niptables -t nat -A POSTROUTING -s 10.0.11.0/24 -o ens5 -j SNAT --to 173.23.0.2 iptables -t nat -A POSTROUTING -s 10.0.11.0/24 -o ens6 -j SNAT --to 173.24.0.1 iptables -t nat -A POSTROUTING -s 10.0.11.0/24 -o ens7 -j SNAT --to 193.168.11.2 Y el DNAT de este router incluye las reglas:\niptables -t nat -A PREROUTING -p tcp --dport 80 -i ens5 -j DNAT --to 10.0.11.2 iptables -t nat -A PREROUTING -p tcp --dport 80 -i ens6 -j DNAT --to 10.0.11.2 iptables -t nat -A PREROUTING -p tcp --dport 80 -i ens7 -j DNAT --to 10.0.11.2 iptables -t nat -A PREROUTING -p tcp --dport 443 -i ens5 -j DNAT --to 10.0.11.2 iptables -t nat -A PREROUTING -p tcp --dport 443 -i ens6 -j DNAT --to 10.0.11.2 iptables -t nat -A PREROUTING -p tcp --dport 443 -i ens7 -j DNAT --to 10.0.11.2 iptables -t nat -A PREROUTING -p tcp --dport 2222 -i ens5 -j DNAT --to 10.0.11.2:22 iptables -t nat -A PREROUTING -p tcp --dport 2222 -i ens6 -j DNAT --to 10.0.11.2:22 iptables -t nat -A PREROUTING -p tcp --dport 2222 -i ens7 -j DNAT --to 10.0.11.2:22 iptables -t nat -A PREROUTING -p tcp --dport 5432 -i ens5 -j DNAT --to 10.0.11.3 iptables -t nat -A PREROUTING -p tcp --dport 5432 -i ens6 -j DNAT --to 10.0.11.3 iptables -t nat -A PREROUTING -p tcp --dport 5432 -i ens7 -j DNAT --to 10.0.11.3 NAT en R3 En el caso del router R3 se indican las siguientes reglas para el SNAT:\niptables -t nat -A POSTROUTING -s 10.0.2.0/24 -o ens5 -j SNAT --to 173.25.0.1 iptables -t nat -A POSTROUTING -s 10.0.2.0/24 -o ens6 -j SNAT --to 193.168.2.2 Y para el DNAT:\niptables -t nat -A PREROUTING -p tcp --dport 80 -i ens5 -j DNAT --to 10.0.2.2 iptables -t nat -A PREROUTING -p tcp --dport 80 -i ens6 -j DNAT --to 10.0.2.2 iptables -t nat -A PREROUTING -p tcp --dport 443 -i ens5 -j DNAT --to 10.0.2.2 iptables -t nat -A PREROUTING -p tcp --dport 443 -i ens6 -j DNAT --to 10.0.2.2 iptables -t nat -A PREROUTING -p tcp --dport 2222 -i ens5 -j DNAT --to 10.0.2.2:22 iptables -t nat -A PREROUTING -p tcp --dport 2222 -i ens6 -j DNAT --to 10.0.2.2:22 iptables -t nat -A PREROUTING -p tcp --dport 5432 -i ens5 -j DNAT --to 10.0.2.3 iptables -t nat -A PREROUTING -p tcp --dport 5432 -i ens6 -j DNAT --to 10.0.2.3 NAT en R4 Si se toma como ejemplo el router R4, las reglas para el SNAT con las que debe contar son:\niptables -t nat -A POSTROUTING -s 10.0.12.0/24 -o ens5 -j SNAT --to 173.24.0.2 iptables -t nat -A POSTROUTING -s 10.0.12.0/24 -o ens6 -j SNAT --to 193.168.12.2 iptables -t nat -A POSTROUTING -s 10.0.12.0/24 -o ens7 -j SNAT --to 173.25.0.2 Y en el caso del DNAT:\niptables -t nat -A PREROUTING -p tcp --dport 80 -i ens5 -j DNAT --to 10.0.12.2 iptables -t nat -A PREROUTING -p tcp --dport 80 -i ens6 -j DNAT --to 10.0.12.2 iptables -t nat -A PREROUTING -p tcp --dport 80 -i ens7 -j DNAT --to 10.0.12.2 iptables -t nat -A PREROUTING -p tcp --dport 443 -i ens5 -j DNAT --to 10.0.12.2 iptables -t nat -A PREROUTING -p tcp --dport 443 -i ens6 -j DNAT --to 10.0.12.2 iptables -t nat -A PREROUTING -p tcp --dport 443 -i ens7 -j DNAT --to 10.0.12.2 iptables -t nat -A PREROUTING -p tcp --dport 2222 -i ens6 -j DNAT --to 10.0.12.2:22 iptables -t nat -A PREROUTING -p tcp --dport 2222 -i ens7 -j DNAT --to 10.0.12.2:22 iptables -t nat -A PREROUTING -p tcp --dport 5432 -i ens5 -j DNAT --to 10.0.12.3 iptables -t nat -A PREROUTING -p tcp --dport 5432 -i ens6 -j DNAT --to 10.0.12.3 iptables -t nat -A PREROUTING -p tcp --dport 5432 -i ens7 -j DNAT --to 10.0.12.3 NAT en R5 Por último, las reglas para el router R5 presentan algunas diferencias puesto que a él sólo se conecta un servidor y, en cambio, cuenta con más interfaces públicas que el resto de routers del escenario. Para hacer SNAT necesita las siguientes reglas:\niptables -t nat -A POSTROUTING -s 10.0.13.0/24 -o ens4 -j SNAT --to 193.168.11.1 iptables -t nat -A POSTROUTING -s 10.0.13.0/24 -o ens5 -j SNAT --to 193.168.12.1 iptables -t nat -A POSTROUTING -s 10.0.13.0/24 -o ens6 -j SNAT --to 193.168.1.1 iptables -t nat -A POSTROUTING -s 10.0.13.0/24 -o ens7 -j SNAT --to 193.168.2.1 Y para hacer DNAT se deben indicar estas reglas:\niptables -t nat -A PREROUTING -p tcp --dport 80 -i ens4 -j DNAT --to 10.0.13.2 iptables -t nat -A PREROUTING -p tcp --dport 80 -i ens5 -j DNAT --to 10.0.13.2 iptables -t nat -A PREROUTING -p tcp --dport 80 -i ens6 -j DNAT --to 10.0.13.2 iptables -t nat -A PREROUTING -p tcp --dport 80 -i ens7 -j DNAT --to 10.0.13.2 iptables -t nat -A PREROUTING -p tcp --dport 443 -i ens4 -j DNAT --to 10.0.13.2 iptables -t nat -A PREROUTING -p tcp --dport 443 -i ens5 -j DNAT --to 10.0.13.2 iptables -t nat -A PREROUTING -p tcp --dport 443 -i ens6 -j DNAT --to 10.0.13.2 iptables -t nat -A PREROUTING -p tcp --dport 443 -i ens7 -j DNAT --to 10.0.13.2 iptables -t nat -A PREROUTING -p tcp --dport 2222 -i ens4 -j DNAT --to 10.0.13.2:22 iptables -t nat -A PREROUTING -p tcp --dport 2222 -i ens5 -j DNAT --to 10.0.13.2:22 iptables -t nat -A PREROUTING -p tcp --dport 2222 -i ens6 -j DNAT --to 10.0.13.2:22 iptables -t nat -A PREROUTING -p tcp --dport 2222 -i ens7 -j DNAT --to 10.0.13.2:22 iptables -t nat -A PREROUTING -p tcp --dport 5432 -i ens4 -j DNAT --to 10.0.13.2 iptables -t nat -A PREROUTING -p tcp --dport 5432 -i ens5 -j DNAT --to 10.0.13.2 iptables -t nat -A PREROUTING -p tcp --dport 5432 -i ens6 -j DNAT --to 10.0.13.2 iptables -t nat -A PREROUTING -p tcp --dport 5432 -i ens7 -j DNAT --to 10.0.13.2 Establecer la política DROP por defecto Info\nEn este caso, se configura un cortafuegos de lista blanca, que bloque cualquier tráfico que no esté permitido expresamente. Para ello se debe establecer una política DROP por defecto.\nConservar el acceso a los routers por SSH Antes de establecer las reglas de cortafuegos que bloquean todo el tráfico en los routers, hay que garantizar el acceso por SSH a estos dispositivos para que sigan siendo accesibles para las tareas de administración. Para garantizar este acceso hay que incluir dos reglas de iptables.\nEn primer lugar, es necesario añadir una regla a la tabla input que acepte el tráfico que tenga como destino el rango de IP de la red local del router y como puerto de destino el 22. Con esta regla, se abre el tráfico SSH de entrada al router para que pueda escuchar peticiones.\nPor otra parte, hay que añadir una regla a la tabla output que acepte la salida de tráfico hacia las direcciones IP del rango de la red local del router cuando tenga como puerto de origen el 22. De esta manera, se abre el tráfico SSH de salida del router hacia su red local para que pueda responder las peticiones.\nR1 R2 R3 R4 R5 iptables -A INPUT -s 10.0.1.0/24 -p tcp --dport 22 -j ACCEPT iptables -A OUTPUT -s 10.0.1.0/24 -p tcp --sport 22 -j ACCEPT iptables -A INPUT -s 10.0.11.0/24 -p tcp --dport 22 -j ACCEPT iptables -A OUTPUT -s 10.0.11.0/24 -p tcp --sport 22 -j ACCEPT iptables -A INPUT -s 10.0.2.0/24 -p tcp --dport 22 -j ACCEPT iptables -A OUTPUT -s 10.0.2.0/24 -p tcp --sport 22 -j ACCEPT iptables -A INPUT -s 10.0.12.0/24 -p tcp --dport 22 -j ACCEPT iptables -A OUTPUT -s 10.0.12.0/24 -p tcp --sport 22 -j ACCEPT iptables -A INPUT -s 10.0.13.0/24 -p tcp --dport 22 -j ACCEPT iptables -A OUTPUT -s 10.0.13.0/24 -p tcp --sport 22 -j ACCEPT Establecer la política DROP por defecto para el resto del tráfico Con el tráfico SSH garantizado para poder acceder a los routers desde cada una de sus redes locales, se puede implementar en todos ellos la política DROP que bloquee todo el resto del tráfico. Para establecer esta política de bloque se usa la opción -P de iptables, que permite establecer una política por defecto (DROP o ACCEPT) en cada una de las tablas de los routers: INPUT, OUTPUT y FORWARD. En concreto, en cada router hay que ejecutar los siguientes tres comandos: iptables -P INPUT DROP; iptables -P OUTPUT DROP; iptables -P FORWARD DROP.\nTras aplicar esta configuración, los servicios de cada uno de los distritos tienen que se inaccesibles para los participantes del resto. Una forma sencilla de comprobar que esta configuración se ha aplicado correctamente es ver cómo desde dentro de la propia red local se puede acceder al router por SSH pero no se puede hacer ping a su IP.\nHacer persistente la configuración de iptables Para hacer persistente la configuración de iptables se pueden reutilizar el servicio y el script creados en el punto 4 para hacer persistente el NAT. Simplemente es necesario volver a volcar al fichero /etc/iptables/rulesv.4 toda la información que devuelve el comando iptables-save cada vez que se modifique el contenido de las tablas.\nConfiguración de las reglas de cortafuegos Los indigentes pueden acceder al servidor de bases de datos de los pobres Para permitir a los indigentes acceder al servidor de bases de datos de los pobres es necesario configurar, por una parte, el router R2 y, por otra, el router R4.\nEn el router R2, se deben incluir reglas que permitan el tráfico de entrada de los paquetes que tengan como destino el puerto 5432 y de salida de los que tengan como origen ese mismo puerto:\niptables -A INPUT -p tcp --dport 5432 -j ACCEPT iptables -A OUTPUT -p tcp --sport 5432 -j ACCEPT En el router R4, en cambio, se deben incluir reglas que permitan el tráfico de entrada de los paquetes que tengan como origen el puerto 5432 y de salida de los que tengan como destino ese mismo puerto:\niptables -A INPUT -p tcp --sport 5432 -j ACCEPT iptables -A OUTPUT -p tcp --dport 5432 -j ACCEPT Los indigentes y los pobres pueden acceder al servidor SSH del distrito 13 Para permitir a los indigentes y los pobres acceder al servidor SSH del distrito 13 se deben configurar los routers R2, R4 y R5.\nEn el router R2 se deben incluir reglas que permitan el tráfico desde la 193.168.11.1 dirigido al puerto 2222 y hacia la misma IP que llegue desde el puerto de origen 2222.\niptables -A FORWARD -s 193.168.11.1 -p tcp --sport 2222 -j ACCEPT iptables -A FORWARD -d 193.168.11.1 -p tcp --dport 2222 -j ACCEPT En el router R4 se deben incluir reglas que permitan el tráfico desde la IP 193.168.12.1 dirigido al puerto 2222 y hacia la misma IP que llegue con puerto de origen también 2222.\niptables -A FORWARD -s 193.168.12.1 -p tcp --sport 2222 -j ACCEPT iptables -A FORWARD -d 193.168.12.1 -p tcp --dport 2222 -j ACCEPT Por último, en el router R5 se deben incluir reglas que permitan el paso del tráfico con origen en las IP 193.168.12.2 ó 193.168.11.2 y con puerto de destino 22 y el que tenga destino en las IP 193.168.11.1 ó 193.168.12.1 y puerto de origen 22.\niptables -A FORWARD -s 193.168.12.2 -p tcp --dport 22 -j ACCEPT iptables -A FORWARD -s 193.168.11.2 -p tcp --dport 22 -j ACCEPT iptables -A FORWARD -d 193.168.12.1 -p tcp --sport 22 -j ACCEPT iptables -A FORWARD -d 193.168.11.2 -p tcp --sport 22 -j ACCEPT Los pijos pueden acceder al servidor web de Thresh, pero solo de 08 a 15 horas Para que los pijos puedan acceder al servidor web de Thresh de 8 a 15h se configuran reglas de cortafuegos en los routers R2, R3 y R4.\nEn el router R2 se tiene que permitir el tráfico con origen en la IP 193.168.2.2 y destino en el puerto 80 y el que tiene destino en esa misma IP y origen también en el puerto 80.\niptables -A FORWARD -s 173.25.0.1 -p tcp --dport 80 -m time --timestart 8:00 --timestop 15:00 -j ACCEPT iptables -A FORWARD -d 173.25.0.1 -p tcp --sport 80 -m time --timestart 8:00 --timestop 15:00 -j ACCEPT En el router R3 se permite el tráfico que va desde la el puerto 80 de la IP 193.168.11.2 y el que se dirige al mismo puerto de esa IP.\niptables -A FORWARD -s 173.24.0.1 -p tcp --sport 80 -m time --timestart 8:00 --timestop 15:00 -j ACCEPT iptables -A FORWARD -d 173.24.0.1 -p tcp --dport 80 -m time --timestart 8:00 --timestop 15:00 -j ACCEPT Finalmente, en el router R4 se configuran reglas que permitan el tráfico que sale desde la IP 193.168.2.2 hacia la 193.168.11.2 y el puerto 80 y el que tiene como origen el puerto 80 de la IP 193.168.11.2 y como destino la dirección 193.168.2.2\niptables -A FORWARD -s 173.25.0.1 -d 173.24.0.1 -p tcp --dport 80 -m time --timestart 8:00 --timestop 15:00 -j ACCEPT iptables -A FORWARD -s 173.24.0.1 -d 173.25.0.1 -p tcp --sport 80 -m time --timestart 8:00 --timestop 15:00 -j ACCEPT Clover puede acceder a los servidores de los superpijos, excepto al SSH Para que Clover pueda acceder al servidor web de los superpijos se deben configurar reglas de cortafuegos en los routers R1, R3 y R5.\nEn el router R1, hay que establecer reglas que permitan el tráfico que tiene origen en la IP 193.168.2.2 y destino en el puerto 80 (después de que el router haya hecho DNAT) y el que tiene destino en la misma IP y origen también en el puerto 80 (antes de que el router haya hecho SNAT).\niptables -A FORWARD -s 193.168.2.2 -p tcp --dport 80 -j ACCEPT iptables -A FORWARD -d 193.168.2.2 -p tcp --sport 80 -j ACCEPT En el router R3 se establecen reglas que permitan el tráfico desde la IP 193.168.1.2 y el puerto 8085 y también las que permitan el tráfico desde la IP de Clove (10.0.2.3) a la 193.168.1.2 por el puerto 8085.\niptables -A FORWARD -s 193.168.1.2 -p tcp --sport 8085 -j ACCEPT iptables -A FORWARD -s 10.0.2.3 -d 193.168.1.2 -p tcp --dport 8085 -j ACCEPT Por último, en el router R5 se permite el tráfico desde la IP 193.168.2.2 hacia la 193.168.1.2 hacia el puerto 8085 y desde la 193.168.1.2 hacia la 193.168.2.2 con origen en el puerto 8085.\niptables -A FORWARD -s 193.168.2.2 -d 193.168.1.2 -p tcp --dport 8085 -j ACCEPT iptables -A FORWARD -d 193.168.2.2 -s 193.168.1.2 -p tcp --sport 8085 -j ACCEPT Para permitir su acceso al servidor Postgres se utilizan las mismas reglas sustituyendo el número de puerto por el del servidor de bases de datos en todos los casos.\nEn el router R1, hay que establecer reglas que permitan el tráfico que tiene origen en la IP 193.168.2.2 y destino en el puerto 5432 y el que tiene destino en la misma IP y origen también en el puerto 5432.\niptables -A FORWARD -s 193.168.2.2 -p tcp --dport 5432 -j ACCEPT iptables -A FORWARD -d 193.168.2.2 -p tcp --sport 5432 -j ACCEPT En el router R3 se establecen reglas que permitan el tráfico desde la IP 193.168.1.2 y el puerto 5432 y también las que permitan el tráfico desde la IP de Clove (10.0.2.3) a la 193.168.1.2 por el puerto 5432.\niptables -A FORWARD -s 193.168.1.2 -p tcp --sport 5432 -j ACCEPT iptables -A FORWARD -s 10.0.2.3 -d 193.168.1.2 -p tcp --dport 5432 -j ACCEPT Por último, en el router R5 se permite el tráfico desde la IP 193.168.2.2 hacia la 193.168.1.2 hacia el puerto 5432 y desde la 193.168.1.2 hacia la 193.168.2.2 con origen en el puerto 5432.\niptables -A FORWARD -s 193.168.2.2 -d 193.168.1.2 -p tcp --dport 5432 -j ACCEPT iptables -A FORWARD -d 193.168.2.2 -s 193.168.1.2 -p tcp --sport 5432 -j ACCEPT Peeta puede entrar al servidor web de Marvel por el puerto 8085 Para permitir que Peeta pueda acceder al servidor web de Marvel por el puerto 8085 se deben establecer reglas de cortafuegos en los routers R1, R4 y R5.\nEn el router R1, hay que establecer reglas que permitan el tráfico que tiene origen en la IP 193.168.12.2 y destino en el puerto 80 (después de que el router haya hecho DNAT) y el que tiene destino en la misma IP y origen también en el puerto 80 (antes de que el router haya hecho SNAT).\niptables -A FORWARD -s 193.168.12.2 -p tcp --dport 80 -j ACCEPT iptables -A FORWARD -d 193.168.12.2 -p tcp --sport 80 -j ACCEPT En el router R4, se establecen reglas que permiten el tráfico con origen en la IP 193.168.1.2 y el puerto 8085 y el que tiene destino en esa misma IP y ese puerto y origen en la 10.0.12.2 para que sólo Peeta y no Katniss pueda comunicarse con Marvel.\niptables -A FORWARD -s 193.168.1.2 -p tcp --sport 8085 -j ACCEPT iptables -A FORWARD -d 193.168.1.2 -s 10.0.12.2 -p tcp --dport 8085 -j ACCEPT En el router R5 se establecen reglas que permiten el tráfico que sale de la IP 193.168.12.2 y va a la 193.168.1.2 hacia el puerto 8085 así como el que sale desde la 193.168.1.2 hacia la 193.168.12.2 y el puerto 8085.\niptables -A FORWARD -s 193.168.12.2 -d 193.168.1.2 -p tcp --dport 8085 -j ACCEPT iptables -A FORWARD -d 193.168.12.2 -s 193.168.1.2 -p tcp --sport 8085 -j ACCEPT Los pijos pueden acceder al servidor Postgres del distrito 13 Para que los pijos puedan acceder al servidor de bases de datos del distrito 13 se configura el cortafuegos de los routers R3 y R5.\nEn el router R3 se permite el tráfico desde la dirección 193.168.2.1 y el puerto 5432, así como el que se dirige a esa misma dirección IP y ese puerto.\niptables -A FORWARD -s 193.168.2.1 -p tcp --sport 5432 -j ACCEPT iptables -A FORWARD -d 193.168.2.1 -p tcp --dport 5432 -j ACCEPT En el router R5, el tráfico que se permite es el que sale de la IP 193.168.2.2 hacia el puerto 5432 y el que se dirige a esa misma dirección desde ese puerto.\niptables -A FORWARD -s 193.168.2.2 -p tcp --dport 5432 -j ACCEPT iptables -A FORWARD -d 193.168.2.2 -p tcp --sport 5432 -j ACCEPT Katniss puede acceder a los servidores SSH de todos los distritos Que Katniss pueda acceder a los servidores SSH de todos los distritos requiere la incorporación de reglas a todos los routers del escenario.\nEn primer lugar, el router R4 tiene que permitir que salgan las peticiones SSH de Katniss a todas las redes y que le lleguen las respuestas desde cualquier otro distrito. Para ello se indican reglas que permitan el tráfico que tiene como destino la IP de Katniss (10.0.12.3) y como origen el puerto 2222 y el que tiene como origen la IP de Katniss (10.0.12.3) y como destino el puerto 2222.\niptables -A FORWARD -d 193.168.12.2 -p tcp --sport 2222 -j ACCEPT iptables -A FORWARD -d 173.0.24.2 -p tcp --sport 2222 -j ACCEPT iptables -A FORWARD -d 173.25.0.2 -p tcp --sport 2222 -j ACCEPT iptables -A FORWARD -s 10.0.12.3 -p tcp --dport 2222 -j ACCEPT Para que pueda acceder al distrito 1 (superpijos) el router R1 debe permitir el tráfico que sale desde la IP 193.168.12.2 y tiene como puerto de destino el 22 (después del DNAT) y el que va hacia la 193.168.12.2 desde el puerto 22 (antes del SNAT). Además, el router R5 tiene que permitir el tráfico desde la 193.168.12.2 hacia la 193.168.1.2 y el puerto 2222 y, al contrario el tráfico desde el puerto 2222 de la IP 193.168.1.2 que va hacia la 193.168.12.2.\n#R1 iptables -A FORWARD -s 193.168.12.2 -p tcp --dport 22 -j ACCEPT iptables -A FORWARD -d 193.168.12.2 -p tcp --sport 22 -j ACCEPT #R5 iptables -A FORWARD -s 193.168.12.2 -d 193.168.1.2 -p tcp --dport 2222 -j ACCEPT iptables -A FORWARD -d 193.168.12.2 -s 193.168.1.2 -p tcp --sport 2222 -j ACCEPT De la misma forma, para acceder al distrito 2 (pijos) necesita que el router R2 permita el tráfico que va desde la IP 173.24.0.2 hacia el puerto de destino el 22 y el que va hacia la misma IP desde el puerto 22.\niptables -A FORWARD -s 173.25.0.2 -p tcp --dport 22 -j ACCEPT iptables -A FORWARD -d 173.25.0.2 -p tcp --sport 22 -j ACCEPT En el caso del distrito 11 (pobres) el router R2 debe incorporar reglas que permitan el tráfico con origen en la IP 173.24.0.2 y destino en el puerto 22 y el que tiene destino en la misma IP y origen en el puerto 22.\niptables -A FORWARD -s 173.24.0.2 -p tcp --dport 22 -j ACCEPT iptables -A FORWARD -d 173.24.0.2 -p tcp --sport 22 -j ACCEPT Por último, como Katniss forma parte del distrito 12 (indigentes) ya cuenta con las reglas de cortafuegos configuradas anteriormente. tanto en el router R4 como en el R5 que le permiten acceder al servidor SSH del distrito 13.\nRechazar un ataque de denegación de servicios por escaneo de puertos al distrito 13 desde los superpijos Para prevenir un ataque de denegación de servicios al distrito 13, se pueden implementar algunas reglas de cortafuegos en el router R5.\nEn primer lugar, se pueden bloquear los paquetes mal formados, que se usan para escanear los puertos de un servidor en busca de vulnerabilidades. Para ello se rechazan los paquetes nulos que no tienen ninguna flag:\niptables -A FORWARD -p tcp --tcp-flags ALL NONE -j DROP Con esta regla el cortafuegos filtra los paquetes que pasen por el router R5 y busca en ellos todas las flags (primer argumento del modificador --tcp-flags). Si de ellas no tiene ninguna (segundo argumento del modificador --tcp-flags), entonces rechaza el paquete.\nTambién se pueden rechazar paquetes cuyas flags revelen otros patrones habituales de ataque. Por ejemplo, se puede indicar con el modificador --tcp-flags que se busquen las flags SYN y FIN (primer argumento del modificador --tcp-flags) y que rechace aquellos paquetes que contengan ambas (segundo argumento del modificador --tcp-flags).\niptables -A INPUT -p tcp --tcp-flags SYN,FIN SYN,FIN -j DROP Igualmente, se puede aplicar un filtro similar al patrón basado en las flags SYN y RST:\niptables -A INPUT -p tcp --tcp-flags SYN,RST SYN,RST -j DROP Todas estas reglas se añaden en primer lugar, de manera que se evita que el cortafuegos tenga que analizar y comparar todo el fichero de reglas antes de rechazar los paquetes de este tipo que lleguen al router en su camino al servidor del distrito 13.\nAdicionalmente, para evitar otro tipo de ataques de denegación de servicio, se puede limitar el tráfico que puede pasar por el router R5 que tenga como origen la IP 193.168.1.2 usando el módulo limit en cada regla de cortafuegos que se refiera a ese tipo de tráfico, si en algún momento la hubiese.\niptables -A FORWARD -s 193.168.1.2 [OTROS CRITERIOS] -p tcp -m limit --limit 10/s -j ACCEPT Configuración de un servidor DHCP en el Router R1 Instalación del servidor DHCP Aunque hay varias opciones para configurar un servidor DHCP en un router linux, la más habitual es usar el servidor isc-dhcp. Para poder usarlo se debe instalar desde los repositorios de Debian:\nsudo apt install isc-dhcp-server Configuración del servidor DHCP Antes de poner en funcionamiento el servidor DHCP se configura, en primer lugar, la interfaz por la que acepta conexiones en el fichero /etc/default/isc-dhcp-server:\nINTERFACESV4=\u0026#34;ens4\u0026#34; El resto de la configuración necesaria se puede establecer en el fichero /etc/dhcp/dhcpd.conf, donde se indican, por ejemplo, la dirección de los servidores DNS, la red y rango de IP que el servidor DHCP debe entregar o el tiempo durante el cual los clientes pueden hacer uso de esas direcciones:\nsubnet 10.0.1.0 netmask 255.255.255.0 { range 10.0.1.2 10.0.1.6; option routers 10.0.1.1; option broadcast-address 10.0.1.255; } Finalmente, se reinicia el servicio.\nsystemctl restart isc-dhcp-server.service Para que los equipos de la red local puedan solicitar direcciones IP por DHCP primero se habilita en el fichero /etc/network/interfaces la configuración por DHCP de la tarjeta de red y se deshabilita la configuración estática.\nPosteriormente, tras reiniciar el servicio con sudo systemctl restart networking.service, la máquina solicita una dirección IP al servidor DHCP.\nConsecuencias del uso del direccionamiento por DHCP Al configurar por DHCP, la dirección IP de los equipos cambia periódicamente. Esto genera varios problemas relevantes en el escenario planteado para esta práctica.\nEn primer lugar, en lo relativo a los cortafuegos, el uso del DHCP dentro de las redes locales sólo afectaría a aquellas reglas en las que se indica que una de las máquinas de la red puede acceder a determinados servidores y otras no, como es el caso de Katniss, Peeta o Cato. Para poder mantener estas reglas si estas redes usasen direcciones IP dinámicas habría que configurar el cortafuegos usando la dirección MAC de estos equipos en lugar de su IP.\nEn el caso de la red 10.0.1.0/24 este caso no se da y, por tanto, la configuración de cortafuegos planteada en la práctica sería posible incluso aunque los equipos no tuviesen un direccionamiento estático.\nSin embargo ,en este escenario hay que tener en cuenta que los equipos de cada red local no sólo actúan como clientes, sino también como servidores de otros equipos ubicados en otras redes. Esto hace que todos los routers tengan que implementar reglas de DNAT, incluido el router R1. Para que el DNAT funcione correctamente, es imprescindible que los servidores cuenten con una IP estática a la que el router pueda redirigir los paquetes según el puerto al que se dirijan.\nPara hacer compatibles el uso del DHCP con el DNAT, sería necesario asignar direcciones IP reservadas en el servidor DHCP a aquellas máquinas que funcionan como servidores, en este caso, ambas máquinas de la red local. Por tanto, es imposible hacer que las reglas planteadas en la práctica funcionen en este supuesto, no por la configuración del cortafuegos, sino por la del DNAT.\n"},{
  "section": "Blog",
  "slug": "/blog/fundamentos-hardware/2024-04-04-instalacion-debian-lvm-proxmox/",
  "title": "Instalación de Debian 12 bajo LVM en Proxmox",
  "description": "",
  "date": "April 4, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "fundamentos-hardware",
  "tags": "Fundamentos de Hardware, debian, linux, instalación, lvm, comandos, snapshot, volúmenes lógicos",
  "content":"Proxmox Virtual Environment, o Proxmox VE, entorno de virtualización de servidores de código abierto basado en Debian. En este post se usa este entorno para crear una máquina virtual en la que se instala un sistema operativo Debian 12 bajo volúmenes lógicos (lvm).\nInstalación del sistema operativo Creación de la máquina En primer lugar se crea la máquina con el botón “Crear VM” de proxmox. A continuación, se le asigna un nombre, en este caso, lvm1.\nPosteriormente se elige el sistema operativo de la máquina. Por ejemplo, Debian 12 con la versión firmware UEFIx86_64.\nPara este ejemplo se añaden dos discos: virtio0, de 3GiB y virtio1, de 2GiB.\nTras configurar y crear la máquina virtual en proxmox, se ejecuta el instalador de Debian 12. El proceso de instalación es el habitual en cuanto a la selección del idioma y la creación de usuarios y contraseñas. En la sección de particionado del proceso de instalación se crea, en primer lugar, la partición de 50MB para el arranque efi:\nCon la partición creada, se arranca el gestor de de volúmenes lógicos para crear el grupo de volúmenes vg01 con el espacio restante en el disco 1:\nAñadir un volumen lógico El sistema se monta en un volumen lógico dentro del grupo de volúmenes vg01 recién creado. Para ello se elige la opción de crear volumen lógico en el menú del gestor de volúmenes lógicos del particionado de discos de Debian y se configuran las características determinadas para este ejemplo.\nPosteriormente, se asigna al volumen lógico creado un sistema de ficheros ext4, el punto de montaje “/” y la etiqueta “sistema”.\nDe esta manera, el disco queda particionado con la siguiente configuración:\nPara terminar con la instalación del sistema operativo, se instalan el sistema básico, el gestor de paquetes y los paquetes por defecto incluidos en la distribución. Después, se carga el gestor de arranque y se reinicia el sistema.\nConfiguración del volumen lógico y creación de un snapshot Añadir disco al grupo vg01 Para añadir un nuevo disco duro a un grupo de volúmenes el primer paso es crear el volumen físico que se va a usar en el grupo de volúmenes con el comando pvcreate.\npvcreate /dev/vdb A continuación, se añade el nuevo volumen físico al grupo de volúmenes con el comando vgextend.\nvgextend vg01 /dev/vdb En este punto el nuevo volumen físico ya forma parte del grupo de volúmenes vg01.\nCrear un snapshot Para crear un snapshot de un volumen lógico se usa el comando lvcreate con la opción -s.\nlvcreate -L 1G -n snapsistema -s /dev/vg01/sistema Con mkfs.ext4 se instala el sistema de archivos en el snapshot.\nmkfs.ext4 /dev/vg01/snapsistema Finalmente, se crea el directorio /mnt/snapsistema y se monta el snapshot en él:\nmkdir -p /mnt/snapsistema mount /dev/vg01/snapsistema /mnt/snapsistema Prevenir que el snapshot se quede sin espacio Para evitar que el snapshot se quede sin espacio hay que editar el fichero de configuración /etc/lvm/lvm.conf. En él se habilitan las opciones snapshot_autoextend_threshold y snapshot_autoextend_percent. En este caso, se asigna un 70% al umbral y un 20% al porcentaje, de manera que si el tamaño del snapshot aumenta de 700 MB (el 70% del tamaño asignado), su tamaño aumentará de manera automática a 1,2 GB (un 20% más del tamaño asignado).\nInformación de los dispositivos de bloque Hay dos discos duros disponibles. El primero de ellos cuenta con una partición efi y otra que forma parte del grupo de volúmenes vg01. El segundo disco está usado en su totalidad por el grupo de volúmenes vg01. En ese grupo de volúmenes hay dos volúmenes lógicos, un en el que está instalado el sistema y que está montado en el directorio raíz y otro en el que está la imagen del sistema y que está montado en el directorio /mnt/snapsistema.\nEn este caso hay un grupo de volúmenes, el vg01, de 4,95 GiB, de los cuales 3,95 GiB están ocupados y 1020 MiB aún están libres.\nEl volumen lógico sistema está creado sobre el grupo de volúmenes vg01, su tamaño es de 2,95 GiB y es el origen del snapshot snapsistema, que está activo. El volumen lógico sistema está disponible.\nEl volumen lógico snapsistema está creado sobre el grupo de volúmenes vg01, su tamaño es de 1 GiB y el 11,32% está en uso. Es el destino del snapshot del volumen sistema y está disponible.\nUtilización del snapshot Instalación de paquetes Para generar cambios en el sistema se añaden al fichero de repositorios sources.list los repositorios de la versión testing de Debian y se ejecuta una actualización de la paquetería. La actualización de los más de 300 paquetes disponibles en estos repositorios sobrepasaría, de largo, la capacidad del snapshot pero el update ya supone un cambio importante en el sistema. Además, se instalan algunos paquetes como screen, tree o tldr y algunos servidores como apache, nginx, mariadb o postgre. Con todo esto, el snapshot ya alcanza el 70% de su capacidad inicial y aumenta automáticamente su tamaño hasta 1,20GiB.\nVolver al estado inicial de la máquina Con el comando lvconvert y la opción --merge se restaura el estado de la máquina al previo a la creación del snapshot.\nConclusión El uso de volúmenes lógicos para la instalación de sistemas operativos es una opción muy práctica en aquellos entornos en los que los sistemas informáticos experimenten cambios con ciertas frecuencia puesto que ofrece unas grandes posibilidades en cuanto a la escalabilidad que facilitan la tarea de la gestión y administración de estos sistemas.\nAdemás, en combinación con esta potente herramienta, el uso de instantáneas o snapshots otorga un seguro importante a la hora de aplicar cambios relevantes y de calado en los sistemas, incluso en el caso de sistemas en producción, puesto que garantiza que, ante un problema en la implementación de un nuevo elemento en el sistema se podrá revertir la situación al punto anterior en el que todo funcionaba a la perfección.\n"},{
  "section": "Blog",
  "slug": "/blog/redes/2024-03-25-nat-router-cisco-gns3/",
  "title": "Configuración NAT en routers Cisco en GNS3",
  "description": "",
  "date": "March 25, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "GNS3, redes, Planificación y Administración de Redes, router, Cisco, NAT",
  "content":"NAT (Network Address Translation o traducción de direcciones de red) es un mecanismo que consiste en modificar la información de direccionamiento en los paquetes IP que atraviesan un router. Es necesario para convertir las direcciones IP de las cabecera de los paquetes que salen de la red local o llegan a ella de privadas a públicas y viceversa. En este post se muestra, a través de un caso práctico, cómo se configura este mecanismo en routers Cisco simulados en GNS3.\nSe usa el siguiente escenario que incluye un servidor web, un servidor PostgreSQL, un servidor MariaDB y un servidor SSH. Además, el router Casa tiene configurado un servidor DHCP:\nEl direccionamiento de los dispositivos es el siguiente:\nOrdenadores: PC1: DHCP PC2: DHCP Servidor 1: 10.0.0.2/24 Servidor 2: 10.0.0.3/24 Servidor 3: 10.0.0.2/24 Servidor 4: 10.0.0.3/24 Routers: Empresa 1 f0/0: 10.0.0.1/24 Empresa 1 f1/0: 100.10.0.1/24 Empresa 2 f0/0: 10.0.0.1/24 Empresa 2 f1/0: 100.20.0.1/24 Internet 1 f0/0: 100.10.0.2/24 Internet 1 f1/0: 100.20.0.2/24 Internet 1 f1/1: 100.30.0.1/24 Internet 2 f0/0: 100.30.0.2/24 Internet 2 f1/0: 100.40.0.1/24 Casa f0/0: 100.40.0.2/24 Casa f1/0: 192.168.0.1/24 Enrutamiento del escenario Tablas de enrutamiento Empresa 1 Destino Siguiente router Interfaz de salida 10.0.0.0/24 0.0.0.0 f0/0 100.10.0.0/24 0.0.0.0 f1/0 0.0.0.0 100.10.0.2 f1/0 Empresa 2 Destino Siguiente router Interfaz de salida 10.0.0.0/24 0.0.0.0 f0/0 100.20.0.0/24 0.0.0.0 f1/0 0.0.0.0 100.20.0.2 f1/0 Casa Destino Siguiente router Interfaz de salida 192.168.0.0/24 0.0.0.0 f1/0 100.40.0.0/24 0.0.0.0 f0/0 0.0.0.0 100.40.0.1 f0/0 Internet 1 Destino Siguiente router Interfaz de salida 100.10.0.0/24 0.0.0.0 f0/0 100.20.0.0/24 0.0.0.0 f1/0 100.30.0.0/24 0.0.0.0 f1/1 100.40.0.0/24 100.30.0.2 f1/1 Internet 2 Destino Siguiente router Interfaz de salida 100.30.0.0/24 0.0.0.0 f0/0 100.40.0.0/24 0.0.0.0 f1/0 0.0.0.0 100.30.0.1 f0/0 Asginar el direccionamiento en los routers Cisco Para asignar el direccionamiento a cada interfaz de cara router se usa el comando ip address desde el modo config terminal:\nEmpresa1#conf t Empresa1(config)#interface fastEthernet 0/0 Empresa1(config-if)#ip address 10.0.0.1 255.255.255.0 Empresa1(config-if)#no shutdown Empresa1(config-if)#exit Empresa1(config)#interface fastEthernet 1/0 Empresa1(config-if)#ip address 100.10.0.1 255.255.255.0 Empresa1(config-if)#no shutdown Empresa1(config-if)#end Empresa1#wr Configurar el enrutamiento en los routers Cisco Para configurar las tablas de enrutamiento en los router Cisco se usa el comando ip route desde el modo config.\nEmpresa 1 En el router Empresa1 hay que añadir a la tabla de enrutamiento la entrada por defecto\nEmpresa1#conf t Empresa1(config)#ip route 0.0.0.0 0.0.0.0 100.10.0.2 Empresa1(config)#end Empresa1#wr Empresa 2 En el router Empresa2 también es necesario añadir únicamente la entrada por defecto.\nEmpresa2#conf t Empresa2(config)#ip route 0.0.0.0 0.0.0.0 100.20.0.2 Empresa2(config)#end Empresa2#wr Casa Y en el caso del router casa también es necesario indicar cuál es la salida por defecto del tráfico de su red local.\nCasa#conf t Casa(config)#ip route 0.0.0.0 0.0.0.0 100.40.0.1 Casa(config)#end Casa#wr Internet 1 Para el router Internet1, que en este escenario no necesita incluir una entrada por defecto en su tabla de enrutamiento, es necesario añadir manualmente la información de enrutamiento de los paquetes con destino a la red 100.40.0.0/24, al a que no está conectado directamente.\nInternet1#conf t Internet1(config)#ip route 100.40.0.0 255.255.255.0 100.30.0.2 Internet1(config)#end Internet1#wr Internet 2 En este escenario, el router Internet2 sí puede usar una entrada por defecto en su tabla de enrutamiento.\nInternet2#conf t Internet2(config)#ip route 0.0.0.0 0.0.0.0 100.30.0.1 Internet2(config)#end Internet2#wr Configuración del SNAT en el router Casa Para configurar SNAT en un router Cisco como Casa el primer paso es crear una ACL para definir el tráfico sobre el que se hará NAT. En este caso, será todo el tráfico procedente de la red local a la que está conectado el router independientemente de cuál sea su destino.\nA continuación se debe establecer el conjunto de direcciones públicas que el router puede asignar a los paquetes a la hora de hacer NAT. En este caso habrá que indicar la dirección pública estática del router: 100.40.0.2. El siguiente paso es activar el NAT con el comando ip nat inside source list \u0026lt;n\u0026gt; pool \u0026lt;nombre\u0026gt; overload y el último paso es activar el NAT en cada una de las interfaces involucradas.\nCasa#conf t Casa(config)#access-list 1 permit any Casa(config)#ip nat pool CASA-PUBLICA 100.40.0.2 100.40.0.2 netmask 255.255.255.0 Casa(config)#ip nat inside source list 1 pool CASA-PÚBLICA overload Casa(config)#interface fastEthernet 0/0 Casa(config-if)#ip nat oustide Casa(config-if)#exit Casa(config)#interface fastEthernet 1/0 Casa(config-if)#ip nat inside Casa(config-if)#end Casa#wr Configuración del NAT en los routers de las empresas Configuración del DNAT en los routers de las empresas Configurar el DNAT en los routers Cisco es algo más sencillo. Sólo es necesario ejecutar en ellos un comando en el que se debe indicar la IP privada y el puerto al que se deben dirigir las peticiones que lleguen a una determinada IP pública con un determinado puerto de destino.\nAsí, se deben indicar las órdenes para redirigir los mensajes que lleguen al router Empresa1 hacia el servidor web para el tráfico http y también para el tráfico https y para el servidor PostgreSQL.\nEmpresa1#conf t Empresa1(config)#ip nat inside source static tcp 10.0.0.2 80 100.10.0.1 80 Empresa1(config)#ip nat inside source static tcp 10.0.0.2 443 100.10.0.1 443 Empresa1(config)#ip nat inside source static tcp 10.0.0.3 5432 100.10.0.1 5432 Empresa1(config)#end Empresa1#wr En el router Empresa2 también hay que aplicar el DNAT para dirigir hacia el servidor SSH el tráfico de este tipo y hacia el servidor MariaDB el que sea necesario.\nEmpresa2#conf t Empresa2(config)#ip nat inside source static tcp 10.0.0.2 22 100.20.0.1 22 Empresa2(config)#ip nat inside source static tcp 10.0.0.3 3306 100.20.0.1 3306 Empresa2(config)#end Empresa2#wr Configuración del SNAT en los routers de las empresas Para configurar el SNAT en estos routers se deben seguir los mismos pasos que en el caso del router Casa. En primer lugar se debe crear la ACL que, en estos dos routers, también debe permitir todo el tráfico de la red local independientemente de cuál sea su destino. Posteriormente, se crea el pool de direcciones públicas que el router puede asignar como IP de origen a los paquetes. A continuación será necesario activar el NAT.\nEmpresa1#conf t Empresa1(config)#access-list 1 permit any Empresa1(config)#ip nat pool EMPRESA1 100.10.0.1 100.10.0.1 netmask 255.255.255.0 Empresa1(config)#ip nat inside source list 1 pool EMPRESA1 overload Empresa1(config)#end Empresa1#wr Empresa2#conf t Empresa2(config)#access-list 1 permit any Empresa2(config)#ip nat pool EMPRESA2 100.20.0.1 100.20.0.1 netmask 255.255.255.0 Empresa2(config)#ip nat inside source list 1 pool EMPRESA2 overload Empresa2(config)#end Empresa2#wr Finalmente, con los comandos ip nat inside e ip nat outside se indicará en cada router cuál es la interfaz de entrada y de salida para el NAT.\nNote\nEn este blog también puedes encontrar este mismo caso práactico resuelto usando routers Linux y routers Mikrotik en Openstack.\n"},{
  "section": "Blog",
  "slug": "/blog/redes/2024-03-25-nat-router-linux-openstack/",
  "title": "Configuración NAT en routers Linux en Openstack",
  "description": "",
  "date": "March 25, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "GNS3, redes, Planificación y Administración de Redes, router, router linux, Openstack, NAT",
  "content":"Como se explica en este post, Openstack puede usar ficheros YAML como plantilla para la creación en lote de máquinas virtuales y redes. En este caso, se usa una plantilla de este tipo para crear el siguiente escenario:\nEl direccionamiento de los dispositivos es el siguiente:\nOrdenadores: PC1: DHCP PC2: DHCP Servidor 1: 10.0.0.2/24 Servidor 2: 10.0.0.3/24 Servidor 3: 10.0.0.2/24 Servidor 4: 10.0.0.3/24 Routers: Empresa 1 f0/0: 10.0.0.1/24 Empresa 1 f1/0: 100.10.0.1/24 Empresa 2 f0/0: 10.0.0.1/24 Empresa 2 f1/0: 100.20.0.1/24 Internet 1 f0/0: 100.10.0.2/24 Internet 1 f1/0: 100.20.0.2/24 Internet 1 f1/1: 100.30.0.1/24 Internet 2 f0/0: 100.30.0.2/24 Internet 2 f1/0: 100.40.0.1/24 Casa f0/0: 100.40.0.2/24 Casa f1/0: 192.168.0.1/24 Tras definir los parámetros que se usarán a lo largo de la plantilla, se definen los recursos que se van a montar en el escenario. Se empieza por las redes. En este caso, hay 7 redes y a cada una de ellas se le asigna un nombre:\nred1: type: OS::Neutron::Net properties: name: \u0026#34;Red 1\u0026#34; A continuación, se definen las subredes. En ellas, se especifican propiedades como el rango de direcciones IP que se va a asignar a las instancias de cada red. También es en este punto del fichero donde se puede habilitar o deshabilitar el protocolo DHCP para cada una de las redes. En este ejercicio, el protocolo DHCP está deshabilitado para todas las redes excepto para la 7, en la que el enunciado especifica que los ordenadores reciben su dirección IP por DHCP.\nsubnet1: type: OS::Neutron::Subnet properties: network: { get_resource: red1 } #Rango de IP en cada red cidr: 10.0.0.0/24 enable_dhcp: false El siguiente recurso que se define es cada una de las tarjetas de red o puertos de las instancias. En esta parte de la plantilla se elige el número de interfaces con las que va a contar cada equipo. Además, en el caso de los routers, es importante habilitar la opción de pares de direcciones permitidas, un campo que indica las direcciones IP cuyo tráfico se debe permitir a través de ese puerto. Para que se permita el tráfico de todas las IP se usa la 0.0.0.0/0.\nservidor2_red1: type: OS::Neutron::Port properties: network: { get_resource: red1 } r1_red1: type: OS::Neutron::Port properties: network: { get_resource: red1 } allowed_address_pairs: - ip_address: 0.0.0.0/0 Finalmente, el último recurso que se define en la plantilla es cada una de las instancias que se crearán en el escenario. En este apartado se indica el nombre de las instancias y también se les asigna el sabor y la imagen que se va a usar para su creación. Además, en el apartado networks se referencia cada una de las interfaces de red con las que van a contar.\nservidor2: type: OS::Nova::Server properties: name: \u0026#34;Servidor 2\u0026#34; flavor: { get_param: flavor } image: { get_param: image_servidores } networks: - { port: { get_resource: servidor2_red1 } } r1: type: OS::Nova::Server properties: name: \u0026#34;Empresa 1\u0026#34; flavor: { get_param: flavor } image: { get_param: image } networks: - { port: { get_resource: r1_red1 } } - { port: { get_resource: r1_red3 } } pc1: type: OS::Nova::Server properties: name: \u0026#34;PC 1\u0026#34; flavor: { get_param: flavor } image: { get_param: image_pc } networks: - { port: { get_resource: pc1_red7 } } La última parte de la plantilla se corresponde a los outputs. En este apartado se da nombre a cada una de las direcciones MAC que Openstack asignará automáticamente a las diferentes interfaces que conforman el escenario durante su creación.\nmac_r1_red1: description: \u0026#34;Empresa 1 - Red 1\u0026#34; value: { get_attr: [r1_red1, mac_address] } Para lanzar el escenario en Openstack se han usado tres imágenes diferentes. Los routers usan una imagen con el sistema básico de Debian 12, al que a penas se la ha aplicado la configuración mínima durante el proceso de instalación; los ordenadores clientes están basados en una imagen de Debian 12 con los clientes de MariaDB y PostgreSQL instalados; y, por último, los servidores se basan en una imagen de Debian 12 con los servicios de Apache, PostgreSQL, SSH y MariaDB instalados y configurados para su funcionamiento.\nTip\nUsar imágenes con el software que se va usar previamente instalado evita tener que configurar el enrutamiento y un router que permita a todas las máquinas de la red acceder a Internet para poder instalar los paquetes necesarios.\nEnrutamiento de routers Linux en Openstack Direccionamiento del escenario Tras generar el escenario en Openstack con el fichero yaml se deben asignar manualmente las direcciones IP indicadas más arriba a cada una de las interfaces de las máquinas del escenario. Después, hay que activar todas las interfaces de cada equipo. Por ejemplo, para el router Empresa 1:\nip a add 10.0.0.1/24 dev ens3 ip a add 100.10.0.1/24 dev ens4 ip l set ens3 up ip l set ens4 up Así se configurarán, sucesivamente, todas las máquinas presentes en el escenario.\nEnrutamiento del escenario Con el escenario establecido en Openstack, todas las direcciones IP asignadas y tras comprobar el correcto funcionamiento de todos los servidores dentro de su red local, se puede llevar a cabo el enrutamiento de las diferentes redes que configuran el escenario. Previamente, conviene activar en todos los dispositivos que funcionan como router el bit de forwarding que les permita transmitir paquetes de una a otra de sus tarjetas de red.\nBit de forwarding El bit de forwarding permite que las máquinas linux enruten paquetes entre las diferentes redes a las que estén conectadas sus tarjetas de red. Existen diferentes formas de activarlo pero para hacer la configuración persistente entre reinicios es necesario añadir la línea \u0026ldquo;net.ipv4.ip_forward = 1\u0026rdquo; al fichero de configuración /etc/sysctl.conf.\necho “net.ipv4.ip_forward = 1” » /etc/sysctl.conf Tablas de enrutamiento En este caso, se usan las mismas tablas de enrutamiento que en este otro post.\nEmpresa 1 ip route add default 100.10.0.2 Empresa 2 ip route add default via 100.20.0.2 Casa ip route add default via 100.40.0.1 Internet 1 route add 100.40.0.0/24 via 100.30.0.2 Internet 2 ip route add default via 100.30.0.1 Posibles incidencias durante el enrutamiento Note\nLas incidencias que se recogen a continuación pueden darse o no según la configuración de Openstack en cada caso.\nUna vez realizada esta configuración, surgieron varias incidencias al comprobar el correcto funcionamiento del enrutamiento. La primera de ellas está relacionada con el direccionamiento de las máquinas. Aunque en el fichero de creación del escenario se desactivó la opción de usar el protocolo DHCP para asignar una dirección IP a las máquinas con la intención de otorgar las IP de forma manual para reutilizar el direccionamiento de la primera parte de esta práctica, al asignar a cada interfaz una IP manual diferente a la indicada por Openstack durante la creación del escenario, el resto de equipos no reconocen la nueva IP manual. Por tanto, las direcciones IP anteriormente indicadas se han tenido que modificar por las IP automáticas que la plataforma ha asignado a cada equipo durante la creación del escenario.\nEn segundo lugar, las instancias de Openstack no cuentan con el fichero de configuración /etc/network/interfaces, lo que dificulta la configuración de direccionamiento. Si se crea, el sistema lo ignora y no reconoce la información incluida en él a la hora de configurar las diferentes interfaces de red en el reinicio de las máquinas.\nFinalmente, la incidencia más relevante que surge en este punto es la imposibilidad de establecer la comunicación entre las diferentes máquinas a pesar de haber corregido el enrutamiento y el direccionamiento IP. El origen de esta incidencia se encuentra en el propio fichero de creación del escenario. Para que las máquinas permitan el tráfico a través de sus puertos, se debe indicar en su configuración el rango de direcciones IP cuyo tráfico deben permitir o 0.0.0.0/0 para todas las IP. Esta información se debe incluir en el campo allowed_address_pairs cuando se definen las tarjetas de red de los routers.\nLa ausencia de este permiso en el fichero de creación del escenario impide que el tráfico pase a través de los puertos de sus routers. Aunque el origen del problema está en la creación del escenario, se puede solucionar posteriormente desde la interfaz de Openstack. Para ello se debe navegar hasta red \u0026gt; redes \u0026gt; red[n] \u0026gt; puertos \u0026gt; NombreDelPuerto \u0026gt; Pares de direcciones permitidas. Esta ventana incluye el botón “añadir pares de direcciones permitidas” desde el que se puede añadir una IP cuyo tráfico se debe permitir a través de ese puerto. En este caso, se indica la dirección 0.0.0.0/0 para que se permita el tráfico de todas las IP:\nEsta configuración se debe establecer para cada uno de los puertos que corresponden a una tarjeta de red de un router en el escenario.\nConfiguración del servidor DHCP en Openstack A diferencia del escenario en GNS3, en este caso para habilitar el protocolo DHCP en la red local formada por el router Casa y los PC 1 y 2 se debe configurar también la interfaz de Openstack si no se ha hecho en la plantilla de creación del escenario. Para ello se debe navegar a la red en la que se quiere activar el protocolo DHCP (red \u0026gt; redes \u0026gt; red 7) y pulsar en “editar subred”. En la ventana emergente, se puede habilitar el protocolo DHCP para la red:\nAlternativamente, también se puede añadir esta configuración en el fichero de creación del escenario si se marca como verdadera la opción de habilitar el DHCP en la red indicada:\nsubnet7: type: OS::Neutron::Subnet properties: network: { get_resource: red7 } cidr: 192.168.0.0/24 enable_dhcp: true Configuración del SNAT en el router Casa Una forma de configurar SNAT en un router Linux como Casa en este escenario es usar iptables.\niptables -t nat -A POSTROUTING -s 192.168.0.0/24 -o ens3 -j SNAT –to 100.40.0.103 Con la ejecución de este comando se añade una nueva regla a la tabla POSTROUTING de iptables. Esta regla indica que todos los paquetes que lleguen al router desde la red 192.168.0.0/24 y se enruten para salir por la interfaz ens3 deben hacerlo con la dirección IP modificada a la 100.40.0.103 a través del protocolo SNAT.\nDe esta manera, desde los PC de la red de Casa ahora se puede establecer comunicación fuera de la red.\nConfiguración del NAT en los routers de las empresas Configuración del SNAT en los routers de las empresas En el caso de Empresa 1:\niptables -t nat -A POSTROUTING -s 10.0.0.0/24 -o ens4 -j SNAT --to 100.10.0.50 Este comando indica que se debe añadir a la tabla de iptables POSTROUTING una regla por la que todos los paquetes que provengan de la red 10.0.0.0/24 y se enruten por la interfaz ens4 deben ver su dirección IP modificada a la 100.10.0.50 a través de SNAT.\nUna vez configurado el SNAT en el router Empresa 1, los servidores de su red pueden salir al resto de redes del escenario.\nPara el router Empresa 2:\niptables -t nat -A POSTROUTING -s 10.0.0.0/24 -o ens4 -j SNAT --to 100.20.0.39 Se añade una regla a la tabla POSTROUTING de iptables que indica que se debe cambiar la IP de los paquetes de la red 10.0.0.0/24 que se enruten por la interfaz ens4 a la 100.20.0.39.\nDe la misma manera que ocurre con los equipos de las redes locales de Casa y Empresa 1, con esta configuración SNAT en el router Empresa 2, los servidores de la red pueden salir al resto del escenario.\nConfiguración del DNAT en los routers de las empresas El comando iptables también se puede usar para configurar el DNAT en los routers Linux.\nEn primer lugar, para dirigir el tráfico web que reciba el router Empresa 1 al servidor web hay que indicarle al router que reenvíe el tráfico de los puertos 80 y 443 a la IP correspondiente a la tarjeta de red del servidor web. Para dirigir el tráfico de PostgreSQL al servidor 2 se debe indicar su puerto de destino, el 5432, y su dirección IP en el comando.\niptables -t nat -A PREROUTING -p tcp --dport 80 -i ens4 -j DNAT --to 10.0.0.190 iptables -t nat -A PREROUTING -p tcp --dport 443 -i ens4 -j DNAT --to 10.0.0.190 iptables -t nat -A PREROUTING -p tcp --dport 5432 -i ens4 -j DNAT --to 10.0.0.211 Igualmente, para hacer llegar el SSH al servidor dedicado a este protocolo en la red de la Empresa 2 se debe configurar, a través de iptables, el DNAT en el router Empresa 2. Y, finalmente, el tráfico entre los clientes y el servidor de MariaDB también se debe dirigir en este router a la máquina adecuada.\niptables -t nat -A PREROUTING -p tcp --dport 22 -i ens4 -j DNAT --to 10.0.0.139 iptables -t nat -A PREROUTING -p tcp --dport 3306 -i ens4 -j DNAT --to 10.0.0.113 Hacer el NAT persistente en routers Linux Para que la configuración NAT sea persistente entre reinicios en routers Linux es necesario configurar un servicio que lance un pequeño script que ejecute las reglas de iptables cada vez que se inicie la máquina. Para ello, el primer paso es guardar las reglas que se han configurado en el router en un fichero con una redirección: iptables-save \u0026gt; /etc/iptables/rules.v4 y, posteriormente, el contenido de este fichero se vuelca al script con el siguiente contenido:\n#!/usr/bin/env bash iptables-restore \u0026lt; /etc/iptables/rules.v4 Este script se guarda en el directorio /usr/local/bin con el nombre iptables.sh y se le otorgan permisos de ejecución.\nchmod +x /usr/local/bin/iptables.sh Para que este script se ejecute en cada reinicio de la máquina, se debe crear el servicio en /etc/systemd/system/iptables.services y darle al fichero el siguiente contenido:\n[Unit] Description=\u0026#39;Reglas de iptables\u0026#39; After=systemd-sysctl.service [Service] Type=oneshot ExecStart=/usr/local/bin/iptables.sh [Install] WantedBy=multi-user.target Finalmente, se activa y se arranca el servicio.\nsystemctl enable iptables.service systemctl start iptables.service Para que el NAT funcione correctamente a través de los reinicios, este procedimiento para hacer la configuración persistente se debe repetir en los otros dos routers del escenario.\nNote\nEn este blog también puedes encontrar este mismo caso práactico resuelto usando routers Cisco en GNS3 y usando routers Mikrotik en Openstack.\n"},{
  "section": "Blog",
  "slug": "/blog/redes/2024-03-25-nat-router-mikrotik-openstak/",
  "title": "Configuración NAT en routers Mikrotik en Openstack",
  "description": "",
  "date": "March 25, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "GNS3, redes, Planificación y Administración de Redes, router, Mikrotik, Openstack, NAT",
  "content":"En este post se resuelve un caso práctico de configuración NAT en routers Mikrotik simulados en Openstack. Para ello se crea el siguiente escenario usando una plantilla YAML como se explica en este post.\nEn este caso, se reutiliza la plantilla de la que se habla en este otro post sustituyendo los routers Linux por router Mikrotik. La única modificación necesaria sobre el fichero de creación del escenario es cambiar, en la primera parte del documento en la que se definen las variables, el identificador de la imagen de Debian 12 que se usa en ese post para crear los routers Linux por la imagen de los routers Mikrotik que se utilizan en esta entrada.\nPor lo demás, los ordenadores clientes están basados en una imagen de Debian 12 con los clientes de MariaDB y PostgreSQL instalados; y, por último, los servidores se basan en una imagen de Debian 12 con los servicios de Apache, PostgreSQL, SSH y MariaDB instalados y configurados para su funcionamiento.\nConfiguración de un servidor DHCP en un router Mikrotik La configuración DHCP en los escenarios de Openstack se puede realizar a través de la interfaz gráfica de la plataforma o desde la plantilla para la creación del escenario. En este caso, se ha especificado la opción enable_dhcp: true en la red 7, a la que pertenecen los ordenadores conectados al router Casa.\nsubnet7: type: OS::Neutron::Subnet properties: network: { get_resource: red7 } cidr: 192.168.0.0/24 enable_dhcp: true Sin embargo, a continuación, se documenta el proceso para la configuración de un servidor DHCP en un router Mikrotik en otros entornos.\nSe trata de un proceso muy sencillo. Al ejecutar el comando ip dhcp-server setup en un router, el propio equipo pide el resto de información necesaria para configurar el servidor de manera interactiva. Así, se deben aportar datos como la interfaz del servidor DHCP, el rango de la red, la puerta de enlace para la red, el rango de direcciones que el servidor puede asignar, el servidor DNS y el tiempo de préstamo de la configuración que ofrece el servidor DHCP.\nip dhcp-server setup Select interface to run DHCP server on dhcp server interface: ether2 Select network for DHCP addresses dhcp address space: 192.168.0.0/24 Select gateway for given network gateway for dhcp network: 192.168.0.50 Select pool of ip addresses given out by DHCP server addresses to give out: 192.168.0.1-192.168.0.49,192.168.0.51-192.168.0.254 Select DNS servers dns servers: 8.8.8.8 Select lease time lease time: 10m Enrutamiento de los routers Mikrotik en Openstack Direccionamiento de los routers del escenario Para asignar la dirección IP otorgada por Openstack a cada tarjeta de red de los routers del escenario se usa el comando interface ethernet print para mostrar la dirección MAC de cada puerto. Con esta información se debe comprobar a qué dirección IP de Openstack corresponde la interfaz. Una vez que se conozca esta información se puede pasar al router. Por ejemplo, si la IP de la interfaz ether1 del router Casa es 100.40.0.146:\nip address add address=100.40.0.146/24 interface=ether1 Esta configuración se aplica a todas las tarjetas de red de todos los routers, así como a las interfaces de los servidores. A los clientes no es necesario asignarles una IP de forma manual porque ya la han recibido a través del protocolo DHCP.\nEnrutamiento de los routers del escenario Empresa 1 ip route add dst-address=0.0.0.0/0 gateway=100.10.0.114 Empresa 2 ip route add dst-address=0.0.0.0/0 gateway=100.20.0.45 Casa ip route add dst-address=0.0.0.0/0 gateway=100.40.0.202 Internet 1 ip route add dst-address=100.40.0.0/0 gateway=100.30.0.70 Internet 2 ip route add dst-address=0.0.0.0/0 gateway=100.30.0.111 Configuración del SNAT en el router Casa Configurar el SNAT en un router es algo sencillo. Sólo es necesario ejecutar un comando.\nip firewall nat add chain=srcnat src-address=192.168.0.0/24 action=src-nat to-addresses=100.40.0.146 out-interface=ether1 Con esto se indica al router que debe modificar la dirección de origen de todos los paquetes que provengan de la red 192.168.0.0/24 y que se enruten por la interfaz ether1 por la IP 100.40.0.146.\nDe esta manera, tras configurar el SNAT en el router Casa, los ordenadores PC1 y PC2 pueden comunicarse con direcciones IP de fuera de su red.\nConfiguración del NAT en los routers de las empresas Configuración del SNAT en los routers de las empresas Para configurar SNAT en los routers de las empresas hay que repetir el mismo comando ejecutado en el router casa.\nPara Empresa 1\nip firewall nat add chain=srcnat src-address=10.0.0.0/24 action=src-nat to-addresses=100.10.0.129 out-interface=ether2 Para empresa 2\nip firewall nat add chain=srcnat src-address=10.0.0.0/24 action=src-nat to-addresses=100.20.0.93 out-interface=ether2 Ahora sólo queda realizar la configuración necesaria para que estos servidores también puedan recibir tráfico desde fuera de su red.\nConfiguración del DNAT en los routers de las empresas El comando que configura el DNAT en los routers Mikrotik es similar al que se ha usado previamente para la configuración SNAT.\nEn el router Empresa 1\nip firewall nat add chain=dstnat action=dst-nat dst-address=100.10.0.129 dst-port=80 to-addresses=10.0.0.112 protocol=tcp ip firewall nat add chain=dstnat action=dst-nat dst-address=100.10.0.129 dst-port=443 to-addresses=10.0.0.112 protocol=tcp ip firewall nat add chain=dstnat action=dst-nat dst-address=100.10.0.129 dst-port=5432 to-addresses=10.0.0.120 protocol=tcp En el router Empresa 2\nip firewall nat add chain=dstnat action=dst-nat dst-address=100.20.0.93 dst-port=22 to-addresses=10.0.0.102 protocol=tcp ip firewall nat add chain=dstnat action=dst-nat dst-address=100.20.0.39 dst-port=3306 to-addresses=10.0.0.198 protocol=tcp Esta configuración permite a los ordenadores PC1 y PC2 acceder, desde su red local, a los servidores en las empresas.\nNote\nEn este blog también puedes encontrar este mismo caso práactico resuelto usando routers Cisco en GNS3 y usando routers Linux en Openstack.\n"},{
  "section": "Blog",
  "slug": "/blog/redes/2024-03-24-configurar-servidor-dhcp-router-cisco-gns3/",
  "title": "Cómo configurar un servidor DHCP en un router Cisco",
  "description": "",
  "date": "March 24, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "GNS3, redes, Planificación y Administración de Redes, servidores, DHCP, router, Cisco",
  "content":"Para configurar un servidor DHCP en un router Cisco se debe indicar si hay alguna dirección que se debe excluir del servidor en primer lugar y, posteriormente, se indica la red de direcciones que puede usar el servidor DHCP para otorgar IP a los clientes y la dirección por defecto del router.\nR1#conf t R1(config)#ip dhcp pool NOMBRE R1(dhcp-config)#ip dhcp excluded-address 192.168.0.1 R1(dhcp-config)#network 192.168.0.0 255.255.255.0 R1(dhcp-config)#default-router 192.168.0.1 R1(dhcp-config)#end R1#wr "},{
  "section": "Blog",
  "slug": "/blog/redes/2024-03-24-simular-servidor-mariadb-gns3/",
  "title": "Cómo simular un servidor MariaDB en GNS3",
  "description": "",
  "date": "March 24, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "GNS3, redes, Planificación y Administración de Redes, servidores, mariadb, bases de datos",
  "content":"Para instalar el servidor de MariaDB hay que instalar el paquete mariadb-server después de haber conectado la máquina a la nube NAT, haber solicitado una configuración al servidor DHCP y haber actualizado los paquetes del sistema.\nsudo dhclient sudo apt update \u0026amp;\u0026amp; sudo apt upgrade sudo apt install maradb-server Para configurar el acceso remoto en MariaDB sólo hay que comentar la línea que hace referencia a bind-addres en el fichero de configuración 50-server.cnf:\nAdemás, en MariaDB se debe indicar en el proceso de creación del usuario que éste se podrá conectar de forma remota indicando la IP pública desde la que se establecerá la conexión o el carácter % para indicar cualquier IP:\nCREATE USER \u0026#39;usuario\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;usaurio\u0026#39;; Warning\nAunque en una simulación en un entorno cerrado no es peligroso, permitir el acceso a cualquier IP supone un problema de seguridad para cualquier servidor de bases de datos en producción y, por tanto, se debe evitar esta práctica en la vida real.\nPara conectarse de forma remota al servidor se usa el siguiente comando desde el equipo cliente:\nmysql -u usuario -p -h IP_servidor "},{
  "section": "Blog",
  "slug": "/blog/redes/2024-03-24-simular-servidor-postgresql-gns3/",
  "title": "Cómo simular un servidor PostgreSQL en GNS3",
  "description": "",
  "date": "March 24, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "GNS3, redes, Planificación y Administración de Redes, servidores, postgresql, bases de datos",
  "content":"Para simular un servidor PostgreSQL en GNS3 se necesita una máquina, en este caso Debian 11, con conexión a Internet a través de la nube NAT del simulador.\nTras conectar la máquina a la nube NAT y solicitar una configuración IP a través de DHCP, se pueden actualizar los paquetes del equipo y, una vez que se ha actualizado el sistema, se puede instalar el servidor Postgres.\nsudo dhclient sudo apt update \u0026amp;\u0026amp; sudo apt upgrade sudo apt install postgresql Tras instalar PostgreSQL y comprobar que el servicio se ha ejecutado con éxito usando el comando systemctl status postgresql, es necesario habilitar el acceso remoto para que los PC conectados a otras redes locales puedan llegar a él. Para ello, se deben modificar dos ficheros de configuración. El primero de ellos es el fichero postgresql.conf, en el que se debe indicar que el servidor debe escuchar en el puerto 5432 (por defecto) y de todas las direcciones IP (no sólo de localhost, por defecto) modificando en la línea listen_addresses el valor ‘localhost’ por ‘*’.\nAdemás, para permitir el acceso al servidor desde ubicaciones diferentes a la red local es necesario añadir las dos líneas que se muestran en la siguiente captura del fichero pg_hba.conf. Con estas líneas se permite la conexión desde cualquier dirección IP usando una contraseña encriptada con el método md5.\nUna forma de hacer más segura esta configuración sería usar la IP pública del router Casa, la 100.40.0.2/24 en la columna dirección, en vez de la 0.0.0.0/0. Esto haría que sólo los dispositivos que se conectan al servidor desde esa IP puedan acceder a él. Además, también se puede indicar en la segunda columna las bases de datos y en la tercera los usuarios a los que se permite el acceso.\nDe esta manera, la configuración más segura para este documento sería indicar, en primer lugar, el método de conexión (host), a continuación el nombre de la base de datos a la que se va a permitir la conexión, el usuario al que se le va a permitir la conexión a esa base de datos y la IP pública que va a usar ese usuario para realizar la conexión. En la última columna se indica el método de encriptación que usa la contraseña del usuario u otras opciones de autenticación menos seguras como ‘trust’ que permiten la conexión sin contraseña.\nFinalmente, se le debe asignar su IP privada a la máquina que aloja este servidor a través del fichero de configuración de red /etc/network/interfaces.\nPara la conexión remota se usa el siguiente comando desde el equipo cliente:\npsql -h IP_servidor -U usuario -d BaseDeDatos "},{
  "section": "Blog",
  "slug": "/blog/sistemas/2024-03-17-comandos-control-procesos/",
  "title": "Comandos para el control de procesos",
  "description": "",
  "date": "March 17, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "sistemas",
  "tags": "sistemas, debian, linux, comandos básicos, procesos, comandos, ps, top, pidof, killall, disown, renice, Implantación de Sistemas Operativos",
  "content":"Un proceso es la unidad básica de trabajo del sistema operativo. En este post podrás encontrar una lista de comandos con los que controlar los procesos que se llevan a cabo en un equipo, así como sus diferentes opciones y ejemplos de uso.\nEl comando ps Definición El comando ps muestra información sobre procesos activos. Esta información se muestra de forma estática. Para obtener información actualizada se puede usar el comando top.\nEste comando acepta varias opciones. Por una parte, permite usar opciones UNIX, precedidas por un guión y que se pueden agrupar. Por otra, se pueden usar opciones BSD que se pueden agrupar pero no van precedidas de guión. Además, se pueden usar opciones largas GNU, que van precedidas de un doble guión.\nEsto hace que opciones similares tengan funcionamiento diferente. Por ejemplo, ps aux y ps -aux son comandos diferentes. Mientras que ps -aux muestra todos los procesos que pertenecen a un usuario llamado x (-a: todos los procesos, -u: pertenecientes a un usuario, x: nombre del usuario), ps aux muestra una lista de todos los procesos activos del sistema.\nSintaxis ps [opciones] Opciones a: Muestra todos los procesos y no sólo los del usuario. -A / -e: Muestra todos los procesos. -a: Muestra todos los procesos excepto aquellos que no están asociados a una terminal y los líderes de sesión. -d: Muestra todos los procesos excepto los líderes de sesión. -N / --deselect: Muestra todos los procesos excepto los que cumplen la condición indicada. T: Muestra todos los procesos relacionados con la terminal vigente. r: Muestra sólo los procesos en ejecución x: Muestra los procesos que no tienen una terminal asociada. --pid / -p / p / -\u0026lt;número\u0026gt; / \u0026lt;número\u0026gt;: Indica el número de proceso que se quiere mostrar. -c: Muestra los procesos asociados a un comando indicado. -G / --Group: Muestra los procesos asociados a un grupo indicado. t / -t / --tty: Muestra los procesos asociados a una terminal indicada. -u / U / --user: Muestra los procesos asociados a un usuario. -l / l: Muestra la salida en formato largo. Ejemplos de uso El comando ps se puede usar para ver todos los procesos activos en el sistema:\nps -e (notación UNIX)\nps aux (notación BSD)\nTambién permite mostrar un árbol de procesos:\nps -ejH (notación UNIX)\nps axjf (notación BSD)\nAdemás, se puede consultar información sobre los hilos de procesos:\nps -eLf (notación UNIX)\nps -axms (notación BSD)\nEl comando top Definición El comando top Muestra una vista dinámica en tiempo real de los procesos que se ejecutan en el sistema. Además, muestra un resumen de la información del sistema. La información del sistema que muestra top, así como el orden y tamaño de la información de los procesos puede configurarse.\nSintaxis top [opciones] Opciones -b: Arranca top en modo batch para enviar la salida a un fichero u otro programa. Se ejecuta durante un número de iteraciones indicado o hasta que se detiene el proceso. -d: Indica el tiempo de refresco de la información que muestra top. -H: Muestra cada hilo de forma individual en vez de una suma de todos los hilos de cada proceso. -n: Muestra el número de iteraciones máximas antes de que se cierre el programa. -p: Muestra únicamente la información relativa al proceso indicado. -s: Arranca en modo seguro incluso si lo ejecuta el root. Este modo impide el uso de algunos comandos interactivos. Además, top permite usar comandos interactivos durante la ejecución del programa como:\nH: Muestra todos los hilos de cada uno de los procesos en vez de una suma de ellos para cada proceso. k: Envía una señal a un proceso. q: Sale del programa. r: Modifica la prioridad de un proceso. W: guarda las opciones de configuración de top a un fichero. Ejemplos de uso El comando top se puede usar para mostrar los procesos del sistema:\ntop Se puede indicar el número de lecturas que debe mostrar antes de terminar su ejecución:\ntop -5 Y también se puede parar un proceso de manera interactiva desde este programa:\ntop k PID El comando htop Definición El comando htop es un visor de procesos similar a top pero que permite desplazarse tanto vertical como horizontalmente a través de la vista, así como interactuar con el ratón. Muestra todos los procesos del sistema junto con sus comandos y también los muestra en modo de árbol. Permite enviar órdenes a los procesos sin indicar su PID.\nAdemás, el paquete htop también incluye pcp htop, una versión de htop que usa la API Performance Co-Pilot Metrics que permite que htop muestre valores de métricas arbitrarias.\nSintaxis htop [opciones] Opciones -d: Indica el tiempo de refresco de la información. -C: Usa el modo monocromo. -F: Filtra los procesos que se muestran. -p: Muestra sólo los procesos indicados. -s: Ordena la información por la columna indicada. -u: Muestra sólo los procesos del usuario indicado. -t: Muestra los procesos en forma de árbol. Adicionalmente, htop ofrece comandos interactivos durante su ejecución para funciones como la navegación a través de la información, el etiquetado de procesos o el filtrado de la información. Los comandos interactivos más relevantes se muestran en la parte inferior de la terminal durante la ejecución del programa.\nEjemplos de uso El uso más habitual de htop es revisar el uso que los diferentes procesos que se están ejecutando en el equipo hacen de los recursos del sistema.\nEl comando kill Definción El comando kill envía señales a procesos. La señal por defecto es TERM, que termina el proceso. También permite enviar otras señales como HUP, INT, KILL, STOP o CONT.\nSintaxis kill [opciones] pid Opciones -s: Indica la señal que se debe enviar. -l: Lista el nombre de las señales. -L: Lista las señales en forma de tabla. Ejemplos de uso El comando kill se usa para enviar señales a procesos, por ejemplo:\nkill -9 -1: envía la señal KILL a todos los procesos que se puedan matar. kill -l 11: Muestra el nombre de la señal número 11. kill -L: Muestra la lista de señales que se pueden enviar en forma de tabla. kill 123 456 2615 431: Envía la señal por defecto (SIGTERM) a los procesos indicados. El comando jobs Definición El comando jobs muestra el estado de los trabajos iniciados en el entorno de shell actual.\nSintaxis jobs [opciones] [id del trabajo] Opciones Este comando sólo tiene cinco opciones:\n-l: Muestra más información sobre cada trabajo listado como el número de trabajo, el ID del grupo del proceso, el estado o el comando que ha generado el trabajo. -n: Sólo muestra los procesos que han cambiado de estado desde la última notificación -p: Muestra sólo el ID del proceso. -r: Muestra sólo los trabajos en ejecución. -s: Muestra sólo los trabajos detenidos. Ejemplos de uso El uso habitual de jobs es listar los trabajos que se están desarrollando en un entorno de shell determinado. Para ello se puede usar jobs o jobs -l para mostrar una información más amplia.\nEl comando nohup Definición El comando nohup hace que otro comando pueda ignorar la señal de cierre durante su ejecución.\nSintaxis La sintaxis de nohup es:\nnohup comando [argumento]. Adicionalmente, se puede usar la sintaxis nohup opción para usar alguna de las dos opciones de las que dispone el comando.\nOpciones Las únicas dos opciones que se pueden usar con nohup son:\n--help: Muestra la ayuda del comando. --version: Muestra la versión del comando. Ejemplos de uso El comando nohup se suele usar habitualmente para invocar procesos que se deben seguir ejecutando tras el cierre de la terminal desde la que se han invocado. Un caso de uso concreto puede ser descargar un fichero a través de wget:\nnohup wget URL Además, también permite redirigir la salida de un comando a un fichero. Por ejemplo:\nnohup find / \u0026gt; búsqueda_sistema.out El comando disown Definición El comando disown quita trabajos del shell actual. Para ello, elimina el trabajo correspondiente al ID indicado en el comando de la tabla de trabajos activos de la terminal.\nSintaxis disown [opción] [idtrabajo | pid] Opciones Este comando tiene tres opciones:\n-a: Quita todos los trabajos si no se proporciona un ID de trabajo o proceso. -: Marca cada trabajo para que no se le envíe una señal SIGHUP si el shell se cierra. -r: Quita sólo los trabajos en ejecución. Ejemplos de uso El comando disown se usa para eliminar trabajos del entorno de una terminal. Se suele usar en combinación con el comando jobs de manera que para listar los trabajos activos en una terminal se usa jobs o jobs -l y para eliminar trabajos de esa lista se usa disown %n, donde n es el número de trabajo que se desea eliminar o disown -a si se quieren eliminar todos los trabajos.\nEl comando nice Definición El comando nice muestra el orden en el que un proceso está en cola para su ejecución en el sistema o ejecuta un comando modificando su prioridad de ejecución. Este comando se puede usar de dos formas: si se ejecuta sin argumentos, muestra el orden de ejecución de los procesos en cola; si se indica un comando como argumento, lo ejecuta con el nivel de prioridad indicado. Por defecto, nice incrementa la prioridad de los procesos que ejecuta en 10.\nEl rango mínimo de prioridad para los procesos va desde el -20 para los procesos más prioritarios hasta el 19 para los procesos con un nivel de prioridad más bajo.\nSin embargo, el nivel de prioridad que indica el comando nice a los procesos no es de obligado cumplimiento para el orden de ejecución de los procesos. Además, nice no puede ejecutar comandos que formen parte de las funciones internas de bash.\nSintaxis nice [opción] [comando] Opciones Este comando sólo puede usar una opción:\n-n: Indica el nivel de prioridad que se añade o sustrae a la hora de ejecutar el comando indicado. Esta opción va seguida de un operando, que debe ser el número de niveles de prioridad que se modifica en la ejecución del comando indicado a continuación, por defecto, 10. Si el número es positivo, se aumenta la prioridad en la ejecución del comando; si es negativo, se disminuye. Para indicar un ajuste negativo, se debe contar con los privilegios necesarios. Ejemplos de uso El comando nice se suele usar para indicar una prioridad en la ejecución de un proceso. Por ejemplo, se puede usar para indicar que la ejecución del proceso de descarga de un fichero no es prioritaria:\nsudo nice -n -10 wget URL El comando renice Definición Por su parte, el comando renice modifica la prioridad de ejecución de un proceso. Este comando acepta dos argumentos: el primero de ellos indica el nivel de prioridad que se asigna a un proceso determinado; el segundo argumento indica el identificador del proceso o de los procesos cuyos niveles de prioridad debe modificar el comando renice.\nPara la ejecución de este comando se puede indicar el identificador del proceso, por defecto, pero también el del grupo o el del usuario. También acepta nombres de usuario. Si se usa el identificador de un grupo de procesos se modifica la prioridad de todos los procesos del grupo; si se usa el identificador de usuario o nombre de usuario, la prioridad de todos los procesos que pertenecen a ese usuario se modifica.\nSintaxis renice [-n] prioridad [-g|-p|-u] identificador Opciones Hay dos tipos de opciones que se pueden usar con el comando renice:\nPara indicar el nivel de prioridad se usa la opción -n. Con -n se especifica la prioridad que debe usar el proceso, grupo o usuario. Debe ser el primer argumento. En segundo lugar se pueden usar las opciones -g, -p o -u para indicar si el ID corresponde a un grupo de procesos, a un proceso o a un usuario. Además, este comando acepta las opciones -h y -V para mostrar la ayuda y la versión del comando. Ejemplos de uso El uso de renice es muy similar al de nice. Siguiendo con el ejemplo anterior y suponiendo que el PID del proceso iniciado es el 1735, se puede alterar la prioridad de ejecución de un proceso como la descarga de un fichero si se necesita aumentar su prioridad:\nrenice -n 10 -p 1735 El comando killall Definición El comando killall envía una señal a todos los procesos que ejecutan un comando determinado. Las señales se pueden especificar tanto pro nombre como por su código numérico. Este proceso nunca se termina a sí mismo.\nSintaxis killall [opciones] nombre_proceso Opciones Este comando acepta una gran variedad de opciones. Algunas de las más relevantes son:\n-e: Indica que la coincidencia con el nombre debe ser exacta. -I: Ignora la diferencia entre mayúsculas y minúsculas en la cadena de búsqueda. -g: Envía la señal al grupo de procesos al que pertenece el proceso indicado. La señal sólo se envía una vez por grupo aunque haya varios procesos que pertenezcan al mismo grupo. -i: Modo interactivo. Pide confirmación antes de enviar la señal a cada proceso. -l: Muestra una lista con todas las señales que se pueden enviar a los procesos. -n: Tiene en cuenta los espacios en la cadena de búsqueda. -o: Considera coincidencia sólo los procesos que comenzaron antes de un período de tiempo indicado. El período de tiempo se puede indicar como un decimal seguido de las unidades s, m, h, d, w, M, y para segundos, minutos, horas, días, semanas, meses y años respectivamente. -r: Interpreta la cadena de búsqueda como una expresión regular. -s: Indica la señal que se debe enviar al proceso o a los procesos indicados. -u: Envía la señal sólo a los procesos que sean propiedad del usuario especificado. En este caso no es necesario indicar un nombre de proceso. Si no se indica un nombre de proceso, envía la señal a todos los procesos que pertenecen al usuario. -w: Espera hasta que los procesos a los que se ha enviado una señal terminen. Verifica si se han terminado los procesos indicados una vez por segundo. -y: Considera coincidencia sólo los procesos que comenzaron después de un período de tiempo indicado. El período de tiempo se puede indicar como un decimal seguido de las unidades s, m, h, d, w, M, y para segundos, minutos, horas, días, semanas, meses y años respectivamente. -Z: Envía la señal sólo a los procesos que tienen un contexto de seguridad que se corresponde con una expresión regular determinada. Ejemplos de uso Con las opciones indicadas, existen varios ejemplos de uso del comando killall:\nkillall -l muestra la lista de señales que se pueden enviar.\nkillall -s STOP wget envía una señal para parar al proceso que depende del comando wget.\nkillall -y 20m envía una señal para terminar a todos los procesos iniciados en los últimos 20 minutos.\nkillall -u debian envía una señal para terminar a todos los procesos del usuario debian.\nEl comando pidof Definición El comando pidof busca el ID del proceso que corresponde a un programa en ejecución. Este comando devuelve el PID de un proceso a partir de su nombre.\nSintaxis pidof [opciones] programa Opciones Algunas de las opciones más relevantes del comando pidof son:\n-s: Devuelve sólo un ID de proceso. -c: Sólo devuelve el ID de los procesos que se estén ejecutando en el mismo directorio de root. Esta opción no se puede usar desde usuarios que no sean root. -q: No devuelve los ID de los procesos, sino que simplemente indica con un valor booleano si la búsqueda ha devuelto algún resultado o no. -x: Devuelve también el ID del proceso de la shell que ejecuta un script determinado. -z: Intenta detectar procesos que estén en estado zombi. Habitualmente estos procesos se ignoran porque pueden provocar que herramientas como pidof se cuelguen. -d: Indica un separador en la salida si devuelve más de un ID de proceso. El separador por defecto es el espacio. -o: Omite el proceso con el ID indicado. Se puede usar para ignorar el ID del proceso padre desde el que se ejecuta el comando, ya sea una shell o un script. Ejemplos de uso El uso habitual de este comando es encontrar el ID que corresponde a un proceso determinado. Por ejemplo pidof bash.\nEl comando bg Definición El comando bg mueve trabajos al segundo plano. Este comando coloca los trabajos cuyo ID se indique como si se hubieran iniciado con \u0026amp;.\nSintaxis bg [id_trabajo] Opciones Este comando no tiene opciones.\nEjemplos de uso El uso habitual de bg es mover trabajos al segundo plano. Por ejemplo, en un entorno de shell en el que se está llevando a cabo una actualización de la paquetería del sistema con apt upgrade -y y este trabajo tiene el identificador 1, se puede mover al segundo plano con bg 1 para poder seguir haciendo uso de la terminal mientras el trabajo se desarrolla.\nEl comando fg Definición El comando fg mueve un trabajo al primer plano. Este comando ubica el trabajo cuyo ID se indique en el primer plano y lo hace el trabajo actual.\nSintaxis bg [id_trabajo] Opciones Este comando no tiene opciones.\nEjemplos de uso El uso habitual de fg es mover trabajos al primer plano. Por ejemplo, si en un entorno de shell se está llevando a cabo una actualización de la paquetería del sistema con apt upgrade en segundo plano y este trabajo tiene el identificador 1, se puede mover al segundo plano con fg 1 para interactuar con el comando cuando pida confirmación para la instalación o actualización de un determinado paquete.\n"},{
  "section": "Blog",
  "slug": "/blog/bases-de-datos/2024-03-07-instalacion-mongodb-debian-12-sgbd-nosql/",
  "title": "Guía de instalación de MongoDB en Debian 12",
  "description": "",
  "date": "March 7, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "bases-de-datos",
  "tags": "Gestión de Bases de Datos, debian, linux, MongoDB, NoSQL, SGBD",
  "content":"MongoDB es un sistema de base de datos NoSQL, orientado a documentos y de código abierto. Este SGBD no guarda los documentos y tablas como ocurre con los relacionales (Oracle, PostgreSQL, MariaDB, MySQL\u0026hellip;), sino que lo hace en estrucuturas de datos en formato BSON llamadas documentos. En este post te cuento cómo puedes instalar este sistema gestor de base de datos en un servidor con Debian 12.\nInstalación de MongoDB Para instalar MongoDB, en primer lugar, se deben instalar los paquetes pnupg y curl.\nsudo apt-get install gnupg curl A continuación se debe importar la clave pública de Mongo.\ncurl -fsSL https://www.mongodb.org/static/pgp/server-7.0.asc | \\ sudo gpg -o /usr/share/keyrings/mongodb-server-7.0.gpg \\ --dearmor Posteriormente se debe crear un fichero de fuentes en el directorio sorurces.list.d:\necho \u0026#34;deb [ signed-by=/usr/share/keyrings/mongodb-server-7.0.gpg ] http://repo.mongodb.org/apt/debian bookworm/mongodb-org/7.0 main\u0026#34; | sudo tee /etc/apt/sources.list.d/mongodb-org-7.0.list A partir de este punto, para instalar MongoDB se puede seguir el procedimiento habitual: actualizar apt e instalar el paquete:\nsudo apt update sudo apt install mongodb-org Se puede comprobar porque tras finalizar el proceso de instalación se han creado los directorios /var/lib/mongodb y /var/log/mongodb.\nls -l /var/lib/ | grep mongodb ls -l /var/log/ | grep mongodb Configuración de MongoDB Antes de comenzar a usar MongoDB es necesario arrancar el servidor y comprobar su estado:\nsudo systemctl start mongodb sudo systemctl status mongodb Además, se debe habilitar el servicio para que su funcionamiento sea persistente durante los reinicios de la máquina:\nsudo systemctl enable mongodb Acceder al servidor de MongoDB Finalmente, se puede acceder al servicio de MongoDB instalado en la máquina local ejecutando el comando mongosh:\nWarning\nMongoDB usa el puerto 27017. Si tu servidor se aloja en una máquina remota deberás revisar que el cortafuegos permita conexiones por este puerto.\n"},{
  "section": "Blog",
  "slug": "/blog/redes/2024-03-03-acl-router-cisco/",
  "title": "Configuración de ACL en routers Cisco",
  "description": "",
  "date": "March 3, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "GNS3, redes, Planificación y Administración de Redes, router, Cisco, ACL, los juegos del hambre, hunger games",
  "content":"Las ACL o listas de control de acceso son un mecanismo que permite controlar el tráfico que atraviesa en router en una red. En este post se demuestra el funcionamiento de las ACL en los routers Cisco con un escenario basado en los personajes de la saga \u0026ldquo;Los juegos del hambre\u0026rdquo;.\nEn concreto, el router que se usa en este caso práctico es el Cisco 7200.\nImportar el router Cisco 7200 El 7200 es el router Cisco más popular en el marketplace de GNS3. Para instalarlo el primer paso es descargar la imagen desde este marketplace.\nA continuación se debe importar a GNS3 desde el menú de añadir plantilla:\nDespués se elige el modelo en la lista de routers.\nY se importa la imagen descargada desde el marketplace:\nTras confirmar la instalación, el dispositivo ya está disponible en GNS3.\nAsignación de direcciones IP Para este escenario se usan los VPCS de GNS3 como ordenadores.\nEl direccionamiento IP de los VPCS del escenario es el siguiente:\nMarvel: 10.0.1.2 Glimmer: 10.0.1.3 Cato: 10.0.2.2 Clover: 10.0.2.3 Thresh: 10.0.11.2 Rue: 10.0.11.3 Peeta: 10.0.12.2 Katniss: 10.0.12.3 A cada uno de los ordenadores se les asigna la IP indicada usando el comando ip. Junto a la dirección IP se indica también su máscara de red y la IP de la puerta de enlace al resto de redes del escenario que, en este caso coincide en las cuatro redes con la IP de la interfaz del router que se conecta a cada swtich.\nip 10.0.1.2/24 10.0.1.1 El direccionamiento IP de los routers del escenario es el siguiente:\nR1 f0/0: 10.0.1.1 R1 f0/1: 172.23.0.1 R1 f1/0: 192.168.1.2 R2 f0/0: 10.0.11.1 R2 f0/1: 172.23.0.2 R2 f1/0: 172.24.0.1 R2 f1/1: 192.168.11.2 R3 f0/0: 10.0.2.1 R3 f0/1: 172.25.0.1 R3 f1/0: 192.168.2.2 R4 f0/0: 10.0.12.1 R4 f0/1: 172.24.0.2 R4 f1/0: 192.168.12.2 R4 f1/1: 172.25.0.2 R5 f0/0: 192.168.11.1 R5 f0/1: 192.168.12.1 R5 f1/0: 192.168.1.1 R5 f1/1: 192.168.2.1 R5 f2/0: 10.0.13.1 Para asignar las direcciones IP a los routers se usa el comando ip address seguido de la dirección IP y la máscara de red desde el modo de configuración de cada una de las interfaces de los routers.\nR1#conf t R1(config)#interface fastEthernet 0/0 R1(config-if)#ip address 10.0.1.1 255.255.255.0 R1(config-if)#no shutdown R1(config-if)#exit R1(config)#interface fastEthernet 0/1 R1(config-if)#ip address 172.23.0.1 255.255.255.0 R1(config-if)#no shutdown R1(config-if)#exit R1(config)#interface fastEthernet 1/0 R1(config-if)#ip address 192.168.1.2 255.255.255.0 R1(config-if)#no shutdown R1(config-if)#end R1#write Enrutamiento del escenario En primer lugar se permite la comunicación entre todos los dispositivos del escenario y el primer paso para garantizar la comunicación entre todos los dispositivos de la red es crear sus tablas de enrutamiento.\nTablas de enrutamiento Marvel Destino Siguiente router Interfaz de salida 0.0.0.0 R1 f0/0 (10.0.1.1) eth0 Glimer Destino Siguiente router Interfaz de salida 0.0.0.0 R1 f0/0 (10.0.1.1) eth0 Cato Destino Siguiente router Interfaz de salida 0.0.0.0 R3 f0/0 (10.0.2.1) eth0 Clover Destino Siguiente router Interfaz de salida 0.0.0.0 R3 f0/0 (10.0.2.1) eth0 Thresh Destino Siguiente router Interfaz de salida 0.0.0.0 R2 f0/0 (10.0.11.1) eth0 Rue Destino Siguiente router Interfaz de salida 0.0.0.0 R2 f0/0 (10.0.11.1) eth0 Peeta Destino Siguiente router Interfaz de salida 0.0.0.0 R4 f0/0 (10.0.12.1) eth0 Katniss Destino Siguiente router Interfaz de salida 0.0.0.0 R4 f0/0 (10.0.12.1) eth0 Router 1 Destino Siguiente router Interfaz de salida Distrito 1 (10.0.1.0) 0.0.0.0 f0/0 Distrito 2 (10.0.2.0) R5 f1/0 (192.168.1.1) f1/0 Distrito 11 (10.0.11.0) R2 f0/1 (172.23.0.2) f0/1 Distrito 12 (10.0.12.0) R2 f0/1 (172.23.0.2) f0/1 R2 (172.23.0.0) 0.0.0.0 f0/1 R2 (192.168.11.0) R2 f0/1 (172.23.0.2) f0/1 R3 (172.25.0.0) R5 f1/0 (192.168.1.1) f1/0 R3 (192.168.2.0) R5 f1/0 (192.168.1.1) f1/0 R4 (172.24.0.0) R2 f0/1 (172.23.0.2) f0/1 R4 (192.168.12.0) R2 f0/1 (172.23.0.2) f0/1 R5 (192.168.1.0) 0.0.0.0 f1/0 R5 (10.0.13.0) R5 f1/0 (192.168.1.1) f1/0 Router 2 Destino Siguiente router Interfaz de salida Distrito 1 (10.0.1.0) R1 f0/1 (172.23.0.1) f0/1 Distrito 2 (10.0.2.0) R4 f0/1 (172.24.0.2) f1/0 Distrito 11 (10.0.11.0) 0.0.0.0 f0/0 Distrito 12 (10.0.12.0) R4 f0/1 (172.24.0.2) f1/0 R1 (172.23.0.0) 0.0.0.0 f0/1 R1 (192.168.1.0) R1 f0/1 (172.23.0.1) f0/1 R3 (172.25.0.0) R4 f0/1 (172.24.0.2) f1/0 R3 (192.168.2.0) R4 f0/1 (172.24.0.2) f1/0 R4 (172.24.0.0) 0.0.0.0 f1/0 R4 (192.168.12.0) R4 f0/1 (172.24.0.2) f1/0 R5 (192.168.1.0) R5 f0/0 (192.168.11.1) f0/1 R5 (10.0.13.0) R5 f0/0 (192.168.11.1) f0/1 Router 3 Destino Siguiente router Interfaz de salida Distrito 1 (10.0.1.0) R5 f1/1 (192.168.2.1) f1/0 Distrito 2 (10.0.2.0) 0.0.0.0 f0/0 Distrito 11 (10.0.11.0) R4 1/1 (172.25.0.2) f0/1 Distrito 12 (10.0.12.0) R4 1/1 (172.25.0.2) f0/1 R1 (172.23.0.0) R5 f1/1 (192.168.2.1) f1/0 R1 (192.168.1.0) R5 f1/1 (192.168.2.1) f1/0 R2 (172.23.0.0) R4 1/1 (172.25.0.2) f0/1 R2 (192.168.11.0) R4 1/1 (172.25.0.2) f0/1 R4 (172.24.0.0) R4 1/1 (172.25.0.2) f0/1 R4 (192.168.12.0) R4 1/1 (172.25.0.2) f0/1 R5 (192.168.1.0) R5 f1/1 (192.168.2.1) f1/0 R5 (10.0.13.0) R5 f1/1 (192.168.2.1) f1/0 Router 4 Destino Siguiente router Interfaz de salida Distrito 1 (10.0.1.0) R2 f1/0 (172.24.0.1) f0/1 Distrito 2 (10.0.2.0) R3 f0/1 (172.25.0.1) f1/1 Distrito 11 (10.0.11.0) R2 f1/0 (172.24.0.1) f0/1 Distrito 12 (10.0.12.0) 0.0.0.0 f0/0 R1 (172.23.0.0) R2 f1/0 (172.24.0.1) f0/1 R1 (192.168.1.0) R2 f1/0 (172.24.0.1) f0/1 R2 (172.23.0.0) R2 f1/0 (172.24.0.1) f0/1 R2 (192.168.11.0) R2 f1/0 (172.24.0.1) f0/1 R3 (172.25.0.0) 0.0.0.0 f1/1 R3 (192.168.2.0) R3 f0/1 (172.25.0.1) f1/1 R5 (192.168.1.0) R5 f0/1 (192.168.12.1) f1/0 R5 (10.0.13.0) R5 f0/1 (192.168.12.1) f1/0 Router 5 Destino Siguiente router Interfaz de salida Distrito 1 (10.0.1.0) R1 f1/0 (192.168.1.2) f1/0 Distrito 2 (10.0.2.0) R3 f1/0 (192.168.2.2) f1/1 Distrito 11 (10.0.11.0) R2 f1/1 (192.168.11.2) f0/0 Distrito 12 (10.0.12.0) R4 f1/0 (192.168.12.2) f0/1 R1 (172.23.0.0) R1 f1/0 (192.168.1.2) f1/0 R1 (192.168.1.0) 0.0.0.0 f1/0 R2 (172.23.0.0) R2 f1/1 (192.168.11.2) f0/0 R2 (192.168.11.0) 0.0.0.0 f0/0 R3 (172.25.0.0) R3 f1/0 (192.168.2.2) f1/1 R3 (192.168.2.0) 0.0.0.0 f1/1 R4 (172.24.0.0) R4 f1/0 (192.168.12.2) f0/1 R4 (192.168.12.0) 0.0.0.0 f0/1 Para trasladar estas tablas de enrutamiento a los diferentes dispositivos que conforman el escenario se usa el comando ip route en los routers Cisco:\nR1#conf t R1(config)#ip route 10.0.2.0 255.255.255.0 192.168.1.1 R1(config)#ip route 10.0.3.0 255.255.255.0 172.23.0.2 R1(config)#ip route 10.0.11.0 255.255.255.0 172.23.0.2 R1(config)#ip route 10.0.12.0 255.255.255.0 172.23.0.2 R1(config)#ip route 192.168.11.0 255.255.255.0 172.23.0.2 R1(config)#ip route 172.24.0.0 255.255.255.0 172.23.0.2 R1(config)#ip route 192.168.10.0 255.255.255.0 172.23.0.2 R1(config)#ip route 172.25.0.0 255.255.255.0 192.168.1.1 R1(config)#ip route 192.168.2.0 255.255.255.0 192.168.1.1 R1(config)#ip route 10.0.13.0 255.255.255.0 192.168.1.1 R1(config)#end R1#write Creación de las ACL Diseño de las ACL En primer lugar, para evitar que a los ordenadores de la red de los superpijos lleguen mensajes del resto de dispositivos se pueden implementar varias ACL. Una opción sería usar ACL extendidas en los router por los que salen al resto de redes los ordenadores de cada una de las redes o distritos, de esta manera, se podría filtrar, en el router de origen, el tráfico que se dirija hacia el distrito de los superpijos desde cada una del resto de las redes. Otra opción es usar una ACL estándar en el router 1 que impida a esta red recibir tráfico del resto de redes del escenario.\nAmbas opciones tienen sus ventajas y sus inconvenientes. Por una parte, la primera opción implica usar ACL extendidas en tres de los routers del escenario, lo que supone un implementación algo más compleja para conseguir el objetivo propuesto. Por otra parte, la segunda opción implica que todo el tráfico que se genere en el escenario dirigido a la red de los superpijos navegará por varios routers antes de llegar a la ACL que bloquee su paso, generando una cierta cantidad de tráfico que no va a ninguna parte por todas las redes. En cambio, la implementación es más sencilla porque se puede conseguir con una ACL estándar en un único router del escenario.\nDe una manera similar, la situación de los indigentes se podría abordar también desde varias perspectivas. Por una parte, se podrían implementar ACL extendidas en los routers de los pijos y los superpijos para bloquear el tráfico que llegue a esas redes desde la red de los indigentes. Sin embargo, parece una opción más sencilla implementar una ACL estándar en el router 4 que impida que el tráfico de esta red salga hacia el resto de redes del escenario. En este caso, para garantizar que el tráfico no llegue a los pijos ni a los superpijos habría que implementar una segunda ACL en el router 2 que impidiese que este tráfico llegase, a través de él, al router 5 y de ahí al 3, que da a la red de los pijos. Teniendo en cuenta que el tráfico debe poder llegar al router 2 para establecer la comunicación entre pobres e indigentes, el uso de esta segunda ACL es obligatorio para conseguir el objetivo planteado.\nFinalmente, para que los pobres y los pijos puedan comunicarse entre ellos a través del router 5, esta ACL en el router 2 debe permitir pasar el tráfico que se origine en la red de los pobres. Para garantizar que este tráfico pasa exclusivamente por el router 5 y no por el 4, se deberá configurar una ACL en este router que bloquee la salida del tráfico que proviene de esta red por la interfaz que comunica el router 4 con el router 3. Esta ACL se deberá combinar, por tanto, con la que se debe implementar también en esa misma interfaz para evitar que los indigentes se puedan comunicar con el resto de distritos.\nPero existen más opciones para configurar las ACL en este escenario. Para conseguir que los superpijos no se puedan comunicar con ninguna otra red la opción más evidente y práctica parece implementar una ACL en todas las interfaces del router 1 que dan al resto de redes del escenario. Para conseguir los otros dos objetivos, en cambio, puede ser suficiente con configurar un par de ACL en el router 3. Si se bloquea la entrada de tráfico de los indigentes por ambas interfaces de este router, éstos sólo se podrán comunicar ya con los pobres. Además, al bloquear el tráfico tanto de entrada desde los pobres como de salida desde los pijos por la interfaz que no conecta al router 5 se evita la comunicación entre ambas redes por cualquier vía que no sea el router 5.\nDe esta manera, los routers e interfaces en los que se deberían implementar las siguientes reglas ACL son estos:\nR1 R3 f1/0: ACL básica que bloquee el tráfico de entrada al router de cualquier red. f0/1: ACL básica que bloquee el tráfico de entrada al router de cualquier red. f0/1: ACL básica que bloquee el tráfico de entrada tanto de las redes de los indigentes como de los pobres y el tráfico de salida de la red de los pijos. f1/0: ACL básica que bloquee el tráfico de entrada desde la red de los indigentes. Con esta configuración de ACL, los superpijos no recibirán tráfico de ninguna red, los indigentes podrán enviar mensajes a los pobres a través de la interfaz f0/1 del router 3 y los pobres a los indigentes a través de la interfaz f1/1 del router 2. Los pobres y los pijos se podrán comunicar únicamente a través del router 5 porque los mensajes de los pobres no pueden salir del router 4 al tres y los de los pijos no pueden salir del 3 al 4.\nImplementación de las ACL Router 1 R1#conf t R1(config)#acces-list 1 deny any R1(config)#interface fastEthernet 0/1 R1(config-if)#ip access-group 1 in R1(config-if)#exit R1(config)#interface fastEthernet 1/0 R1(config-if)#ip access-group 1 in R1(config-if)#end R1#write Router 3 R3#conf t R3(config)#acces-list 1 deny 10.0.12.0 0.0.0.255 R3(config)#acces-list 1 deny 10.0.11.0 0.0.0.255 R3(config)#acces-list 1 permit any R3(config)#acces-list 2 deny 10.0.2.0 0.0.0.255 R3(config)#acces-list 2 permit any R3(config)#acces-list 3 deny 10.0.12.0 0.0.0.255 R3(config)#acces-list 3 permit any R3(config)#interface fastEthernet 0/1 R3(config-if)#ip access-group 1 in R3(config-if)#ip access-group 2 out R3(config-if)#no shutdown R3(config-if)#exit R3(config)#interface fastEthernet 1/0 R3(config-if)#ip access-group 3 in R3(config-if)#no shutdown R3(config-if)#end R3#write Configuración de un servidor DHCP Configuración del servidor El primer paso para configurar el servidor DHCP de los superpijos es indicarle al router el rango de direcciones que tiene disponible para asignar a través de este protocolo. De todas las combinaciones posibles de direcciones dentro de su red, el servidor DHCP deberá reservar la 10.0.1.1 para el router. Además, el servidor debe asignar sólo direcciones que se encuentren en el rango de las 5 primeras, por tanto, las direcciones entre la 10.0.1.6 y la 10.0.1.255 también deberán estar excluidas.\nPosteriormente, se puede crear un pool DHCP que indique al servidor que puede otorgar direcciones de la red 10.0.1.0/24 a los dispositivos que las soliciten. Además, en este momento de la configuración del servidor DHCP se debe indicar también la dirección IP de la puerta de enlace de la red. Además, se pueden configurar algunos aspectos más del servicio DHCP como el servidor DNS por defecto, el nombre de dominio de la red o el tiempo de préstamos de las direcciones aunque, en este caso, no es necesario.\nR1#conf t R1(config)#ip dchp excluded-address 10.0.1.1 R1(config)#ip dchp excluded-address 10.0.1.6 10.0.1.255 R1(dhcp-config)#network 10.0.1.0 255.255.255.0 R1(dhcp-config)#default-router 10.0.1.1 R1(dhcp-config)#lease 0 0 10 R1(dhcp-config)#end R1#wr ACL extendidas Diseño de las ACL En el nuevo escenario que se plantea es necesario implementar varias modificaciones. A excepción del router 1, que aún debe mantener las mismas reglas que impidan la conexión entre los dispositivos de su red y el resto de redes, todas las demás indicaciones han cambiado. Por tanto, si bien es cierto que una modificación de las ACL existentes podría ser compatible con el nuevo escenario parece más lógico eliminar las ACL creadas previamente en el resto de routers puesto que todas ellas impedirían que se cumpliesen los objetivos que se plantean y, sobre todo, porque para mantenerlas habría que sustituir la mayoría de ellas por ACL extendidas, lo cual implica, en la práctica, la eliminación de la ACL básica y la creación de una ACL extendida en su lugar.\nEn primer lugar, para permitir la comunicación entre Peeta y Clove se pueden implementarse dos reglas diferentes. Por una parte, se puede establecer una ACL en la interfaz f0/1 del router 3 que permita el tráfico desde Clove hasta Peeta y deniegue el resto. Por otra, se puede establecer una ACL en la interfaz f1/1 del router 4 que permita el tráfico desde Peeta hasta Clove y deniegue el resto.\nA esta condición hay que sumar que Katniss y Cato deben poder comunicarse también. Por tanto, la ACL que permita la comunicación entre Peeta y Clove debe incluir una segunda condición previa a la denegación de todo el tráfico que permita el tráfico desde Cato a Katniss (si se aplica en el router 3) o desde Katniss a Cato (si se aplica en router 4).\nDe la misma manera, para bloquear la comunicación entre Katniss y Rue pero garantizar que Peeta se pueda seguir comunicando con los pobres también existen dos opciones: se puede implementar una ACL en la interfaz f0/1 del router 4 que deniegue los mensajes desde Katniss a Rue o bien se puede implementar una ACL en la interfaz f1/0 del router 2 que deniegue los mensajes desde Rue a Katniss.\nFinalmente, para que Cato y Thresh no puedan comunicarse, y aunque también se podría tratar de implementar una ACL en el router 5, las opciones más óptimas parecen el uso de una ACL en la interfaz f1/0 del router 3 que deniegue el tráfico desde Cato hacia Thresh y permita el resto o el uso de una ACL en la interfaz f0/1 del router 2 que deniegue el tráfico de Thresh a Cato y permita el resto.\nEn todos estos casos será necesario el uso de ACL extendidas porque será necesario que las reglas incluyan, de manera explícita, información tanto del origen como del destino de los mensajes que deben filtrar.\nAsí, los routers e interfaces en los que es necesario implementar estas reglas ACL para conseguir los objetivos propuestos son los siguientes:\nR2 R3 f1/1: ACL extendida que deniegue el tráfico de salida desde Thresh hacia Cato y permita el resto. f1/0: ACL extendida que deniegue el tráfico de salida desde Rue hacia Katniss y permita el resto. f0/1: ACL extendida que permita el tráfico de salida desde Clove hacia Peeta y el tráfico de salida desde Cato hacia Katniss y deniegue el resto. Implementación de las ACL Router 2 R2#conf t R2(config)#access-list 101 deny ip 10.0.11.2 0.0.0.0 10.0.2.2 0.0.0.0 R2(config)#interfaz fastEthernet 1/1 R2(config-if)#ip access-group 101 out R2(config-if)#exit R2(config)#access-list 101 permit ip any any R2(config)#access-list 102 deny ip 10.0.11.3 0.0.0.0 10.0.12.3 0.0.0.0 R2(config)#access-list 102 permit ip any any R2(config)#interfaz fastEthernet 1/0 R2(config-if)#ip access-group 102 out R2(config-if)#end R2#wr Router 3 R3#conf t R3(config)#access-list 101 permit ip 10.0.2.3 0.0.0.0 10.0.12.2 0.0.0.0 R3(config)#access-list 101 permit ip 10.0.2.2 0.0.0.0 10.0.12.3 0.0.0.0 R3(config)#interfaz fastEthernet 0/1 R3(config-if)#ip access-group 101 out R3(config-if)#end R3#wr Incorporar un servidor web al escenario Para completar este caso práctico, se añade un servidor web instalado en una máquina Debian 11 al escenario.\nPara que el resto de redes puedan comunicarse con el servidor web es necesario incluir su IP en la tabla de enrutamiento de los dispositivos que forman parte de estas redes. Teniendo en cuenta que la interfaz del router 5 que se conecta al servidor web tiene la IP 10.0.13.1, del rango de direcciones IP de la red 10.0.13.0/24, el servidor web también tiene que tener una dirección dentro de este rango, por ejemplo, la 10.0.13.2.\nNote\nEl proceso para añadir y configurar un servidor web en GNS3 se desarrolla detalladamente en este otro post.\nPara que tanto los ordenadores del distrito 11 como los del distrito 12 puedan acceder a este servidor web es necesario que los routers 2 y 4 incluyan en sus tablas de enrutamiento la información necesaria para alcanzar este destino. En el caso del router 2 sería necesario añadir la siguiente línea a la tabla de enrutamiento:\nDestino Siguiente router Interfaz de salida Servidor web (10.0.13.0) R5 f0/0 (192.168.11.1) f0/1 R2(config)#ip route 10.0.13.0 255.255.255.0 192.168.11.1 En el router 4 la línea que se debe añadir a la tabla de enrutamiento es la siguiente:\nDestino Siguiente router Interfaz de salida Servidor web (10.0.13.0) R5 f0/1 (192.168.12.1) f1/0 R4(config)#ip route 10.0.13.0 255.255.255.0 192.168.12.1 Una vez configurado el enrutamiento, los equipos en la red 10.0.12.0/24 ya pueden establecer la comunicación con el servidor web, sin embargo, los equipos de la red 10.0.11.0/24 tienen la comunicación prohibida con este servidor debido al uso previo de ACL en el router.\nPor tanto, es necesario modificar también las ACL implementadas en estos routers para garantizar que se permita la comunicación entre los ordenadores de estos distritos y el servidor web.\nR2(config)#access-list 101 permit tcp 10.0.11.0 0.0.0.255 10.0.13.0 0.0.0.255 eq 80 Con esta nueva regla ACL, la red 10.0.11.0/24 ya tendrá permitida la comunicación con el servidor web ubicado en la red 10.0.13.0/24 siempre que se use el protocolo HTTP, es decir, siempre que la comunicación se establezca a través del puerto 80.\nPor último, queda implementar una última ACL que permita cumplir con la condición de que sólo los miembros de los distritos 11 y 12 puedan acceder al servidor web. Para ello, es necesario implementar una ACL en la interfaz f2/0 del router 5 que permita el tráfico de entrada al router que tenga como origen la red del servidor (10.0.13.0/24) y el puerto 80 y que tenga como destino las redes 10.0.12.0/24 o 10.0.11.0/24 y que deniegue todo el resto del tráfico.\nR5#conf t R5(config)#access-list 101 permit tcp 10.0.13.0 0.0.0.255 eq 80 10.0.11.0 0.0.0.255 eq 80 R5(config)#access-list 101 permit tcp 10.0.13.0 0.0.0.255 eq 80 10.0.12.0 0.0.0.255 eq 80 R5(config)#interface fastEthernet 2/0 R5(config-if)#ip access-group 101 in R5(config-if)#end R5#wr "},{
  "section": "Blog",
  "slug": "/blog/redes/2024-03-03-simular-servidor-web-gns3-nginx-apache/",
  "title": "Cómo simular un servidor web en GNS3",
  "description": "",
  "date": "March 3, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "Wireshark, GNS3, redes, Planificación y Administración de Redes, servidor web, nginx, apache",
  "content":"Existen varias formas de crear un servidor web en un escenario de GNS3. En este post se optará por añadir una máquina Linux con Debian 11 en la que se instalará el servidor Nginx para que pueda actuar a forma de servidor web en el escenario.\nAñadir una máquina Debian al escenario Para crear un servidor web en GNS3 es necesario incluir una máquina que pueda cumplir esta función. En este caso se usará una máquina con Debian 11. Para que esta máquina se pueda usar en el proyecto es necesario importar la plantilla. Tal y como ocurre en el caso del router que se ha instalado también para esta práctica, el procedimiento comienza pulsando el botón new template.\nEsto abre una ventana en la que se puede elegir cómo importar la plantilla, en este caso, desde el servidor de GNS3.\nEn la lista con todas las opciones disponibles se busca y elige la máquina Debian.\nA continuación se carga la imagen desde la carpeta Images/QEMU que se genera durante la instalación de GNS3 y ya se puede proceder a la importación de esta plantilla.\nInstalación y configuración del servidor web Para instalar el servidor web, ya sea Nginx o Apache, en la máquina Debian 11 del escenario de GNS3 es necesario que se pueda conectar a Internet. Con este objetivo se puede añadir de forma provisional una nube NAT al escenario que permita la conexión entra la máquina Debian e Internet, de manera que se puedan actualizar los paquetes instalados y descargar nuevos.\nUna vez que la máquina está incorporada al escenario y conectada a la nube nat, se puede arrancar y acceder a ella. Lo primero que se debe hacer es establecer una configuración TCP/IP que le permita conectarse a Internet. En este caso, como la nube NAT cuenta con un servidor DHCP se puede hacer usando el comando dhclient:\nsudo dhclient Con la conexión a Internet configurada y establecida es necesario actualizar la paquetería de la máquina antes de proceder a instalar cualquier paquete nuevo.\nsudo apt update \u0026amp;\u0026amp; sudo apt upgrade sudo apt install nginx Con el sistema actualizado, se puede instalar el servidor web elegido, por ejemplo, Nginx\nsudo apt install nginx o Apache\nsudo apt install apache2 Para comprobar que tras el proceso de instalación el servicio de Nginx o Apache se arranca de forma automática se puede ejecutar el comando correspondiente\nsudo systemctl status nginx.service sudo systemctl status apache2.service Si no se ha arrancado, se puede hacer con el comando\nsudo systemctl start nginx sudo systemctl start apache2 Una vez que se ha Nginx está funcionando en el servidor se debe configurar la dirección IP estática de esta máquina a la que el resto de ordenadores deberá acceder para consultar el contenido alojado en él. En este caso se usa la IP 10.0.13.2. Esta información se debe indicar en el fichero de configuración /etc/network/interfaces:\nTras editar el fichero /etc/network/interfaces se reinicia el servicio networking.\nsudo systemctl restart networking.service Adicionalmente, como paso final de la configuración se puede añadir contenido al servidor editando el fichero /var/www/html/index.html y, si fuera necesario, añadiendo directorios y ficheros a esta estructura para crear la web.\n"},{
  "section": "Blog",
  "slug": "/blog/redes/2024-02-27-enrutamiento-red-openstack/",
  "title": "Cómo enrutar una red en OpenStack",
  "description": "",
  "date": "February 27, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "redes, Planificación y Administración de Redes, OpenStack, enrutamiento, Debian, tcpdump, virtualización, router linux, ip route",
  "content":"OpenStack es un proyecto de cloud computing (computación en la nube) de software libre y código abierto. Ofrece una estructura como servicio (IaaS) y permite virtualizar equipos en los servidores en los que esté configurado. Además, la plataforma permite crear redes virtuales, de manera que las diferentes máquinas virtuales pueden comunicarse entre sí. En este post se recoge un caso práctico en el que se configura el enrutamiento de una pequeña red de máquinas virtuales creadas en OpenStack.\nCreación de la red en OpenStack Las redes en OpenStack se pueden crear de forma manual, creando cada una de las máquinas y configurando la conexión entre ellas a través de la interfaz gráfica de la plataforma pero también se pueden crear de forma automatizada. Este tipo de creación de máquinas virtuales en lote requiere la creación previa de un fichero YAML como plantilla en el que se incluye la información necesaria para la creación de las máquinas y redes. Desde el menú \u0026ldquo;stacks\u0026rdquo; se puede lanzar la creación de una plantilla YAML pulsando el botón \u0026ldquo;lanzar stack\u0026rdquo;.\nPara este caso práctico se usa un escenario formado por seis máquinas, de las cuales tres funcionan como PC y las otras tres como routers.\nConfiguración de los nodos PC1 Puesto que sólo está conectado a un router por su única tarjeta de red, la tabla de enrutamiento de PC1 se puede simplificar hasta dejarla en una única línea.\nDestino Siguiente router Interfaz de salida Por defecto R1: 172.23.1.8 ens3 Para trasladar esta tabla a la configuración del ordenador se puede usar el comando ip route:\nip route add default via 172.23.1.8 PC2 Puesto que sólo está conectado a un router por su única tarjeta de red, la tabla de enrutamiento de PC2 se puede simplificar hasta dejarla en una única línea.\nDestino Siguiente router Interfaz de salida Por defecto R2: 172.25.2.255 ens3 Para trasladar esta tabla a la configuración del ordenador se puede usar el comando ip route:\nip route add default via 172.25.2.255 PC3 Puesto que sólo está conectado a un router por su única tarjeta de red, la tabla de enrutamiento de PC3 se puede simplificar hasta dejarla en una única línea.\nDestino Siguiente router Interfaz de salida Por defecto R3: 172.27.1.204 ens3 Por el mismo motivo que en los casos anteriores, para PC3 tampoco es necesario trasladar esta tabla a la configuración de la máquina.\nip route add default via 172.27.1.204 Router 1 Este router sólo se conecta a un ordenador y otro router. Por tanto, su tabla de enrutamiento sólo necesitará dos entradas: la de la interfaz por la que se comunica con el ordenador al que está conectado y la de la interfaz por la que se comunica con el resto de la red a través del router 2.\nDestino Siguiente router Interfaz de salida Por defecto R2: 172.24.2.230 ens3 Para trasladar esta tabla a la configuración de la máquina se puede usar el comando ip route:\nip route add default via 172.24.2.230 Además, se debe activar en este dispositivo el bit de forwarding, por ejemplo, modificando el fichero /proc/sys/net/ipv4/ip_forward:\necho 1 \u0026gt; /proc/sys/net/ipv4/ip_forward Router 2 El router 2 está conectado a un ordenador pero también a dos routers. Esto lo convierte en un dispositivo que deberá enrutar una gran cantidad de tráfico en la red y, además, hace que su tabla de enrutamiento sea algo más compleja que las del resto de dispositivos porque no se pueden simplificar tantas entradas.\nDestino Siguiente router Interfaz de salida R1 R1: 172.24.2.206 ens3 R3 R3: 172.26.2.36 ens5 PC1 R1: 172.24.2.206 ens3 PC2 172.25.2.142 ens4 PC3 R3: 172.26.2.36 ens5 Para trasladar esta tabla a la configuración de la máquina se puede usar el comando ip route:\nip route add 172.24.0.0/16 via 172.24.2.206 ip route add 172.26.0.0/16 via 172.26.2.36 ip route add 172.23.0.0/16 via 172.24.2.206 ip route add 172.27.0.0/16 via 172.26.2.36 Además, se debe activar en este dispositivo el bit de forwarding, por ejemplo, modificando el fichero /proc/sys/net/ipv4/ip_forward:\necho 1 \u0026gt; /proc/sys/net/ipv4/ip_forward Router 3 Este router sólo se conecta a un ordenador y otro router. Por tanto, su tabla de enrutamiento sólo necesitará dos entradas: la de la interfaz por la que se comunica con el ordenador al que está conectado y la de la interfaz por la que se comunica con el resto de la red a través del router 2.\nDestino Siguiente router Interfaz de salida Por defecto R2: 172.26.0.146 ens3 Puesto que ya hay conectividad entre PC3 y el router 3, para trasladar esta tabla a la configuración de la máquina se puede usar el comando ip route y, a continuación, se debe activar en este dispositivo el bit de forwarding, por ejemplo, modificando el fichero /proc/sys/net/ipv4/ip_forward:\necho 1 \u0026gt; /proc/sys/net/ipv4/ip_forward Una vez que se ha configurado el escenario de acuerdo a la descripción previamente expuesta, todas las máquinas que lo conforman pueden comunicarse entre sí.\nCaptura del tráfico entre PC1 y PC3 en router 2 Captura con tcpdump Con el comando tcpdump, la opción -vvv que aporta la mayor cantidad de información posible y el argumento host 172.23.1.187 and 172.27.1.204 se puede filtrar el tráfico que circula por la red entre PC1 y PC3 en cualquiera de los dos routers por los que pasa: el router 2 o el router 3.\ntcpdump -vvv host 172.23.1.187 and 172.27.1.204 En el caso de la siguiente imagen, el tráfico que se ha capturado en el router 2.\nLa captura se produce en un momento en el que la red ya estaba totalmente configurada y en el que se había estado trabajando en el enrutamiento de los diferentes dispositivos de la red recientemente. Esto hace que en la captura de tráfico que se muestra no aparezcan paquetes que usan el protocolo ARP para descubrir las direcciones IP de los dispositivos vecinos puesto que las tablas de memoria ARP tienen esa información almacenada.\nPor tanto, en la captura de tráfico se recogen 18 paquetes que han pasado por la tarjeta de red del router 2 que se ha usado para realizarla. En ella, se alternan las líneas tanto de petición como de respuesta de un ping que se ha enviado desde el PC1 al PC3. En cada una de estas líneas se incluye, en primer lugar, un código de tiempo con la hora a la que se ha capturado el paquete. A continuación, se muestra una serie de datos relevantes para el análisis del tráfico capturado. Algunos de ellos tienen una relevancia mayor que otros. Por ejemplo, se muestra el ttl de cada paquete o el protocolo que se está usando, en este caso ICMP (ping).\nPosteriormente se muestra la IP de origen y destino de cada uno de los paquetes capturados. En el caso de las peticiones, el origen es la IP del PC1 (172.23.1.187) y el destino es la IP del PC3 (172.27.1.204). En las líneas que se corresponden con los paquetes de respuesta del ping, el orden de las direcciones IP es el inverso puesto que el origen de estos mensajes es el PC3 y su destino el PC1. Posteriormente, la captura especifica el tipo de paquete del que se trata, bien ICMP echo request si es el ping que envía el PC1 al PC3 o bien ICMP echo reply si es la respuesta de ping que el PC3 devuelve al PC1. También se muestra el número de secuencia de cada paquete dentro del ping, así como la longitud del paquete: 64 bits.\nCaptura con tshark Instalación de tshark Para instalar el paquete tshark en el router 2 (en el que se va a realizar la captura) es necesario conectar el equipo a Internet. En primer lugar se debe conectar de alguna manera este escenario con la red externa de OpenStack que permite accede a Internet. Un opción es crear un nuevo router y conectarlo tanto a la red exterior como a un dispositivo del escenario de enrutamiento, en este caso, el router 2.\nPosteriormente, se debe añadir una interfaz al router:\nY, en la ventana de configuración de la nueva interfaz se debe indicar la red de la que va a formar parte (en este caso la 172.24.0.0/16), así como la dirección IP que funcionará como puerta de enlace para la red:\nUna vez que la red ya tiene esta conexión física con Internet, el router 2 ya puede hacer ping fuera de la red, por ejemplo, a 8.8.8.8.\nPero para que pueda resolver nombres de dominio y acceder a los respositorios de debian es necesario configurar el DNS. Esto se puede hacer añadiendo una línea al fichero /etc/resolvconf indicando la dirección de un servidor DNS a través del comando resolvectl, teniendo en cuenta que se debe reiniciar el servicio después:\nresolvectl dns ens3 8.8.8.8 systemctl restart networkd Con esta configuración ya se pueden resolver nombres de dominio y, por tanto, instalar paquetes desde los repositorios de Debian.\nCaptura con tshark En el caso de la captura con tshark, la información que se recoge es muy similar a la que se encuentra en la captura con tcpdump:\nLa mayor parte del tráfico que se registra es tráfico de petición de respuesta del ping que hace PC1 (172.23.1.187) a PC3 (172.27.1.204). En estos paquetes se puede ver la dirección IP de origen y de destino, el protocolo que usan (ICMP) así como su tamaño (98 bytes) y su tipo (Echo (ping) request o reply según si se trata de una petición o una respuesta). También se indica el número de secuencia dentro del ping y el ttl. Además, de la misma manera que se muestra en la interfaz gráfica de wireshark, se indica a qué petición corresponde cada respuesta del ping.\nEn esta captura aparecen, además, dos paquetes que no habían aparecido en la captura realizada con tcpdump y que corresponden a una petición y una respuesta ARP. En ellos se ve cómo primero el equipo con la IP 172.24.0.2 (un servidor DHCP) hace una petición ARP para conocer la dirección MAC del equipo con la IP 172.24.2.230 (el router 2). A continuación el router 2 contesta a esa petición con su dirección MAC.\nA diferencia de las peticiones ARP habituales, en este caso, el equipo con la IP 172.24.0.2 envía la petición no a la dirección de broadcast (FF:FF:FF:FF:FF:FF) sino a la MAC del router 2. De esta manera, en la captura de estos dos paquetes se muestra, en primer lugar la MAC de origen, a continuación la de destino, después el protocolo usado (ARP) y el tamaño del paquete (42 bytes). Finalmente, se incluye también el contenido del mensaje en formato legible, ya sea la pregunta o la respuesta.\n"},{
  "section": "Blog",
  "slug": "/blog/sistemas/2024-02-27-permisos-ugoa-acl-debian/",
  "title": "Gestión de permisos UGOA y ACL en Debian",
  "description": "",
  "date": "February 27, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "sistemas",
  "tags": "sistemas, debian, linux, comandos básicos, comandos, usuarios, seguridad, permisos, ugoa, ACL, Implantación de Sistemas Operativos",
  "content":"El propósito de este post es demostrar el funcionamiento de los permisos UGOA y las listas de control de acceso (ACL) en Debian a través de ejemplos y casos prácticos.\nNote\nAntes de leer este post es recomendable tener conocimientos sobre la creación de usuarios y la gestión de políticas de seguridad en Debian.\nPermisos UGOA Para mostrar el funcionamiento de los permisos UGOA primero se crean varios grupos de usuarios:\nsudo groupadd -g 1100 sistemas sudo groupadd -g 1200 desarrollo sudo groupadd -g 1300 explotación También se crea una estructura de directorios:\nsudo mkdir -p /proyecto/{sistemas,desarrollo,expliotacion} Estos directorios corresponden al usuario root y cada uno de ellos pertenecen al grupo homónimo:\nsudo chown root:sistemas /proyecto/sistemas/ sudo chown root:desarrollo /proyecto/desarrollo/ sudo chown root:explotacion /proyecto/explotacion/ Estos directorios deben tener permiso de lectura, escritura y ejecución para usuario y grupo y ninguno para otros:\nsudo chmod ug=rwx,o= /proyecto/{sistemas,desarrollo,expliotacion} Para comprobar el funcionamiento de la configuración de permisos que se muestra en este post se crean dos usuarios para cada grupo:\nsudo sudo useradd -g 1100 -u 1101 -p usuario -d /proyecto/sistema/ sistemas1 sudo sudo useradd -g 1100 -u 1102 -p usuario -d /proyecto/sistema/ sistemas2 sudo sudo useradd -g 1200 -u 1201 -p usuario -d /proyecto/desarrollo/ desarrollo1 sudo sudo useradd -g 1200 -u 1202 -p usuario -d /proyecto/desarrollo/ desarrollo2 sudo sudo useradd -g 1300 -u 1301 -p usuario -d /proyecto/explotacion/ explotacion1 sudo sudo useradd -g 1300 -u 1302 -p usuario -d /proyecto/explotacion/ explotacion2 Con esta configuración de permisos cada usuario sólo puede acceder a su directorio de trabajo y no al resto. Para crear un escenario más complejo que permita mostrar más opciones en la gestión de permisos vamos a suponer que los usuarios de sistemas deben tener acceso de lectura, escritura y ejecución al directorio sistemas, desarrollo y explotación; los usuarios de desarrollo deben tener acceso de lectura, escritura y ejecución al directorio desarrollo y explotación; y los usuarios de explotación deben tener acceso de lectura, escritura y ejecución al directorio explotación únicamente.\nPara que los usuarios del grupo sistema puedan acceder a los directorios desarrollo y explotación se deben incorporar a los grupos que tienen permisos sobre esos directorios como sus grupos secundarios con el comando groupmod:\nsudo groupmod -U sistemas1 -a desarrollo sudo groupmod -U sistemas1 -a explotacion sudo groupmod -U sistemas2 -a desarrollo sudo groupmod -U sistemas2 -a explotacion Igualmente, para que los usuarios del grupo desarrollo puedan acceder también al directorio explotación se les debe asignar el grupo explotación como secundario para que puedan disfrutar también de sus permisos:\nsudo groupmod -U desarrollo1 -a explotacion sudo groupmod -U desarrollo2 -a explotacion Y, tras aplicar estos cambios, los usuarios del grupo sistemas pueden acceder a los tres directorios, los del grupo desarrollo pueden acceder tanto al directorio desarrollo como explotación pero no a sistemas y, finalmente, los usuarios del grupo explotación sólo pueden acceder al directorio explotación.\nOtra forma de conseguir que usuarios de los grupos sistemas y desarrollo accedan a directorios que pertenecen a otros grupos es asignar a esos grupos una contraseña. De esta manera, usando el comando sg, los usuarios que lo necesiten podrían cambiar su identidad a miembros de estos grupos para realizar acciones sobre los directorios especificados.\nLa asignación de grupos secundarios es una fórmula que permite menos interacción por parte del usuario que, simplemente, sabrá que puede acceder a esos directorios en los que necesita trabajar. El uso de contraseñas para los grupos, en cambio, obliga al usuario a tener un cierto conocimiento del esquema del sistema en el que está trabajando y puede dificultar el acceso a los contenidos alojados en algunos de estos directorios en momentos determinados, por eso, en este caso, se ha optado por la primera opción.\nListas de control de acceso (ACL) Para demostrar el funcionamiento de las ACL se crea un nuevo grupo con dos nuevos usuarios que deben tener los mismos permisos que los usuarios del grupo sistema pero, esta vez, la configuración se realizará usando ACL en lugar de configurando los permisos UGOA.\nPrimero se crea el grupo y el directorio de los operadores y los dos usuarios:\n#Creación del grupo sudo groupadd -g 1400 operadores #Creación del directorio sudo mkdir -p /proyecto/operadores/ #Creación de los usuarios sudo useradd -g 1400 -u 1401 -d /proyecto/operadores/ -s /bin/bash operador1 sudo useradd -g 1400 -u 1402 -d /proyecto/operadores/ -s /bin/bash operador2 Para otorgar permisos al grupo operadores se usan las ACL. Con el comando setfacl y la opción -m se asigna al grupo operadores permiso de lectura, escritura y ejecución sobre cada uno de los directorios sobre los que tienen estos permisos los usuarios del grupo sistemas.\nAdemás, con la opción -R la ACL se hace recursiva para que afecte a todos los subdirectorios dentro de cada uno de estos directorios y con -d se convierte en una ACL por defecto, de manera que se aplicará a todos los directorios y ficheros que se creen dentro de cada uno de los directorios sistemas, desarrollo y explotación.\nAsí, los operadores cuentan con los mismos permisos que los usuarios del grupo sistemas:\nsudo setfacl -Rdm g:operadores:rwx /proyecto/sistemas/ /proyecto/desarrollo/ /proyecto/explotacion/ Con esta configuración, los usuarios del grupo operadores cuentan con los mismos permisos que los del grupo sistemas. La configuración de ACL se puede consultar con el comando getacl seguido de la ruta al directorio cuyas ACL se quieran conocer.\n"},{
  "section": "Blog",
  "slug": "/blog/sistemas/2024-02-18-creacion-usuarios-seguridad-debian/",
  "title": "Creación de usuarios y políticas de seguridad en Debian",
  "description": "",
  "date": "February 18, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "sistemas",
  "tags": "sistemas, debian, linux, comandos básicos, comandos, usuarios, seguridad, permisos, ugoa, Implantación de Sistemas Operativos",
  "content":"En este post se explica, a través de varios casos prácticos y ejemplos, el uso adecuado de los comandos básicos para la creación de usuarios y el establecimiento de políticas de seguridad en los sistemas operativos basados en Debian.\nCreación de usuarios y grupos Para ver el funcionamiento de los comandos para la creación de usuarios y grupos en Debian se crean dos usuarios de nombre externo1 y externo2, que tengan el UID 1200 y UID 1201 respectivamente, tengan como comentario Becarios. Además tendrán como shell /bin/bash y sus propios directorios personales. Ambos deben pertenecer al grupo externos de GID 1300.\nPara ello, primero se crea el grupo:\ngroupadd -g 1300 externos Y, a continuación, los usuarios:\nuseradd -u 1200 -c Becarios -s /bin/bash -m -g 1300 externo1 useradd -u 1201 -c Becarios -s /bin/bash -m -g 1300 externo1 Durante la creación de los usuarios externo1 y externo2 no se ha establecido una contraseña para estos usuarios, por tanto, no cuentan con un método de autenticación para acceder al sistema. Para solventar este problema, es necesario generar una contraseña para cada uno de estos usuarios:\n~$ sudo passwd externo1 New password: Retype new password: passwd: password updated succesfully ~$ sudo passwd externo2 New password: Retype new password: passwd: password updated succesfully Tras aplicar esta configuración, ambos usuarios pueden acceder al sistema.\nSe crea un nuevo grupo.\ngroupadd -g 1400 itinerantes Se pueden añadir usuarios a este nuevo grupo modificando el fichero /etc/group añadiendo la siguiente línea:\nitinerantes:x:1400:externo1 Políticas de seguridad Establecer condiciones para el cambio de contraseñas Con el comando chage se pueden establecer condiciones para el cambio de contraseñas de determinados usuarios. En este caso, se modifica la información de cambio de contraseña de externo1 para que no se pueda cambiar la contraseña antes de 10 días y sea obligatorio cambiar la contraseña cada 30 días.\nsudo chage -m 10 -M 30 externo1 El mismo resultado se puede conseguir usando el comando passwd:\nsudo passwd -n 10 -x 30 externo 1 Verificar la integridad de los ficheros de contaseñas El comando pwck verifica la integridad de los ficheros que recogen la información de autenticación de los usuarios. Este comando comprueba que las entradas de los ficheros /etc/passwd y de /etc/shadow tiene el formato adecuado y contienen información válida. Además, puede eliminar las entradas que no cumplen estos requisitos o que tienen errores incorregibles.\nPara el fichero /etc/passwd verifica que cada entrada cuente con el número correcto de campos, un nombre de usuario único y válido y un identificador de grupo y usuario, un grupo primario, un directorio home y una shell válidas. En el fichero /etc/shadow, pwck verifica que cada entrada de passwd tenga un entrada correspondiente en el fichero shadow y viceversa, que las contraseñas estén especificadas en el fichero de referencia, que las entradas tengan un número de campos adecuado, que sean entradas únicas y que las fechas de modificación de contraseñas sean correctas.\nLas principales opciones del comando pwck son -r, para ejecutarlo en modo solo lectura; y -s para ordenar las entradas por UID.\nDe la misma forma, el comando grpck comprueba la integridad de los grupos. Verifica que todas las entradas de los ficheros /etc/group y /etc/gshadow tienen un formato y contenido correcto. También puede eliminar las entradas incorrectas.\nEn el fichero /etc/group, el comando grpck verifica que los campos contenga el número adecuado de campos, un nombre de grupo único y válido, un identificador y una lista de miembros y administradores válidas y su entrada correspondiente en el fichero /etc/gshadow.\nCuenta con las mismas opciones que el comando pwck, como -r para mostrar la salida en modo sólo lectura o -s para ordenar las entradas en los ficheros por GID.\nEstos comandos se pueden emplear, por ejemplo, para comprobar la consistencia de las ficheros de configuración relacionados con usuarios y grupos después de haber estado trabajando en la creación de usuarios y grupos o modificando esta información en el sistema.\nPermisos y control de acceso a directorios En este ejemplo se crean las carpetas externos e itinerantes. Dichas carpetas pertenecerán a root y al grupo de su nombre. En ellas todos los miembros pertenecientes a cada grupo podrán acceder y escribir en su carpeta. Además, todo objeto creado por un usuario debe pertenecer a su grupo. También se crea la carpeta public y a ella podrán acceder y escribir todos los usuario del sistema pero no podrán borrar objetos que no les pertenezcan.\nPara configurar este escenario se debe crear, en primer lugar, un directorio que sea propiedad del root y, dentro de él, los directorios indicados: externos e itinerantes.\nmkdir -p directorios/externos mkdir -p directorios/itinerantes A continuación, se debe modificar el grupo al que pertenecen cada uno de estos directorios para que sea accesibles a los usuarios que formen parte de estos grupos:\nchgrp -R 1300 externos/ chgrp -R 1400 itinerante/ Para permitir acceder y modificar el contenido de su respectivo directorio a los miembros de cada grupo se puede usar un permiso 775 (rwxrwx\u0026mdash;) en el directorio. Con este permiso, tanto el usuario como todos los miembros del grupo podrán acceder al directorio así como escribir y borrar los ficheros que contiene.\nPara la carpeta pública, a la que todos deben poder acceder y escribir pero no borrar se deben asignar permisos de lectura y ejecución a otros pero no de escritura. Así, los permisos de este directorio deberían ser rwxr-xr-x o 755. Puesto que el directorio es propiedad del usuario y del grupo root, un permiso rwxrwxr-x o 775 tendría el mismo efecto ya que los usuarios que accedan a él no deberían pertenecer tampoco al grupo root y, por tanto, tampoco podrían borrar el contenido con esos permisos. En cualquier caso, el permiso rwxr-xr-x, por defecto para los directorios, otorga un mayor grado de seguridad.\nmkdir -p directorio/publica Grupos con contraseñas Con el comando groupmod se puede añadir o modificar la contraseña de un grupo, en este caso se pone la contraseña \u0026ldquo;itinerantes\u0026rdquo; al grupo del mismo nombre:\ngroupmod -p itinerantes itinerantes El uso de este comando evita que haya que editar los diferentes ficheros de configuración, lo que podría generar inconsistencias en la configuración de usuarios y grupos.\nFicheros de conexiones El fichero /etc/issue contiene un mensaje de identificación del sistema que se imprime antes del indicador de login.\nPor su parte, /etc/issue.net es un fichero de configuración en el que se puede incluir un mensaje o identificación del sistema que se mostrará justo antes de que aparezca el prompt en una sesión telnet. Puede mostrar diferentes informaciones que se indican en el fichero con el carácter % y una letra que hace referencia a la información que se quiere mostrar. Por ejemplo, %t muestra el tty que se está usando, %D muestra el nombre del dominio, %d muestra la hora y fecha actual, %s muestra el nombre del sistema operativo, %r muestra el número de release del sistema operativo y %v muestra la versión del sistema operativo.\nEl fichero /etc/motd (message of the day) contiene el texto que se muestra tras un inicio de sesión exitoso antes de que se ejecute el intérprete de órdenes del sistema.\nEstos ficheros se pueden utilizar para configurar la información que se muestra a los usuarios al iniciar sesión en su máquina como, por ejemplo, un mensaje de bienvenida, información sobre la situación de la máquina o una información relevante dirigida a los usuarios de un sistema.\nPor ejemplo, para avisar a todos los usuarios de un paro por mantenimiento se puede editar el fichero /etc/issue, que muestra el texto que se incluya en él antes de la línea de login al realizar la conexión a una máquina.\nEsto se puede hacer usando un editor desde la terminal como nano al añadir el siguiente texto al fichero /etc/issue:\nDebian GNU/Linux 12 \\n \\l El sistema se parará el 19/02/2024 a las 15:00 por mantenimiento. Tip\nCon \\n se escribe por pantalla el nombre de la máquina.\nCon \\l se escribe por la máquina el nombre del tty en uso.\nA partir de ese momento todos los usuarios verán este mensaje antes de introducir sus credenciales para el inicio de la sesión en la máquina.\nPara particularizar este tipo de mensajes a cada usuario en concreto, la configuración se debe aplicar al fichero oculto .bashrc de cada uno de los usuarios a los que se quiera dirigir. Mientras que los ficheros del directorio etc/ issue, issue.net y motd son accesibles para todos los usuarios que se conectan al sistema, el fichero .bashrc contiene una configuración específica para cada usuario.\nPor tanto, para configurar un mensaje personalizado de inicio de sesión para un usuario concreto se debe editar ese mensaje en su fichero .bashrc.\nPor último, para incluir estos mensajes de bienvenida en las conexiones por SSH se debe editar el fichero de configuración de este servicio. En primer lugar, para mostrar los mensajes que se recogen en el fichero /etc/issue, que se muestran previos al inicio de sesión, se debe editar la línea banner del fichero de configuración del servicio SSH /etc/ssh/sshd_config para indicar que se quiere mostrar un banner y la ruta al fichero que contiene el texto que debe incluir ese banner:\nBanner /etc/issue El mensaje del día (motd), también cuenta con su propia línea en el fichero de configuración del SSH. Esta línea aparece comentada por defecto. Si se activa y se cambia la opción de print motd a yes se mostrará el contenido del fichero /etc/motd cada vez que se realice una conexión de forma exitosa a través de SSH:\nPrintMotd yes Junto al mensaje del día, el fichero de configuración SSH también incluye la posibilidad de mostrar o no la información sobre la última conexión.\nEn cualquiera de estos casos, tras realizar una modificación en el fichero de configuración del servicio de SSH /etc/ssh/sshd_config se debe reiniciar este servicio:\nsystemctl restart ssh.service Info\nPara conocer más sobre gestión de permisos y listas de acceso en Debian puedes consultar este otro post.\n"},{
  "section": "Blog",
  "slug": "/blog/redes/2024-02-07-que-es-arp-como-funciona/",
  "title": "Qué es ARP y cómo funciona",
  "description": "",
  "date": "February 7, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "redes, ARP, caché ARP, MAC, MAC flooding, MAC spoofing, Planificación y Administración de Redes",
  "content":"El protocolo de resolución de direcciones (ARP) es el protocolo de comunicaciones responsable de encontrar la dirección MAC que corresponde a una determinada dirección IP. Lo hace a través de un conjunto de tramas de petición y respuesta.\nLas fases del protocolo ARP Petición ARP La petición ARP debe ser un mensaje de difusión porque debe llegar a todas las máquinas de la red, de manera que pueda recibirlo aquella cuya dirección MAC se pretende conocer.\nEn una captura de Wireshark una petición ARP se muestra con el siguiente resumen:\nPetición ARP (en azul)\rSe trata de un mensaje que, en este caso, tiene origen en el dispositivo Private_66:68:00 y que tiene como destino la dirección de broadcast de la red. Su longitud es de 64 bytes y, como información, Wireshark muestra el mensaje “¿Quién tiene la IP 192.168.122.1? Díselo a 192.168.122.25”.\nRespuesta ARP La respuesta ARP no necesita ser un mensaje de difusión porque su destino es únicamente el mismo dispositivo que ha lanzado la petición de broadcast a toda la red, de manera que el dispositivo que tiene configurada la IP por la que pregunta el equipo de origen contesta sólo a ese equipo con la información de su dirección MAC a través de esta respuesta.\nEn una captura de Wireshark una respuesta ARP se muestra con el siguiente resumen:\nRespuesta ARP (en azul)\rSe trata de un mensaje que, en este caso, tiene origen en el dispositivo RealtekU_e7:19:e0 y que tiene como destino el dispositivo que había lanzando anteriormente la petición: Private_66:68:00. Su longitud es de 46 bytes y, como información, Wireshark muestra el mensaje “192.168.122.1 está en 52:54:00:e7:19:e0”, es decir, un mensaje que relaciona la IP indicada en la petición de broadcast con la MAC del dispositivo que está contestando a la petición.\nEn el detalle, tanto la trama de la petición como la de la respuesta ARP son muy similares y sólo presentan dos diferencias. En primera lugar, la trama de la petición tiene como destino la MAC de broadcast mientras que la respuesta tiene tanto en su origen como en su destino la MAC de dos máquinas concretas dentro de la red.\nPor otra parte, la trama de respuesta incluye información sobre la VLAN a la que pertenece el dispositivo al que se dirige el mensaje.\nPetición ARP\rRespuesta ARP\rLa caché ARP El funcionamiento de la caché ARP se puede demostrar con un pequeño escenario de cuatro ordenadores conectados a un switch. Al crear el escenario en GNS3 y consultar la tabla de caché ARP de cada uno de los ordenadores conectados al switch, la tabla está vacía.\nDespués de hacer ping entre el PC1 y el PC2, ambos guardan una entrada en su tabla ARP. En la tabla ARP de PC1 se recoge la dirección MAC del PC2 junto a su dirección IP y, de la misma manera, en la tabla ARP del PC2 se recoge la dirección MAC del PC1 junto a su IP. En cambio, la tabla ARP del resto de ordenadores continúa vacía.\nSi desde el PC1 se hace un ping al PC3 las tablas ARP de ambos ordenadores se actualizan, de manera que PC1 conserva información de la dirección MAC e IP de PC3 y PC3 tiene información de la dirección MAC e IP de PC1.\nSin embargo, la información de la dirección MAC del PC2 que el PC1 había almacenado después del primer ping ha desaparecido de la tabla. Esto se debe a que esta tabla es de tipo caché y la información que contiene sólo se almacena de forma temporal. De hecho, al consultar la tabla, se muestra también el tiempo que queda para que se borren, de manera automática, cada una de las entras que contiene.\nDe esta manera, si se hace un ping desde PC1 a cada uno de los otros tres ordenadores y se consulta la tabla ARP en un corto período de tiempo, PC1 tendrá almacenadas las direcciones MAC de todos los otros ordenadores de la red. Y el resto de dispositivos tendrán almacenada la dirección MAC de PC1. Pero transcurrido el tiempo indicado en las respectivas tablas ARP para la eliminación de estos registros, todas ellas volverán a estar vacías.\nEl comando ip neigh El comando ip neigh se puede usar para ver o manipular las entradas de la tabla ARP de los dispositivos. Con las diferentes órdenes que admite, ip neigh puede mostrar los dispositivos conectados a la red, mostrar las propiedades de estos dispositivos, añadir nuevas entradas a la tabla ARP o eliminar entradas antiguas de esta tabla.\nLa orden ip neighour add añade una nueva entrada a la tabla ARP, la orden ip neighour change modificada una entrada en la tabla ARP, ip neigh delete elimina una entrada de la tabla ARP, la orden ip neighour replace añade una nueva entrada en la tabla ARP o la modifica si ya existía, ip neighour delete elimina entradas de la tabla ARP, la orden ip neighour flush vacía la tabla ARP o elimina las entradas indicadas, ip neighour show lista las entradas de esta tabla y la orden ip neigh get busca la entrada de la tabla ARP de un destino que corresponde a un dispositivo indicado.\nEn definitiva, el comando ip neigh tiene dos utilidades importantes: por una parte, mostrar la tabla ARP del equipo y filtrar la información que ofrece y, por otra, intervenir sobre los datos que recoge esa tabla.\nPara mostrar la caché ARP se puede ejecutar el comando ip neigh sin más opciones ni argumentos o se puede indicar la opción show. Ambas sintaxis son equivalentes. Este comando devuelve la caché ARP. Todas las entradas de esta tabla mantienen la misma estructura, de manera que recogen, en primer lugar, la IP del dispositivo vecino, a continuación el nombre de la tarjeta de red a la que está conectado ese dispositivo vecino, la dirección del nivel de enlace (lladdr) o MAC y el estado, que se puede identificar como stale, si el dispositivo vecino es válido pero inalcanzable; delay, si la información está obsoleta y se está esperando un respuesta ARP; probe, si se está probando la conexión con el dispositivo vecino; failed, si el dispositivo vecino no es accesible; o reachable, si el dispositivo vecino es válido y accesible.\nUna alternativa al comando ip neighbour o ip neighbour show es el comando arp (o arp -a), que muestra la misma información con una estructura ligeramente diferente. En este caso lista primero el nombre del dispositivo vecino (junto a su dirección IP si se especifica la opción -a). También se muestra la dirección MAC y el estándar que usa la comunicación entre ambos dispositivos. En el formato sin la opción -a se añade también la información sobre el índice de máscara. Finalmente, se indica la interfaz de red a la que se conecta cada uno de los dispositivos vecinos.\nLa otra utilidad principal del comando permite manipular esta tabla ARP añadiendo, modificando o eliminando entradas.\nPara añadir una entrada se debe usar la orden ip neighbour add. En esta orden se debe indicar la IP del dispositivo vecino que se quiere añadir a la tabla, su dirección MAC precedida de la palabra lladdr, el nombre del dispositivo al que se conecta el dispositivo vecino precedido de la palabra dev y el estado de la entrada ARP precedido de la palabra nud. Algunas opciones para el estado de las entradas de la tabla ARP, además de las mencionadas anteriormente stale y reachable, son permanent (o perm) para indicar que la entrada es válida siempre y sólo puede ser eliminada de forma manual por el administrador de la red o noarp para indicar que no es necesario que la entrada se valide porque es válida siempre pero se puede eliminar de forma automática cuando termine su vida útil.\nip neigh add 192.168.10.10 lladdr 00:5v:9d:16:v8:02 dev eth0 nud perm Al igual que ocurre con ip neighbour show, la opción de añadir entradas a la tabla ARP también tiene un equivalente usando el comando arp y la opción -s. En ese caso la sintaxis es arp -s IP MAC.\narp -s 192.168.10.10 00:5v:9d:16:v8:02 Una de las modificaciones habituales que se puede hacer precisamente usando el comando ip neighbour sobre una tabla ARP es cambiar esta etiqueta de estado en las diferentes entradas. Para ello se debe usar la orden ip neighbour chg acompañada de la IP del dispositivo vecino, el nombre de la tarjeta de red a la que se conecta ese dispositivo vecino precedido de la palabra dev y el nuevo estado precedido de la palabra nud.\nPara eliminar entradas de esta tabla se usa la orden ip neighbour delete, acompañada de la IP del dispositivo vecino junto al nombre de la interfaz a la que se conecta ese vecino precedido de la palabra dev.\nip neigh del 192.168.10.10 dev eth0 Su equivalente en el comando arp es la opción -d, seguida de la IP cuya entrada se quiere eliminar de la tabla ARP.\narp -d 192.168.10.10 Además, para eliminar una o todas las entradas de una tabla ARP se puede usar también la opción ip neighbour flush seguido de all si se pretende vaciar la caché.\nip -s -s neigh flush all O seguido de la dirección IP correspondiente a la entrada de la caché ARP que se busque eliminar.\nip -s -s neigh flush 192.168.10.10 ARP gratuito Los mensajes ARP gratuitos son aquellos que se envían sin esperar ninguna respuesta ARP a cambio o que no responden a ninguna petición ARP. Son mensajes que los equipos de una red utilizan para informar a sus dispositivos vecinos de cuál es su dirección IP y su dirección MAC.\nEste tipo de mensajes siempre tiene como MAC de destino la dirección de difusión. Una particularidad del ARP gratuito es que usa como IP de destino y también como IP de origen la IP del propio equipo que emite el mensaje, de manera que el mensaje confirma al receptor la IP que se relaciona con la dirección MAC de origen.\nEl ARP gratuito es útil en el proceso de arranque de una máquina, cuando el equipo lo puede usar para comunicar su IP y su MAC al resto de la red. El objetivo de estos mensajes en este caso es anunciar a la red que existe el dispositivo que se acaba de conectar y que forma parte de la misma e incluir su información en la caché ARP de los dispositivos vecinos sin pedirles iniciar un proceso de comunicación ARP completo.\nLos dispositivos que reciben este tipo de mensajes no necesariamente guardarán esta información en sus tablas ARP, por lo que no siempre es beneficioso para los equipos de la red emplear el ARP gratuito. Sin embargo, tampoco supone ningún problema su uso.\nAdemás, este tipo de mensajes ARP también se usa para mantener actualizadas las tablas ARP de dispositivos como los switches. En estos casos, un nodo puede enviar un mensaje de difusión ARP gratuito para informar al resto de dispositivos de la red de que la dirección MAC que se corresponde con su IP ha cambiado y esa información necesita ser actualizada en la tabla ARP del resto de dispositivos vecinos.\nEste escenario se puede producir cuando se modifica manualmente la dirección MAC de un dispositivo. Aunque esto es poco habitual, puede ocurrir, por ejemplo, al abrir una máquina virtual en un dispositivo diferente al de su creación. En este caso, la máquina virtual tendrá la misma IP pero su dirección MAC será diferente.\nEl ARP gratuito es fundamental, además, en redes en las que hay dispositivos configurados de manera redundante. En estos casos, se pueden incluir en las redes dispositivos que comparten una misma IP y pueden compartir o no una dirección MAC. Cuando esto ocurre, la única forma de garantizar que la comunicación se mantiene entre todos los dispositivos de la red es a través del uso de los mensajes de ARP gratuito.\nEn el caso de que haya redundancia de IP entre dos dispositivos, es decir, cuando dos dispositivos tienen una misma IP pero direcciones MAC diferentes, el ARP gratuito se usa para informar al resto de dispositivos de la red con cual de los dos dispositivos se debe comunicar en cada momento. Por ejemplo, si alguno de ellos experimenta un error en su funcionamiento, el otro enviará un mensaje ARP gratuito indicando al resto de vecinos de la red que la suya es la nueva dirección MAC a la que se deben dirigir los paquetes que tengan como destino la IP redundante. Este mensaje modificará las tablas ARP de los dispositivos de la red para garantizar la comunicación entre ellos.\nEn ocasiones esta redundancia también se da no sólo entre la IP de dos dispositivos sino también entre su dirección MAC de manera que ambos quedan identificados por la misma IP y MAC dentro de la red. En este caso, la información de las tablas ARP del resto de dispositivos de la red no debe experimentar ninguna modificación en caso de avería de alguno de estos dispositivos redundantes pero el switch sí necesita saber que este cambio se ha producido.\nPara ello, ante un fallo en el funcionamiento de uno de los dispositivos redundantes, el otro envía un paquete ARP gratuito a la red. Al recibir este paquete, el switch actualiza su tabla de direccionamiento, de manera que pueda redirigir los paquetes que tienen como destino la IP y la MAC redundante hacia el puerto en el que esté conectado el dispositivo que ha emitido el mensaje ARP gratuito. Esta modificación garantiza la comunicación entre el dispositivo con IP y MAC redundante y el resto de dispositivos de la red.\nARP spoofing El ARP spoofing consiste en la suplantación de un equipo de la red local a través del protocolo ARP. Esto se consigue enviando información falsa a los equipos conectados a una red de manera que el atacante suplanta con su propia dirección MAC la MAC de uno de los equipos de la red. Habitualmente, la MAC suplantada suele ser aquella que esté asociada a la IP de la puerta de enlace, lo que permite interceptar todas las comunicaciones que circulan entre la red local y el resto de redes. Para suplantar una dirección MAC, los atacantes suelen enviar respuestas ARP gratuitas que no responden a ninguna petición de ningún equipo y así alteran las tablas ARP de los dispositivos de la red.\nUna vez que ha suplantado a este dispositivo, el atacante puede recopilar la información que circula por la red dirigida a la IP asociada a la MAC suplantada y también puede controlar el tráfico de la red porque una vez que recibe la información dirigida a la MAC suplantada puede reenviar el tráfico a la MAC real que ha sido suplantada, modificarlos o bloquearlos.\nSi el atacante reenvía el tráfico a la MAC original el ataque puede ser pasivo o activo según si altera o no esos datos durante el ataque, respectivamente. En estos casos se puede usar el ARP spoofing para realizar un ataque de tipo Man in the middle, en el que el atacante intercepta las comunicaciones entre dos partes de forma clandestina para extraer información o para controlar o manipular los mensajes que circulan en esa comunicación.\nSi el atacante interrumpe el tráfico y no lo reenvía a la MAC suplantada se puede usar el ARP spoofing para realizar un ataque de tipo DoS (denegación de servicio), que consiste en enviar una gran cantidad de mensajes ARP asignando múltiples direcciones IP a una sola MAC hasta que la máquina de destino no pueda gestionar semejante cantidad de respuestas ARP.\nPor las características de este tipo de ataques, el ARP spoofing no se puede llevar a cabo de manera remota excepto si se puede acceder a una máquina que forme parte de la red que se quiere atacar. El envenenamiento ARP requiere que la máquina que lo ejecute esté conectada a la red sobre la que se lleva a cabo el ataque, ya sea ésta la máquina del atacante o una máquina de la red vulnerable a la que el atacante pueda acceder de manera remota.\nExisten varias formas de proteger una red frente a este tipo de ataques. La más evidente es usar tablas ARP estáticas, evitando el uso de caché dinámicas y asignando de manera manual una dirección MAC a cada IP de cada dispositivo de la red en cada uno de los dispositivos que deban establecer conexiones entre ellos. Evidentemente, esta solución no es práctica en la mayoría de casos y sólo es viable en redes muy pequeñas. En el resto de casos, crear y mantener actualizadas las tablas ARP de forma manual resulta una tarea completamente inabordable.\nCon la inspección o snooping de DHCP un dispositivo de red puede guardar un registro de las direcciones MAC de todos los dispositivos que están conectados a cada uno de sus puertos para detectar así cualquier suplantación de ARP.\nAdemás, existe software desarrollado con el objetivo de detectar estas suplantaciones como Arpwatch, que monitoriza las tablas ARP de la red y notifica a su administrador cada vez que se produce un cambio en una entrada de una de ellas. Este tipo de herramientas también permite controlar qué dispositivos hay conectados a la red y qué programas están usando la conexión. Igualmente, pueden llegar a detectar e identificar posibles dispositivos que puedan ser intrusos en la red para evitar que accedan a ella.\nUna práctica útil para evitar o minimizar la gravedad de los ataques con ARP spoofing puede ser subdividir la red, ya sea de manera física o de manera lógica mediante el uso de VLAN. Así se consigue evitar que un ataque acceda a toda la red y se limita su impacto únicamente a la parte que presenta alguna vulnerabilidad.\nEn sistemas y redes modernas se pueden implementar también protocolos de seguridad como el Secure Neighbour Discovery (SEND), que garantiza, a través de algoritmos de encriptación, que los mensajes que recibe un equipo de una red provienen del equipo de origen del que dicen provenir y, por lo tanto, verifica que estos mensajes no han sido interceptados en el trayecto.\nPor último, está también la posibilidad de comprobar si hay direcciones MAC clonadas en la red. Habitualmente, cuando una dirección MAC corresponde a más de una dirección IP se puede tomar como un indicio de que se puede estar produciendo una suplantación de ARP, aunque no siempre tiene por qué ser así. Se puede usar el protocolo RARP que, a la inversa que el ARP, permite consultar las direcciones IP asociadas a una dirección MAC para comprobar si existen en la red direcciones MAC que cumplan esta característica y analizar los motivos por los que esa MAC tiene más de una IP asociada. De esta forma, se pueden detectar este tipo de ataques ARP spoofing.\nAtaque ARP spoofing en Wireshark\nUn ataque de tipo ARP spoofing se puede detectar en Wireshark atendiendo a dos criterios. En primer lugar, como se puede observar en los dos primeros paquetes capturados, el dispositivo que realiza el ataque, con la MAC 00:0C:29:A5:89:97 tiene dos direcciones IP diferentes asociadas a su misma dirección MAC.\nAdemás, se recogen varios paquetes de tipo ARP reply desde el dispositivo atacante (00:0C:29:A5:89:97) a las otras dos máquinas de la red que no responden a ninguna petición desde éstas. Es decir, no hay ningún mensaje con el contenido “¿Quién es 192.168.253.131? Díselo a 192.168.253.128” o “¿Quién es 192.168.253.128? Díselo a 192.168.253.133” pero sí que hay varios paquetes con el mensaje “192.168.253.131 está en 00:0C:29:A5:89:97” y “192.168.253.128 está en 00:0C:29:A5:89:97”, que son los que el atacante está utilizando para hacer llegar su MAC a las tablas ARP de los otros dos ordenadores de la red.\nMAC flooding La técnica de MAC flooding o MAC attack se utiliza para atacar a los switches de una red local e interceptar información de sus usuarios. Consiste en inundar la tabla de direcciones MAC de los switches de la red con direcciones falsas. Para ello, el atacante envía múltiples paquetes con direcciones MAC de origen falsas que el switch guarda en su tabla de direcciones MAC hasta que se llena y no es capaz de almacenar más información.\nEntonces, el switch comienza a tener un funcionamiento más parecido al de un hub, de manera que transmite todos los paquetes que recibe a todos sus puertos para que pueda mantenerse la comunicación entre todos los dispositivos de la red. Esta técnica da acceso al atacante a todos los dispositivos conectados a cada uno de estos puertos del switch.\nCuando esta técnica tiene éxito, el atacante puede usar una herramienta de análisis de paquetes para capturar la información sensible que circula por la red entre otros equipos y que no sería accesible si la tabla de direccionamiento MAC del switch estuviese funcionando correctamente. Tras realizar un ataque MAC flooding se puede ejecutar un ataque ARP spoofing sobre la red vulnerable, lo que permitiría al atacante seguir teniendo acceso a la red incluso aunque la tabla de direccionamiento MAC del switch recupere su correcto funcionamiento.\nEs difícil detectar este tipo de ataques si no se mantiene una monitorización de la red, ya que los indicios de que se está produciendo un ataque pueden responder a múltiples factores. Por ejemplo, este tipo de ataques se puede detectar cuando a un dispositivo comienza a llegar tráfico de la red que está dirigido a otros equipos. Adicionalmente, los ataques MAC suelen implicar un aumento drástico del tráfico en la red o un reducción en la velocidad.\nAunque las medidas de seguridad para proteger a las redes frente a los ataques de tipo ARP spoofing pueden ayudar a prevenir ataques MAC, para evitar este tipo de ataques existen estrategias de seguridad específicas como el port security, un mecanismo que incluyen los routers y los switches que limita el número de direcciones MAC que pueden añadir a su tabla de direccionamiento a la vez que permite especificar que unas direcciones MAC determinadas no se puedan sobrescribir, lo que le permite al dispositivo conservar la información de las direcciones MAC reales de la red en caso de un desbordamiento de direcciones MAC. Además, port security permite al switch bloquear el puerto desde el que sospecha que se está produciendo uno de estos ataques.\nEn este caso, segmentar la red mediante la configuración de VLAN virtuales no tendria efecto para limitar un ataque MAC flooding, ya que en caso de que éste se produzca, el switch desbordará la información que pase por él a todos los puertos, independientemente de la VLAN a la que pertenezcan.\nAdicionalmente, el filtrado de direcciones MAC permite que el switch sólo acepte paquetes que tengan como origen una MAC conocida, de manera que todas aquellas direcciones MAC de origen de los paquetes recibidos por el switch que no estén incluidas en la lista de direcciones conocidas no se guardarán en su tabla de direccionamiento MAC y, por tanto, se evitará así que esta tabla se pueda llenar.\nFinalmente, se debe tener en cuenta que el uso de herramientas para monitorizar el tráfico de la red es una estrategia fundamental en la prevención y detección de este y otros tipos de ataque. Algunas de estas herramientas cuentan con configuraciones específicas que permiten detectar de forma automática estos ataques y bloquear el tráfico proveniente de los dispositivos que los están ejecutando.\nAtaque MAC flooding en Wireshark\nComo se muestra en esta imagen, una forma sencilla de detectar un ataque de MAC flooding en una captura de tráfico de Wireshark es observando cómo aparecen en ella más direcciones MAC que dispositivos hay en la red. De hecho, en este ejemplo concreto es muy evidente que lo que se está produciendo es un ataque de este tipo porque se recoge un aumento drástico del tráfico en un momento puntual y, además, se encuentra un paquete, el seleccionado en azul, que corresponde a un ping entre dos ordenadores (192.168.12.1 y 192.168.12.2) ajenos en la red que, si no se estuviese produciendo el ataque, no debería llegar al ordenador que realiza la captura (192.168.12.16).\nMAC spoofing La técnica de MAC spoofing o broadcast spoofing consiste en cambiar a ojos del sistema operativo la dirección MAC de un dispositivo. Esta técnica inhibe la utilidad de las listas de control de acceso en routers y switches además de permitir que se oculte un dispositivo en la red o que suplante la dirección MAC de otro.\nPara llevar a cabo un ataque con MAC spoofing un atacante puede emplear diferentes estrategias. Entre ellas, puede manipular directamente el hardware de su tarjeta de red con un switch interno que le permita modificar la MAC de origen en los mensajes que salen de ella pero también puede usar un tercer dispositivo entre el atacante y el switch de la red para hacer llegar sus mensajes con la dirección MAC del dispositivo legítimo de la red. Otra técnica de MAC spoofing empleada habitualmente consiste en usar la dirección MAC de un punto de acceso legítimo de la red o interceptar paquetes que circulan por la red con una MAC de origen legítima que se quiere suplantar y modificar el contenido de esos paquetes para hacerlos llegar al destino deseado.\nEsta técnica se usa con mucha frecuencia para atacar redes inalámbricas, especialmente redes wifi, y tener acceso a las credenciales de los usuarios. Por ejemplo, permite crear puntos de acceso no autorizados que suplantan la dirección MAC del punto de acceso legítimo a los que los usuarios se conectan usando sus credenciales. De esta manera, el atacante puede tener acceso a esta información, que pasa por el falso punto de acceso antes de llegar al legítimo.\nComo ocurre con los ataques de ARP spoofing y de MAC flooding, la técnica del MAC spoofing requiere que el ataque se realice desde dentro de la propia red local, lo que obliga al atacante a estar físicamente cerca de esta red.\nAlgunas medidas de prevención contra los ataques MAC spoofing pueden ser controlar que la red no es accesible a través de ningún puerto o servicio que no sea necesario, usar Firewall que añadan niveles de seguridad a la red y permitan un mayor control sobre los datos que circulan por ella o usar métodos de autenticación seguros como, por ejemplo, la autenticación en dos pasos.\nConviene tener en cuenta que tecnologías como el Bluetooth pueden ser especialmente vulnerables a este tipo de ataques y pueden permitir al atacante tener acceso a información como la dirección MAC del dispositivo con la que podría suplantar un punto de acceso no autorizado.\n"},{
  "section": "Blog",
  "slug": "/blog/sistemas/2024-02-04-gestion-sistema-ficheros-debian/",
  "title": "Creación y configuración de un sistema de ficheros en Debian 12",
  "description": "",
  "date": "February 4, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "sistemas",
  "tags": "sistemas, debian, linux, comandos, sistema de ficheros, Implantación de Sistemas Operativos",
  "content":"En este post se plantea un caso práctico en el que se emplean varios comandos para la configuración de sistemas de ficheros en Debian. En concreto, se trata de un ejemplo en el que se instala Debina 12 en una máquina con recursos limitados en VirtManager y, posteriormente, se amplía el espacio de almacenamiento añadiendo un nuevo disco duro y clonando el sistema en él.\nInfo\nPara este post se usan qemu/kvm y VirtManager como software de virtualización. Aquí te explico cómo instalarlo en Debian.\nParticionado de los discos Disco de origen Durante el proceso de instalación de Debian12 en la máquina virtual se definen las siguientes particiones:\nPartición efi: 50MB. Partición /: 2GB. Swap: el resto de espacio sobrante. Disco de destino Para crear un nuevo disco duro en VirtManager es necesario acceder a la ventana “añadir hardware” desde la configuración de la máquina virtual. A continuación, se debe indicar el tamaño del dispositivo y, por último, pulsar el botón de crear. Tras seguir estos pasos, el nuevo disco duro se habrá añadido a la máquina virtual y ya estará disponible en la lista de dispositivos que aparece en la ventana de configuración.\nAl listar los dispositivos de bloque con el comando lsblk -f también deberían aparecer en la máquina tanto el disco duro original (vda), de 2GB, como el segundo disco duro (vdb), de 10GB.\nPara crear el particionado del disco duro en Debian se pueden usar aplicaciones como fdisk o gdisk. En este caso se ha optado por el uso del comando fdisk. En primer lugar, se debe establecer una nueva tabla de particiones GPT vacía con el comando g.\nPosteriormente, para cada partición, se crea, se le asigna un número, primer y último sector (tamaño).\nTras crear todas las particiones necesarias en el disco duro, el comando fdisk permite también asignarles un tipo determinado hasta llegar a tener una tabla de particiones como la siguiente:\nCreación del sistema de ficheros Para asignar un sistema de ficheros a cada partición se usa el comando mkfs seguido de .fs donde \u0026ldquo;fs\u0026rdquo; es el sistema de ficheros que se busca asignar a cada partición. La primera de las particiones listadas anteriormente usará un sistema de ficheros de tipo vfat y el resto uno de tipo ext4. Para poder asignar el sistema de ficheros FAT32 a la partición de tipo EFI se debe instalar previamente el paquete dosfstools.\nTras la instalación de este paquete se pueden usar los comandos mkfs.vfat y mkfs.ext4 para dar formato a cada una de las particiones. Por último, para darle un sistema de ficheros de tipo swap a la última partición del nuevo disco duro se puede usar el comando mkswap.\nmkfs.vfat /deb/vdb1 mkfs.ext4 /deb/vdb2 mkfs.ext4 /deb/vdb3 mkfs.ext4 /deb/vdb4 mkfs.ext4 /deb/vdb5 mkfs.ext4 /deb/vdb6 mkswap /dev/vdb7 Montaje del nuevo disco El primer paso para montar el nuevo disco en la máquina es crear un punto de montaje. Para ello, se usará el directorio /mnt y en él, se habilitarán nuevos directorios con mkdir que sirvan de punto de montaje para cada una de las particiones del nuevo disco duro.\nmkdir -p /mnt/vdb/vdb{1..7} A continuación, se pueden montar las diferentes particiones sobre cada uno de sus nuevos puntos de montaje y también se puede habilitar la nueva partición swap en el equipo.\nmount /dev/vdb1 /mnt/vdb/vdb1 mount /dev/vdb2 /mnt/vdb/vdb2 mount /dev/vdb3 /mnt/vdb/vdb3 mount /dev/vdb4 /mnt/vdb/vdb4 mount /dev/vdb5 /mnt/vdb/vdb5 mount /dev/vdb6 /mnt/vdb/vdb6 swapon /dev/vdb7 En este punto, todas las particiones del nuevo disco duro están montadas en sus respectivos puntos de montaje y funcionando con el sistema de ficheros adecuado que se le ha asignado previamente durante este proceso.\nVolcado de información al nuevo disco Una vez que el nuevo disco está funcionando en la máquina, se debe trasladar la información a sus nuevas ubicaciones. Para ello se usará el comando cp para copiar los contenidos de los diferentes directorios del disco original (vda), de 2GB al nuevo disco (vdb) de 10GB.\nDirectorio /home El primer directorio que se trasladará al nuevo disco será el directorio /home. Para ello, el primer paso debe ser copiar el contenido del directorio /home del disco duro original en la partición 4 del nuevo disco duro.\ncp -r /home/* /mnt/vdb/vdb4 A continuación, se habilitará como punto de montaje de esta partición el directorio /home del sistema en el fichero de configuración /etc/fstab con el formato\nPARTLABEL=\u0026#34;/home\u0026#34; /home ext4 defaults 0 0 Adicionalmente, se puede copiar el contenido de este directorio en el disco duro original con el nombre /home.old para garantizar que no se pierde esta información.\ncp -r /home /home.old Directorio /var Para volcar la información del directorio /var al nuevo disco se debe seguir el mismo procedimiento. De esta manera, en primer lugar se copiará la información del directorio a la partición del disco que se montará a continuación en este punto, en este caso la partición 5.\ncp -r /var/* /mnt/vdb/vdb5 El siguiente paso es añadir este nuevo punto de montaje al fichero de configuración /etc/fstab.\nDirectorio /usr De la misma forma que en los casos anteriores, para volcar la información de este directorio al nuevo disco se usa el comando cp.\ncp -r /usr/* /mnt/vdb/vdb6 A continuación, se configura este nuevo punto de montaje en el fichero /etc/fstab.\nPartición EFI Una vez que todos los directorios están copiados y montados en sus nuevos puntos de montaje, se debe repetir la misma operación con la EFI, el directorio de arranque /boot, en el que está el kernel del sistema operativo y el resto de contenidos del directorio raíz.\nPara trasladar la EFI a su nuevo disco, se procede de la misma forma. La información de arranque del sistema se encuentra en el directorio /boot/efi, por lo que será éste el que se copie a la partición 1 del nuevo disco duro.\ncp -r /boot/efi/* /mnt/vdb/vdb1 Y, al igual que en los casos anteriores, se indicará el nuevo punto de montaje de la EFI en el fichero de configuración /etc/fstab. En este caso, además para evitar duplicidades con el punto de montaje, se debe comentar la línea correspondiente a la partición EFI del anterior disco duro.\nDirectorio /boot La siguiente modificación que se puede aplicar es la del directorio /boot. Para ello se procederá como con el resto de directorios que ya se han trasladado con éxito al nuevo disco duro.\nEn primer lugar se copia el contenido del directorio a la partición correspondiente del nuevo disco.\ncp -r /boot/* /mnt/vdb/vdb2 Y, a continuación, se indica el nuevo punto de montaje en el fichero de configuración fstab.\nDirectorio raíz En este punto llega el momento de trasladar todo el resto del sistema al nuevo disco duro. Para esta tarea se puede usar la opción -t del comando cp, que copia todos los ficheros indicados como origen en un directorio marcado como destino con esa opción. Pero durante el proceso de copia de todos estos directorios, que suponen un gran volumen de información, el comando cp devuelve los siguientes mensajes de error debido a la falta de espacio en el dispositivo.\nSe da una situación llamativa puesto que el espacio del directorio raíz completo en el disco original es de sólo 1,8GB, mientras que en el nuevo disco duro parece que ya se han ocupado los 3,4GB destinados a esta partición.\nPara solucionar este problema, se puede arrancar la máquina en modo recuperación con sistema operativo live y, desde el intérprete de comandos, montar, por una parte, el directorio raíz del antiguo disco duro, en este caso en el directorio /mnt/vda/vda3, y, por otra parte, la partición del nuevo disco duro donde se quiere trasladar esa información, en este caso, en el directorio /mnt/vdb/vdb3. Con ambas particiones montadas en el directorio /mnt del sistema operativo live, ya se puede ejecutar el comando de copia como se muestra en la siguiente captura de pantalla.\ncp -r /mnt/vda/vda3/bin/ /mnt/vda/vda3/dev/ /mnt/vda/vda3/etc/ /mnt/vda/vda3/initrd.img /mnt/vda/vda3/initrd.img.old /mnt/vda/vda3/lib/ /mnt/vda/vda3/lib32/ /mnt/vda/vda3/lib64/ /mnt/vda/vda3/libx32/ /mnt/vda/vda3/lost+found/ /mnt/vda/vda3/media/ /mnt/vda/vda3/mnt/ /mnt/vda/vda3/opt/ /mnt/vda/vda3/proc/ /mnt/vda/vda3/root/ /mnt/vda/vda3/run/ /mnt/vda/vda3/sbin/ /mnt/vda/vda3/srv/ /mnt/vda/vda3/sys/ /mnt/vda/vda3/tmp/ /mnt/vda/vda3/vmlinuz /mnt/vda/vda3/vmlinuz.old -t /mnt/vdb/vdb3 Tras esta copia, todo el contenido del directorio raíz del disco duro original se ha copiado en la partición del nuevo disco duro que debe albergar todo ese contenido, excepto los directorios que ya se han movido a sus correspondientes nuevas particiones.\nEn este caso, también resulta llamativa la diferencia de tamaño entre el directorio raíz del disco duro original y el directorio raíz del nuevo disco duro: 1,7GB frente a sólo 3,8MB. Esta diferencia se puede explicar, en parte, porque en este nuevo directorio raíz ya no están directorios como el /var o el /usr, que contienen una parte importante de la información del sistema.\nEl sistema operativo live puede ser un buen entorno para terminar de conformar el nuevo fichero de configuración /etc/fstab en este segundo disco duro antes de volver a arrancar la máquina.\nSi tenemos en cuenta que este debería ser el nuevo fichero fstab del equipo, cabe eliminar las líneas que dirigían a particiones del anterior disco duro e indicar, exclusivamente, en qué punto del sistema se deben montar las nuevas particiones que, en este punto de la instalación, deberían contener ya toda la información para el funcionando del equipo.\nArrancar con el nuevo disco duro y resolución de problemas Para el siguiente arranque de la máquina se configura el nuevo disco duro como dispositivo de arranque pero, al intentar arrancar la máquina sin el disco original, el equipo no consigue comenzar a funcionar.\nTras comprobar que todos los ficheros y directorios del sistema se han copiado correctamente a sus particiones de destino se encuentran dos errores importantes para el funcionamiento del sistema.\nEn primer lugar, durante el proceso de volcado de la información al nuevo disco duro no se habían creado los directorios /boot, /home, /var y /usr en el directorio raíz y, por tanto, estas particiones no tenían un punto en el que montarse. Para crear estos directorios que servirán como punto de montaje a las diferentes particiones se puede montar el dispositivo de bloques en el entorno del instalador de un sistema operativo live.\nSe debe montar la partición que contiene la raíz, en este caso /dev/vdb3 y, a continuación, crear en ella los directorios indicados anteriormente.\nmkdir -p /mnt/vdb/vdb3/boot mkdir -p /mnt/vdb/vdb3/home mkdir -p /mnt/vdb/vdb3/var mkdir -p /mnt/vdb/vdb3/usr Tras haber creado estos directorios en el sistema del nuevo disco duro, ya se puede ejecutar este sistema de archivos desde una terminal en el sistema operativo live. Pero al consultar los dispositivos de bloque montados en el sistema llama la atención que en el punto de montaje /boot/efi no se monta la partición del nuevo disco duro, sino la del disco original de 2GB.\nEsto lleva a comprobar el fichero de configuración /etc/fstab en el que se indican los puntos de montaje de cada una de las partes del sistema. Parece que todas las particiones están correctamente configuradas, en concreto, la partición EFI no presenta ningún error que llame la atención en un primer momento y, como se puede ver, la partición del disco duro original está comentada, por lo que no se debería montar.\nUn forma alternativa de montar la partición puede ser referirse a ella por UUID en vez de usar el nombre del partlabel. Pero, al consultar este identificador, se descubre cuál es el problema que estaba haciendo que se montase la partición EFI del disco vda, en vez de la del disco vdb: las etiquetas partlabel se habían intercambiado en el fichero fstab. Como muestra la salida del comando blkid, la etiqueta de la partición EFI nueva es “UEFI” y no “efi”, como indicaba el fichero fstab y que, en realidad, estaba indicando que se debía montar la partición EFI del dispositivo de bloques /dev/vda.\nTras localizar el error, la solución es tan sencilla como cambiar la etiqueta de la partición en el fichero de configuración.\nWarning\nEs recomendable extremar la precaución a la hora de usar el campo PARTLABEL para identificar particiones o usar métodos alternativos como el identificador único UUID para evitar este tipo de errores.\nUna vez hecho esto, se debe reinstalar el cargador de arranque grub en el nuevo sistema. En este caso, se puede hacer desde la interfaz gráfica del modo rescate del sistema operativo live.\nTras realizar estos pasos, se puede comprobar que, al reiniciar el equipo el sistema ya lanza el grub con las diferentes opciones de arranque.\nAdemás, si se accede a la configuración del firmware de la UEFI ya aparece como primera opción en el menú de arranque el sistema operativo que se ha configurado a lo largo de esta práctica en el nuevo disco duro. Pero este sistema aún no permite el arranque. Al lanzarlo se muestra un error que indica que no se encuentra uno de los dispositivos y tampoco localiza uno de los ficheros que debería estar ubicado en el directorio /boot.\nPara localizar el dispositivo que está resultando problemático se puede ejecutar el sistema usando un sistema operativo live y, una vez que se esté trabajando con él se puede buscar a qué dispositivo hace referencia ese UUID.\nEn concreto, se trata del disco /dev/vda3, que es la partición del disco original que contiene el sistema. Este disco no debería montarse durante el arranque, puesto que debería producirse con el nuevo disco configurado.\nEn segundo lugar, el fichero que no se ha podido encontrar debería estar en la partición que contiene el directorio boot en el nuevo disco duro. Al montar esta partición en un entorno de instalador y listar su contenido, el fichero no encontrado aparece ubicado correctamente en la partición del disco duro.\nTambién en la partición que contiene la raíz se encuentra el enlace que apunta al fichero que no se había encontrado en el directorio /boot.\nPara intentar solucionar estos errores, se puede intentar reinstalar el grub desde la terminal que proporciona este sistema operativo live con el sistema del nuevo disco duro arrancado.\ngrub-install Durante el proceso se indica que el sistema no soporta las variables EFI. Para solventar este problema se deben cargar estas variables.\nmount -t efivarfs none /sys/firmware/efi/efivars/ En este caso, el grub se instala sin devolver ninguna advertencia.\nEl siguiente paso necesario tras la instalación del grub es su actualización. Durante este proceso, parece que el grub ha conseguido encontrar los ficheros que, en el anterior inicio no se habían podido localizar.\nupdate-grub Finalmente, después de haber reinstalado y actualizado el grub a través de la terminal, el nuevo sistema ha arrancado en el siguiente reinicio sin ningún problema y se han montado correctamente todas las particiones en los puntos de montaje indicados.\nEn este punto, el sistema se ha trasladado completamente al nuevo disco duro, que ya ofrece un sistema 100% funcional con el espacio de almacenamiento más ampliado.\n"},{
  "section": "Blog",
  "slug": "/blog/sistemas/2024-02-03-instalar-qemu-kvm-virtualizacion-debian/",
  "title": "Cómo instalar qemu/kvm en Debian 12 para virtualizar equipos",
  "description": "",
  "date": "February 3, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "sistemas",
  "tags": "sistemas, debian, linux, comandos, qemu, virtualizacion, virtmanager, kvm, Implantación de Sistemas Operativos",
  "content":"Qemu es un potente virtualizador que permite el uso de máquinas virtuales en equipos que usen sistemas operativos basados en Debian y otras distribuciones GNU/Linux. Este software se complementa a la perfección con VirtManager, que ofrece una interfaz gráfica amigable para realizar todas las tareas relacionadas con la virtualización.\nAntes de comenzar con la instalación de estos paquetes es necesario saber si el equipo tiene capacidad para virtualizar. Con lshw se comprueba que el ordenador ofrece esta posibilidad. Para ello se busca la bandera “vmx” o “smv”, que indica si el microprocesador tiene activada esta opción:\nlshw | egrep -o ‘vmx|smv’ Además, con cpu-checker se puede comprobar si el ordenador tiene capacidad para virtualizar con kvm con el comando kvm-ok.\nPosteriormente se instalan los paquetes necesarios.\nsudo apt update sudo apt install qemu-system libvirt-clients libvirt-daemon-system bridge-utils virt-manager Para comprobar si la instalación ha generado los grupos kvm y libvirt se consulta el fichero de configuración /etc/group.\nCon adduser ‘nombre de usuario’ ‘nombre de grupo’ se añade el usuario a los grupos kvm y libvirt.\nadduser usuario kvm adduser usuario libvirt Se usa el comando systemctl con la opción status y el argumento libvirtd para comprobar si el servicio está funcionando. Con las opciones start o enable se arranca o activa el arranque automático del servicio.\nsudo systemctl status libvirtd sudo systemctl enable libvirtd sudo systemctl start libvirtd "},{
  "section": "Blog",
  "slug": "/blog/fundamentos-hardware/2024-02-01-comando-parted/",
  "title": "Ejemplos de uso del comando parted en Debian",
  "description": "",
  "date": "February 1, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "fundamentos-hardware",
  "tags": "Fundamentos de Hardware, debian, linux, comandos básicos, parted, comandos",
  "content":"Parted es un programa que manipula particiones de disco. Soporta múltiples formatos de tablas de particiones como MS-DOS y GPT. Es útil para crear espacio para nuevos sistemas operativos, reorganizar el uso del disco y copiar su contenido a un nuevo disco duro.\nAsí, parted permite crear, destruir, redimensionar, mover y copiar particiones de disco. Este programa puede usar múltiples formatos de particiones, tales como DOS, Mac, Sun, BSD, GPT, MIPS y PC98, así como el tipo loop que permite su uso en RAID/LVM.\nAdemás, parted puede detectar y eliminar sistemas de archivos ASFS/AFFS/APFS, Btrfs, ext2/3/4, FAT16/32, HFS, JFS, linux swap, UFS, XFS y ZFS. Por otra parte, este programa también puede crear y modificar sistemas de archivos de algunos de estos tipo.\nEl uso de parted debe ser cuidadoso porque un error en su utilización puede provocar una pérdida de datos en el disco duro, por lo que es aconsejable hacer una copia de seguridad del contenido del disco antes de trabajar con este programa de particionado como con el resto de herramientas de este tipo.\nSintaxis La sintaxis para invocar a este programa es:\nparted [opciones] [dispositivo [orden [opciones…]…]] De manera que se puede lanzar el programa desde la línea de comandos sin ninguna opción ni argumento y una vez iniciado, indicar las diferentes acciones y dispositivos sobre los que se desea trabajar.\nTambién existe la opción de trabajar en una sola línea de comandos indicando junto al nombre del programa, las opciones que se desean usar y los dispositivos sobre los que se van a realizar las tareas indicadas.\nOpciones Algunas opciones generales para el uso del comando parted son:\n-h, --help. Muestra un mensaje de ayuda. -l, --list. Lista las particiones de todos los dispositivos de bloques. -m, --machine. Devuelve la información en modo analizable. -s, --script. Nunca pide la intervención del usuario. -a alineación, --align=alineación. Determina el tipo de alineación para las nuevas particiones. Los tipos que se pueden usar son none, que usa la mínima alineación permitida por el tipo de disco; cylinder, que alinea las particiones a los cilindros; minimal, que usa la mínima alineación necesaria para alinear las particiones lógicas a los bloques físicos; y optimal, que alinea las particiones a un múltiplo del tamaño físico del bloque, de manera que garantice un funcionamiento óptimo. Estas opciones no tienen mucho sentido en la actualidad puesto que ya se suele trabajar con discos de estado sólido y este modo de trabajar con las particiones está orientado al uso de discos mecánicos, cada vez más en desuso. Órdenes Tras la opción u opciones que se deban especificar en el uso de parted, se puede indicar también uno o varios dispositivos sobre los que el programa debe trabajar. Si no se indica ningún dispositivo de bloques, parted usará el primero que encuentre. Posteriormente, también se pueden indicar las órdenes que el programa debe llevar a cabo sobre cada uno de los dispositivos indicados. Alguna de estas órdenes pueden ser:\nhelp. Muestra la ayuda general o la ayuda de una orden específica indicada. mklabel. Crea una nueva tabla de particiones del tipo indicado entre las opciones \u0026ldquo;aix\u0026rdquo;, \u0026ldquo;amiga\u0026rdquo;, \u0026ldquo;bsd\u0026rdquo;, \u0026ldquo;dvh\u0026rdquo;, \u0026ldquo;gpt\u0026rdquo;, \u0026ldquo;loop\u0026rdquo;, \u0026ldquo;mac\u0026rdquo;, \u0026ldquo;msdos\u0026rdquo;, \u0026ldquo;pc98\u0026rdquo; o \u0026ldquo;sun\u0026rdquo;. mkpart. Crea una nueva partición. Si se está usando una tabla de particiones de tipo msdos o dvh se debe especificar si la partición es primaria, lógica o extendida. Si la tabla de particiones es de tipo GPT, se debe indicar un nombre de la partición y, adicionalmente, se puede indicar el sistema de ficheros que se quiere usar en la partición entre las opciones que permite parted: \u0026ldquo;btrfs\u0026rdquo;, \u0026ldquo;ext2\u0026rdquo;, \u0026ldquo;ext3\u0026rdquo;, \u0026ldquo;ext4\u0026rdquo;, \u0026ldquo;fat16\u0026rdquo;, \u0026ldquo;fat32\u0026rdquo;, \u0026ldquo;hfs\u0026rdquo;, \u0026ldquo;hfs+\u0026rdquo;, \u0026ldquo;linux-swap\u0026rdquo;, \u0026ldquo;ntfs\u0026rdquo;, \u0026ldquo;reiserfs\u0026rdquo;, \u0026ldquo;udf\u0026rdquo; o \u0026ldquo;xfs\u0026rdquo;. A diferencia del resto de herramientas de particionado que se han usado en clase, parted permite dar un sistema de ficheros a cada partición directamente en el momento de su creación sin tener que usar también el comando mkfs en un paso posterior a la creación de las particiones del disco. name. Da nombre a una partición. print. Muestra la tabla de particiones, los dispositivos disponibles, el espacio libre, las particiones encontradas o una partición en concreto. quit. Sale del programa. rescue. Permite recuperar una partición perdida indicando el punto de inicio y de fin de la partición. resizepart. Redimensiona una partición indicando un nuevo punto de fin. rm. Elimina una partición. select. Elige el dispositivo a editar. Ejemplos de uso Un ejemplo de uso del comando parted puede consistir en particionar un disco duro. En este ejemplo se va a utilizar un disco duro llamado /dev/vdb. Para poder usarlo, el primer paso es ejecutar el programa parted y, a continuación, seleccionar el disco.\nselect /dev/vdb Posteriormente, se puede establecer una nueva tabla de partciones de tipo GPT con la orden mklabel.\nCon la tabla de particiones creadas, ya se puede usar la orden mkpart para crear las diferentes particiones en el disco. Cabe destacar que, con esta herramienta, se puede dar un sistema de ficheros a la partición desde su creación como se muestra en la siguiente imagen.\nmkpart uefi fat32 1M 100M mkpart / ext4 101M 1G Para ver la tabla de particiones creada se puede usar la orden print. Además, parted permite redimensionar particiones con la orden resizepart.\nresizepart 2 512M Con la orden rm se puede eliminar una partición.\nrm 1 Conclusión Parted puede resultar un comando útil para el particionado de discos duros gracias a las mejoras que implementa respecto a otras herramientas similares, tales como la posibilidad de redimensionar o recuperar particiones, así como la opción de dotar a cada partición de un sistema de ficheros desde el momento mismo de su creación.\nEn las tareas del administrador de sistemas, donde puede ser habitual el trabajo con particionado de discos de forma intensiva, herramientas de este tipo que facilitan el proceso y disminuyen los pasos necesarios para alcanzar un objetivo pueden ser una baza interesante a tener en cuenta.\n"},{
  "section": "Blog",
  "slug": "/blog/redes/2024-01-28-importar-dispositivos-gns3/",
  "title": "Cómo importar dispositivos a GNS3",
  "description": "",
  "date": "January 28, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "redes, switch, router, GNS3, cisco, tinycore linux, Planificación y Administración de Redes",
  "content":"En muchas ocasiones es habitual necesitar importar dispositivos que no están incluidos en la instalación básica de GNS3 para simular redes similares a las que podemos encontrar en la vida real. En este tutorial hay un par de ejemplos en los que se importan las imágenes de diferentes dispositivos en el simulador.\nImportar un router con módulo switch Cisco C3725 a GNS3 Para importar un dispositivo a GNS3 se puede acceder, en primer lugar a la ventana de configuración siguiendo Edit -\u0026gt; Preferences -\u0026gt; IOS Routers y seleccionar el botón “new” para importar un nuevo dispositivo.\nA continuación, se puede elegir entre usar una imagen nueva o una previamente importada. Si no se ha indicado con anterioridad la ruta a la imagen, se debe hacer en este momento.\nPosteriormente, se debe indicar que se está importando un router de tipo Etherswitch (según la documentación de GNS3 esto es importante). Marcar esta casilla cambia automáticamente el nombre del dispositivo a Etherswitch router y lo coloca en la categoría de dispositivos swithces en vez de routers.\nLa documentación de GNS3 también indica que en la siguiente ventana se debe aumentar la cantidad de memoria RAM predeterminada a 256 MiB.\nEn la ranura 0 aparece el adaptador Dual FastEthernet GT96100-FE y en la ranura 1 está preinstalado el módulo NM-16ESW. La documentación de GNS3 indica que no se debe reemplazar el adaptador GT96100-FE por un módulo switch porque el dispositivo no funcionaría. En esta configuración se puede añadir un segundo módulo NM-16ESW, un adaptador NM-1FE-TX single FastEthernet o un adaptador NM-4T serial port a la ranura 2.\nTras pulsar siguiente, se pueden añadir módulos WIC en la siguiente página. Pueden ser adaptadores WIC-1T o WIC-2T serial port. La documentación de GNS3 dice que no es mala idea añadir alguno aunque indica que no es necesario hacerlo sin especificar cuál es el criterio que se debe seguir para tomar una u otra decisión.\nA continuación se debe indiciar un valor Idle-PC para el dispositivo. No se hace, podría consumir el 100% del tiempo de proceso del core de la CPU al ejecutarse, mientras que con un valor Idle-PC definido, esto no ocurre.\nEl valor Idle-PC puede aparecer automáticamente en la ventana de configuración al cambiar de página. Si no es así, se debe seleccionar el botón “Idle-PC finder” para buscar uno. Esto puede llevar varios segundos, dependiendo de la velocidad del ordenador.\nTras finalizar el asistente, el dispositivo ya debe aparecer en la pestaña de plantillas IOS Router de la ventana preferencias.\nEn este punto, la documentación de GNS3 indica que se debe comprobar que el dispositivo tiene, al menos, 1MB para el disco PCMCIA disk0, como es el caso.\nUn aspecto que se debe tener en cuenta de este dispositivo, tal y como indica la documentación de GNS3, es que, al añadirlo a una topología en el espacio de trabajo de la aplicación, los primeros dos puertos FastEthernet (fa0/0 y fa0/1) corresponden al módulo GT96100-FE y son únicamente puertos de router. Esta es una características de diseño y, por tanto, estos puertos no se pueden usar como swtiches. Con el adaptador NM-16ESW instalado en la ranura 1, tal y como aparece por defecto, los puertos de switch corresponden a las interfaces desde el fa1/0 al fa1/15.\nImportar una máquina Tinycore Linux con Firefox Para instalar estos dispositivos se puede acceder a la barra de herramientas de “end devices” y, desde ahí, seleccionar “new template”.\nHay varias opciones de instalación disponibles. En este caso, se instala desde el marketplace de GNS3.\nEn la siguiente ventana se puede buscar el dispositivo que se quiere instalar.\nSe debe elegir a continuación si instalarlo en un servidor remoto, en GNS3VM o en local.\nA continuación se debe indicar el binario qemu que debe usar el dispositivo, en este caso, el que se indica por defecto.\nSi el dispositivo no se ha instalado previamente, habrá que pulsar el botón “download” para descargar el fichero de instalación. En caso contrario, se puede proceder a instalar el dispositivo. Si se cuenta con una imagen pero no se ha importado a GNS3, también está la opción de importar el fichero de instalación en este paso.\nPor último, finaliza el asistente de instalación del dispositivo y se muestra un mensaje de éxito.\nTras cerrar el asistente, el nuevo dispositivo ya está disponible en la pestaña de dispositivos finales de la barra de dispositivos de GNS3.\n"},{
  "section": "Blog",
  "slug": "/blog/redes/2024-01-28-configuracion-switches-gns3-vlan-portbonding-port-mirroring/",
  "title": "Configuración de switches en GNS3",
  "description": "",
  "date": "January 28, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "redes, switch, router, GNS3, VLAN, port bonding, port mirroring, Planificación y Administración de Redes",
  "content":"En este post se muestran varios ejemplos de configuración de switches gestionables en el simulador GNS3. A los dispositivos se les aplican configuraciones como la creación de VLAN, la configuración del port bonding entre switches o el uso del port mirroring para monitorizar el tráfico de la red.\nEste caso práctico parte del siguiente escenario:\nNote\nAntes de seguir el desarrollo de este post conviene conocer cómo importar los dispositivos necesarios al simulador GNS3.\nCreación de dos VLAN En primer lugar, se debe asignar una dirección IP a los dispositivos conectados a los diferentes swtiches para que estén todos en la misma red. Se usará la siguiente configuración:\nPC1: 192.168.0.1/24 PC2: 192.168.0.2/24 PC3: 192.168.0.3/24 PC4: 192.168.0.4/24 Servidor de datos: 192.168.0.10/24 Para asignar la dirección IP a un VPCS de GNS3:\nip 192.168.0.1/24 save A continuación se establecen las VLAN en los switches de la red:\nSwtich 1: Puerto 0: VLAN 1 tipo dot1q Puerto 1: VLAN 1 tipo dot1q Swtich 2: Puerto 0: VLAN 1 tipo dot1q Puerto 6: VLAN 20 tipo access Puerto 7: VLAN 10 tipo access Switch 3: Puerto 0: VLAN 1 tipo dot1q Puerto 6: VLAN 10 tipo access Puerto 7: VLAN 20 tipo access Con esta configuración vemos cómo mientras que el PC2 (192.168.0.2) se puede conectar el PC4 (192.168.0.4), no existe conectividad entre PC2 (192.168.0.2) y PC3 (192.168.0.3):\nAunque los switches por defecto de GNS3 son más limitados que unos de Cisco, por ejemplo, cuentan con una pequeña interfaz de configuración en la que se puede trabajar con los elementos imprescindibles de un switch gestionable, de manera que se puede realizar este ejercicio. En este caso, esto ha sido posible porque esta interfaz de configuración permite trabajar con las VLAN y los enlaces encapsulados dot1q.\nLos distintos tipos de puertos que se han usado en este ejercicio para configurar los switches Ethernet de GNS3 han sido access y dot1q. Se debe asignar como tipo “access” aquellos puertos que se van a conectar a los equipos finales, es decir, cada una de las máquinas que van a formar parte de una VLAN. El tipo dot1q, en cambio, hace referencia al protocolo IEEE 802.1Q, que desarrolla un mecanismo que permite a múltiples redes compartir de forma transparente el mismo medio físico, sin problemas de interferencia entre ellas, llamado trunking. También se conoce como dot1Q el protocolo de encapsulamiento usado para implementar este mecanismo en redes Ethernet, tal y como se ha hecho en este ejercicio.\nConfiguración de una VLAN asimétrica Configuración para permitir el acceso de PC1 y PC3 a Internet Para conseguir que PC1 y PC3 puedan acceder a Internet hay que configurar el puerto que conecta el switch 1 con la nube NAT como un puerto de tipo “access” que forma parte de la VLAN 10, la misma que los ordenadores PC1 y PC3:\nSwtich 1: Puerto 0: VLAN 1 tipo dot1q Puerto 1: VLAN 1 tipo dot1q Puerto 7: VLAN 10 tipo access De esta manera, sólo los equipos conectados a la VLAN 10 pueden tener acceso a Internet.\nEl siguiente paso es configurar la tarjeta de red tanto de PC1 como de PC3 para que puedan solicitar una configuración de red al servidor DHCP que tiene la nube NAT. En los VPCS de GNS3 esto se hace con el comando dhcp.\nUna vez obtenida la configuración DHCP tanto PC1 como PC3 pueden acceder a Internet.\nSin embargo, PC2 y PC4, que no forman parte de la VLAN 10, en la que está la nube NAT, no pueden hacerlo. De hecho, ni siquiera pueden solicitar una configuración DHCP a la nube NAT porque, tal y como se ve en las siguientes capturas, ambos equipos envían tres mensajes DHCP discover cada vez que se ejecuta el comando dhcp pero éste no llega al servidor DHCP y, por tanto, no reciben ningún mensaje DHCP offer:\nConfiguración para permitir el acceso de todos los ordenadores al servidor de datos Para que todos los ordenadores puedan acceder al servidor de datos se debe modificar la configuración del switch 1 de la siguiente forma:\nSwtich 1: Puerto 0: VLAN 1 tipo dot1q Puerto 1: VLAN 1 tipo dot1q Puerto 6: VLAN 1 tipo dot1q Puerto 7: VLAN 10 tipo access A continuación, le asignamos una IP dentro de la red local (192.168.0.10) al servidor de datos para que el resto de equipos se pueda conectar a él.\nip 192.168.0.10/24 save Para que todos los equipos estén configurados dentro de la misma red, es necesario volver a establecer una dirección IP estática en los ordenadores PC1 y PC3.\nUna vez hecho esto, todo parecería indicar que, con esta configuración, todos los equipos de la red deberían tener acceso al servidor de datos, sin embargo, ninguno de ellos lo consigue. Esto se debe a la limitación que presentan los switches instalados por defecto en GNS3 para trabajar con VLAN asimétricas.\nEn este punto no se puede seguir trabajando con los switches Ethernet por defecto de GNS3. Parece que la configuración que se ha usado para conectar entre sí los diferentes swtiches de la red usando el tipo de puerto dot1q sólo funciona entre este tipo de dispositivos y no permite comunicar ordenadores, servidores y otros equipos con todas las VLAN presentes en la red a la vez.\nUna vez encontrada a esta limitación, parece que es momento de continuar usando los router con módulo swtich Cisco 3725.\nPara llevar a cabo el proceso de configuración de los routers Cisco 3725 en este escenario, se intentarán seguir las instrucciones proporcionadas por José Domingo Muñoz en la entrada “Simulando switch Cisco en GNS3” de su blog.\nEl primer paso, por tanto, debería ser activar los puertos en todos los switches, sin embargo, al usar el comando indicado, parece que los puertos que se van a usar como switch (fe1/0 - fe1/15) ya están activados en los tres dispositivos y, por tanto, la conectividad entre los cuatro equipos ya es completa.\nEn este caso, las VLAN no se pueden configurar desde la ventana de configuración de la interfaz gráfica de GNS3, sino que es necesario acceder a la configuración de los switches a través de la terminal. Primero se crean las VLAN.\nESW1#vlan database ESW1(vlan)# vlan 10 ESW1(vlan)# vlan 20 ESW1(vlan)# exit #write Una vez creadas las dos VLAN que se están usando en esta práctica (10 y 20), se asignan los puertos que corresponden a cada una de ellas.\nESW2#conf t ESW2(config)#interface fastEthernet 1/6 ESW2(config-if)#switchport access vlan 20 ESW2(config-if)#exit ESW2(config)#interface fastEthernet 1/7 ESW2(config-if)#switchport access vlan 10 ESW2(config-if)#exit ESW2(config)#exit ESW2#wr Tras repetir esta operación en los tres switches, se configuran también el trunk.\nESW3#conf t ESW3(config)#interface fastEthernet 1/0 ESW3(config-if)#switchport mode trunk ESW3(config-if)#switchport trunk allowed vlan 1-1005 ESW3(config-if)#exit ESW3(config)#exit ESW3#wr Finalmente, una vez realizada esta configuración, se consigue la conectividad entre PC1 y PC3, por una parte, y PC2 y PC4 por otra.\nAdemás, si se solicita una configuración TCP/IP al servidor DHCP, los equipos conectados a la VLAN 10 también pueden acceder a Internet con esta configuración, mientras que los equipos de la VLAN 20 no tienen acceso a ese servidor DHCP.\nParecería lógico entender que la forma de permitir el acceso de todos los dispositivos al servidor de aplicaciones es conectarlo a la red a través de un puerto en modo trunk. Sin embargo, el resultado es que con esta configuración ni los equipos de la VLAN 10 ni los de la VLAN 20 tienen acceso al servidor.\nEsto se debe a que el modo trunk de los puertos del switch Cisco se reserva exclusivamente para las conexiones entre dispositivos similares y sólo se pueden conectar a este tipo de puertos switches o routers. El servidor, aunque sea un dispositivo que debe ser accedido por todas las máquinas de la red, es entendido por estos switches como un dispositivo final y, por tanto, no puede usar puertos de tipo trunk.\nUna vez alcanzada esta limitación, parece que otra opción posible para conseguir el objetivo del ejercicio es incluir el puerto al que se conecta el servidor de aplicaciones en ambas VLAN de manera simultánea.\nAl intentar implementar esta configuración nos encontramos que los swtiches Cisco empleados en este caso práctico no permiten asignar un mismo puerto del dispositivo a más de una VLAN a la vez. Así, al configurar dos VLAN en el mismo puerto, primero la VLAN 10 y, posteriormente, la VLAN 20, en este caso se observa que en la configuración del switch únicamente se ha guardado la última modificación, de manera que se ha asignado el puerto al que está conectado el servidor de aplicaciones, de manera exclusiva, a la VLAN 20.\nDe esta forma, el servidor es ahora accesible para los dispositivos que forman parte de esa VLAN pero no para el resto. Además, como la nube NAT forma parte de la VLAN 10, el servidor de aplicaciones tampoco tiene acceso a Internet como el resto de dispositivos de la VLAN 20, de la que forma parte a todos los efectos con esta configuración.\nPara poder configurar un enrutamiento entre diferentes VLAN se debe asignar una dirección IP diferente a los equipos que forman parte de cada una de ellas. En este caso, los equipos de la VLAN 10 tendrán unas ip del rango 192.168.10.0/24 y los de la VLAN 20 estarán en el rango de la red 192.168.20.0/24.\nA continuación, se debe configurar la interfaz de switch virtual (SVI) que va a permitir usar el switch como un dispositivo de nivel 3 y, por tanto, asociar una dirección IP a cada VLAN para poder crear un enrutamiento entre ellas.\nESW1#conf t ESW1(config)#interface vlan 10 ESW1(config-if)#ip add 192.168.10.1 255.255.255.0 ESW1(config-if)#no shutdown ESW1(config-if)#exit ESW1(config)#interface vlan 20 ESW1(config-if)#ip add 192.168.20.1 255.255.255.0 ESW1(config-if)#no shutdown ESW1(config-if)#exit ESW1(config)#exit ESW1#wr Finalmente, tras configurar las IP de ambas VLAN en todos los routers, se debe habilitar el enrutamiento por IP para poder usar los puertos de switch como puertos de nivel 3 con el comando ip routing en todos los switches.\nESW3#conf t ESW3(config)#ip routing ESW3(config)#exit ESW3#wr En este punto, cada ordenador llega tanto a los dispositivos de su propia VLAN como a los de otras aunque llama la atención al diferencia entre el tiempo que se tarda en completar un ping entre dos ordenadores de la misma VLAN (0,676 ms entre PC1 y PC3, por ejemplo) y el que se necesita para completar un ping entre dos ordenadores de VLAN diferente (16,234 ms entre PC1 y PC4, por ejemplo).\nPara permitir el acceso de todos los dispositivos en todas las VLAN al servidor de datos se ha configurado el puerto f1/6 del switch 1, conectado al servidor, como puerto enrutado de nivel 3 usando el comando no switchport. Esto debería permitir que se pueda dotar a este puerto de una configuración IPv4 para poder hacer un enrutamiento entre el servidor y las VLAN.\nAl intentar asignar una IP a este puerto enrutado el propio router limita el uso de direcciones IP para que la del puerto f1/6 no coincida con ninguna del rango ni de la VLAN 10, ni de la VLAN 20.\nESW1#conf t ESW1(config)#interface fastEthernet 1/6 ESW1(config-if)#ip add 192.168.10.1 255.255.255.0 ESW1(config-if)#no switchport ESW1(config-if)#no shutdown ESW1(config-if)#end ESW1#wr Ahora que el servidor ya está conectado a un puerto enrutado se puede configurar este enrutamiento para permitir a las VLAN 10 y 20 el acceso al servidor. En el switch 1:\nESW1#conf t ESW1(config)#router ospf 10 ESW1(config-router)#network 192.168.10.0 0.0.0.255 area 0 ESW1(config-router)#network 192.168.20.0 0.0.0.255 area 0 ESW1(config-router)#network 192.168.1.0 0.0.0.255 area 0 ESW1(config-router)#end ESW1#wr De esta forma, tanto las VLAN 10 y 20 como el servidor de datos quedan correctamente enrutados (f1/6).\nCon esta configuración, todos los ordenadores de la red pueden acceder al servidor de datos (192.168.1.2). Sin embargo, también pueden comunicarse entre las diferentes VLAN que se han creado. Para garantizar que las VLAN cumplen su función y generan dos redes estancas que no se pueden comunicar entre ellas, se deben implementar listas de control de acceso (ACL) en los routers. Para hacerlo, el primer paso debe ser crear en cada uno de los routers que conectar equipos que pertenecen a una única VLAN las listas de acceso.\nEn el router 2, se deben indicar dos ACL diferentes. Cada una de ellas se deberá asignar posteriormente a una de las interfaces que conecta cada equipo de la VLAN 10 o de la VLAN 20. Para el equipo de la VLAN 10 se configura la lista de acceso 10, que le impide recibir paquetes provinientes de las IP del rango 192.168.20.0/24, es decir, de la VLAN 20. En esta caso, junto a la IP no se indica la máscara de red, sino una máscara llamada wildcard, que es la inversa a la máscara de red y es el tipo de máscara que el sistema operativo de los dispositivos de Cisco usa para la configuración de las listas de control de acceso. La segunda orden de esta ACL es permitir todo el resto del tráfico que circula por la red.\nPara el equipo de la VLAN 20 se configura la lista de acceso 20, que le impide recibir paquetes privinietnes de las IP del rango 192.168.10.0/24, es decir, de la VLAN 20 y le permite recibir todo el resto del tráfico que circula por la red.\nESW2#conf t ESW2(config)#access-list 10 deny 192.168.20.0 0.0.0.255 ESW2(config)#access-list 10 permit any ESW2(config)#access-list 20 deny 192.168.10.0 0.0.0.255 ESW2(config)#access-list 10 permit any ESW2(config)#exit ESW2#wr Una vez que se han creado todas las ACL que se necesitan para regular el tráfico que pasa por este router, se debe asignar cada una de ella a una interfaz del dispositivo. En este caso se asigna a la interfaz f1/7 (que conecta el switch con el PC1) la ACL 10 y a la interfaz f1/6 (que conecta el switch con el PC2) la ACL 20.\nAmbas ACL se asignan en modo “in” de manera que el router debe filtrar los paquetes que van a salir por esa interfaz y permitir o denegar su paso según los criterios especificados anteriormente. Otra opción es asignar las ACL a las interfaces en modo “out”, lo que impediría que los paquetes dirigidos a las direcciones denegadas saliesen a circular por la red, reduciendo así el tráfico dentro de la misma. Sin embargo, la documentación de Cisco recomienda implementar las ACL lo más cerca posible del destino. Además, el modelo de router con el que se está trabajando en esta práctica no soporta la configuración “out” en las ACL.\nESW2#conf t ESW2(config)#interface fastEthernet 1/7 ESW2(config-if)#ip access-group 10 in ESW2(config-if)#exit ESW2(config)#interface fastEthernet 1/6 ESW2(config-if)#ip access-group 20 in ESW2(config-if)#end ESW2#wr Pero a pesar de haber establecido esta configuración de listas de accesos tanto en el switch 2 como en el 3, los ordenadores de las diferentes VLAN de la red siguen pudiendo establecer comunicación entre ellos a través de ping.\nConfiguración de un port bonding El primer paso para crear el portbonding es configurar todos los puertos implicados con las mismas características, es decir, todos ellos deben estar en el mismo modo, en este caso, trunk y pertenecer a la misma VLAN o rango de VLAN.\nESW1#conf t ESW1(config)#interface fastEthernet 1/1 ESW1(config-if)#switchport mode trunk ESW1(config-if)#switchport trunk allowed vlan 1-1005 ESW1(config-if)#exit ESW1(config)#interface fastEthernet 1/3 ESW1(config-if)#switchport mode trunk ESW1(config-if)#switchport trunk allowed vlan 1-1005 ESW1(config-if)#end ESW1#wr Tras repetir esta operación en todos los switches, se debe configurar el portbonding en cada uno de ellos de la siguiente forma:\nESW1#conf t ESW1(config)#interface range fastEthernet 1/1 , fastEthernet 1/3 ESW1(config-if-range)#channel-group 3 mode on ESW1(config-if-range)#end ESW1#wr De esta manera, la configuración queda establecida con dos channel-group llamados grupo 2 (entre el switch ESW1 y el switch ESW2) y grupo 3 (entre el switch ESW1 y el switch ESW3), cada uno de ellos con dos puertos asignados en cada uno de los routers.\nEn este punto el port bonding está configurado. Se puede demostrar su correcta configuración a través de las diferentes herramientas del switch Cisco. Por ejemplo, con el comando show interfaces port-channel 2 en el switch ESW1, se muestra que este port bonding entre el switch de cabecera y el switch 2 cuenta con un ancho de banda de 20000 Kbps y una latencia de 1000 microsegundos. Además, indica que se trata de una conexión de tipo full duplex a 100Mbps y que el port bonding está formado pro dos miembros: las interfaces Fa1/0 y Fa1/2.\nEn el otro extremo de este port-channel se muestra la misma información especificando está vez las interfaces Fa1/0 y Fa1/1 como miembros de este prot bonding en el switch ESW2.\nPor otra parte, el port-channel 3, que conecta el switch de cabecera con el switch ESW3, también presenta un ancho de banda de 200000 Kbps y una latencia de 1000 microsegundos. También se identifica como una conexión de tipo full duplex a 100Mbps y cuenta con los puertos Fa1/1 y Fa1/3 de este switch.\nEn el otro extremo del cable, el switch 3 muestra la misma información indicando esta vez que las interfaces que forman parte de este port bonding son los puertos Fa1/0 y Fa1/1 de este switch.\nEl comando show etherchannel \u0026lt;n\u0026gt; summary, donde \u0026lt;n\u0026gt; es el número de portchannel sobre el que se desea obtener información muestra el estado del port bonding. Para describir el estado, este comando usa diferentes flags para indicar el estado de los elementos del portchannel. Por ejemplo, el flag D indica que un puerto del portchannel está apagado, el flag P indica que un puerto forma parte de un portchannel y el flag s indica que un puerto está suspendido. Para los portchannel que usan el protocolo LACP, el flag H puede indicar que se encuentra en modo standby.\nAdemás, otros flags también se usan para indicar el estado del propio portbonding. Algunos de ellos son el flag R para indicar que el portchannel es de nivel 3, el S para indicar que es de nivel 2, los flags U o N para indicar si está o no en uso, respectivamente o el flag f para indicar un fallo en la localización de los puertos.\nConfiguración de un port mirroring En primer lugar, se conecta el PC5 a uno de los puertos libres del switch. En este caso, la conexión se ha realizado entre el PC5 y el puerto f1/15 del switch ESW1.\nTras establecer esta conexión, se debe configurar el router 1 para que el PC5 pueda acceder al tráfico de la VLAN 10 que llega por su puerto f1/0.\nSin embargo, tras incluir el port-channel 2 (formado por los puertos f1/0 y f1/2) del switch ESW1 en la sesión de monitorización, al intentar filtrar el tráfico que se busca monitorizar por la VLAN, en este caso la 10, para poder discernir el tráfico proveniente del PC1 del proveniente del PC2, el switch 1 devuelve un mensaje de error que indica que el dispositivo no soporta el filtro por VLAN.\nUna forma de solucionar este problema es conectar el PC5 al switch ESW2, donde no es necesario filtrar por el tráfico por vlan puesto que el tráfico que circula por su puerto f1/7 es únicamente el del PC1. Para conectar el PC5 al switch ESW2 se va a usar, de nuevo, en este caso, el puerto f1/15 de este switch.\nEn este caso ya se puede configurar la sesión de monitorización indicando como puerto de origen el f1/7 y como puerto de destino el f1/15.\nESW2#conf t ESW2(config)#monitor session 1 source interface fastEthernet 1/7 ESW2(config)#monitor session 1 destination interface fastEthernet 1/15 ESW2(config)#end ESW2#wr Así, se puede comenzar a monitorizar el tráfico de la red. Si se hace una captura del tráfico que circula entre el PC1 y el resto de la red se aprecian diferentes bloques claramente diferenciados.\nEn primer lugar (en azul), se observan un conjunto de mensajes del protocolo DHCP que circulan por la red. En concreto, se trata de mensajes de tipo DHCP Discover, Request y Decline todos ellos enviados a la dirección IP de difusión de la red (255.255.255.255) y que no tienen respuesta por parte del PC1.\nPosteriormente (en amarillo) se produce un proceso de comunicación del protocolo ARP. Se cuentan varios mensajes enviados por PC1 a la dirección de difusión de la red para descubrir la MAC de destino con la que tiene que establecer la comunicación. En los tres primeros de estos mensajes, el dispositivo que funciona como puerta de enlace (con la IP 192.168.122.1) busca la MAC que corresponde a la tarjeta de red que tiene asociada la IP 192.168.122.65. El cuarto, es un mensaje ARP que envía PC1 para descubrir la dirección MAC a la que debe enviar al mensaje que tiene como IP de destino la dirección 192.168.122.1, la de la puerta de enlace.\nFinalmente, en el quinto mensaje del protocolo ARP que aparece en la captura, el PC1 recibe la información de la dirección MAC asociada a la puerta de enlace de la red.\nA continuación, sigue un bloque de una cantidad mayor de mensajes del protocolo ICMP (en rosa) que reflejan el intercambio de información que se produce al hacer ping entre el PC1 y una dirección IP de Internet, en este caso, se ha usado la 8.8.8.8.\nAl final de la captura, hay otros dos mensajes ARP (en amarillo) en los que el PC1 recibe un mensaje de la puerta de enlace preguntando su dirección MAC y, posteriormente, PC1 contesta esa petición.\n"},{
  "section": "Blog",
  "slug": "/blog/sistemas/2024-01-07-comandos-programacion-tareas-script-bash/",
  "title": "Comandos para la programación de tareas",
  "description": "",
  "date": "January 7, 2024",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "sistemas",
  "tags": "sistemas, debian, linux, comandos básicos, programación, sleep, watch, crontab, comandos, Implantación de Sistemas Operativos",
  "content":"La programación de tareas es una característica muy útil en el ámbito de la administración de sistemas informáticos, especialmente al programar scripts. En este post se repasa brevemente la información más relevante sobre los principales comandos que se pueden usar con esta finalidad.\nSleep Definición La ejecución del comando sleep provoca una pausa de un tiempo determinado en el flujo de trabajo de la terminal. La duración de la pausa se indica a través de los argumentos que deben ser números. Si hay varios argumentos, la pausa será igual a la suma de todos ellos. Las opciones determinan la unidad de tiempo a la que se refieren los argumentos.\nSintaxis sleep NÚMERO [SUFIJO] Info\nNúmero: cantidad de tiempo que debe durar la pausa\nSufijo: unidad de tiempo\nOpciones El comando sleep tiene un funcionamiento sencillo y solo admite números (no es necesario que sean enteros) como argumentos y unidades de medida de tiempo como opciones. Las opciones son:\ns: segundos (por defecto). m: minutos. h: horas. d: días. Ejemplos de uso El uso del comando sleep está especialmente indicado para el trabajo con scripts o para la creación de tareas complejas en una única línea de comandos (one line).\nPor ejemplo, la linea de comandos\nsudo apt update; sleep 5; sudo apt upgrade ejecutará el comando update, hará una pausa de 5 segundos y, a continuación, ejecutará el comando upgrade.\nWatch Definición El comando watch ejecuta otro comando de forma reiterada y muestra por pantalla la salida y los errores del comando indicado. El objetivo de watch es mostrar la evolución del resultado de la ejecución de un comando a lo largo del tiempo. La frecuencia de repetición de la ejecución del comando de watch por defecto es de 2 segundos y ejecutará el comando reiteradamente hasta que se interrumpa su ejecución.\nSintaxis watch [opciones] comandos Opciones Algunas de las principales opciones del comando watch son:\n-d, --differences[=permanent]: Resalta las diferencias entre las diferentes actualizaciones de la ejecución del comando. Si se usa el argumento “permanent”, watch mostrará todos los cambios desde la primera iteración. -n, --interval segundos: Indica el intervalo de actualización. -p, --precise: Hace que el intervalo de ejecución del comando sea más preciso a nivel de fracción de segundo. -t, --no-title: Deshabilita el encabezado que muestra el intervalo de actualización, el comando y la hora de la última actualización en la parte superior de la pantalla. -b, --beep: Activa un aviso sonoro si se produce algún error en la ejecución del comando. -e, --errexit: Pausa la ejecución del comando si se produce un error. -g, --chgexit: Sale de la ejecución si hay un cambio en la salida del comando. -q, --equexit \u0026lt;cycles\u0026gt;: Sale de la ejecución cuando la salida del comando no cambia tras un número determinado de iteraciones. -c, --color: Interpreta colores y estilos ANSI. -w, --no-wrap: Trunca las líneas largas en la salida del comando en vez de mostrar toda la información en varias líneas. Ejemplos de uso El comando watch puede resultar muy útil en tareas de monitorización en las que se necesita mantener una vigilancia sobre la ejecución de otros comandos. También es un comando práctico para alertar de posibles errores, ya que cuenta con varias opciones para detectar y notificar cambios o errores en la ejecución del comando indicado.\nPor ejemplo, con la ejecución del comando watch -d ls -l se pueden observar los cambios a lo largo del tiempo en el contenido del directorio en el que se ejecute el comando. Con la opción -d se pueden observar resaltados los cambios en la salida de ls entre cada iteración.\nAt Definición El comando at acepta órdenes a través de la entrada por teclado o desde un fichero y las ejecuta en un momento posterior. At conlleva varios comandos asociados. Por ejemplo, con at se pueden ejecutar órdenes a una hora determinada, con atq se listan los trabajos pendientes, con atrm se borran trabajos de la lista de tareas pendientes y con batch se ejecutan órdenes cuando lo permite el nivel de carga del sistema.\nEl comando at permite indicar especificaciones de tiempo complejas usando el estándar POSIX.2. Acepta el formato de hora HH:MM pero también expresiones como “midnight”, “noon” o “teatime”. También acepta sufijos como AM o PM, así como los nombres de los meses. También se puede indicar un período de tiempo con “now +” un número de minutos, horas, días o semanas. Además, el comando at también acepta expresiones como “today” o “tomorrow”.\nSintaxis at tiempo at -f fichero -t tiempo Opciones Algunas de las opciones más empleadas junto al comando at son:\n-V: Muestra el número de versión en la salida de error estándar y termina. -q cola: Permite especificar la cola a la que se quiere añadir una tarea. Las colas se nombran con una letra de la a a la z y de la A a la Z. La cola a es la que se usa por defecto para at y la cola b para batch. Además, existe una cola especial, \u0026ldquo;=\u0026rdquo;, que está reservada para trabajos en ejecución. Si se usa la opción -q con el comando atq, sólo mostrará aquellas tareas que se encuentren en la cola indicada. -m: Envía un correo al usuario cuando el trabajo termina incluso si no hubiese salida que mostrar. -M: No envía ningún correo al usuario. -u username: Indica el usuario al que se debe enviar el correo en vez de al usuario que ejecuta el comando. -f fichero: Indica el fichero desde el que se lee el trabajo en lugar de la entrada estándar. -t time: Indica la hora a la que se ejecuta la tarea con el formato [[CC]YY]MMDDhhmm[.ss] -l: Es un alias para atq. -r: Es un alias para atrm. -d: Es un alias para atrm. -b: Es un alias para batch. -v: Muestra la hora a la que se ejecutará la tarea antes de leerla en el formato \u0026ldquo;Thu Feb 20 14:50:00 1997\u0026rdquo;. -c: Manda las tareas listadas en la línea de órdenes a la salida estándar. -o fmt: Usa el formato strftime-like para la lista de tareas. Ejemplos de uso Con todas sus opciones, herramientas y potencial, el comando at es uno de los más completos a la hora de gestionar la programación de tareas en GNU/Linux. At otorga una gran flexibilidad a los administradores de sistemas para organizar el flujo de trabajo de la forma más eficiente posible postergando la ejecución de tareas, ya sean comandos concretos o scripts más complejos, para momentos posteriores.\nPor ejemplo, con la ejecución del comando\nat midnight at\u0026gt; sudo apt update \u0026amp;\u0026amp; sudo apt upgrade se actualizarán los paquetes del sistema a las 12 de la noche.\nCrontab Definición Crontab es el programa para la instalación, desinstalación, listado y matenimiento de los ficheros para los usuarios del daemon cron en Vixie Cron. Cron es un programa tipo daemon para ejecutar comandos programados.\nCron usa los ficheros almacenados en el directorio /var/spool/cron/crontabs y /etc/crontab. Estos ficheros, junto al resto de ficheros usados por cron en su funcionamiento no se deben acceder ni editar de forma manual, sino que es necesario usar el comando crontab para trabajar con ellos.\nLos ficheros crontab recogen las tareas que debe ejecutar el daemon cron. Cada tarea se debe definir como una única línea en el fichero indicando con diferentes campos cuándo se debe ejecutar y qué comando se debe utilizar en la tarea. Para definir la hora se deben usar valores concretos (en este orden) de minutos, horas, día del mes, mes, y día de la semana o usar un asterisco (*) para indicar cualquier valor posible de ese campo.\nAdemás, crontab permite configurar ficheros como /etc/cron.allow o /etc/cron.deny, que recogen la lista de usuarios con o sin permiso para usar la programación de comandos a través de Cron. Cuando los ficheros crontab se han instalado, cron ya cuenta con la información necesaria para funcionar. Entonces, comprueba en los ficheros crontab en el sistema cada minuto si hay algún comando que se deba ejecutar en ese minuto. Si lo hay, lo ejecuta y envía la salida del comando por correo electrónico al propietario del fichero crontab.\nSintaxis Crontab OPCIÓN Opciones Algunas de las principales opciones que se pueden usar con el comando crontab son:\n-u: Especifica el nombre de usuario cuyo crontab se va a usar o modificar. Por defecto, crontab trabaja sobre el fichero del usuario activo. -n: Examina el fichero crontab del usuario para revisar la sintaxis y muestra un mensaje si la sintaxis es correcta pero no efectúa ningún cambio en los ficheros crontab. -l: Muestra el fichero crontab del usuario por pantalla. También se puede redireccionar la salida a un fichero. -r: Elimina el fichero crontab. -e: Permite editar el fichero crontab a través de un editor. Al salir del editor, el crontab se instalará automáticamente. -i: Muestra una pregunta que espera confirmación antes de eliminar un fichero crontab. Ejemplos de uso El comando crontab se puede usar para la gestión de tareas programadas. Una de las ventajas de este comando es que permite la programación de tareas periódicas y complejas mediante la edición e instalación de los ficheros crontab que pueden contener una gran cantidad de información. Crontab es muy útil, por ejemplo, para realizar tareas de mantenimiento de los sistema que se deban ejecutar de manera sistemática a lo largo del tiempo.\nPor ejemplo, añadiendo la tarea\n0 5 * * 1 tar -zcf /var/backups/home.tgz /home/ al fichero crontab se puede ejecutar un backup de todas las cuentas de usuario a las 5 de la mañana una vez por semana.\n"},{
  "section": "Blog",
  "slug": "/blog/redes/2023-12-11-uso-basico-wireshark-tutorial/",
  "title": "Uso básico de Wireshark",
  "description": "",
  "date": "December 11, 2023",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "Wireshark, redes, Planificación y Administración de Redes",
  "content":"Wireshark es una herramienta que captura del tráfico que circula por una red y permite analizar el contenido de los paquetes que se envían y reciben desde las máquinas conectadas. Este software permite capturar los paquetes que viajan por una red, filtrarlos, y ver su contenido para poder analizar el tipo de tráfico del que se trata.\nTráfico básico en una comunicación En esta captura aparecen paquetes que usan protocolos como MDNS. Entre el resto de paquetes aparecen varios paquetes que usan el protocolo UDP con una IP de origen 192.168.0.177 y destino de broadcast que mi ordenador está recibiendo periódicamente. Más allá de eso encontramos, en primer lugar una petición y una respuesta ARP que mi ordenador usa para conocer la dirección MAC del router de casa, varias peticiones y respuestas DNS que el ordenador necesita para averiguar la dirección IP a la que debe hacer ping (la de www.google.com) y, finalmente, una sucesión de peticiones y respuestas de mensajes Echo (ping) que usan el protocolo ICMP. Entre tanto, aparece también alguna petición y respuesta ARP que llega desde la puerta de enlace en busca de la IP de mi ordenador.\nTráfico generado por ping Se realiza una captura de 10 segundos haciendo ping a www.google.com en condiciones similares a las planteadas para el ejercicio anterior con la opción del modo promiscuo activada.\nDurante la captura se han registrado los siguientes paquetes:\nProtocolo Nº de paquetes ARP 2 IP 35 ICMP 22 TCP 0 UDP 13 DNS 10 Los datos del primer paquete IP recibido son:\nCampo Valor Dir. IP origen 192.168.0.1 Dir. IP destino 192.168.0.32 Protocolo DNS Tamaño 101 bytes TTL 64 Identificador 0x9d29 (40233) Los campos en el resumen de los paquetes capturados en Wireshark En la imagen se muestra una captura de los paquetes ICMP generados tras la ejecución de la orden ping www.elpais.com. En total se capturan 8 mensajes: 4 de tipo echo (ping) request y otros cuatro de tipo echo (ping) reply.\nSi analizamos estos mensajes, podemos observar que son mensajes de tipo 8: echo (ping) request o de tipo 0: echo (ping) reply, que todos ellos usan el código 0 y que el tamaño de cada uno de los paquetes es de 98 bytes de datos.\nAdemás, el análisis de las cabeceras IP de estos mensajes indica que cuentan con cabeceras IP de una longitud de 20 bytes. La longitud total es de 84 bytes y estos mensajes cuentan con 48 bytes de datos.\nEjemplo de uso de los filtros de captura de Wireshark Con el filtro de captura udp and src port 53 or dst port 53 se pueden filtrar únicamente aquellos paquetes que se envían o reciben para realizar peticiones o recibir respuestas desde el servidor DNS.\nEl datagrama UDP de estos mensajes tiene una longitud variable en cada caso. En la captura aparecen paquetes tanto de 82 bytes como de 174, 158, 96, 97 ó 162 bytes. Otro elemento que cambia en cada una de las peticiones DNS que se han registrado en esta captura es el puerto del ordenador. Mientras que el puerto del servidor siempre es constante (puerto 53), el puerto del ordenador no es el mismo en cada petición y el sistema operativo asigna un puerto diferente a cada una de ellas, de manera que el puerto de origen o destino cambia en cada pareja de peticiones y respuestas al servidor DNS.\nSi se desactiva el filtro de captura, se puede comprobar que, al hacer un ping a la dirección IP de la máquina en la que está alojada la web www.nba.com, la 92.123.57.194, wireshark no consigue capturar ningún paquete que se corresponda con una petición o una respuesta DNS. Esto se debe a que, al no usar una URL a la hora de hacer el ping, no es necesario traducir ningún nombre de dominio a la IP y, por tanto, no es necesario usar ese servicio.\nAnálisis del tráfico ARP en Wireshark Durante la ejecución del comando ping a www.barrapunto.com se han capturado con el filtro arp cuatro mensajes ARP, dos de ellos de petición y otros dos de respuesta.\nEl primero de ellos es una petición ARP que lanza el ordenador a la dirección de difusión para buscar la dirección MAC de la puerta de enlace, a la que debe enviar los paquetes de petición Echo. A continuación, se captura de la respuesta a esta petición ARP, en la que el router contesta con su dirección MAC.\nPor último, aparecen otros dos mensajes de petición y respuesta ARP en los que el router solicita la MAC del ordenador y el ordenador contesta con esa información al router.\nTras esta captura de tráfico, y sin volver a borrar la memoria caché ARP se realiza otra captura con el mismo filtro aplicado. En este caso, Wireshark no puede encontrar ningún paquete durante la captura que cumpla con los requisitos indicados en el filtro.\nEsto es así porque en esta ocasión el ordenador conserva en su memoria caché ARP la dirección MAC de la puerta de enlace a la que debe enviar las peticiones Echo, de la misma manera que el router conservar en su memoria caché ARP la dirección MAC de la tarjeta de red del ordenador al que tiene que enviar las respuestas según van llegando.\nAnálisis del tráfico generado por traceroute El primer tipo de paquete capturado en este ejercicios es una serie de paquetes DNS que corresponden a la petición DNS desde el ordenador para conocer la dirección IP de www.rae.es. Se trata de dos peticiones y dos respuestas que permiten al ordenador conocer a qué dirección IP debe enviar los mensajes necesarios para ejecutar el comando traceroute, en este caso, la 104.26.1.151.\nEn segundo lugar se captura un bloque de 16 mensajes UDP con origen en el ordenador (192.168.0.32) y destino en www.rae.es (104.26.1.151). Pero estos mensajes no se envían al puerto privilegiado asignado al servicio web, sino que se envían a puertos que van del 33434 al 33449, aumentando progresivamente en cada mensaje.\nTodos ellos son paquetes de 74 bytes que contienen un mensaje de 32 bytes de datos.\nEstos 16 paquetes se agrupan en bloques de 3, cada uno de ellos con un TTL diferente. De esta forma, los tres primeros paquetes capturados tiene un time-to-live de 1 y aumenta progresivamente hasta los paquetes capturados en el orden 13, 14 y 15 que presentan un TTL de 5 cada uno de ellos. La excepción está en el último paquete de este bloque, cuyo TTL es 6 pero este dato sólo se encuentra en un paquete y no en tres como en los casos anteriores. Los otros dos paquetes de este bloque se encuentran a continuación, tras el primer grupo de mensajes ICMP ttl exceeded que se recibe.\nA continuación, se registran en la captura una serie de mensajes del protocolo ICMP ordenados en grupos de tres. Cada grupo tiene asignada una IP de origen diferente, de manera que los tres primeros provienen de la IP 192.168.0.1, es decir, la puerta de enlace de la red, los tres siguientes de la 10.195.192.1, otra IP privada correspondiente a otra red, los tres siguientes provienen de la 193.149.1.56, que es una IP pública de Internet, otros tres llegan desde la IP 172.70.58.2 y, por último, hay tres paquetes que tienen como IP de origen la IP pública de la web www.rae.es, la 104.26.1.151.\nEstas direcciones IP corresponden con las que devuelve el comando traceroute durante su ejecución.\nTodos estos mensajes son de tipo 11 (time-to-live exceeded) y su código es el 0 (time to live exceeded in transit). Para todos ellos el TTL es 1.\nLos siguientes paquetes que se han registrado en esta captura forman un nuevo bloque de mensajes UDP con origen en el ordenador (192.168.0.32) y destino en www.rae.es (104.26.1.151). Realmente, lo que ocurre aquí es que, a la vez que se enviaba el bloque de mensajes UDP se han empezado a recibir los mensajes ICMP anteriores, lo que ha hecho que aparezcan intercalados en la captura. Sin embargo, este bloque de mensajes UDP no es diferente, sino la continuación del bloque anterior. De hecho, los primeros dos mensajes de este bloque completan, junto con el último mensaje inmediatamente anterior a los paquetes ICMP, el conjunto de 3 mensajes con el mismo TTL del bloque anterior.\nDe manera sucesiva se siguen enviando mensajes de este tipo a puertos consecutivos de la IP de destino, en este caso, desde el 33450 (el siguiente al usado en el último mensaje de este tipo) hasta el 33459. También sucesivamente, se va aumentando el TTL hasta llegar a 9 en los últimos dos mensajes del bloque. En este caso, tampoco se registra en la captura un grupo de 3 mensajes con el mismo TTL, sino que son solo dos los que tienen un TTL con valor 9.\nPor último, se registra un último bloque de mensajes ICMP. En él se incluyen dos mensajes que realmente pertenecen al bloque anterior y, aunque no aparezcan los primeros en este bloque, si se revisa el campo “stream index” de cada uno de ellos, se puede comprobar que, en realidad, se transmitieron antes del primer mensaje capturado en este bloque (resaltado en azul en la captura de pantalla).\nPor tanto, la última parte relevante de esta captura de tráfico es este bloque de 8 paquetes ICMP de tipo 3 (destination unreachable) y código 3 (port unreachable). Se trata de mensajes que se envian desde la IP pública de www.rae.es destinados al ordenador. Todos ellos hacen referencia a un número de puerto determinado dentro del rango que se ha usado para enviar los mensajes UDP comentados anteriormente. En concreto, los puertos que han devuelto mensajes de este tipo son los puertos del 33452 al 33459.\nAnálisis del triple apretón de manos (3-way handshake) Durante la captura de tráfico planteada en este ejercicio (solicitar la página web www.nba.com desde un navegador), se han registrado un total de 9824 paquetes TCP o UDP. De ellos, 8583 son paquetes UDP y los 1241 restantes son paquetes TCP.\nCon la herramienta para seguir el flujo TCP se puede comprobar que, en este caso, se ha realizado una petición HTTP al servidor web que ha tenido su correspondiente respuesta.\nGracias a esta opción, se pueden seguir en la captura todos los paquetes transmitidos entre cliente y servidor en este proceso.\nTras aplicar el filtro que permite esta herramienta aparecen tres paquetes TCP marcados como SYN, SYN-ACK y ACK respectivamente, que hacen referencia al mecanismo de TCP 3-Way Handshake (triple apretón de manos) para crear la sesión entre cliente y servidor.\nA partir de aquí, cliente y servidor empiezan a intercambiar información HTTP. ya pueden empezar a enviar toda la información HTTP. El primer mensaje que envía el cliente al servidor tras el establecimiento de la conexión es una petición tipo GET con destino al puerto 80 de la IP pública del servidor web.\nEn la cabecera del nivel de aplicación de este mensaje se puede comprobar que el cliente solicita la web www.nba.com e indica que la versión HTTP empleada es la 1.1. Esta cabecera recoge también información sobre el host o servidor en el que está alojada esta web.\nEl siguiente mensaje en el flujo TCP analizado es la respuesta HTTP que el servidor devuelve al cliente. Esta respuesta incluye un código de estado 301, que indica que el recurso solicitado ha sido movido permanentemente y redirige a dicho recurso. Al seleccionar el paquete en wireshark, se puede acceder a todas las cabeceras del mensaje que contienen información relevante en este sentido.\nFinalmente, se sucede un bloque de peticiones y respuestas marcadas como ACK, FIN – ACK y RST que indican la finalización de la conexión entre el cliente y el servidor.\nIdentificar ficheros descargados vía HTTP con Wireshark En primer lugar, con un filtro de captura que permita registrar sólo los paquetes relacionados con HTTPS, por ejemplo, aquellos que usen un puerto 80, se captura el tráfico de una petición web en la que se descargue algún fichero.\nEntonces se debe localizar la línea de la petición GET en la captura de tráfico para acceder, desde ahí al seguimiento del flujo HTTP.\nEn la ventana emergente de seguimiento del flujo HTTP se pueden ver las peticiones del cliente al servidor en rojo y las respuestas del servidor en azul.\nCada respuesta viene precedida de un encabezado con información sobre el tipo de petición, tipo de conexión, tamaño del contenido, tipo de servidor, última modificación de la web, fecha de la petición y otros datos de interés. A continuación, se puede ver el contenido del fichero descargado vía HTTP.\nDe forma sucesiva, aparecen en este registro todas las peticiones con sus correspondientes respuestas así como todos los ficheros descargados con cada una de las respuestas.\nLa opción Expert Information de Wireshark La opción Expert Information de Wireshark es un diálogo que permite registrar información de las posibles anomalías y elementos de interés que forman parte de un fichero de captura. Su objetivo es aportar una mejor idea del comportamiento inesperado en una red, de manera que se puedan localizar e identificar los posibles problemas de manera más rápida y ágil que con una búsqueda manual a través de la lista de paquetes.\nEl cuadro de diálogo Expert Information agrupa los sucesos que recoge por nivel de gravedad y los muestra con un código de color. Así, usa el azul para aquellos eventos propios del transcurso normal de una red, el cian para eventos relevantes como códigos de errores comunes, el amarillo para advertencias de sucesos como que una aplicación devuelva un código de error poco común y el rojo para errores como la recepción de paquetes dañados.\nJunto al nivel de gravedad del suceso recogido, este cuadro de diálogo también muestra otra información como un breve resumen de cada entrada, así como el tipo de incidencia por la que se ha incluido en el diálogo cada elemento y el protocolo que utiliza. Desde las preferencias de Wireshark, se puede añadir a la lista de paquetes capturados que el programa muestra por defecto una nueva columna en la que se añade el nivel de gravedad de aquellos paquetes que constituyan una incidencia recogida en “expert information”.\nComo ejemplo, en el cuadro de diálogo “Expert information” de la captura de tráfico anterior se recogen las siguientes incidencias:\nComo se puede ver en la imagen, aparecen agrupadas por gravedad, de mayor a menor, junto a su descripción, tipo y protocolo. En este caso, todas las incidencias forman parte del grupo “sequence”, esto es, se trata problemas relacionados con el número de secuencia de los paquetes, es decir, se representan en esta lista paquetes que se han recibido desordenados o que han necesitado ser retransmitidos.\nEn este otro ejemplo, aparecen elementos que forman parte de otros grupos, por ejemplo, el grupo “protocol”, que indica que se ha producido una violación de las especificaciones del protocolo, o el grupo “undecoded”, que indica que ese paquete contiene información que no ha podido ser decodificada correctamente.\nPor último, en este otro caso, se observa como algunas incidencias incluyen una posible explicación en su campo de resumen. Por ejemplo, en la segunda fila aparece un elemento del protocolo TCP con la marca de gravedad advertencia y del grupo secuencia que indica en su descripción que se ha incluido como tal porque el segmento anterior no se capturó. Sin embargo, en este mismo campo se añade una aclaración: se trata de un error común al inicio de las capturas.\nPor otra parte, cada una de estas filas de incidencias permiten desplegar un contenido que muestra todos aquellos paquetes a los que hacen referencia, incluyendo su número en la secuencia de registro de la captura junto a la información del paquete que se aporta en la ventana principal de capturas de Wireshark, así como el grupo al que pertenece la incidencia y el protocolo que usa el paquete. Esto aporta más información relevante como, por ejemplo, si se trata de errores en paquetes consecutivos o aislados, si las incidencias pueden estar o no relacionadas y más información sobre los paquetes concretos implicados en cada una de estas entradas.\n"},{
  "section": "Blog",
  "slug": "/blog/sistemas/2023-11-24-comando-xargs/",
  "title": "El comando xargs",
  "description": "",
  "date": "November 24, 2023",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "sistemas",
  "tags": "sistemas, debian, linux, comandos básicos, xargs, comandos, Implantación de Sistemas Operativos",
  "content":"Función del comando xargs El comando xargs permite la construcción y ejecución de líneas de comando desde la entrada estándar. Este comando lee los elementos de la línea de la entrada estándar delimitados por espacios o líneas y ejecuta el comando una o más veces con el argumento inicial seguido de los elementos elementos indicados por teclado.\nSi no se indica ningún otro comando, el comando que xargs ejecuta por defecto es echo.\n~$ xargs Hola esto es una prueba Hola esto es una prueba Tras su ejecución, xargs espera una entrada desde el teclado. En este momento se puede introducir una cadena de texto como en el ejemplo anterior pero también un comando que se ejecutará cuando se especifique el fin de la entrada por teclado.\nAplicación del comando xargs La principal aplicación de xargs es facilitar y dinamizar las tareas de la administración del sistema. De esta forma, por ejemplo, se pueden listar los ficheros almacenados en varios directorios con la ejecución de un único comando. Por ejemplo, la ejecución de xargs ls -l espera que se introduzcan por teclado los directorios cuyo contenido se quiere listar. Tras indicar los diferentes directorios se indica el fin de la entrada por teclado.\n~$ xargs ls -l /tmp ./Descargas ./pruebas Como respuesta, xargs devuelve la lista del contenido de todos los directorios indicados.\nOpciones más utilizadas del comando xargs Algunas de las opciones más comúnmente utilizadas en la ejecución de xargs son:\n-0 --null. Los nombres de fichero de entrada se terminan con un carácter nulo en lugar de con espacio en blanco, y las comillas y barra inversa no son especiales (cada carácter se toma literalmente). Deshabilita el final de la cadena de fin de fichero, que se trata como cualquier otro argumento. Es útil cuando los argumentos pueden contener espacio en blanco, comillas o barras invertidas. -e[eof-str], --eof[=eof-str]. Establece la cadena de fin de fichero a eof-str. Si la cadena de fin de fichero ocurre como una línea de la entrada, el resto de la entrada se descarta. Si esta opción no se da, la cadena de fin de fichero predeterminada es \u0026ldquo;_\u0026rdquo;. -i[replace-str], --replace[=replace-str]. Reemplaza ocurrencias de replace-str en los argumentos iniciales con nombres leídos de la entrada estándar. Además, los blancos no entrecomillados no delimitan los argumentos. -L max-lines, -l[max-lines], --max-lines[=max-lines]. Utiliza como mucho max-lines líneas de entrada no en blanco por cada línea de órdenes; el valor predeterminado de max-lines es 1. -n max-args, --max-args=max-args. Utiliza como mucho max-args argumentos por cada línea de órdenes. -p, --interactive. Pregunta al usuario si se debe ejecutar cada línea de órdenes, y lee una línea de la terminal. Sólo ejecuta la línea de órdenes si la respuesta empieza con \u0026ldquo;y\u0026rdquo; o \u0026ldquo;Y\u0026rdquo; (o quizás el equivalente local, en español \u0026ldquo;s\u0026rdquo; o \u0026ldquo;S\u0026rdquo;). -r, --no-run-if-empty. Si la entrada estándar no contiene algo distinto de blancos, no se ejecuta la orden. Normalmente, la orden se ejecuta una vez incluso si no hay entrada. -s max-chars, --max-chars=max-chars. Utiliza como mucho max-chars caracteres por cada línea de órdenes, incluyendo la orden y los argumentos iniciales, y los nulos terminadores en los finales de las cadenas de argumentos. -t, --verbose. Muestra la línea de órdenes en la salida estándar de errores antes de ejecutarla. -P max-procs, --max-procs=max-procs. Ejecuta hasta max-procs procesos de una vez; el valor predeterminado es 1. Si max- procs es 0, xargs ejecutará tantos procesos como sea posible de una vez. Ejemplos de utilización del comando xargs Un ejemplo de uso interesante para el comando xargs puede ser hacer búsquedas de diferentes archivos en un mismo directorio sin tener que reescribir todo el comando. Por ejemplo, para buscar los ficheros cuyo nombre empieza por “fichA” o “fichB” en el directorio ./prueba/origen/ podemos ejecutar xargs -L 1 find -name y, a continuación, ir introduciendo los criterios de búsqueda, en este caso, fichA*.txt en primer lugar y fichB*.txt posteriormente. De esta forma, la ejecución del comando devolverá todas las coincidencias con ambas búsquedas en el directorio especificado.\n~$ xargs -L 1 find -name fichA*.txt ./fichA5.txt ./fichA.txt ./fichA6.txt ./fichA4.txt ./fichA3.txt ./fichA2.txt ./fichA1.txt fichB*.txt ./fich3.txt ./fichB.txt ./fichB2.txt ./fichB1.txt Otra utilidad interesante de xargs puede ser crear ficheros o directorios de forma más rápida y cómoda con una sola línea. Por ejemplo, se puede usar el siguiente comando para crear tres ficheros de nombre A.txt, B.txt y C.txt.\necho A B C | xargs touch Con xargs también se pueden hacer búsquedas amplias con una única orden. Por ejemplo, usando el siguiente comando se pueden buscar todos los ficheros del directorio /etc con extensión .conf que incluyan la palabra root.\nfind /etc -iname \u0026#34;*.conf\u0026#34; | xargs grep \u0026#34;root\u0026#34; "},{
  "section": "Blog",
  "slug": "/blog/redes/2023-11-24-escenario-enrutamiento-gns3/",
  "title": "Escenario de enrutamiento en GNS3",
  "description": "",
  "date": "November 24, 2023",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "GNS3, enrutamiento, Wireshark, redes, Planificación y Administración de Redes",
  "content":"En esta práctica se parte de un escenario recreado en el simulador GNS3 y, a partir de él, se enruta el tráfico entre los diferentes equipos que forman la red para permitir la comunicación entre todas las máquinas.\nMontar el escenario en GNS3 completando las direcciones IP Para configurar el escenario indicado en la práctica se deben ordenar y nombrar las diferentes redes. En primer lugar aparece una red con dos ordenadores conectados (H1 y H2). Se indica que la dirección IP de H2 es 192.168.10.2/24, por tanto, para que H1 esté en la misma red tiene que tener una dirección IP como por ejemplo 192.168.10.3/24.\nPara configurar esta red en GNS3 se deben crear los dos ordenadores junto al switch al que deben ir conectados. Para mantener el orden, los switches adoptarán en su nombre el último número de la máscara de red de cada red. En este caso, el switch se llamará Switch10.\nUna vez que se han creado todos los dispositivos, se deben configurar. En el caso de los ordenadores es necesario acceder al archivo de configuración y, en él, descomentar la línea indicada para asignar una dirección IP de forma manual al equipo.\nEste procedimiento se debe repetir con todos los ordenadores que forman parte de cada una de las redes establecidas en la práctica.\nEn la siguiente red sólo hay un ordenador, con la IP 192.168.20.2/24. Este equipo se llama H3.\nLos ordenadores H4 y H5 están conectados al Switch30. El H4 tiene la IP 192.168.30.2/24 y el H5 usa la IP 192.168.30.3/24.\nFinalmente, hay una cuarta red formada por los ordenadores H6, con la IP 192.168.40.2/24 y H7, con la IP 192.168.40.3/24, conectados al Switch40.\nTodos los equipos se han configurado para asignarle sus direcciones IP y máscaras de red correspondientes. A continuación hay que incluir los routers a esta red para poder establecer las conexiones que indica el enunciado.\nEl primer paso para incorporar un router al escenario de GNS3 es importar la plantilla al programa, eligiendo la opción “nueva plantilla” de la ventana de dispositivos del área de trabajo.\nEsta importación se puede hacer de forma manual, desde el servidor o a través de un archivo con extensión .gns3a. En el caso de usar la opción de importación manual, GNS3 pide que se indique el archivo con extensión .gns3a que se quiere utilizar.\nEl siguiente paso es elegir un tipo de servidor para instalar la plantilla.\nPosteriormente se debe importar la imagen del SO del router que se pretende importar. En este caso es necesario marcar la opción “permitir ficheros personalizados” para poder instalar la imagen descargada de Internet.\nTras confirmar la instalación de la versión de la imagen del router de Cisco que corresponde al fichero de imagen que se ha seleccionado durante el proceso de importación de la plantilla, el nuevo router ya está disponible en la lista de dispositivos del proyecto de GNS3.\nFinalmente, para llegar al escenario planteado en el enunciado de la práctica sólo queda colocar los diferentes routers en cada punto y conectarlos a los dispositivos indicados.\nUna vez que están colocados y conectados todos los dispositivos, es necesario asignarle sus correspondientes direcciones IP a cada una de sus interfaces:\nRouter Interfaz IP R1 f0/0 192.168.10.1/24 f1/0 192.168.50.1/24 R2 f0/0 192.168.20.1/24 f1/0 192.168.50.2/24 f2/0 192.168.60.2/24 f3/0 192.168.70.2/24 f4/0 80.1.1.1/8 R3 f0/0 192.168.30.1/24 f1/0 192.168.60.1/24 R4 f0/0 192.168.40.1/24 f1/0 192.168.70.1/24 R5 f0/0 80.59.1.152/8 f1/0 90.0.0.1/8 ISP 90.1.1.1/8 Para trasladar esta información al escenario de GNS3, se puede acceder a cada uno de los routers a través de la consola y, desde allí, asignarle la dirección IP y máscara de red a las tarjetas de red de estos dispositivos.\nR4#conf t R4(config)#interface f0/0 R4(config-if)#ip address 192.168.40.1 255.255.255.0 R4(config-if)#no shutdown Tablas de enrutamiento Tabla de enrutamiento de H1 y H2 Destino Siguiente router Interfaz de salida 192.168.10.0 0.0.0.0 e0 0.0.0.0 192.168.10.1 e0 Tabla de enrutamiento de H3 Destino Siguiente router Interfaz de salida 192.168.20.0 0.0.0.0 e0 0.0.0.0 192.168.20.1 e0 Tabla de enrutamiento de H4 y H5 Destino Siguiente router Interfaz de salida 192.168.30.0 0.0.0.0 e0 0.0.0.0 192.168.30.1 e0 Tabla de enrutamiento de H6 y H7 Destino Siguiente router Interfaz de salida 192.168.40.0 0.0.0.0 e0 0.0.0.0 192.168.40.1 e0 Tabla de enrutamiento de R1 Destino Siguiente router Interfaz de salida 192.168.10.0 0.0.0.0 f0/0 0.0.0.0 192.168.50.2 f1/0 Tabla de enrutamiento de R2 Destino Siguiente router Interfaz de salida 192.168.10.0 192.168.50.1 f1/0 192.168.20.0 0.0.0.0 f0/0 192.168.30.0 192.168.60.1 f2/0 192.168.40.0 192.168.70.1 f3/0 0.0.0.0 80.59.1.152 e0 Tabla de enrutamiento de R3 Destino Siguiente router Interfaz de salida 192.168.30.0 0.0.0.0 f0/0 0.0.0.0 192.168.60.2 f1/0 Tabla de enrutamiento de R4 Destino Siguiente router Interfaz de salida 192.168.40.0 0.0.0.0 f0/0 0.0.0.0 192.168.70.2 f1/0 Tabla de enrutamiento de R5 Destino Siguiente router Interfaz de salida 192.168.10.0 80.1.1.1 f0/0 192.168.20.0 80.1.1.1 f0/0 192.168.30.0 80.1.1.1 f0/0 192.168.40.0 80.1.1.1 f0/0 80.0.0.0 0.0.0.0 f0/0 0.0.0.0 90.1.1.1 f1/0 Configuración de las tablas de enrutamiento en los routers Cisco en GNS3 Una vez que las direcciones IP de todas las interfaces de red están asignadas a los routers de la escena de GNS3, la mayor parte de entradas de las tablas de enrutamiento se completan por defecto. Sin embargo, conviene revisar y, si fuese necesario, complementar la información almacenada en estos dispositivos.\nAnálisis de las cachés ARP Para limpiar la memoria caché ARP de los VPCS H6 y H7 se ejecuta el comando clear arp.\nEl comando para limpiar la memoria caché ARP de los routers es clear arp, sin embargo, en este caso, la tabla ARP no se llega a vaciar en ningún momento. Esto se debe a que los routers Cisco que se están usando en esta práctica elaboran esta tabla de forma automática sin necesidad de que haya tráfico en la red. Es decir, en el momento en el que se ejecuta el comando clear arp y se eliminan las entradas de la memoria caché ARP del router, este vuelve a lanzar peticiones ARP a todos los dispositivos conectados a él para volver a elaborar esta tabla.\nTras limpiar todas las cachés ARP de los equipos indicados se ejecuta el ping entre H6 y R5. Tres construir el mensaje en el nivel de aplicación y asignarle los puertos en el de transporte, en el nivel de red se añaden las direcciones IP de origen y destino a la trama. En este caso, no interviene el protocolo DNS porque se está indicando la IP de destino directamente al ejecutar el comando ping. La IP de origen se asigna también de forma automática por parte del ordenador, que ya tiene su dirección IP previamente configurada.\nEn el nivel de enlace, en cambio, sí que interviene el protocolo ARP en el proceso de asignación de las direcciones MAC de destino y origen a las cabeceras de la trama. En este primer paso de la transmisión del mensaje al ejecutar el ping que se produce en el ordenador H6, el equipo asigna su propia dirección MAC a la cabecera del nivel de enlace de la trama como dirección MAC de origen y envía una petición ARP request a la red en busca de la dirección MAC que corresponde a la tarjeta de red con la IP 192.168.40.1, es decir, la tarjeta de red del router de su red que funciona como puerta de enlace para este equipo.\nEl resto de equipos de la red recibe esta petición y el router contesta con una respuesta ARP reply, que llega al ordenador H6 con la dirección MAC de la tarjeta de red del router. Este ordenador la incluye en la cabecera de la trama y, además, la guarda en su memoria caché ARP.\nSin embargo, aunque la petición ARP request que envió el ordenador H6 ha llegado a todos los dispositivos de la red, la respuesta ARP reply sólo se ha enviado al ordenador que solicitó esta información, de manera que el otro ordenador conectado a la misma red, H7, no ha recibido el mensaje ARP reply del router y, por tanto, no conoce su dirección MAC. Esto se puede comprobar al consultar la tabla de la memoria caché ARP de este equipo, que sigue vacía.\nEl router conectado a esta red, R4, es el siguiente punto en el camino del mensaje ping entre H6 y R5. Este router tiene ya guardad en su memoria caché ARP la dirección MAC del ordenador H6, que lanzó una petición ARP en el primer paso de la transmisión del mensaje.\nEn el nivel de enlace, este router vuelve a realizar una petición ARP para conocer la MAC de destino. Para ello, en primer lugar consulta su tabla de enrutamiento para comprobar la IP del siguiente router al que tiene que dirigir el mensaje, en este caso, la 192.168.70.2 y, cuando la conoce, lanza una petición ARP a todos los dispositivos conectados para solicitar la dirección MAC que corresponde a esa IP.\nEl dispositivo cuya tarjeta de red tiene configurada esa dirección, responde la petición de R4 con una respuesta ARP que incluye su dirección MAC. Así, el router R4 guarda esa información en la cabecera de la trama y, como se puede comprobar en la siguiente captura, la almacena también en su tabla de memoria caché ARP.\nEn el siguiente router, R2, se repite el proceso. En este caso no se aplica ninguna modificación a la trama en el nivel de red pero sí en el nivel de enlace. En primer lugar, el router comprueba la dirección IP de destino incluida en la trama y la busca en su tabla de enrutamiento para conocer el siguiente paso en el camino, en este caso, la dirección de destino 80.59.1.152 ya está indicada en la tabla de enrutamiento. Entonces, R2 envía una petición ARP al resto de equipos de la red para solicitar la dirección MAC asociada a la IP de destino y R5 devuelve una respuesta ARP con su dirección MAC. El router R2 modifica la información de la cabecera del nivel de enlace de la trama para modificar la MAC de origen por su propia MAC y la de destino por la de R5 y guarda la dirección MAC de R5 en su memoria caché ARP.\nFinalmente, el mensaje ping consigue llegar a su destino en el router R5.\nUna vez que R5 recibe el mensaje ping que envió el ordenador H6, tiene que devolver una respuesta. Para construir la trama, en primer lugar elabora el mensaje ping de vuelta en el nivel de aplicación, con los puertos correspondientes en el nivel de transporte y, a continuación, añade la cabecera del nivel de red incluyendo como IP de origen su propia dirección IP y como IP de destino la IP que aparece como IP de origen en la trama que ha recibido.\nPara completar la cabecera del nivel de enlace, R5 tiene que consultar su tabla de enrutamiento y descubrir a qué IP debe dirigir el mensaje para que llegue a su destino, en este caso la 80.1.1.1. Cuando la conoce, lanza una petición ARP a su red solicitando la MAC asociada a esa IP que R2 contesta con una respuesta ARP con la información sobre su dirección MAC. Entonces, R5 construye la cabecera del nivel de enlace con su MAC como MAC de origen y la de R2 como MAC de destino. También almacena la dirección MAC de R2 en su memoria caché ARP.\nEl recorrido de vuelta se hace más sencillo. Cuando el ping de vuelta vuelve a llegar a R2, este router puede modificar la cabecera del nivel de enlace sin necesidad de realizar ninguna petición ARP porque conserva la dirección MAC del destino del mensaje, la de R4, en su memoria caché ARP. Con esta información puede modificar la cabecera de la trama y transmitir el mensaje.\nCuando R4 recibe el mensaje, como también conserva la dirección MAC del ordenador H6 simplemente modifica esa información en la cabecera del nivel de enlace de la trama y transmite el mensaje al ordenador.\nCon este último paso, el ping de vuelta llega hasta el ordenador H6. Y todo esto ocurre en sólo unos 47 milisegundos.\nCaptura del tráfico con Wireshark Captura del tráfico en el punto A Petición ARP El primer campo relevante en la captura del tráfico en el punto indicado como A en la práctica muestra la petición ARP que hace el router R1 a los dispositivos conectados a la misma red. Tal y como la describe Wireshark, el router pregunta qué dispositivo tiene la dirección IP 80.59.1.152 y pide que se transmita esa información a su IP 192.168.50.1.\nEn la información de este campo se puede observar que la dirección de destino de la petición ARP es la dirección MAC broadcast (ff:ff:ff:ff:ff:ff) y el origen del mensaje es la dirección MAC ca:01:17:f4:00:1c, que corresponde a la IP 192.168.50.1, asociada a la tarjeta de red 1/0 del router R1.\nA continuación, también indica que se trata de una petición ARP (Address Resolution Protocol), a través de Ethernet e IPv4, que es de tipo petición y recoge también la dirección MAC e IP del remitente así como la IP del destinatario. El campo de la dirección MAC de destino está a 0 porque el objetivo de esta petición es, precisamente, obtener esa información.\nRespuesta ARP El siguiente campo en la captura muestra la respuesta a esta petición. En este caso, el software resume la respuesta ARP que devuelve el router R2 como “80.59.1.152 is at ca:02:0e:20:00:1c”. Es decir, identifica este mensaje como una respuesta ARP que incluye la información de la dirección MAC que el router R1 había solicitado en el mensaje anterior.\nEn este caso, como destino se muestra la dirección MAC del router R1, ca:01:17:f4:00:1c, y como fuente del mensaje, se identifica la dirección MAC del router R2, ca:02:0e:20:00:1c. También se indica que el tipo del mensaje es ARP.\nConcretamente, se identifica el mensaje como una respuesta ARP y, por tanto, se le asigna el código de operación 2. Como este mensaje ya sí incluye la información sobre la dirección MAC del router R2, este dato se muestra como contenido del mensaje en la dirección MAC del remitente y se indica como direcciones MAC e IP del destinatario las de la tarjeta de red 1/0 del router R1.\nPetición echo (ping) Una vez conocida la dirección MAC a la que el router R1 tiene que transmitir los mensajes, comienza la transmisión del ping propiamente dicho. En los siguientes campos se alternan, de forma consecutiva, peticiones y respuestas de ping.\nEn el resumen, se observa este siguiente campo que contiene un mensaje de tipo ping con origen en 192.168.10.3 y destino en 80.59.1.152. Pero el análisis detallado de las diferentes cabeceras de la trama puede aportar más información.\nEn primer lugar, en el nivel de aplicación, se construye un mensaje de 56 bytes, que es el que se enviará al dispositivo que se ha indicado como destino del ping.\nEn el nivel de transporte se identifica el protocolo como Internet Control Message Protocol (ICMP) y el mensaje aparece identificado como un mensaje de tipo 8, es decir, una petición echo (ping). En esta cabecera de la trama se identifican también el origen y destino del mensaje con un código numérico.\nA continuación, en el nivel de red se añade a la trama la información de las IP de origen y destino. En este caso, se indica que se usan direcciones del protocolo IPv4 y se especifican cuál corresponde al origen de la trama, 192.168.10.3, y cuál al destino, 80.59.1.152.\nPor último, en la cabecera del nivel de enlace se añade a la trama la información sobre la dirección MAC de origen y destino del mensaje.\nRespuesta echo (ping) El siguiente campo registra la respuesta echo (ping) a la petición anterior, tal y como se indica en el resumen. Se trata de un mensaje ICMP con origen en la IP 80.59.1.152 y destino en la 192.168.10.3.\nEn el nivel de aplicación, se construye en mensaje con los mismos 56 bytes de información que se habían enviado previamente en la petición por parte del ordenador H1.\nEn el nivel de enlace se añade a la cabecera de la trama información relacionada con el tipo de mensaje, en este caso un mensaje de tipo 0, una respuesta de echo (ping) que usa el protocolo Internet Control Message Protocol (ICMP). Además, se identifica el origen y destino del mensaje con los códigos numéricos 2749 y 48394.\nEn este caso, se incluye también información adicional como el tiempo de respuesta (30,377ms).\nEn la cabecera del nivel de red se invierte ahora el orden de las direcciones IP que se muestran. En este caso, la dirección IP de origen es la 80.59.1.152 y la de destino es la 192.168.10.3.\nPor último, en el nivel de enlace, también se altera el orden de las direcciones MAC, de manera que en la respuesta, la MAC de origen es la dirección que en la petición correspondía a la MAC de destino y la de destino es la dirección MAC que en la petición correspondía al origen.\nCaptrua del tráfico en el punto B La captura en el punto B indicado en la práctica presenta algunas diferencias respecto al tráfico capturado en el punto A. Para encontrar algunas de ellas es necesario analizar detenidamente el contenido de las cabeceras de las tramas transmitidas, sin embargo, hay una diferencia que es evidente al ver una imagen general de la captura de tráfico en wireshark.\nEn primer lugar, llama la atención que, en este caso, no se ha podido detectar ningún mensaje ARP ni de petición ni de respuesta. Esto se explica porque esta captura de tráfico se ha llevado a cabo a continuación de la anterior y, por tanto, los dispositivos implicados ya contaban con las direcciones MAC del resto de dispositivos de su red implicados en la ruta en su memoria caché ARP, de manera que no es necesario que vuelvan a pedir esta información.\nPetición echo (ping) Para encontrar el resto de novedades en esta captura de tráfico conviene analizar con más detenimiento un par de los campos que muestra wireshark.\nEn el primero de ellos no se aprecia diferencia alguna en el nivel de aplicación. Nuevamente, el mensaje está formado por 56 bytes de información que se transmiten desde el ordenador H1 al router R5.\nLa cabecera del nivel de transporte ofrece también una información muy similar a la que incluían las tramas capturadas en el punto A: el tipo de mensaje que se está transmitiendo (tipo 8, petición echo (ping)), junto a los códigos numéricos que identifican el destino y el origen del mensaje, 29887 y 49012.\nTampoco hay diferencias en la información que añade a la trama la cabecera en el nivel de red: las direcciones IP de origen y destino coinciden con las que se incluyen en las tramas capturadas en el punto A.\nEn cambio, en el nivel de enlace, el mensaje sí presenta diferencias respecto a la información que contenían las cabeceras de este nivel en el punto A. En este caso, el mensaje se ha capturado entre el router R2 y el router R5, por tanto, las direcciones MAC que se incluyen en esta cabecera son la de la tarjeta de red del router R2 como MAC de origen y la de la tarjeta de red del router R5 como MAC de destino.\nEsto es así porque mientras que el mensaje debe conservar durante todo el proceso de transmisión la IP de destino para saber cuál es el último punto al que se debe dirigir y la IP de origen para que el último equipo pueda saber a dónde debe dirigir la respuesta, la dirección MAC necesita cambiar en cada paso de la ruta, de manera que la información se pueda transmitir al siguiente router del camino.\nRespuesta echo (ping) En el caso de la respuesta capturada en el punto B, las similitudes y diferencias con la respuesta capturada en el punto A van a ser las mismas que las analizadas en el mensaje de petición.\nAsí, se puede observar que en el nivel de aplicación nuevamente se ha construido un mensaje de 56 bytes de información.\nEn el nivel de transporte se ha identificado el mensaje como una respuesta echo (ping) que usa el protocolo ICMP y se han asignado también los códigos numéricos correspondientes al origen y destino del mensaje. Además, como ocurre en el punto A, se incluye información sobre el tiempo de respuesta (7,046ms). En este caso, como el mensaje se ha capturado mucho más cerca del dispositivo que ha generado la respuesta que en el análisis del punto A, el tiempo de respuesta es considerablemente más reducido.\nY en el nivel de red, la cabecera alternado la información de las direcciones IP de origen y destino especificando ahora que el origen del mensaje es el router R5 (80.59.1.152) y el destino el ordenador H1 (192.168.10.3).\nFinalmente, la cabecera del nivel de enlace recoge en esta caso como MAC de origen la dirección del router R5 y como MAC de destino la del router R2, de manera que las direcciones MAC son las inversas que las que se mostraban en la cabecera del nivel de enlace de la trama correspondiente a la petición de echo (ping) en este mismo punto.\n"},{
  "section": "Blog",
  "slug": "/blog/redes/2023-11-17-comandos-supervisi%C3%B3n-redes-debian-windows/",
  "title": "Comandos de supervisión de redes",
  "description": "",
  "date": "November 17, 2023",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "Windows, GNU/Linux, comandos, redes, Planificación y Administración de Redes",
  "content":"Windows Configuración de propiedades TCP/IP En la ventana de configuración de las propiedades de TCP/IP en Windows se pueden configurar dos elementos: la dirección IP y la dirección de servidor DNS.\nPara la configuración de la dirección IP, se puede asignar manualmente la dirección IP del ordenador, esto es el número de 32 bits expresado en notación decimal puntuada que identifica de manera única a este dispositivo dentro de la red local.\nEn el siguiente campo se puede indicar también la máscara de red expresada igualmente en notación decimal puntuada. Este campo indica qué bits de la dirección IP corresponden a la dirección de red y cuáles a la dirección de máquina, es decir, indica qué parte de la dirección IP de cada equipo se refiere al número que se le asigna a la red para identificarla y que deben compartir todas las direcciones IP de todos los dispositivos que formen parte de esa misma red y qué parte de la dirección IP de cada dispositivo identifica, de manera única, al dispositivo dentro de la red.\nPor último, también se puede configurar la puerta de enlace predeterminada, es decir, la dirección IP privada de la red, también expresada en notación decimal puntuada, a la que se deben dirigir los mensajes que no están destinados a ninguno de los dispositivos conectados a esa red. Habitualmente, esta dirección IP coincide con la dirección IP privada del router.\nPor otra parte, hay varios campos que permiten configurar también las direcciones del servidor DNS. En concreto, se puede indicar la dirección del servidor DNS preferido y la dirección del servidor DNS alternativo. Es decir, estos campos permiten indicar la dirección IP de los servidores tanto preferido como alternativo que se van a encargar de buscar la dirección IP correspondiente a las URL que se busquen desde un navegador web. Así se puede comunicar un dispositivo con otros conectados a otras redes sin tener que conocer las respectivas direcciones IP de cada uno de ellos.\nDesde esta ventana de configuración, también se puede acceder a la configuración avanzada de TCP/IP. En esta configuración avanzada se pueden agregar, editar o quitar direcciones IP configuradas en el equipo. También se puede operar agregando, editando o quitando puertas de enlace predeterminadas de forma manual.\nAdemás, una segunda pestaña incluye opciones para la configuración del DNS. En ella se pueden agregar y ordenar varias direcciones de servidores DNS, teniendo en cuenta el orden de uso. También permite marcar las opciones de anexar sufijos DNS principales y específicos para las conexiones, anexar sufijos primarios del sufijo DNS principal y anexar los sufijos indicados manualmente en el orden que se recoja en el cuadro de texto de la ventana de configuración. Finalmente, también se recogen las posibilidades de registrar en DNS las direcciones de la conexión actual y usar el sufijo DNS de la conexión actual para el registro en DNS.\nLa última pestaña que se recoge en esta ventana de configuración avanzada de TCP/IP se refiere a las direcciones WINS, que también se pueden agregar, editar, quitar u ordenar según su uso. En esta pestaña también se puede habilitar o deshabilitar la búsqueda de LMHOSTS o configurar NetBIOS con tres opciones: predeterminada, que usa la configuración de NetBIOS del servidor DHCP; habilitar NetBIOS a través de TCP/IP; o deshabilitar NetBIOS a través de TCP/IP.\nUtilidad del comando ping El comando ping calcula el tiempo mínimo, medio y máximo de respuesta en la conexión entre dos puntos de una red. Este comando permite saber si un dispositivo puede llegar a otro de forma correcta o no. También aporta comunicación sobre el tiempo que se tarda en mantener esa comunicación. Es una herramienta útil para encontrar posibles errores en las tablas de enrutamiento.\nEl comando ping permite saber si un problema de acceso a una web puede ser derivado de un fallo de la conexión con el servidor o si, por el contrario, se trata de otro tipo de problema. Otro ejemplo de uso es comprobar si desde un dispositivo de una red local hay acceso a otros dispositivos o recursos compartidos como, por ejemplo, un impresora.\nAdemás, en casos en los que hay cortes de Internet o problemas de conectividad el comando ping permite identificar si el origen del error está en la red local o en el servicio de Internet, ya que este comando permite descartar que haya problemas en la red local doméstica al hacer un ping a la puerta de enlace del dispositivo que se está usando. En cambio, para comprobar si el problema está en la conexión a Internet se puede hacer un ping a una dirección IP de fuera de la red para comprobar si hay un corte en la comunicación o una latencia demasiado alta.\nOtro ejemplo de uso del comando ping es el análisis de la latencia en redes inalámbricas.\nPero el comando ping también se puede usar con otros objetivos. Por ejemplo, para conocer la IP que usa un dominio web, se puede usar el comando ping con el modificador -a o para conocer la dirección IP asociada a una cuenta de correo electrónico se puede usar el comando ping seguido de la dirección de correo electrónico que se quiere consultar.\nLa salida del comando ipconfig El comando ipconfig es un comando de Windows que permite conocer información como las direcciones IP y MAC del ordenador o la dirección IP del router.\nAl usar el comando ipconfig en Windows, se muestran por pantalla algunos datos relevantes sobre la conexión del ordenador. En primer lugar, se muestra información sobre la configuración de la IP y, posteriormente, se muestran datos relevantes relacionados con los dispositivos que permiten la conexión a la red del ordenador.\nPor ejemplo, el campo descripción muestra el nombre de adaptador o tarjeta de red empleado para realizar la conexión, el campo dirección IPv4 muestra la dirección IP única asignada al ordenador dentro de la red local expresada en notación decimal puntuada.\nEl campo máscara de subred indica qué bits de la dirección IP corresponden a la dirección de red y cuáles a la dirección de máquina, es decir, indica qué parte de la dirección IP de cada equipo se refiere al número que se le asigna a la red para identificarla y que deben compartir todas las direcciones IP de todos los dispositivos que formen parte de esa misma red y qué parte de la dirección IP de cada dispositivo identifica, de manera única, al dispositivo dentro de la red.\nA continuación aparece el campo puerta de enlace predeterminada, que muestra la dirección IP del equipo que tiene acceso a Internet y que, habitualmente, suele ser el router en el caso de las redes locales domésticas.\nTambién se incluyen en esta pantalla algunos datos relativos a los servidores DNS. En concreto, se muestra la dirección IP de los servidores, habitualmente dos, con los que el router asigna la dirección IP correspondiente a cada nombre de dominio de las páginas web solicitadas por los usuarios a través de los navegadores web.\nUn último campo que cabe destacar es el de estado de DHCP, que muestra si la configuración dinámica de host está habilitada y, por tanto, si usa una dirección IP estática o fija entre el equipo y el host o no. Si el estado de DHCP es habilitado, cada vez que se inicie una conexión se usará una dirección IP diferente; si el estado es deshabilitado, la dirección IP se mantendrá fija en todas las conexiones.\nUtilidad de ipconfig /renew Una de las funciones del comando ipconfig es renovar la configuración de DHCP para todos los adaptadores o para un adaptador específico dentro de la red. Para poder usar el parámetro /renew del comando ipconfig es necesario que los adaptadores estén configurados para obtener automáticamente una dirección IP. Si no se especifica el nombre de un adaptador, se renueva la configuración de DHCP de todos los adaptadores del ordenador.\nPara renovar la configuración de DHCP de un único adaptador es necesario indicarlo en la sintaxis del comando. Para conocer el nombre del adaptador sobre el que se quiere efectuar esta acción se debe ejecutar el comando ipconfig sin parámetros y elegir el adaptador deseado de entre los que devuelve la ejecución del comando.\nUtilidad del comando arp -a El comando arp muestra y modifica las entradas en la memoria caché del Protocolo de resolución de direcciones (ARP). La memoria caché de ARP contiene una o varias tablas que se usan para almacenar direcciones IP y sus direcciones físicas de Ethernet o Token Ring resueltas. Hay una tabla independiente para cada adaptador de red Ethernet o Token Ring instalado en el equipo. Si se usa el parámetro -a junto al comando arp se muestran las tablas de caché de arp actuales para todas las interfaces. Es decir, para conocer las tablas de caché arp para todas las interfaces se debe ejecutar el comando arp -a.\nUtilidad del comando netstat El comando netstat muestra las conexiones TCP activas, los puertos en los que escucha el equipo, las estadísticas de Ethernet, la tabla de enrutamiento IP, las estadísticas IPv4 (para los protocolos IP, ICMP, TCP y UDP) y las estadísticas de IPv6 (para los protocolos IPv6, ICMPv6, TCP a través de IPv6 y UDP a través de IPv6).\nEste comando es útil si se quiere conocer cuáles son las conexiones TCP activas en el equipo y los puertos TCP y UDP en los que escucha el ordenador.\nAdemás, netstat también se puede usar para ver estadísticas Ethernet, como el número de bytes y paquetes enviados y recibidos.\nOtra utilidad del comando netstat es conocer las estadísticas por protocolo para los protocolos TCP, UDP, ICMP e IP, así como para los protocolos IPv6 e ICMPv6 si están instalados.\nPor último, este comando también se puede emplear para conocer el contenido de la tabla de enrutamiento de IP.\nts/img/redes/practica4/img22.png)\nUtilidad del comando nslookup El comando nslookup muestra información que se puede usar para diagnosticar la infraestructura del Sistema de nombres de dominio (DNS).\nNslookup permite resolver direcciones IP asociadas a un determinado dominio. A través de este comando podemos obtener la dirección IP si conocemos el nombre, o al contrario, conocer el nombre del dominio si sabemos la dirección IP. Pero más allá de conocer el nombre o dirección IP también sirve para solucionar problemas de resolución de nombres y comprobar el estado actual de los servidores.\nEste comando cuenta con un modo de depuración que puede ser llamado con el comando nslookup set debug.\nUna de las utilidades que se le puede dar a nslookup es encontrar la IP de un nombre de dominio en un servidor DNS determinado.\nOtro posible uso de esta herramienta es buscar el nombre de dominio de una determinada dirección IP en el servidor DNS predeterminado en el equipo.\nEn general, nslookup es ampliamente usado para analizar problemas a la hora de acceder a una determinada página web, para saber la dirección IP asociada a una determinada web o para comprobar si un servidor DNS funciona correctamente.\nUtilidad del comando tracert Tracert es una herramienta de diagnóstico que determina la ruta de acceso a un destino mediante el envío de mensajes de solicitud de eco del Protocolo de mensajes de control de Internet (ICMP) o ICMPv6 al destino con valores de campo de período de vida (TTL) cada vez mayores. Cada enrutador a lo largo de la ruta de acceso debe disminuir el TTL de un paquete IP en al menos 1 antes de reenviarlo. En la práctica, el TTL es un contador máximo de vínculos. Cuando el TTL de un paquete alcanza 0, se espera que el enrutador devuelva un mensaje ICMP time Exceeded al equipo de origen.\nEste comando determina la ruta de acceso enviando el primer mensaje de solicitud de eco con un TTL de 1 e incrementando el TTL en 1 en cada transmisión posterior hasta que el destino responde o se alcanza el número máximo de saltos. El número máximo de saltos es 30 de forma predeterminada y se puede especificar mediante el parámetro /h.\nLa ruta de acceso se determina examinando los mensajes de ICMP time Exceeded devueltos por los enrutadores intermedios y el mensaje de eco de respuesta devuelto por el destino. Sin embargo, algunos enrutadores no devuelven mensajes de tiempo excedido para paquetes con valores TTL vencidos y son invisibles para el comando tracert. En este caso, se muestra una fila de asteriscos (*) para ese salto. La ruta de acceso mostrada es la lista de interfaces de enrutador cercano/lateral de los enrutadores en la ruta de acceso entre un host de origen y un destino. La interfaz cercana/lateral es la interfaz del enrutador que está más cerca del host emisor en la ruta de acceso.\nEl comando tracert tiene utilidad a la hora de averiguar si hay algún problema en el camino hacia un equipo de la red local o a un sitio web. Este comando aporta información sobre si la comunicación hacia el host de destino se pierde o interrumpe en algún punto del camino. Gracias a los resultados que devuelve, se puede averiguar en qué punto ocurre el problema.\nUno de los usos principales de este comando es el diagnóstico de errores en redes muy grandes en las que un paquete puede elegir diferentes caminos para llegar a su host de destino. Gracias a él, se puede saber por qué equipos de la red está pasando el paquete de datos enviado y así se puede mejorar el rendimiento de la red local.\nUtilidad del comando route print El comando route muestra y modifica las entradas de la tabla de enrutamiento de IP local. Si se le añade el parámetro print, el comando mostrará toda la información de la tabla de enrutamiento del ordenador. El comando route print se usa para ver la tabla de enrutamiento de un ordenador.\nAveriguar la IP pública de un router Se puede conocer la IP pública de una red de varias formas. La más sencilla de todas las opciones posibles es acceder a una de las múltiples herramientas web que ofrecen este tipo de información con una simple visita a su web como ocurre, por ejemplo, con cual-es-mi-ip.net. Este tipo de páginas muestra la IP pública desde la que se accede a ellas pero también otra información asociada a este dato como la compañía desde la que se realiza la conexión, si se está usando o no un proxy o la localización desde la que se está navegando por Internet.\nSin embargo, esta información también se puede conocer usando el comando nslookup.\nGNU/Linux Configuración de propiedades TCP/IP Hay dos formas de configurar los parámetros TCP/IP de una tarjeta de red en GNU/Linux. La primera de ellas es hacerlo a través de la interfaz gráfica, al igual que en el caso anterior con Windows.\nPara ello se puede usar la aplicación de conexiones de red y acceder a la conexión que se desee configurar.\nEn la nueva ventana se pueden modificar parámetros como el método de conexión (DHCP automático, manual, compartida con otros equipos o sólo enlace local) y se pueden añadir varias direcciones IP estáticas indicando su dirección, máscara de red y puerta de enlace. Además, se pueden añadir otros datos relevantes para la configuración TCP/IP como los servidores DNS adicionales, los dominios de búsqueda adicionales o la ID del cliente DHCP.\nAdemás, en otras pestañas de esta misma ventana se pueden configurar otros elementos como la red inalámbrica, la seguridad de la red a través de contraseña, el proxy y otros ajustes generales de la conexión.\nSin embargo, esta configuración también se puede llevar a cabo desde la línea de comandos. Para ello, el primer paso debe ser averiguar el nombre de la interfaz de red que se quiere configurar usando un comando como ip o iconfig.\nCon esta información, se puede acceder y modificar el fichero /etc/network/interfaces, que contiene la configuración TCP/IP de la tarjeta de red, entre otros parámetros importantes para las conexiones del ordenador.\nPor defecto este fichero contiene una configuración automática de los elementos de conexión a la red con los que cuenta el ordenador. Sin embargo, modificando la información que contiene se puede establecer una configuración TCP/IP diferente a la predeterminada para las diferentes tarjetas de red del equipo.\nUtilidad del comando ifconfig El comando ifconfig se puede utilizar desde la línea de comandos para asignar una dirección a una interfaz de red o para configurar o mostrar la información de configuración actual de la interfaz de red. El comando ifconfig debe usarse al inicio del sistema para definir la dirección de red de cada interfaz presente en una máquina.\nEn general, ifconfig permite configurar y ver los parámetros de la interfaz de red para las redes que hacen uso de TCP/IP residentes en el kernel de GNU/Linux. También permite asignar direcciones a una interfaz de red o configurar la información de configuración de esa interfaz según sea necesario.\nLa utilidad principal de ifconfig es conseguir información relacionada con las tarjetas de red de un ordenador. Este comando ofrece información sobre el nombre del adaptador, el número actual de MTU, la dirección IP asignada, la dirección MAC del adaptador, los paquetes enviados y recibidos o los paquetes con error y redireccionados.\nAdemás, ifconfig también permite habitiltar o deshabilitar una interfaz desde la línea de comandos.\nifconfig wlp2s0 down ifconfig wlp2s0 up El comando ifconfig también puede tener otros usos como, por ejemplo, establecer una nueva máscara de red o dirección IP a una interfaz determinada.\nifconfig wlp2s0 netmask 255.255.255.0 ifconfig wlp2s0 192.168.0.15 También permite modificar otros parámetros como la unidad máxima de transmisión (UMT), la puerta de enlace o la dirección MAC, así como crear alias para cada una de las interfaces de red. Finalmente, cabe destacar que ifconfig también se puede usar para obtener la información más relevante relacionada con una tarjeta de red de forma muy resumida.\n¿Hay alguna información de las que se obtiene con ipconfig /all que no aparezca? El comando ipconfig /all muestra los siguientes datos que no están disponibles al ejecutar ifconfig: sufijo DNS específico para la conexión, descripción de la tarjeta de red, dirección física, DHCP habilitado, configuración automática habilitada, servidor DHCP, puerta de enlace predeterminada IAID DHCPv6, DUID de cliente DHCPv6, servidores DNS y NetBIOS sobre TCP/IP.\nEsta es la información que se ha podido conseguir de otra forma:\nDescripción de la tarjeta de red Puerta de enlace predeterminada: route -n Servidores DNS: cat /etc/resolv.conf | grep nameserver Utilidad del comando dhclient El cliente DHCP de Internet Software Consortium, dhclient, proporciona un medio para configurar una o más interfaces de red utilizando el protocolo Dynamic Host Configuration Protocol, el protocolo BOOTP, o si estos protocolos fallan, asignando una dirección estáticamente.\nLa utilidad de este comando es configurar el servidor DHCP en un ordenador.\nDiferencias de netstat y ping entre Windows y GNU/Linux Netstat La primera gran diferencia a la hora de usar el comando netstat entre Windows y GNU/Linux es que mientras que en el primer caso simplemente hay que introducir el comando en la terminal y ejecutarlo, en el segundo se debe instalar el paquete que contiene este binario antes de poder ejecutarlo puesto que no viene instalado por defecto.\nOtra diferencia de netstat entre estos dos sistemas operativos es que en el caso de GNU/Linux muestra, por defecto, toda la información de conexiones sin necesidad de añadir ningún parámetro al comando mientras que en Windows es necesario añadir el parámetro -a.\nAdemás, cabe destacar que en GNU/Linux existe la opción de acceder a estadísticas del uso de la red a través del comando netstat si se añade el parámetro -s.\nping En el caso del comando ping la principal diferencia está en su uso. Windows envía, por defecto, cuatro paquetes de 32 bytes y, a partir de esa transmisión de información calcula las estadísticas que devuelve el comando, como porcentaje de paquetes perdidos y velocidad mínima, máxima y media de transmisión. En cambio, el comando ping en GNU/Linux envía por defecto paquetes de 64 bytes hasta que se interrumpa manualmente el proceso y, a partir de esas pruebas, devuelve las mismas estadísticas.\nUtilidad del comando dig Dig es un comando que permite realizar consultas a servidores DNS para obtener información relacionada con este servicio. Este comando permite hacer cualquier consulta DNS como registros tipo A (direcciones IP), TXT (texto), MX (servidores de correo) y los propios servidores de nombres. Por eso, dig se usa mucho para el diagnóstico de servidores DNS.\nEn general, uno de los principales usos del comando dig es obtener registros del servidor DNS de varios tipos.\nOtro uso frecuente del comando dig es obtener los servidores de nombre.\nAdemás, dig también se puede usar para obtener registros de otros tipos como MX o TXT.\nDiferencias entre traceroute y tracert Tal y como ocurre en el caso de netstat, la primera gran diferencia entre traceroute y tracert es que mientras este último está instalado en Windows, traceroute no está disponible en GNU/Linux hasta que se instala por parte del usuario.\nMás allá de esto, la única diferencia relevante en la salida que se muestra por pantalla al ejecutar el comando entre traceroute y tracert es el orden de los datos que se representan. Mientras tracert muestra primero las diferentes informaciones relacionadas con la velocidad de la transmisión de la información y al final de la línea las diferentes direcciones IP, traceroute lo hace al contrario y muestra al principio de la línea la información relativa a las diferentes direcciones IP y, más a la derecha, los datos que indican las diferentes velocidades que esta herramienta devuelve.\nUtilidad del comando wget El comando wget se utiliza para descargar archivos de Internet. Este comando también los guarda automáticamente en el directorio de trabajo actual. La descarga no es interactiva, es decir, el proceso puede llevarse a cabo sin haber iniciado sesión. También permite reanudar descargas incompletas o interrumpidas.\nWget es un recuperador por red no interactivo. Así, la utilidad principal del comando wget es descargar archivos de Internet.\nOtra posible utilidad es descargar archivos de Internet con nombres diferentes.\nwget -O- https://www.virtualbox.org/download/oracle_vbos_2016.asc Además, wget también se puede emplear con otros fines como, por ejemplo, limitar la velocidad de las descargas o el número de intentos.\nwget --limit-rate=500k https://ftp.gnu.org/gnu/wget/wget2-latest.tar.gz wget -tries=100 https://ftp.gnu.org/gnu/wget/wget2-latest.tar.gz Otra utilidad relevante de wget es la de ejecutar descargas de ficheros de Internet en segundo plano.\nwget -b https://ftp.gnu.org/gnu/wget/wget2-latest.tar.gz Por último, cabe destacar la que, probablemente, sea una de las utilidades más prácticas del comando wget: descargar páginas web completas.\nwget --mirror https://ftp.gnu.org/gnu/wget/ Utilidad del comando tcpdump y combinación con ngrep El comando tcpdump es una herramienta que se usa principalmente para analizar el tráfico que circula por una red. Tcpdump permite al usuario capturar y mostrar en tiempo real los paquetes transmitidos y recibidos por la red a la cual el ordenador está conectado.\nUna de las principales funciones de tcpdump es depurar aplicaciones en tiempo real que utilizan la red para comunicarse. También se puede usar para depurar la propia red y para capturar y leer datos enviados por otros usuarios u ordenadores. El objetivo de la captura de toda esta información es almacenarla para poder estudiarla posteriormente.\nOtro uso que se le puede dar a tcpdump es comprobar que el tráfico de una red es el esperado teniendo en cuenta su uso, así como capturar y leer los datos de otros equipos de la red.\nAdemás, tcpdump puede ser una herramienta peligrosa si se emplea con malas intenciones puesto que un usuario que tiene el control de un router a través del cual circula tráfico no cifrado puede usar tcpdump para conseguir contraseñas u otras informaciones.\nEl comando tcpdump devuelve una gran cantidad de información, por tanto, puede resultar muy práctico combinar su uso con el de un paginador como ngrep.\nUtilidad del comando arp y opción equivalente del comando ip El comando arp se usa para encontrar los detalles de los dispositivos conectados cuando el protocolo convierte la IP a MAC. Este comando manipula la memoria caché ARP del sistema. También permite un volcado completo de la memoria caché ARP. Arp puede añadir entradas a la tabla de la memoria caché ARP del sistema, eliminarlas o mostrar el contenido actual.\nExiste también una opción del comando ip que muestra la misma información que si se ejecuta el comando arp. La opción equivalente del comando ip para conseguir obtener esta misma información es neighbour.\nPosibilidades del comando ip de GNU/Linux La sintaxis del comando ip está formada por el nombre del comando seguido de una o varias opciones y un objeto. Como se puede apreciar en la página del manual del comando, existe una gran variedad de opciones y objetos que se pueden aplicar a este comando.\nSYNOPSIS ip [ OPTIONS ] OBJECT { COMMAND | help } ip [ -force ] -batch filename OBJECT := { link | address | addrlabel | route | rule | neigh | ntable | tunnel | tuntap | maddress | mroute | mrule | monitor | xfrm | netns | l2tp | tcp_metrics | token | macsec | vrf | mptcp | ioam } OPTIONS := { -V[ersion] | -h[uman-readable] | -s[tatistics] | -d[etails] | -r[esolve] | -iec | -f[amily] { inet | inet6 | link } | -4 | -6 | -B | -0 | -l[oops] { maximum-addr-flush-at‐ tempts } | -o[neline] | -rc[vbuf] [size] | -t[imestamp] | -ts[hort] | -n[etns] name | -N[umeric] | -a[ll] | -c[olor] | -br[ief] | -j[son] | -p[retty] } Entre las opciones, algunas de las más relevantes son -b o -batch, que lee los comandos del fichero que se indique y los invoca; -s, -stats o -statistics, que muestra más información que en el modo normal; -d o -details, que también muestra la información de forma más detallada; -r o -resolve, que sustituye las direcciones IP por los nombres de dominio DNS en la información que muestra por pantalla; o -br o -brief, que muestra solo información básica en formato tabular para facilitar su lectura.\nSin embargo, donde realmente reside el potencial del comando ip es en la variada lista de objetos que especifican el aspecto de la configuración de la red sobre el que este comando puede ejecutar sus tareas. Entre los objetos más relevantes que recoge el manual de este comando están address, que trabaja sobre la dirección IPv4 o IPv6 de un dispositivo; link, para configurar dispositivos de red; monitor, para monitorizar la red; neighbour, para trabajar con las entradas de la caché de ARP; netns, para gestionar los nombres de los dispositivos de la red; ntable, para gestionar las operaciones de la memoria caché; route, para trabajar sobre la tabla de enrutamientos; stats, para gestionar y mostrar las estadísticas de las diferentes interfaces de la red o tcp_metrics, para gestionar y monitorizar las métricas de las comunicaciones TCP.\nCon esta gran variedad de aspectos de la configuración de red sobre los que ip puede trabajar, este comando se convierte en le más completo y el que más opciones aporta para la gestión de redes a través de una única herramienta.\n"},{
  "section": "Blog",
  "slug": "/blog/sistemas/2023-11-10-ejemplos-comandos-basicos-debian/",
  "title": "Ejemplos de uso de comandos básicos en Debian",
  "description": "",
  "date": "November 10, 2023",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "sistemas",
  "tags": "sistemas, debian, linux, comandos básicos, ls, cd, mkdir, cp, mv, rm, comandos, Implantación de Sistemas Operativos",
  "content":"En esta entrada se recogen algunos ejercicios básicos que demuestran el uso de los comandos más usados en Debian y otras distribuciones GNU/Linux.\nEjemplos de uso del comando ls Listar todos los archivos del directorio bin Para realizar esta acción hay que acceder en primer lugar al directorio bin usando cd /./bin y, posteriormente, se pueden listar los archivos que contiene con ls -lh, para que muestre el contenido en forma de lista y el tamaño de los archivos en términos más fácilmente comprensibles.\ncd /./bin ls -lh Listar todos los archivos del directorio tmp En este caso, se debe repetir el mismo procedimiento que en el ejercicio anterior sustituyendo el directorio bin por tmp. Primero se accede con cd /./tmp y posteriormente se listan los archivos con ls -lRh. En este caso, se ha usado también la opción -R para listar recursivamente en los directorios dentro del directorio.\ncd /./tmp ls -lRh Listar todos los archivos del directorio etc que empiecen por \u0026ldquo;t\u0026rdquo; en orden inverso Al igual que en los casos anteriores, se accede al directorio con cd /./etc y después se listan los archivos con ls -lr t*. En este caso, la opción -r muestra el resultado en orden inverso y el argumento t* pide que se listen todos los archivos que empiezan por \u0026ldquo;t\u0026rdquo;.\ncd /./etc ls -lr t* Listar todos los archivos del directorio dev que empiecen por \u0026ldquo;tty\u0026rdquo; y tengan 5 caracteres En este caso, se accede con cd /./dev y, posteriormente, se listan los archivos con ls -lh tty??. Los signos de interrogación, a diferencia del asterisco, sustituyen a un único carácter cada uno.\ncd /./dev ls -lh tty?? Listar todos los archivos del directorio dev que empiecen por \u0026ldquo;tty\u0026rdquo; y acaben en \u0026ldquo;1\u0026rdquo;,\u0026ldquo;2\u0026rdquo;,\u0026ldquo;3\u0026rdquo; ó \u0026ldquo;4\u0026rdquo; En ls -lh tty*[1,2,3,4] el asterisco en este caso indica que se puede sustituir por uno o varios caracteres y la lista recoge todas las opciones de caracteres que se quieren listar como último carácter.\ncd /./dev ls -lh tty*[1,2,3,4] Listar todos los archivos del directorio dev que empiecen por \u0026ldquo;t\u0026rdquo; y acaben en \u0026ldquo;C1\u0026rdquo;. cd /./dev ls -lh t*C1 Listar todos los archivos, incluidos los ocultos, del directorio raíz Con el comando cd / se navega hasta el directorio raíz. Una vez allí, con el comando ls -la se listan todos sus archivos. La opción -a hace que se muestren también los archivos que empiezan por un ., es decir, los ocultos.\ncd / ls -la Listar todos los archivos del directorio etc que no empiecen por \u0026ldquo;t\u0026rdquo; En primer lugar se debe navegar al directorio etc con cd /./etc y, después listar los archivos con ls -l [!t]*. Para ello, se usa el carácter ! para indicar indicar una cadena de texto en la que el primer carácter sea distinto de \u0026ldquo;t\u0026rdquo; y el * para indicar que el resto de caracteres es indiferente.\ncd /etc ls -l [!t]* Listar todos los archivos del directorio usr y sus subdirectorios Para listar los archivos y subdirectorios de usr hay que cambiar al directorio /usr en primer lugar con cd /usr y, después, listar los archivos con ls -lR. En este caso, la opción -R fuerza la búsqueda recursiva dentro de los subdirectorios del directorio actual.\ncd /usr ls -lR Mostrar el día y la hora actual Para mostrar el día y la hora se usa el comando date.\nComandos para navegar entre directorios Cambiarse al directorio tmp Con el comando cd /tmp se cambia el directorio actual al directorio tmp.\nVerificar que el directorio actual ha cambiado Para verificar que el directorio actual ha cambiado se usa el comando pwd, que devuelve la ruta del directorio actual, en este caso /tmp en vez de /home/usuario, donde usuario corresponde al nombre de usuario que tiene la sesión iniciada.\n~$ cd /tmp /tmp$ pwd /tmp Con un solo comando posicionarse en el directorio $HOME Para cambiar al directorio home, se puede usar el comando cd ~, que navega del directorio actual al directorio /home/usuario.\nListar todos los ficheros del directorio HOME mostrando su número de inodo Para este ejercicio se usa el comando ls -lia para listar los archivos. Con la opción -i se muestra el número de inodo y con la opción -a se muestran los archivos ocultos.\ncd ~ ls -lia Crear en vuestro directorio de inicio, un directorio prueba Para crear un directorio se usa el comando mkdir seguido del nombre del directorio.\nmkdir prueba Crear los directorios dir1, dir2 y dir3 en el directorio prueba. Dentro de dir1 crear el directorio dir11. Dentro del directorio dir3 crear el directorio dir31. Dentro del directorio dir31, crear los directorios dir311 y dir312 En primer lugar, con mkdir se crean los directorios dentro de prueba: dir1, dir2 y dir 3 con una lista entre llaves. A continuación, dentro de dir1 se crea dir 11 y dentro de dir3, dir31.\nFinalmente, haciendo uso de una nueva lista, se crean los directorios dir311 y dir312 dentro de dir31.\nmkdir -p prueba/{dir1,dir2,dir3} prueba/dir1/dir11 prueba/dir3/dir31 prueba/dir3/dir31/{dir311,dir312} Copiar, mover y borrar ficheros Copiar el archivo /etc/motd a un archivo llamado mensaje de nuestro directorio prueba Para copiar un archivo se usa el comando cp con la ruta del archivo que se quiere copiar como primer argumento y la ruta de destino de la copia como segundo.\ncp /etc/mod ~/prueba/mensaje Copiar el archivo mensaje en dir1, dir2 y dir3 Nuevamente, para copiar el archivo se usa el comando cp con la ruta del archivo que se quiere copiar como primer argumento y la ruta de destino de la copia como segundo.\ncp ~/prueba/mensaje ~/prueba/dir1 cp ~/prueba/mensaje ~/prueba/dir2 cp ~/prueba/mensaje ~/prueba/dir3 Copiar los archivos del directorio rc2.d que se encuentra en /etc al directorio dir31 En este caso se usa la opción -r del comando cp para copiar de forma recursiva todo el contenido del directorio /etc/rc2.d.\ncp -r /etc/rc2.d ~/prueba/dir3/dir31 Copiar en el directorio dir311 los archivos de /bin que tengan una a como segunda letra y su nombre tenga cuatro letras En este ejemplo se usa la expresión regular [A-z] para indicar que una letra ocupa esa posición en el nombre del archivo.\ncp /bin/[A-z]a[A-z][A-z] ~/prueba/dir3/dir31/dir311 Copiar el directorio de otro usuario y sus subdirectorios debajo de dir11 (incluido el propio directorio) Para copiar el directorio y subdirectorios de otro usuario se usa la opción -a del comando cp, que copia recursivamente los subdirectorios dentro del directorio indicado conservando los atributos de los archivos incluidos en ellos.\ncp -a /home/usuario ~/prueba/dir1/dir11 Mover el directorio dir31 y sus subdirectorios debajo de dir2 Para mover un directorio se usa el comando mv con la ruta del directorio que se quiere mover como primer argumento y la ruta del directorio destino como segundo argumento.\nmv ~/prueba/dir3/dir31 ~/prueba/dir2 Mostrar por pantalla los archivos ordinarios del directorio HOME y sus subdirectorios Para mostrar todos los archivos del directorio home y sus subdirectorios se puede usar el comando find con la opción -type para filtrar la lista por tipo de ficheros y f para obtener sólo los ficheros de tipo ordinario.\nfind -type f Ocultar el archivo mensaje del directorio dir3 En GNU/Linux los archivos ocultos son aquellos que empiezan por un ., por tanto, para ocultar el archivo solo hay que renombrarlo con un . delante usando, por ejemplo, el comando cp.\ncp ~/prueba/dir3/mensaje ~/prueba/dir3/.mensaje Borrar los archivos y directorios de dir1, incluido el propio directorio El comando rm, seguido de una ruta de un directorio lo elimina. La opción -r hace que se eliminen recursivamente todos los directorios que contiene.\nrm -r ~/prueba/dir1 Copiar al directorio dir312 los ficheros del directorio /dev que empiecen por \u0026ldquo;t\u0026rdquo;, acaben en una letra que vaya de la \u0026ldquo;a\u0026rdquo; a la \u0026ldquo;b\u0026rdquo; y tengan cinco letras en su nombre cp /dev/t[A-z][A-z][A-z][a-b] ~/prueba/dir3/dir31/dir312 Borrar los archivos de dir312 que no acaben en \u0026ldquo;b\u0026rdquo; y tengan una \u0026ldquo;q\u0026rdquo; como cuarta letra rm ~/prueba/dir3/dir31/dir312/???q*[!b] Mover el directorio dir312 debajo de dir3 De nuevo, para mover un directorio se usa el comando mv con la ruta del directorio que se quiere mover como primer argumento y la ruta del directorio destino como segundo argumento.\nmv ~/prueba/dir3/dir31/dir312 ~/prueba/dir3 "},{
  "section": "Blog",
  "slug": "/blog/sistemas/2023-10-30-empaquetadores-compresores-debian/",
  "title": "Empaquetadores y compresores/descompresores en Debian",
  "description": "",
  "date": "November 3, 2023",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "sistemas",
  "tags": "sistemas, debian, linux, apt, empaquetadores, compresores, tar, gzip, zip, rar, compress, xz, 7z comandos, Implantación de Sistemas Operativos",
  "content":"Empaquetador tar Definición El empaquetador tar crea y manipula archivos que son, en realidad, colecciones de varios ficheros. Tar ofrece un método sistematizado y organizado de controlar grandes volúmenes de datos.\nEl programa tar se usa para crear y manipular archivos tar, que son archivos individuales que contienen el contenido de varios ficheros cuyos nombres, propietarios y otra información pueden conservar.\nLos ficheros contenidos en estos archivos se llaman miembros (members). El término extracción se refiere al proceso de copiar estos archivos miembros en un fichero en el sistema de ficheros. A la acción de extraer todos los miembros de un archivo también se la llama “extraer el archivo”. El término desempaquetar también se puede usar para referirse a la extracción de varios o todos los miembros de un archivo.\nExtraer un archivo no destruye la estructura del archivo, de la misma forma que crear un archivo no destruye las copias de los ficheros que existen fuera del archivo.\nTar ofrece la posibilidad de crear archivos tar, así como extraer ficheros de archivos previamente creados, almacenar fichero adicionales o actualizar la lista de ficheros que han sido almacenados en un archivo.\nOriginalmente, tar se usaba para almacenar archivos en cintas magnéticas y el nombre del programa viene de “tape archiver” (archivador de cinta). Sin embargo, tar puede enviar su salida a cualquier dispositivo disponible, ficheros o programas, a través de tuberías (pipes). Incluso puede acceder a dispositivos o ficheros remotos.\nEl programa tar se usa con mucha frecuencia para almacenar ficheros relacionados para su transferencia a través de una red, de manera que se puedan transferir como una única unidad. Los archivos tar también se suelen usar para almacenamiento de larga duración.\nOtro uso habitual de tar es el de las copias de seguridad. Los archivos tar conservan la información de los ficheros y la estructura de directorios, lo que hace que tar sea usado habitualmente para crear copias de seguridad de discos. Una copia de seguridad guarda una colección de ficheros y directorios en un disco, protegiendo la información contra una posible destrucción accidental. El programa tar tiene funcionalidades especiales que permiten que se pueda usar para hacer volcados de todos los ficheros de un sistema de ficheros.\nPor último, otro uso habitual de tar es la transferencia de información. Con tar se puede crear un archivo en un sistema, transferirlo a otro y extraerlo en él. De esta forma, se puede transferir un grupo de ficheros de un sistema a otro de forma cómoda y ordenada.\nOpciones más comunes y ejemplos de utilización Algunas de las opciones más comunes y su ejemplo de utilización para tar son:\ntar -A [OPTIONS] ARCHIVE ARCHIVE tar {--catenate|--concatenate} [OPTIONS] ARCHIVE ARCHIVE Empaqueta un archivo al final del otro. Los argumentos son los nombres de los archivos que se van a empaquetar. Todos los archivos deben tener el mismo formato que el resto de archivos con los que se van a empaquetar.\ntar -c [-f ARCHIVE] [OPTIONS] [FILE…] tar --create [--file ARCHIVE] [OPTIONS] [FILE…] Crea un nuevo archivo.\ntar -d [-f ARCHIVE] [OPTIONS] [FILE…] tar {--diff|--compare} [--file ARCHIVE] [OPTIONS] [FILE…] Encuentra las diferencias entre el archivo y el sistema de ficheros.\ntar --delete [--file ARCHIVE] [OPTIONS] [MEMBER…] Elimina ficheros o miembros del archivo. Los argumentos se refieren al nombre de los archivos miembros que se van a eliminar.\ntar -r [-f ARCHIVE] [OPTIONS] [FILE…] tar --append [-f ARCHIVE] [OPTIONS] [FILE…] Empaqueta ficheros al final de un archivo. Los argumentos se usan igual que con -c (\u0026ndash;create).\ntar -t [-f ARCHIVE] [OPTIONS] [MEMBER…] tar --list [-f ARCHIVE] [OPTIONS] [MEMBER…] Lista el contenido de un archivo. Los argumentos son opcionales y especifican los nombres de los miembros que se deben listar.\ntar --test-label [--file ARCHIVE] [OPTIONS] [LABEL…] Prueba la etiqueta de volumen y sale. Sin argumentos devuelve el volumen y sale, si se usan argumentos compara la etiqueta de volumen de cada argumento y devuelve un 0 si encuentra alguna coincidencia y un 1 si no.\ntar -u [-f ARCHIVE] [OPTIONS] [FILE…] tar --update [--file ARCHIVE] [OPTIONS] [FILE…] tar --update [-f ARCHIVE] [OPTIONS] [FILE…] Empaqueta ficheros que son más nuevos que la copia correspondiente en el archivo. Los argumentos tienen el mismo significado que con -c y -r.\ntar -x [-f ARCHIVE] [OPTIONS] [MEMBER…] tar {--extract|--get} [-f ARCHIVE] [OPTIONS] [MEMBER…] Extrae ficheros de un archivo. Los argumentos son opcionales. Especifican el nombre de los miembros del archivo que se van a extraer.\nExtensión de los ficheros Los ficheros empaquetados con tar tienen la extensión .tar.\nPaquete donde se encuentra tar se encuentra en el paquete tar, ubicado en la ruta /usr/bin/tar.\nCompresor/descompresor gzip Definición La orden gzip reduce el tamaño del archivo nombrado usando el código Lempel-Ziv (LZ77). Cuando sea posible, cada fichero se reemplaza por una con extensión .gz manteniendo la propiedad, acceso y fecha de modificación.\nSi el fichero tiene un nombre demasiado largo para el sistema de ficheros, gzip también puede truncar el nombre. Por defecto, mantiene el mismo nombre en los ficheros comprimidos. Además, gzip también puede descomprimir ficheros creados por gzip, zip, comrpess o pack.\nOpciones más comunes y ejemplos de utilización Un ejemplo de utilización de gzip es el siguiente:\ngzip [OPTION]… [FILE]… Entre las opciones más comunes se encuentran:\n-c, --stdout. Escribe el fichero en salida estándar y mantiene sin cambio los ficheros originales. -d, --decompress. Descomprime los ficheros indicados. -f, --force. Fuerza la sobreescritura del fichero de salida y comprime los enlaces. -h, --help. Muestra la ayuda del comando. -k, --keep. Conserva el fichero de entrada. -l, --list. Lista el contenido de los ficheros comprimidos -n, --no-name. No conserva ni recupera el nombre y la hora de modificación del fichero original. -N, --name. Guarda y recupera el nombre y la hora de modificación del fichero original. -r, --recursive. Opera de forma recursiva en directorios. -t, --test. Comprueba la integridad de los ficheros comprimidos. -v, --verbose. Modo verboso -V, --version. Muestra el número de versión. -1, --fast. Comprime más rápido. -9, --best. Comprime mejor. Extensión de los ficheros Los ficheros empaquetados con gzip tienen la extensión .gz.\nPaquete donde se encuentra Gzip se encuentra en el paquete gzip, ubicado en la ruta /usr/bin/gzip y en el paquete klibc-utils, ubicado en la ruta /usr/lib/klibc/bin/gzip.\nCompresor/descompresor xz Definición El programa xz es una herramienta de compresión de datos de propósito general con una sintaxis de línea de comando similar a gzip y bzip2. Soporta el formato nativo .xz pero también .lzma.\nCon xz se pueden comprimir o descomprimir cada fichero según un modo de operación seleccionado. El nombre del fichero comprimido deriva del fichero original. Al comprimir, se añade al fichero original el sufijo .xz o .lzma. Al descomprimir, se elimina el sufijo. Además, xz también reconoce las extensiones .txz y .tlz y las sustituye por .tar.\nTras comprimir o descomprimir un fichero, xz copia también el propietario, grupo, permisos, hora de acceso y de modificación del fichero origen.\nOpciones más comunes y ejemplos de utilización Un ejemplo de utilización de xz es el siguiente:\nxz [OPTION]… [FILE]… Entre las opciones más comunes se encuentran:\n-z, --compress. Comprime el fichero. Es el modo de operación por defecto. -d, --decompress, --uncompress. Descomprime el fichero. -t, --test. Comprueba la integridad de los ficheros comprimidos. -l, --list. Lista información sobre los ficheros comprimidos. No se produce ninguna descompresión. -k, --keep. No elimina los ficheros de entrada. -f, --force. Realiza varias acciones: Si el fichero objetivo existe, lo elimina antes de comprimirlo o descomprimirlo. Comprime o descomprime aunque el fichero sea un enlace simbólico de un fichero normal. -c, --stdout, --to-stdout. Escribe la información comprimida o descomprimida a la salida estándar en vez de a un fichero. -S .suf, --suffix=.suf. Permite seleccionar la extensión del archivo. Al comprimir, se puede elegir una extensión diferente a .xz y .lzma. Al descomprimir, reconocer los ficheros con el sufijo indicado además de .xz, .lzma, .txz, .tlz o .lz. Extensión de los ficheros Los ficheros empaquetados con xz tienen la extensión .xz o .lzma. También reconoce y descomprime ficheros con extensiones como .txz, .tlz o .tz.\nPaquete donde se encuentra Xz se encuentra en el paquete xz, ubicado en la ruta /usr/bin/xz.\nCompresor/descompresor bzip2 Definición El programa bzip2 comprime ficheros usando la compresión de Burrows-Wheeler y el código de Huffman. Esta compresión es, generalmente, mejor que la obtenida con compresores más convencionales basados en LZ77/LZ78. Está consturido sobre la librería libbzip2, una librería flexible para el manejo de datos comprimidos en formato bzip2.\nLas opciones de bzip2 son muy similares a las de gzip pero no idénticas. Cada fichero se sustituye por una versión comprimida de sí mismo con el nombre original y la extensión .bz2. Los ficheros comprimidos conservan la fecha de modificación, permisos y, cuando es posible, propiedad que el original. Bzip2 no sobreescribe los ficheros originales por defecto. Si el fichero no usa una extensión reconocible por bzip2 (.bz2, .bz, .tbz2 o .tbz), bzip2 advierte de que no se ha podido averiguar la extensión y usa el nombre del fichero original con la extensión .out.\nOpciones más comunes y ejemplos de utilización Algunos ejemplos de utilización de bzip2 son los siguientes:\nbzip2 [OPTION]… [FILE]… bunzip2 [OPTION]… [FILE]… bzcat [OPTION]… [FILE]… bzip2recover FILE Entre las opciones más comunes se encuentran:\n-c --stdout. Comprime o descomprime a la salida estándar. -d --decompress. Descomprime el fichero indicado. -z --compress. Comprime el fichero indicado. -t --test. Comprueba la integridad de los ficheros comprimidos. -f --force. Fuerza la sobreescritura del fichero de salida. Por defecto, bzip2 no sobreescribe los ficheros de salida. -k --keep. Conserva los ficheros de entrada durante la compresión o descompresión. -s --small. Reduce el uso de memoria para la compresión, descompresión y comprobación de los ficheros. -v --verbose. Modo verboso. Muestra el ratio de compresión para cada fichero. -L --license -V --version. Muestra la versión, licencia, términos y condiciones del software. -1 (or --fast) to -9 (or --best). Determina el tamaño de los bloques de compresión. Extensión de los ficheros Los ficheros empaquetados con bzip2 tienen la extensión .bz2. También reconoce y descomprime ficheros con extensiones como .bz, .tbz2 o .tbz.\nPaquete donde se encuentra bzip2 se encuentra en el paquete bzip2, ubicado en la ruta /usr/bin/bzip2.\nCompresor/descompresor 7z Definición 7-Zip es software de fuente abierta. La mayor parte del código fuente se distribuye bajo la licencia GNU LGPL. Algunas partes del código están bajo la licencia BSD de 3 cláusulas.\n7-Zip es un archivador de ficheros que soporta 7z, que implementa la compresión algorítmica LZMA con una ratio de compresión muy alta. El ratio de compresión en 7z es entre un 30% y un 50% mejor que en el formato zip.\nCada fichero indicado se comprime a uno con extesión .7z y después se elimina.\nOpciones más comunes y ejemplos de utilización Un ejemplo de utilización de p7zip es el siguiente:\np7zip [OPTION]… [FILE]… Entre las opciones más comunes se encuentran:\n-c, --stdout, --to-stdout. Escribe la salida a la salida estándar. -d, --decompress, --uncompress. Descomprime los archivos. -f, --force. Fuerza la compresión o descompresión. -k, --keep. No elimina el fichero de entrada. --. Trata todos los argumentos que siguen como nombres de ficheros aunque comiencen con un guión (-). Extensión de los ficheros La extensión de los ficheros comprimidos con 7z es .7z.\nPaquete donde se encuentra 7z se encuentra en el paquete p7zip, ubicado en la ruta /usr/bin/p7zip. P7zip también es una librería ubicada en la ruta /usr/lib/p7zip.\nCompresor/descompresor zip Definición Zip empaqueta y comprime ficheros. Zip es una utilidad de compresión y empaquetado de ficheros análoga a una combinación de los comandos tar y compress de Unix y es compatible con PKZIP.\nEste programa es útil para empaquetar un conjunto de ficheros para su distribución, para archivar ficheros y para ahorrar espacio en el disco duro comprimiendo temporalmente ficheros y directorios que no se usan.\nZip almacena uno o varios ficheros comprimidos en un único archivo zip, junto con información sobre los ficheros (nombre, ruta, fecha y hora de la última modificación, protección e información de comprobación de la integridad del fichero). Una estructura de directorios completa se puede empaquetar en un fichero zip con un único comando. Zip puede comprimir los ficheros o guardarlos sin compresión.\nOpciones más comunes y ejemplos de utilización Un ejemplo de utilización de zip es el siguiente:\nzip [OPTION]... [FILE]... [INPATH]... Entre las opciones más comunes se encuentran:\n-f --freshen. Reemplaza una entrada existente en el archivo zip sólo si se ha modificado más recientemente que la versión que ya se encuentra en el archivo. -u --update. Afecta sólo a ficheros nuevos o modificados. -d --delete. Elimina entradas de un archivo zip. -m --move. Mueve ficheros a un archivo zip. -r --recurse-path. Afecta recursivamente al contenido de un directorio. -j --junk-path. No guarda los nombres de los directorios. -0 --output-file. Solo almacena los ficheros sin comprimirlos. -# (-0 … -9). Indica la velocidad de compresión. -1 comprime más rápido; -9 comprime mejor. -v --verbose. Modo verboso. Muestra información por pantalla. -c --entry-comments. Añade comentarios de una línea para cada fichero. -z --archive-comment. Añade comentarios de varias líneas al archivo completo. -@ --names-stdin. Toma la lista de ficheros de entrada de la entrada estándar. -o --latest-time. Asigna la fecha de modificación del fichero más antiguo al archivo zip. -x --exclude. Excluye los ficheros indicados -i --include. Incluye los ficheros indicados. -F --fix. Se usa si alguna falta alguna parte del acrhivo. -FF –fixfix se usa si el archivo está demasiado dañado. -D --no-dir-entries. No crea entradas para directorios en el archivo zip. -A --adjust-sfx. Hace un archivo ejecutable que se extrae automáticamente. -J --junk-sfx. Almacena el nombre del fichero guardado pero no los nombres de los directorios. -T --test. Comprueba la integridad de los ficheros -X --no-extra. No almacena atributos extra de los ficheros. -e --encrypt. Encripta el contenido del archivo. -n --suffixes. No comprime los fiches con la extensión indicada. Extensión de los ficheros La extensión de los ficheros comprimidos con zip es .zip.\nPaquete donde se encuentra zip se encuentra en el paquete zip, ubicado en la ruta /usr/bin/zip.\nCompresor/descompresor rar Definición Rar es un compresor y archivador que empaqueta ficheros con compresión.\nOpciones más comunes y ejemplos de utilización Un ejemplo de utilización de zip es el siguiente:\nrar \u0026lt;command\u0026gt; [-\u0026lt;switch 1\u0026gt; -\u0026lt;switch N\u0026gt;] archive [files…] Entre las opciones más comunes se encuentran:\n-a. Añade ficheros al archivo. -c. Añade comentarios al archivo. -cf. Añade comentarios al fichero. -cw. Añade un comentario a un fichero especificado. -d. Elimina ficheros del archivo. -e. Extrae ficheros del directorio actual. No crea subdirectorios. -f. Actualiza los ficheros del archivo. -k. Bloquea los archivos. -l[t]. Lista el contenido del archivo -m[f]. Mueve los archivos. Con f se mueven solo los ficheros y no se eliminan los directorios. -p. Muestra el fichero por la salida estándar. -r. Repara el archivo -t. Comprieba la integridad de los ficheros. -u. Actualiza los ficheros de un archivo. -v[t]. Modo verboso. Muestra información del archivo. -x. Extra ficheros sin la ruta completa. Extensión de los ficheros La extensión de los ficheros comprimidos con rar es .rar.\nPaquete donde se encuentra rar se encuentra en el paquete rar, ubicado en la ruta /usr/bin/rar.\nCompresor/descompresor unzip Definición Lista, comprueba y extrae los ficheros almacenados en un archivo zip. Por defecto, unzip extrae los ficheros en el directorio de trabajo.\nOpciones más comunes y ejemplos de utilización Un ejemplo de utilización de unzip es el siguiente:\nunzip [OPTION]… [FILE]… Entre las opciones más comunes se encuentran:\n-p. Extrae los ficheros a una tubería. -f. Actualiza los ficheros existentes y no crea ninguno nuevo. -u. Actualiza los ficheros y crea los que sean necesarios. -v. Lista en modo verboso y muestra información de la versión. -x. Excluye los ficheros indicados. -n. No sobreescribe ficheros existentes. -o. Sobreescribe ficheros -j. No crea directorios. -K. Conserva los permisos de setuid/setgid/tracky -l. Lista los ficheros en formato corto. -t. Comprueba la integridad de los ficheros comprimidos. -z. Muestra sólo los comentarios. -T. Usa la marca temporal más antigua para el archivo. -d. Extrae los ficheros a exdir. -a. Convierte automáticamente cualquier fichero de texto. -aa. Trata todos los ficheros como ficheros de texto. -M. Muestra el resultado en el paginador “more”. Extensión de los ficheros Unzip descomprime archivos con formato .zip.\nPaquete donde se encuentra Unzip se encuentra en el paquete unzip, ubicado en la ruta /usr/bin/unzip.\nCompresor/descompresor unrar Definición El programa unrar extrae ficheros de archivos rar.\nOpciones más comunes y ejemplos de utilización Un ejemplo de utilización de unzip es el siguiente:\nunrar command [-switch ...] archive [file ...] [@listfiles ...] [path...] [path_to_extract/] Entre las opciones más comunes se encuentran:\ne. Extrae los ficheros al directorio de trabajo. l. Lista el contenido del archivo. t. Comprueba la integridad de los ficheros v. Lista el contenido del archivo en modo verboso. x. Extrae los ficheros con una ruta completa. -ag. Genera nombres de archivo usando la fecha actual. -ai. Ignora los atributos de los ficheros. -c-. Deshabilita los comentarios. -cl. Convierte los nombres de los ficheros a minúsculas. -cu. Convierte los nombres de los ficheros a mayúsculas. -ep. Excluye las rutas de los nombres. -kb. Mantiene los ficheros extraídos rotos. -o+. Sobreescribe ficheros existentes. -o-. No sobreescribe los ficheros existentes. -or. Renombra los ficheros automáticamente. -r. Afecta recursivamente a los subdirectorios. -sl\u0026lt;tamaño\u0026gt;. Procesa los ficheros con un tamaño menor del especificado. -sm\u0026lt;tamaño\u0026gt;. Procesa los ficheros con un tamaño mayor del especificado. -u. Actualiza los ficheros -v. Lista todos los volúmenes. -x\u0026lt;fichero\u0026gt;. Excluye el fichero especificado -x@\u0026lt;lista\u0026gt;. Excluye los ficheros de la lista especificada. Extensión de los ficheros unrar descomprime archivos con formato .rar.\nPaquete donde se encuentra unrar se encuentra en el paquete unrar, ubicado en la ruta /usr/bin/unrar.\nCompresor/descompresor compress Definición Compress reduce el tamaño de los ficheros indicados usando el código adaptativo Lempel-Ziv. Cuando sea posible, cada fichero se reemplaza por uno con la extensión .Z y se mantienen la propiedad de los ficheros y la hora de acceso y modificación. Si no se especifican los ficheros, se comprimen los ficheros de la entrada estándar a la salida estándar. Compress sólo intenta comprimir ficheros normales e ignora los enlaces simbólicos. Los ficheros comprimidos usando compress se pueden restaurar a su forma original usando uncompress.real.\nOpciones más comunes y ejemplos de utilización Un ejemplo de utilización de compress es el siguiente:\ncompress [OPTION]… [NAME]… Entre las opciones más comunes se encuentran:\n-c. Escribe a la salida estándar. No modifica los ficheros. -r. Opera de forma recursiva. Si algún fichero especificado es un directorio, compress accede al directorio y comprime todos los ficheros que encuentre en él. -V. Muestra la versión antes de realizar ninguna compresión o descompresión. -b. Indica el nivel de compresión en n.º de bits. -v. Muestra el porcentaje de reducción de cada fichero comprimido. --. Indica que todo el resto de argumentos se deben tratar como rutas. Extensión de los ficheros Compress comprime archivos en formato .Z.\nPaquete donde se encuentra Compress se encuentra en el paquete ncompress, ubicado en la ruta /usr/bin/ncompress.\n"},{
  "section": "Blog",
  "slug": "/blog/redes/2023-10-31-instalaci%C3%B3n-wireshark-debian-12-bookworm-windows-10/",
  "title": "Instalación de Wireshark y GNS3 en Debian 12 y Windows 10",
  "description": "",
  "date": "October 31, 2023",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "redes",
  "tags": "Wireshark, GNS3, redes, Planificación y Administración de Redes",
  "content":"1. Instalación de Wireshark 1.1. Instalación en Debian 12 El paso previo al inicio de la instalación del software requerido para esta práctica es, como en cualquier proceso de instalación en Debian, actualizar los paquetes instalados en la máquina a través de las órdenes apt update y apt upgrade.\nCon el software del equipo actualizado, se puede comenzar con la instalación, en primer lugar, de Wireshark. Para ello, sólo hay que ejecutar en la terminal la orden apt install wireshark, tal y como se explica en la documentación técnica disponible en la web del software y, posteriormente, aceptar la ejecución del proceso de instalación.\nCuando finalice la ejecución de esta orden, Wireshark estará instalado en Debian 12 y listo para usarse.\n1.2. Instalación en Windows 10 El primer paso para la instalación de Wireshark en Windows 10 es acceder a la web del software y descargar el instalador.\nUna vez finalizada la descarga, al ejecutar el archivo de instalación, Windows pide conceder permisos a la aplicación para que haga cambios en el dispositivo.\nDespués de concederle esos permisos, lanza un asistente de instalación en el que se puede navegar por varias pantallas para configurar los diferentes elementos de la instalación hasta que, finalmente, se puede ejecutar el proceso.\nEl instalador muestra una primera pantalla de bienvenida, seguido de una pantalla en la que se recoge la licencia del software con fines informativos, otra nueva pantalla en la que se pueden elegir los componentes que se desean instalar, otra en la que se eligen los accesos directos que se van a generar durante la instalación, en la siguiente se debe indicar la ruta de la carpeta del programa, después se ofrece la posibilidad de instalar junto a Wireshark también Packet Capture y en la siguiente ventana USB Capture. Finalmente, se ejecuta el proceso de instalación.\nFinalmente, tras completarse el proceso de instalación, se debe reiniciar el equipo.\n2. Instalación de GNS3 2.1. Instalación en Debian El proceso de instalación de GNS3 no es tan sencillo como el de Wireshark. Además, la documentación oficial del proyecto GNS3 no recoge las instrucciones de instalación para Debian 12, que no son exactamente iguales a las que se debe seguir en distribuciones anteriores del mismo sistema operativo.\nEl primer paso es la instalación de varios paquetes relacionados con Python.\napt install python3-pip python3-venv python3-pyqt5.qtsvg python3-pyqt5.qtwebsockets A continuación, se deben instalar varios paquetes relacionados con qemu, según la documentación oficial, tales como qemu, qemu-kvm, qemu-utils, libvirt-clients, libvirt-daemon-system y virtinst. Muchos de estos paquetes generan problemas a la hora de su instalación en Debian 12.\nGracias a la orden apt search qemu, aparece una opción, qemu-system, con la que se deben instalar estos paquetes en el equipo y que sí es compatible con Debian 12. Por tanto, en este punto, se puede probar esta opción ejecutando apt install qemu-system.\nEsta instalación puede devolver algunos errores. Para tratar de solventarlos, se ejecutan las órdenes apt install qemu-system --fix-missing y apt --fix-broken install.\nSin embargo, aunque parece que algunos errores se han podido solucionar, está claro que aún quedan errores de dependencias que persisten.\nDe momento, estos errores no impiden continuar con los pasos indicados en el proceso de instalación. El siguiente es la instalación de una nueva serie de paquetes: wireshark, xtightvncviewer, apt-transport-https, ca-certificates, curl, gnupg2 y software-properties-common.\nY hasta aquí llegan las instrucciones incluidas en la documentación oficial de GNS3 para su instalación en Debian.\nPero la realidad es que aún quedan varios pasos más hasta poder instalar y, por fin, ejecutar este software. Concretamente, se debe crear y activar un entorno virtual de Python e instalar una serie de paquetes desde PyPI, según las instrucciones indicadas por un usuario del foro superuser.com. Para crear el entorno virtual se ejecuta la orden python3 -m venv gns3env y para activarlo source gns3env/bin/activate. Entonces, se puede instalar el primer paquete: pyqt5. Finalmente, se instalan también los paquetes gns3-server y gns3-gui.\npip install pyqt5 pip install gns3-server pip install gns3-gui 2.2. Instlación en Windows 10 La instalación de GNS3 en Windows no presenta tantas dificultades. En primer lugar, se debe acceder a la web de GNS3 para crear una cuenta y, con ella, descargar el archivo ejecutable que va a guiar la instalación.\nTras crear la cuenta, descargar y ejecutar el instalador, el sistema pregunta si se debe conceder permiso al software para hacer cambios en el dispositivo.\nUna vez concedidos los permisos, se lanza el ejecutable. Primero muestra una pantalla de bienvenida y, a continuación, muestra también la licencia. En la siguiente pantalla se debe seleccionar una carpeta del menú de inicio o crear una nueva para el programa y después se eligen los componentes que se van a instalar, la ruta en la que se instalará el programa y el tipo de máquina virtual en las sucesivas pantallas.\nFinalmente, se ejecuta el proceso de instalación y, una vez finalizado, se muestra una última pantalla de confirmación de la instalación.\n3. Instalación de GNS3 VM La instalación de GNS3 VM es un proceso sencillo que sigue los mismos pasos tanto si se instala en un SO Windows como si se hace en Debian. Se puede hacer de forma autónoma o a través del asistente de instalación incluido en GNS3.\n3.1. Instalación de GNS3 VM de forma autónoma en Debian 12 En este primer ejemplo, se instalará GNS3 VM en una máquina que usa Debian 12 como sistema operativo. Para hacerlo, no se seguirán los pasos indicados en el asistente de instalación que se puede lanzar desde GNS3 sino que se seguirán las instrucciones que se recogen en la documentación del programa en su web.\nEn primer lugar se debe descargar el archivo de la web de GNS3.\nPosteriormente, se debe descomprimir el archivo e importarlo a VirtualBox desde el menú archivo → importar servicio virtualizado.\nEsta acción lanza un asistente para la configuración en el que se debe indicar, en primer lugar, la ubicación del archivo que se desea importar.\nFinalmente, en la siguiente ventana, se muestran las propiedades que se van a configurar en el proceso de importación del archivo.\nTras pulsar en terminar, la importación y configuración ha finalizado.\n3.2. Instalación de GNS3 VM con asistente en Windows 10 Si se prefiere usar el asistente de instalación, el proceso para conseguir hacer funcionar GNS3 VM es ligeramente más sencillo. Desde GNS3 se debe lanzar el asistente de instalación, que te indica que debes instalar VirtualBox o VMWare en el equipo. Una vez realizado este paso, el asistente descarga automáticamente el archivo con extensión .ova al equipo y lanza VirtualBox. En la nueva ventana, solo hay que seleccionar la opción de importar.\nA continuación, el asistente añade la ruta al archivo con extensión .ova que se va a importar para configurar GNS3 VM.\nDespués, en la siguiente ventana, se muestran las preferencias del servicio, algunas de las cuales se pueden modificar.\nFinalmente, tras pulsar en terminar, GNS3 VM está configurado.\n"},{
  "section": "Blog",
  "slug": "/blog/sistemas/2023-10-25-conceptos-basicos-apt/",
  "title": "Conceptos básicos del gestor de paquetes apt",
  "description": "",
  "date": "October 25, 2023",
  "image": null,
  "imageSM": null,
  "searchKeyword": "",
  "categories": "sistemas",
  "tags": "sistemas, debian, linux, apt, paquetes, comandos, Implantación de Sistemas Operativos",
  "content":"1. Prerrequisitos de la gestión de paquetes Debian 1.1. Sistema de gestión de paquetes El archivo de Debian está formado por nodos espejos a los que se puede acceder a través del sistema de gestión de paquetes apt (herramienta de empaquetado avanzado), que gestiona los 70312 paquetes disponibles en estos nodos de Debian.\nLos tres comandos principales de apt son apt, para todas las operaciones de la línea de órdenes; apt-get, como opción de reserva en sistemas antiguos en los que apt no está disponible; y aptitude, para la gestión interactiva mediante la interfaz de texto.\n1.2. Configuración de paquetes Algunos paquetes importantes en la gestión de paquetes en Debian son:\ndpkg. Sistema de gestión de paquetes de bajo nivel para Debian. apt. Front-end de APT para administrar paquetes. aptitude. Front-end de APT para gestionar paquetes de forma interactiva con consola de pantalla completa. tasksel. Front-end de APT para instalar las tareas seleccionadas: tasksel(8). unattended-upgrades. Paquete mejorado de APT, para permitir la instalación automática de actualizaciones de seguridad. gnome-software. Centro de software para GNOME a través de interfaz gráfica. synaptic. Gestor de paquetes gráfico. apt-utils. Utilidades de APT. apt-listchanges. Herramienta de notificación de cambios en el histórico de paquetes. apt-listbugs. Relación de bugs críticos después de cada instalación APT. apt-file. Utilidad APT para la búsqueda de paquetes a través de la interfaz de línea de órdenes apt-rdepends. Relación de dependencias recursivas de los paquetes. 1.3. Precauciones principales La guía de referencia de Debian recomienda usar la versión estable del SO y aplicar sólo actualizaciones de seguridad e indica que, hasta entender muy bien el sistema, se debe evitar incluir pruebas o versiones no estables en la lista de fuentes, mezclar Debian estándar con otros archivos no Debian (como Ubuntu) en la lista de fuentes, no crear el archivo “/etc/apt/preferences”, no modificar el comportamiento de la herramienta de gestión de paquetes a través de los archivos de configuración, no instalar paquetes aleatorios, no borrar ni modificar los archivos de “/var/lib/dpkg” y no instalar paquetes sin probarlos en un entorno seguro.\n1.4. Conviviendo con actualizaciones continuas Para usar versiones más nuevas, Debian recomienda elegir la versión testing y limita el uso de la versión unstable a un entorno para depurar paquetes por parte de los desarrolladores. La guía indica que los paquetes de la suite testing se actualizan con la suficiente frecuencia como para ofrecer las funciones más recientes. Para ello, recomienda establecer el nombre “trixie” de la versión testing en la lista de fuentes.\nAdemás, recomienda que, como precaución, se use u sistema de arranque dual con la versión stable en otra partición del equipo, se tenga a mano el CD de instalación para poder hacer un arranque de recuperación del sistema si fuese necesario, se instale el paquete apt-listbugs para comprobar la información del sistema de seguimiento de errores antes de la actualización y se conozca la infraestructura del sistema de paquetes para poder solucionar los problemas que puedan surgir.\n1.5. Fundamentos del archivo de Debian El sistema APT permite acceder al archivo de Debian. APT especifica la fuente de los datos en el archivo de lista de fuentes. Este archivo se encuentra en el directorio /etc/apt/ con el nombre sources.list y sources.list.d. En él, cada línea define la fuente de datos para el sistema APT, la línea deb indica las fuentes de paquetes binarios y la línea deb-src indica la fuente de los paquetes fuente. En cada línea, el primer argumento es la URL root del espejo del archivo de Debian que se use y el segundo es el nombre de la suite o nombre en clave de la distribución. El tercer argumento y sucesivos recogen la relación de nombres de área válidos del archivo Debian.\nEn este sentido, la guía muestra varias advertencias. La primera es que solo la versión estable pura (bookworm) con las actalizaciones de seguridad proporciona la mejor estabilidad. También recomienda no mezclar la versión estable con paquetes de pruebas o inestables. Otra de las advertencias es que se debe evitar indicar más de una de las tres versiones “estable”, “en pruebas” o “inestable” en el archivo de lista de fuentes porque sólo la última es útil.\nPor otra parte, también sugiere incluir el enlace a las actualizaciones de seguridad en la lista de fuentes para habilitar este tipo de actualizaciones.\nEl proceso para el desarrollo de los paquetes de Debian comienza con una entrega a la distribución inestable, después pasan a la distribución en pruebas, donde se comprueba el estado de los informes de errores y su compatibilidad con el último conjunto de paquetes de la distribución. Tras realizar intervenciones manuales para hacer la distribución en pruebas totalmente consistente y libre de errores se publica como estable. Puede ocurrir que en las versiones en prueba e inestable se generen errores porque se suben paquetes rotos al repositorio, hay retrasos en la recepción de nuevos paquetes, hay problemas con el tiempo de sincronización de los archivos o se realizan acciones manuales sobre el archivo para la eliminación de paquetes, por eso, la guía indica que si se quiere usar este tipo de archivos se debe ser capaz de arreglar este tipo de problemas.\n1.6. Debian es 100% software libre La guía de referencia de Debian explica que este SO es 100% software libre porque instala por defecto únicamente software libre, proporciona sólo software libre en el área principal (main), recomienda ejecutar únicamente el software libre del área principal y no hay paquetes en principal que dependa o recomienden paquetes de otras áreas. Sin embargo, hay paquetes fuera del sistema Debian que están alojados en los servidores de Debian en las áreas non-free, non-free-firmware y contrib para dar soporte a las necesidades de los usuarios. Estos paquetes implican restricciones a las libertades que sí recogen los paquetes de software libre, falta de soporte de Debian y contagio al 100% del sistema libre Debian.\n1.7. Dependencias de paquetes El sistema Debian establece relaciones de dependencia entre los paquetes. Algunos tipos de dependencia son:\n«Depende» (Depends). Declara una dependencia obligatoria y es obligatorio que todos los paquetes enumerados sean instalados al mismo tiempo o que estén instalados previamente. «Predepende» (Pre-depends). Son como las dependencias, con la excepción de que es obligatorio que estén instalados completamente con anterioridad. «Recomienda» (Recommends). Determina una dependencia fuerte, pero no obligatoria. La mayoría de los usuarios no querrán instalar el paquete al menos que todos los paquetes enumerados en este campo estén instalados. «Sugiere» (Suggests). Declara una dependencia débil. Muchos usuario podrían beneficiarse de su instalación si bien tendrán una funcionalidad suficiente sin ellos. «Mejora» (Enhances). Declara una dependencia débil como Sugerida pero va en la dirección contraria. «Rompe» (Breaks). Declara una incompatibilidad, generalmente con una versión concreta. La solución más común es actualizar todos los paquetes que se encuentran enumerados en este campo. «Incompatibles» (Conflicts). Declara su total incompatibilidad. Todos los paquetes enumerados en este campo deben ser eliminados para conseguir instalar el paquete. «Sustituye» (Replaces). Se declara cuando los archivos instalados por el paquete sustituyen a los archivos de los paquetes que se enumeran. «Proporciona» (Provides). Se declara cuando el paquete proporciona todos los archivos y funcionalidades de los paquetes enumerados. 1.8. Flujo de eventos de las órdenes de gestión de paquetes La guía de referencia indica que el flujo que se debe seguir a la hora de gestionar los paquetes a través de apt es:\nUpdate – Para recuperar metadatos del archivo remoto y actualizar la copia local de los metadatos de apt. Upgrade – Para resolver las dependencias de los paquetes, recuperar los binarios cuya versión candidata es diferente a la instalada, desempaquetar los binarios recuperados e instalarlos. Install – Para seleccionar los paquetes indicados, resolver sus dependencias, recuperar los binarios del repositorio, desempcaquetarlos e instalarlos. Remove – Para seleccionar los paquetes enumerados, resolver las dependencias, y eliminarlos excepto los archivos de configuración. Purge – Para seleccionar los paquetes indicados, resolver las dependencias y eliminarlos, incluidos los archivos de instalación. 1.9. Soluciones a problemas básicos en la gestión de paquetes Para buscar soluciones a problemas en la gestión de paquetes, la guía de Debian dirige a la documentación específica de Debian o del paquete, resolverlos a través de la página del sistema de seguimiento de errores de Debian o de los informes de errores del paquete o a través de una búsqueda en Google.\n1.10. Cómo seleccionar paquetes Debian Para elegir un paquete, la guía de Debian recomienda priorizar los esenciales sobre los que no lo son, los del área main sobre los de contrib y non-free, los de prioridad rquerida sobre los importantes, estándar, opcionales y extra, los que cumplen dependencias de otros, los que presentan mayor número de votos e instalaciones, los que cuentan con actualizaciones regulares del desarrollador, los que no presentan errores críticos, graves ni leves en el sistema de seguimiento de errores de Debian, los que cuentan con mayor atención de los desarrolladores a los informes de errores, los que cuentan con mayor número de errores solucionados recientemente y los que tienen menor número de errores en funcionalidades que no son nuevas.\n1.11. Cómo hacer frente a los requisitos contradictorios En caso de que se desee instalar un paquete que no está disponible para la suite de Debian que se esté usando, la guía de referencia recomienda primero intentar instalar estos programas en un sistema sandbox, ejecutarlos en entornos chroot y construir versiones de esos binarios que sean compatibles con el sistema Debian. A pesar de estas recomendaciones, reconoce que otras técnicas más “brutales” como apt-pinning, también permiten instalar este tipo de paquetes no compatibles.\n2. Operaciones básicas en la gestión de paquetes 2.1. apt vs. apt-get / apt-cache vs. aptitude apt, apt-get / apt-cache y aptitude son las tres herramientas básicas para la gestión de paquetes en Debian. aptitude es muy amigable pero no es recomendable para actualizaciones del sistema entre distribuciones estables y puede recomendar la eliminación masiva de paquetes en las actualizaciones del sistema en pruebas o inestable.\napt-get y apt-cache son las herramientas más básicas de apt. Ofrecen únicamente interfaz por línea de órdenes, son la opción más adecuada para la actualización principal del sistema, tienen un motor robusto para la resolución de dependencias, necesitan menos recursos de hardware, usan expresiones regulares sobre el nombre y la descripción del paquete y permiten gestionar varias versiones del mismo paquete.\napt es un interfaz de alto nivel para la gestión de paquetes. También opera desde la línea de órdenes, tiene una barra de progreso cuando se instalan paquetes mediante apt install y borra, por defecto, los paquetes .deb descargados en la caché después de instalarlos con éxito.\nLa orden aptitude es más flexible, con un interfaz interactivo a pantalla completa por línea de órdenes, pensado para la gestión interactiva de paquetes diaria. Necesita más recursos de hardware pero tiene un sistema de búsqueda mejorado y permite gestionar múltiples versiones de paquetes de forma más sencilla que apt-get y apt-cache.\n2.2. Operaciones básicas de gestión de paquetes utilizando la línea de órdenes Las órdenes apt, apt-get / apt-cache y aptitude se pueden mezclar sin problema. Aunque aptitude es una herramienta más sofisticada, con un mejor motor de resolución de dependencias de paquetes, puede causar algunos errores. En este caso, usar apt o apt-get/ apt-caché puede solucionar el error.\n2.3. Uso interactivo de aptitude Con la orden sudo aptitude -u se puede iniciar aptitude en modo interactivo. Aptutiude ejecuta de manera automática las acciones pendientes. Estas son algunas de las operaciones básicas que se pueden realizar a través de las órdenes apt, apt-get / apt-cache y aptitude con sus correspondientes descripciones:\nSintaxis de apt Sintaxis de aptitude Sintaxis de apt-get/apt-cache Descripción apt update aptitude update apt-get update Actualiza la metainformación de los paquetes apt install foo aptitude install foo apt-get install foo Instala la versión candidata del paquete «foo» y sus dependecias apt upgrade aptitude safe-upgrade apt-get upgrade Actualiza los paquetes ya instalados a las nuevas versiones candidatas sin eliminar ningún paquete apt full-upgrade aptitude full-upgrade apt-get dist-upgrade Actualiza los paquetes ya instalados a las nuevas versiones candidatas y elimina los paquetes que necesite apt remove foo aptitude remove foo apt-get remove foo Elimina el paquete «foo» sin eliminar sus archivos de configuración apt autoremove N/A apt-get autoremove Elimina los paquetes autoinstalados que ya no son necesarios apt purge foo aptitude purge foo apt-get purge foo Elimina el paquete «foo» y sus archivos de configuración apt clean aptitude clean apt-get clean Limpia por completo el repositorio local de los archivos de paquetes descargados apt autoclean aptitude autoclean apt-get autoclean Limpia el repositorio local de los archivos de paquetes descargados que son obsoletos apt show foo aptitude show foo apt-cache show foo Muestra información detallada sobre el paquete «foo» apt search expresión_regular aptitude search expresión_regular apt-cache search expresión_regular Busca paquetes que concuerden con expresión_regular N/A aptitude why expresión_regular N/A Argumenta la razón por la que el paquete que concuerda con la expresión_regular debe ser instalado N/A aptitude why-not expresión_regular N/A Argumenta la razón por la que el paquete que concuerda con la expresión_regular no debe ser instalado N/A aptitude search '~i!~M' apt-mark showmanual Enumera los paquetes que se instalaron de forma manual 2.4. Combinaciones de teclado con aptitude La orden aptitude también permite examinar el estado de los paquetes a través del modo pantalla completa usando alguna de las combinaciones de teclado que se listan a continuación:\nTecla Función F10 o Ctrl-t Menú ? Muestra la ayuda de las combinaciones de teclas (una relación más completa) F10 → Ayuda → Manual de usuario Muestra el Manual de Usuario u Actualiza la información de archivo del paquete + Marca el paquete para ser actualizado o instalado - Marca el paquete para ser eliminado (mantiene los archivos de configuración) _ Marca el paquete para ser purgado (borra los archivos de configuración) = Marca el paquete para ser conservado (hold) U Marca todos los paquetes actualizables (sería el equivalente a una actualización completa) g Comienza la descarga y la instalación de los paquetes seleccionados q Sale de la pantalla actual y guarda los cambios x Sale de la pantalla actual sin guardar los cambios Intro Muestra la información de un paquete C Muestra el registro de cambios del paquete l Cambia el número de paquetes que se muestran / Busca la primera coincidencia \\ Repite la última búsqueda 2.5. Visualización de paquetes en aptitude En el modo interactivo de pantalla completa de aptitude, los paquetes se muestran siguiendo este formato:\nidA libsmbclient -2220kB 3.0.25a-1 3.0.25a-2 Bandera* Nombre del paquete Variación del espacio de disco usado Versión actual Versión candidata Info\nBandera: estado actual (primera letra), acción planeada (segunda letra), automática (tercera letra)\nLa guía enumera diferentes formas de mostrar los paquetes en aptitude: vista del paquete, por defecto; recomendaciones de auditoría, que muestra una relación de paquetes que se recomiendan por algún paquete marcado para la instalación pero sin instalar aún; relación plana, lista de paquetes sin clasificar para usar con expresiones regulares; navegador de etiquetas debtags, que muestra la relación de paquetes clasificados según las etiquetas Debian; y vista del paquete fuente, que agrupa los paquetes en función de su paquete fuente.\nDel modo por defecto, vista de paquetes, aclara que puede mostrar los paquetes actualizables, los paquetes nuevos, los instalados, los no instalados, los creados localmente que se hayan quedado obsoletos, los virtuales (relacionados con la misma función) y las tareas (paquetes con diferentes funciones que son necesarios para realizar una tarea).\n2.6. Opciones del método de búsqueda con aptitude La guía recoge las diferentes opciones con las que se pueden buscar paquetes usando aptitude, ya sea a través del intérprete de órdenes con los argumentos search o show después del comando aptitude, todo ello seguido de una expresión regular o el nombre del paquete respectivamente para conocer el estado de instalación, nombre del paquete y descripción corta o, bien, la descripción detallada del paquete; o bien a través del modo interactivo de pantalla completa usando las teclas 1 para limitar la vista de los paquetes a los coincidentes, / para buscar los paquetes, \\ para buscar hacia atrás, n para encontrar el siguiente resultado en la búsqueda o N para encontrar el resultado anterior.\n2.7. La fórmula de la expresión regular de aptitude La orden aptitude permite el uso de fórmulas de expresión regular. La guía de referencia de Debian incluye la siguiente relación de expresiones regulares que se pueden usar en aptitude.\nDescripción de las reglas extendidas de encaje Fórmula de la expresión regular Nombre del paquete que encaja ~n nombre_de_la_expresión_regular Encaja en la descripción ~d descripcion_de_la_expresión_regular Nombre de la tarea que encaja ~t expresión_regular_de_tareas Encaja con las etiquetas debian ~G expresion_regular_de_etiquetas Encaja con el desarrollador ~m expresión_regular_del_desarrollador Encaja con la sección del paquete ~s expresión_regular_de_sección Encaja con la versión del paquete ~V expresión_regular_de_la_versión Encaja con la distribución ~A {bookworm,trixie,sid} Encaja con el origen ~O {debian,…} Encaja con la prioridad ~p {extra,important,optional,required,standard} Encaja con los paquetes esenciales ~E Encaja con paquetes virtuales ~v Encaja con nuevos paquetes ~N Encaja con acciones pendientes ~a {install,upgrade,downgrade,remove,purge,hold,keep} Encaja con paquetes instalados ~i Encaja con paquetes marcados con A-mark (paquetes auto-instalados) ~M Encaja con paquetes instalados sin la marca A (paquetes seleccionados por el administrador) ~i!~M Encaja con paquetes instalados y que se pueden actualizar ~U Encaja con paquetes eliminados pero no purgados ~c Encaja con paquete eliminados y purgados o que se pueden eliminar ~g Encaja con paquetes que declaran una dependencia rota ~b Encaja con paquetes que declaran una dependencia rota de un tipo ~B type Encaja el patrón sobre paquetes que tienen una dependencia tipo ~D [tipo:]patrón Encaja el patrón con paquetes que tienen una dependencia rota de tipo ~DB [tipo:]patrón Encaja con paquetes en los cuales el patrón encaja con paquetes que declaran una dependencia tipo ~R [tipo:]patrón Coinciden con paquetes a los que el paquete coincidente patrón declara dependencia rota tipo ~RB [tipo:]patrón Encaja con los paquetes con los que los paquetes instalados tienen dependencias ~R~i Encaja con los paquetes que no dependen de ningún paquete instalado !~R~i Encaja con los paquete que dependen o son recomendados por otros paquetes instalados ~R~i | ~Rrecommends:~i Encaja con los paquetes según el patrón filtrados por la versión ~S filtro patrón Encaja con todos los paquetes (verdad) ~T No Encaja con ningún paquete (falso) ~F 2.8. Resolución de dependencias en aptitude La guía de referencia indica que aptitude se puede configurar de manera que la selección de un paquete no solo marque a todos los definidos en su relación de dependencias, sino también a los incluidos entre sus recomendados. Si estos paquetes no van a ser necesarios en el futuro, aptitude los elimina de forma automática.\n2.9. Registro de la actividad de los paquetes La actividad de gestión de paquetes queda registrada en el sistema. La guía de referencia de Debian avisa de que no es fácil conseguir una comprensión rápida de estos archivos de registro. Hay tres registros importantes: /var/log/dpkg.log, que registra la actividad de dpkg para las acciones sobre paquetes; /var/log/apt/term.log, que registra las acciones genéricas de APT; y /var/log/aptitude, que registra las acciones de la orden aptitude.\n"}]
